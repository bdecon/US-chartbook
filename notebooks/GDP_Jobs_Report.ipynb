{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining GDP data with the jobs report\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "Updated: September 20, 2020\n",
    "\n",
    "----\n",
    "\n",
    "Notes:\n",
    "\n",
    "The basic idea here is to use the BEA population estimates plus CPS employment rate and hours worked trends to estimate GDP per hour of work. BLS does this process for its productivity and costs report, using much more comprehensive data, however this approximation has proven decent over time.\n",
    "\n",
    "The biggest challenge is correctly estimating the average hours worked. All of the published measures are either too-low-frequency or don't have a broad enough definition of workers. I want to capture all workers, regardless of full-time or part-time status or of whether they work for the private sector. Also want to capture second and third jobs. As a result, I selected total actual hours worked from the CPS microdata, specifically finding the trend using x13as with default settings. Hours worked from the CPS microdata have issues around holidays falling in the reference week, and also do not capture hours worked for some important categories of labor such as self-employed persons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:52:21.722364Z",
     "start_time": "2024-07-25T13:52:20.713320Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *\n",
    "\n",
    "qtrs = {1: 1, 2: 1, 3: 1, 4: 2, 5:2, 6:2, 7:3, 8:3, 9:3, 10:4, 11:4, 12:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:52:25.293809Z",
     "start_time": "2024-07-25T13:52:21.724070Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPS-based estimated employment rate and average actual hours\n",
    "avghrs = lambda x: np.average(x.HRSACTT.replace(-1, 0), weights=x.WGT)\n",
    "aah, epop = {}, {}\n",
    "cols = ['HRSACTT', 'LFS', 'MONTH', 'AGE']\n",
    "for year in range(1989, 2025):\n",
    "    wgt = 'PWSSWGT' if year >= 1998 else 'BASICWGT'\n",
    "    df = pd.read_feather(cps_dir / f'cps{year}.ft', \n",
    "                         columns=cols + [wgt]).rename({wgt: 'WGT'}, axis=1)\n",
    "    emp = df.query('LFS == \"Employed\" and AGE >= 15')\n",
    "    ah = (emp.groupby('MONTH').apply(avghrs))\n",
    "    aah.update({pd.to_datetime(f'{year}-{month}-01'): value \n",
    "                for month, value in list(zip(ah.index, ah.values))})\n",
    "    ep = (emp.groupby('MONTH').WGT.sum() / df.groupby('MONTH').WGT.sum()) * 100\n",
    "    epop.update({pd.to_datetime(f'{year}-{month}-01'): value \n",
    "                 for month, value in list(zip(ep.index, ep.values))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:52:28.266223Z",
     "start_time": "2024-07-25T13:52:25.295184Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:203: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in the estimated spectrum of the regARIMA residuals.\n",
      "  \n",
      " WARNING: At least one visually significant trading day peak has been\n",
      "          found in one or more of the estimated spectra.\n",
      "  warn(errors, X13Warning)\n",
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:203: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in the estimated spectrum of the regARIMA residuals.\n",
      "  \n",
      " WARNING: At least one visually significant trading day peak has been\n",
      "          found in one or more of the estimated spectra.\n",
      "  warn(errors, X13Warning)\n"
     ]
    }
   ],
   "source": [
    "# Seasonally-adjust monthly data and save\n",
    "res = pd.DataFrame({'EPOP': epop, 'AAH': aah})\n",
    "pop = (pd.read_csv(data_dir/'nipa20600.csv', index_col='date', \n",
    "                  parse_dates=True))\n",
    "res['POP'] = pop['B230RC'] / 1000\n",
    "\n",
    "res['EPOP_sa'] = x13_arima_analysis(res['EPOP']).seasadj\n",
    "res['AAH_trend'] = x13_arima_analysis(res['AAH']).trend\n",
    "res['AAH_sa'] = x13_arima_analysis(res['AAH']).seasadj\n",
    "\n",
    "# Fill future population data from Census\n",
    "popm = (pd.read_csv(data_dir/'pop_est_bea.csv', index_col='date', \n",
    "                    parse_dates=True).divide(1000).round(-1).divide(1000))\n",
    "pop = pd.concat([res['POP'].dropna(), popm['POP']])\n",
    "pop = pop[~pop.index.duplicated(keep='last')]\n",
    "res = pd.concat([res.drop('POP', axis=1), pop], axis=1)\n",
    "\n",
    "# Handle cases where no population estimate is available for December, yet\n",
    "if f'{res.index[-1].year}-12-01' not in res.index:\n",
    "    poplt = ((res.POP.dropna().pct_change().iloc[-1] + 1) \n",
    "             * res.loc[f'{res.index[-1].year}-11-01', 'POP'])\n",
    "    res.loc[f'{res.index[-1].year}-12-01', 'POP'] = poplt\n",
    "\n",
    "# Estimate total hours\n",
    "res['EMP_sa'] = ((res['EPOP_sa'] / 100) * res['POP']) / 1_000\n",
    "res['TOT_HRS'] = (res['EMP_sa'] * res['AAH_trend'] * 52)\n",
    "\n",
    "res.to_csv(data_dir / 'gdpjobslvl_mo.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:52:28.291881Z",
     "start_time": "2024-07-25T13:52:28.268481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First, the US \\textbf{population} \\index{population} is nearly 337 million, as of April 2024 (see {\\color{lime!90!green}\\textbf{---}}), an increase of 90 million since 1989. Since 1989, the population has grown at an average annual rate of 0.9 percent; the current rate is around 0.5 percent. \n",
      "\n",
      "The current rate is 1.1 percentage points above the 30-year average. \n",
      "\n",
      "In April 2024, the average workweek is 36.9 hours. \n",
      "\n",
      "Since 1989, total hours worked have increased at an average annualized rate of 1.3 percent. Since the pre-pandemic peak in October 2019, hours worked have decreased by a total of 0.9 percent. \n"
     ]
    }
   ],
   "source": [
    "res = pd.read_csv(data_dir / 'gdpjobslvl_mo.csv', index_col='date', \n",
    "                  parse_dates=True).dropna()\n",
    "ltpop = value_text(res['POP'].iloc[-1], style='plain', \n",
    "                   ptype='million', digits=0, round_adj=True)\n",
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "chval = res.dropna()['POP'].iloc[-1] - res['POP'].iloc[0]\n",
    "\n",
    "chtxt = value_text(chval, style='plain', casual=True,\n",
    "                   ptype='million', digits=0, round_adj=True)\n",
    "\n",
    "# Population Growth rates\n",
    "popgr = growth_rate_monthly(res['POP'])\n",
    "ltpopgr = value_text(popgr.iloc[-1], style='plain')\n",
    "prpopgr = value_text(popgr.mean(), style='plain')\n",
    "\n",
    "# Population text\n",
    "cl = c_line('lime!90!green')\n",
    "text = (f'First, the US \\\\textbf{{population}} \\index{{population}} '+\n",
    "        f'is {ltpop}, as of {ltdt} {cl}, '+\n",
    "        f'an increase of {chtxt} since 1989. Since 1989, the '+\n",
    "        f'population has grown at an average annual rate of {prpopgr}; '+\n",
    "        f'the current rate is around {ltpopgr}.')\n",
    "write_txt(text_dir / 'gdpjobspop.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "# Epop text \n",
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "ltval = value_text(res['EPOP_sa'].iloc[-1], style='plain')\n",
    "mndiff = res['EPOP_sa'].mean() - res['EPOP_sa'].iloc[-1]\n",
    "difftxt = value_text(-mndiff, style='above_below', ptype='pp')\n",
    "\n",
    "text = (f'The current rate is {difftxt} '+\n",
    "        'the 30-year average.')\n",
    "write_txt(text_dir / 'gdpjobsepop.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "# Average workweek text\n",
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "lthrs = res['AAH_trend'].iloc[-1].round(1)\n",
    "\n",
    "text = (f'In {ltdt}, the average workweek is {lthrs} hours.')\n",
    "write_txt(text_dir / 'gdpjobsaah.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "# End nodes\n",
    "colors = {'EPOP_sa': 'green!30!teal!90!black', 'AAH_trend': 'blue', \n",
    "          'POP': 'lime!90!green', 'TOT_HRS': 'orange'}\n",
    "for name, color in colors.items():\n",
    "    adj = node_adj(res[name].to_frame())[name]\n",
    "    node = end_node(res[name], color, digits=1, offset=adj,\n",
    "                    date='m', full_year=True)\n",
    "    write_txt(text_dir / f'gdpjobnode_{name}.txt', node)\n",
    "\n",
    "# Total hours worked text\n",
    "pcdt = res['TOT_HRS'].loc['2019':'2020'].idxmax()\n",
    "pcdtxt = dtxt(pcdt)['mon1']\n",
    "ch89txt = value_text(growth_rate_monthly(res['TOT_HRS']).mean(), \n",
    "                     adj='avg_ann')\n",
    "chpc = ((res['TOT_HRS'].iloc[-1] / \n",
    "         res.loc[pcdt, 'TOT_HRS'].mean()) - 1) * 100\n",
    "chpctxt = value_text(chpc, adj='total')\n",
    "\n",
    "text = (f'Since 1989, total hours worked have {ch89txt}. '+\n",
    "        f'Since the pre-pandemic peak in {pcdtxt}, hours '+\n",
    "        f'worked have {chpctxt}. ')\n",
    "write_txt(text_dir / 'gdpjobstothrs.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:44:40.990085Z",
     "start_time": "2023-05-30T00:44:40.987999Z"
    }
   },
   "source": [
    "### Labor Productivity\n",
    "\n",
    "See technical note about sectors excluded by nonfarm business productivity: https://www.bls.gov/news.release/prod2.tn.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:52:28.890816Z",
     "start_time": "2024-07-25T13:52:28.293377Z"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv(data_dir / 'gdpjobslvl_mo.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "\n",
    "data = res.resample('QS').mean()\n",
    "cd = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC'].iloc[-1]\n",
    "rgdp = nipa_df(retrieve_table('T10106')['Data'], ['A191RX'])\n",
    "gdp = rgdp / rgdp.iloc[-1] * cd\n",
    "data['GDP'] = gdp['A191RX']\n",
    "data['LPROD'] = data['GDP'] / data['TOT_HRS']\n",
    "\n",
    "# Official estimate for nonfarm businesses from BLS\n",
    "data['LPROD_BLS'] = fred_df2('OPHNFB', start='1988')\n",
    "data['HRS_BLS'] = fred_df2('HOANBS', start='1988')\n",
    "\n",
    "# Convert to indices\n",
    "for i in ['LPROD', 'LPROD_BLS','LPROD','TOT_HRS', 'GDP', \n",
    "          'POP', 'EPOP_sa', 'AAH_trend']:\n",
    "    data[f'{i}_idx'] = (data[i] / data.loc['2000-01-01', i]) * 100\n",
    "    \n",
    "data.to_csv(data_dir / 'gdpjobslvl.csv', index_label='date')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:52:28.910981Z",
     "start_time": "2024-07-25T13:52:28.892234Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labor productivity has increased substantially over the long term. From 1989 to 1999, labor productivity for the total economy increased 17.2 percent. From 1999 to 2009, labor productivity increased 18.9 percent, and from 2009 to 2019, labor productivity increased 11.0 percent.\n",
      "\n",
      "From 1989 to 2019, total economy productivity growth averaged 1.5 percent per year; GDP growth averaged 2.5 percent per year and work hours increased one percent per year. Since 2019, total economy labor productivity growth averages 2.2 percent per year, with average GDP growth of two percent and an average decrease of 0.2 percent in work hours.\n"
     ]
    }
   ],
   "source": [
    "# Store calculations for key series and date ranges\n",
    "srs = ['LPROD', 'GDP', 'TOT_HRS']\n",
    "\n",
    "ltdt = data.dropna().index[-1]\n",
    "dts = [('1989-01-01', '1999-01-01'),\n",
    "       ('1999-01-01', '2009-01-01'),\n",
    "       ('2009-01-01', '2019-01-01'),\n",
    "       ('1989-01-01', '2019-10-01'), \n",
    "       ('2019-10-01', ltdt)]\n",
    "\n",
    "d = {}\n",
    "for sr, (dt1, dt2) in itertools.product(srs, dts):\n",
    "    t1 = dt1[2:4]\n",
    "    t2 = dt2[2:4] if isinstance(dt2, str) else 'LT'\n",
    "    n = f'{sr}{t1}{t2}'\n",
    "    s = data.loc[dt1:dt2, sr]\n",
    "    r = cagr(s)\n",
    "    d[f'cagr_{n}'] = r\n",
    "    d[n] = ((s.iloc[-1] / s.iloc[0]) - 1) * 100\n",
    "    \n",
    "ch8999 = value_text(d['LPROD8999'])\n",
    "ch9909 = value_text(d['LPROD9909'])\n",
    "ch0919 = value_text(d['LPROD0919'])\n",
    "\n",
    "ltgr = value_text(d['cagr_LPROD8919'], style='plain')\n",
    "ltgdpgr = value_text(d['cagr_GDP8919'], style='plain')\n",
    "lthrsgr = value_text(d['cagr_TOT_HRS8919'])\n",
    "rgr = value_text(d['cagr_LPROD19LT'], style='plain')\n",
    "rgdpgr = value_text(d['cagr_GDP19LT'], style='plain')\n",
    "rhrsgr = value_text(d['cagr_TOT_HRS19LT'], style='increase_of', \n",
    "                    adj='average', threshold=0.1)\n",
    "\n",
    "text = ('Labor productivity has increased substantially over the '+\n",
    "        'long term. From 1989 to 1999, labor productivity for the '+\n",
    "        f'total economy {ch8999}. From 1999 to 2009, labor '+\n",
    "        f'productivity {ch9909}, and from 2009 to 2019, labor '+\n",
    "        f'productivity {ch0919}.\\n\\nFrom 1989 to 2019, total '+\n",
    "        f'economy productivity growth averaged {ltgr} per year; '+\n",
    "        f'GDP growth averaged {ltgdpgr} per year and work hours '+\n",
    "        f'{lthrsgr} per year. Since 2019, total economy labor '+\n",
    "        f'productivity growth averages {rgr} per year, with average '+\n",
    "        f'GDP growth of {rgdpgr} and {rhrsgr} in work hours.')\n",
    "write_txt(text_dir / 'gdpjobs_lprod.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributions to growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:52:28.931765Z",
     "start_time": "2024-07-25T13:52:28.913024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2024 Q2, population growth contributed 0.46 percentage point to annualized GDP growth, and, for comparison, added 0.58 percentage point in 2019 Q4. Changes in the employed share of the population contributed 0.96 percentage point in the latest quarter, and added 1.62 percentage points in the fourth quarter of 2019. Changes in average hours worked subtracted 0.13 percentage point from GDP growth in the latest quarter and added 0.36 percentage point in 2019 Q4. Lastly, productivity contributed 1.53 percentage points to GDP growth in 2024 Q2, compared to virtually no addition in 2019 Q4.\n"
     ]
    }
   ],
   "source": [
    "# Quarterly contribution to growth\n",
    "srs = {'EPOP_sa': 'epop_contr', 'POP': 'pop_contr', \n",
    "       'AAH_trend': 'hours_contr', 'lprod': 'prod', \n",
    "       'GDP': 'gdp'}\n",
    "df = data.copy()[['GDP', 'POP', 'EPOP_sa', 'AAH_trend']].dropna()\n",
    "df['hh_inp'] = df['POP'] * df['EPOP_sa'] * df['AAH_trend']\n",
    "df['lprod'] = df['GDP'] / df['hh_inp']\n",
    "c = ((((df.pct_change() + 1) ** 4) - 1) * 100).rename(srs, axis=1).dropna()\n",
    "c.to_csv(data_dir / 'gdpjobs.csv', index_label='date')\n",
    "\n",
    "# Annual GDP Growth Contribution\n",
    "dfa = (c.groupby(c.index.year).filter(lambda x: len(x) == 4)\n",
    "            .resample('AS').mean())\n",
    "dfa.to_csv(data_dir / 'gdpjobsa.csv', index_label='date')\n",
    "\n",
    "# Text\n",
    "prdt = '2019-10-01'\n",
    "prdate = dtxt(pd.to_datetime(prdt))['qtr1']\n",
    "prdate2 = dtxt(pd.to_datetime(prdt))['qtr2']\n",
    "datetxt = dtxt(c.index[-1])['qtr1']\n",
    "lt = c.iloc[-1]\n",
    "pr = c.loc[prdt]\n",
    "\n",
    "# Change default settings\n",
    "def vt(value, style='contribution', casual=False):\n",
    "    return value_text(value, style=style, ptype='pp', \n",
    "                      digits=2, casual=casual, threshold=0.02)\n",
    "\n",
    "poplt = vt(lt['pop_contr'], style='contribution_to')\n",
    "poppr = vt(pr['pop_contr'], casual=True)\n",
    "emplt = vt(lt['epop_contr'])\n",
    "emppr = vt(pr['epop_contr'], casual=True)\n",
    "hrslt = vt(lt['hours_contr'], style='contribution_to', casual=True)\n",
    "hrspr = vt(pr['hours_contr'], casual=True)\n",
    "prodlt = vt(lt['prod'], style='contribution_to')\n",
    "prodpr = vt(pr['prod'], style='contribution_of', casual=True)\n",
    "\n",
    "text = (f'In {datetxt}, population growth {poplt} annualized GDP growth, '+\n",
    "        f'and, for comparison, {poppr} in {prdate}. Changes in the '+\n",
    "        f'employed share of the population {emplt} in the latest quarter, '+\n",
    "        f'and {emppr} in {prdate2}. Changes in average '+\n",
    "        f'hours worked {hrslt} GDP growth in the latest quarter and {hrspr} '+\n",
    "        f'in {prdate}. Lastly, productivity {prodlt} GDP growth in {datetxt}, '+\n",
    "        f'compared to {prodpr} in {prdate}.')\n",
    "write_txt(text_dir / 'gdpjobsch.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T13:52:28.951495Z",
     "start_time": "2024-07-25T13:52:28.933296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the latest full year of data, covering 2023, growth is relatively broad-based. The main contribution is an increase in labor productivity and employment. Labor productivity added 2.3 percentage points, the higher employment rate added 0.7 point, and hours worked subtracted 0.3 point from overall growth. \n"
     ]
    }
   ],
   "source": [
    "# Summary of latest year text\n",
    "sl = {'pop_contr': 'population', 'epop_contr': 'employment', \n",
    "      'hours_contr': 'hours worked', 'prod': 'labor productivity'}\n",
    "ltyval = dfa[sl.keys()].iloc[-1].rename(sl)\n",
    "gctext, _ = gc_desc(ltyval, 2, 5)\n",
    "st = 'is the result of'\n",
    "if gctext.count(st) > 1:\n",
    "    gctext = gctext.split(st)[0] + st + gctext.split(st)[2]\n",
    "    \n",
    "epopnm = ('the higher employment rate' if dfa.epop_contr.iloc[-1] > 0.4 \n",
    "          else 'the lower employment rate' if dfa.epop_contr.iloc[-1] < -0.4\n",
    "          else 'the employment rate')\n",
    "hoursnm = ('longer average workweeks' if dfa.hours_contr.iloc[-1] > 0.4 \n",
    "          else 'the drop in hours worked' if dfa.hours_contr.iloc[-1] < -0.4\n",
    "          else 'hours worked')\n",
    "rn = {'employment': epopnm,\n",
    "      'population': 'population growth',\n",
    "      'hours worked': hoursnm}\n",
    "ltyval = ltyval.rename(rn).sort_values()\n",
    "ltyr = dfa.index[-1].year\n",
    "cat1 = ltyval.index[-1].capitalize()\n",
    "cv1 = value_text(ltyval.iloc[-1], 'contribution', casual=True, ptype='pp')\n",
    "cat2 = ltyval.index[-2]\n",
    "cv2 = value_text(ltyval.iloc[-2], 'contribution', casual=True, ptype='point')\n",
    "cat3 = ltyval.index[0]\n",
    "cv3 = value_text(ltyval.iloc[0], 'contribution_to', casual=True, ptype='point')\n",
    "\n",
    "text = (f'In the latest full year of data, covering {ltyr}, {gctext} '+\n",
    "        f'{cat1} {cv1}, {cat2} {cv2}, and {cat3} {cv3} overall growth. ')\n",
    "write_txt(text_dir / 'gdpjobsch_ann.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
