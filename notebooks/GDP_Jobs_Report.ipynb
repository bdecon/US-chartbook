{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining GDP data with the jobs report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T22:45:54.952624Z",
     "start_time": "2019-08-28T22:45:54.460497Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *\n",
    "\n",
    "qtrs = {1: 1, 2: 1, 3: 1, 4: 2, 5:2, 6:2, 7:3, 8:3, 9:3, 10:4, 11:4, 12:4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T16:01:13.529392Z",
     "start_time": "2019-08-27T16:01:07.688129Z"
    }
   },
   "outputs": [],
   "source": [
    "aah = {}\n",
    "epop = {}\n",
    "cols = ['HRSACTT', 'LFS', 'BASICWGT', 'MONTH', 'PWSSWGT']\n",
    "for year in range(1989, 2020):\n",
    "    if year >= 1998:\n",
    "        wgt = 'PWSSWGT'\n",
    "    else:\n",
    "        wgt = 'BASICWGT'\n",
    "    df = pd.read_feather(cps_dir / f'cps{year}.ft', columns=cols)\n",
    "    ah = (df.query('LFS == \"Employed\"')\n",
    "            .groupby('MONTH').apply(lambda x: np.average(x.HRSACTT, weights=x.BASICWGT)))\n",
    "    aah.update({f'{year}-{month}-01': value for month, value in list(zip(ah.index, ah.values))})\n",
    "    \n",
    "    ep = (df.query('LFS == \"Employed\"').groupby('MONTH')[wgt].sum() / \n",
    "          df.groupby('MONTH')[wgt].sum())\n",
    "    epop.update({f'{year}-{month}-01': value for month, value in list(zip(ep.index, ep.values))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-27T16:19:35.123315Z",
     "start_time": "2019-08-27T16:19:35.115300Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(epop).to_csv('epop.csv', index_label='date', header=True)\n",
    "pd.Series(aah).to_csv('aah.csv', index_label='date', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can't seem to get X-13ARIMA-SEATS running on linux so I've used a virtual machine to convert epop.csv and aah.csv to epop_sa.csv and aah.csv using x13as with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T22:45:58.328832Z",
     "start_time": "2019-08-28T22:45:58.283940Z"
    }
   },
   "outputs": [],
   "source": [
    "epop_sa = (pd.read_csv('raw/epop_sa.csv', header=None, names=['date', 'value'], parse_dates=[0])\n",
    "           .set_index('date').resample('QS').mean())\n",
    "\n",
    "aah_sa = (pd.read_csv('raw/aah_sa.csv', header=None, names=['date', 'value'], parse_dates=[0])\n",
    "           .set_index('date').resample('QS').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T22:45:59.438610Z",
     "start_time": "2019-08-28T22:45:59.363223Z"
    }
   },
   "outputs": [],
   "source": [
    "gdp_code = ('T10106', ['A191RX'])\n",
    "pop_code = ('T70100', ['B230RC'])\n",
    "gdp = nipa_df(retrieve_table(gdp_code[0])['Data'], gdp_code[1]).sort_index()\n",
    "pop = nipa_df(retrieve_table(pop_code[0])['Data'], pop_code[1]).sort_index()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['epop'] = epop_sa['value']\n",
    "df['pop'] = pop['B230RC']\n",
    "df['hours'] = aah_sa['value'] * 52\n",
    "df['gdp'] = gdp['A191RX']\n",
    "df['input'] = (df['pop'] * df['epop']) * df['hours']\n",
    "df['gdpinp'] = df['gdp'] / df['input']\n",
    "\n",
    "\n",
    "df['epop_c'] = ((df['pop'] * df['epop'].mean()) * df['hours']) * df['gdpinp']\n",
    "df['pop_c'] = ((df['pop'].mean() * df['epop']) * df['hours']) * df['gdpinp']\n",
    "df['hours_c'] = ((df['pop'] * df['epop']) * df['hours'].mean()) * df['gdpinp']\n",
    "\n",
    "df_g = growth_rate(df)\n",
    "\n",
    "df_g['pop_contr'] = df_g['gdp'] - df_g['pop_c']\n",
    "df_g['epop_contr'] = df_g['gdp'] - df_g['epop_c']\n",
    "df_g['hours_contr'] = df_g['gdp'] - df_g['hours_c']\n",
    "df_g['prod'] = df_g['gdp'] - df_g['pop_contr'] - df_g['epop_contr'] - df_g['hours_contr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T22:46:00.420036Z",
     "start_time": "2019-08-28T22:46:00.414068Z"
    }
   },
   "outputs": [],
   "source": [
    "result = df_g[['pop_contr', 'epop_contr', 'hours_contr', 'prod']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-28T22:46:01.480370Z",
     "start_time": "2019-08-28T22:46:01.460340Z"
    }
   },
   "outputs": [],
   "source": [
    "result.to_csv(data_dir / 'gdpjobs.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
