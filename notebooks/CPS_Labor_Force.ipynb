{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Statistics from CPS Microdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wquantiles\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *\n",
    "\n",
    "dt = cps_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview data and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_wt = {y: 'PWSSWGT' if y > 1993 else 'BASICWGT' for y in range(1989, 2021)}\n",
    "\n",
    "cols = ['LFS', 'AGE', 'MONTH', 'YEAR', 'FEMALE']\n",
    "\n",
    "df = pd.concat([(pd.read_feather(cps_dir / f'cps{y}.ft', columns=cols + [w])\n",
    "                   .rename({w: 'WGT'}, axis=1)) \n",
    "                for y, w in yr_wt.items()], sort=False)\n",
    "df['DATE'] = pd.to_datetime(dict(year=df.YEAR, month=df.MONTH, day=1))\n",
    "data = df.groupby(['DATE', 'LFS']).WGT.sum().unstack().rename({'nan': 'Children'}, axis=1) / 1000000\n",
    "data.to_csv(data_dir/ 'cps_lfs.csv', index_label='date')\n",
    "\n",
    "datelt = data.index[-1].strftime('%B %Y')\n",
    "dateyr = data.index[-13].strftime('%B %Y')\n",
    "datepr = f\"{data.index[-13].strftime('%B %Y')} to {datelt}\"\n",
    "\n",
    "write_txt(text_dir / 'cps_lfs_date.txt', datelt)\n",
    "write_txt(text_dir / 'cps_lfs_dateyr.txt', dateyr)\n",
    "write_txt(text_dir / 'cps_lfs_datepr.txt', datepr)\n",
    "\n",
    "epop = data[\"Employed\"].iloc[-1] / data.iloc[-1].sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'As of {datelt}, {data[\"Employed\"].iloc[-1]:.1f} million '+\n",
    "        'people are employed (including self-employment). ')\n",
    "\n",
    "write_txt(text_dir / 'cps_lfs0.txt', text)\n",
    "\n",
    "text = ('Labor provided within a household is not captured by GDP compilation '+\n",
    "        'methods (expenditures, output, or income), though household surveys '+\n",
    "        'offer some insight into this important category of labor. The '+\n",
    "        'number of people who are considered employed divided by the total '+\n",
    "        'population is the employment rate or employment-to-population ratio, '+\n",
    "        f'which is {epop:.1f} percent as of {datelt}.')\n",
    "\n",
    "write_txt(text_dir / 'cps_lfs.txt', text)\n",
    "\n",
    "unemp = (data[\"Unemployed\"].iloc[-1] / (data[\"Unemployed\"].iloc[-1] + data[\"Employed\"].iloc[-1])) * 100\n",
    "lfpr = (data[\"Unemployed\"].iloc[-1] + data[\"Employed\"].iloc[-1]) / data.iloc[-1].sum() * 100\n",
    "\n",
    "text = (f'As of {datelt}, there are {data[\"Unemployed\"].iloc[-1]:.1f} million '+\n",
    "        'unemployed people. The combined group of employed and unemployed people '+\n",
    "        'is the labor force. The number of unemployed people divided by the number '+\n",
    "        f'of people in the labor force is the unemployment rate, currently {unemp:.1f} percent. '+\n",
    "        'The number of people in the labor force divided by the total population is the '+\n",
    "        f'labor force participation rate, currently {lfpr:.1f} percent.')\n",
    "\n",
    "write_txt(text_dir / 'cps_lfs2.txt', text)\n",
    "    \n",
    "cols2 = cols + ['NILFREASON', 'PWSSWGT']\n",
    "\n",
    "datalt = cps_1mo(cps_dir, cps_date(), cols2)\n",
    "\n",
    "student = (datalt.query('NILFREASON == \"School\"').PWSSWGT.sum() / 1000000)\n",
    "care = (datalt.query('NILFREASON == \"Family\"').PWSSWGT.sum() / 1000000)\n",
    "disill = (datalt.query('NILFREASON == \"Disabled/Ill\"').PWSSWGT.sum() / 1000000)\n",
    "disc = (datalt.query('NILFREASON == \"Discouraged\"').PWSSWGT.sum() / 1000000)\n",
    "ret = (datalt.query('NILFREASON == \"Retired\"').PWSSWGT.sum() / 1000000)\n",
    "\n",
    "nilfpop = data[['NILF', 'Children']].iloc[-1].sum()\n",
    "text = ('Non-participants usually comprise about half of the population, and '+\n",
    "        f'total {nilfpop:.1f} million in {datelt}. The category includes '+\n",
    "        f'children ({data[\"Children\"].iloc[-1]:.1f} million), students '+\n",
    "        f'({student:.1f} million), unpaid caregivers ({care:.1f} million), those '+\n",
    "        f'unable to work due to disability or illness ({disill:.1f} million), '+\n",
    "        f'those who want a job but have given up looking ({disc:.1f} '+\n",
    "        f'million), and retirees and the elderly ({ret:.1f} million).')\n",
    "\n",
    "write_txt(text_dir / 'cps_lfs3.txt', text)\n",
    "    \n",
    "data['Total'] = data[['Employed', 'Unemployed', 'NILF']].sum(axis=1)\n",
    "result = data.drop('Children', axis=1).resample('QS').mean()\n",
    "\n",
    "growth_contrib_ann(result, 'Total').to_csv(data_dir / 'cps_lfs2.csv', index_label='date')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['LFS', 'PWSSWGT', 'AGE', 'MONTH', 'YEAR', 'MJH',\n",
    "        'FEMALE', 'NILFREASON', 'UNEMPTYPE', 'PTECON', 'WORKFT']\n",
    "\n",
    "df = cps_1mo(cps_dir, cps_date(), cols).query('AGE >= 15')\n",
    "df2 = cps_1mo(cps_dir, cps_date() - pd.DateOffset(years=1), cols).query('AGE >= 15')\n",
    "\n",
    "age_groups = [(15, 30), (30, 60), (60, 86)]\n",
    "sex = [0, 1]\n",
    "d = {'Population': {'query': 'PWSSWGT > 0'}, \n",
    "     '\\hspace{2mm}Employed': {'query': 'LFS == \"Employed\"'}, \n",
    "     '\\hspace{4mm}Multiple jobs': {'query': 'MJH == 1'},     \n",
    "     '\\hspace{4mm}Full-time': {'query': 'WORKFT == 1'},  \n",
    "     '\\hspace{4mm}Part-time': {'query': 'WORKFT == 0'}, \n",
    "     '\\hspace{6mm}Economic reasons': {'query': 'PTECON == 1'},\n",
    "     '\\hspace{2mm}Unemployed': {'query': 'LFS == \"Unemployed\"'}, \n",
    "     '\\hspace{2mm}Not in Labor Force': {'query': 'LFS == \"NILF\"'}, \n",
    "     '\\hspace{4mm}Discouraged': {'query': 'NILFREASON == \"Discouraged\"'}, \n",
    "     '\\hspace{4mm}Disabled/Ill': {'query': 'NILFREASON == \"Disabled/Ill\"'}, \n",
    "     '\\hspace{4mm}Family/Care': {'query': 'NILFREASON == \"Family\"'}, \n",
    "     '\\hspace{4mm}School': {'query': 'NILFREASON == \"School\"'}, \n",
    "     '\\hspace{4mm}Retirement': {'query': 'NILFREASON == \"Retired\"'}}\n",
    "\n",
    "d2 = {k: {} for k, v in d.items()}\n",
    "\n",
    "lf_groups = list(zip(d.keys(), [d[i]['query'] for i in d.keys()])) \n",
    "\n",
    "for name, query in lf_groups:\n",
    "    totval = df.query(query).PWSSWGT.sum()/1000\n",
    "    d[name]['Total, 15+'] = f'{totval:,.0f}'\n",
    "    chval = totval - df2.query(query).PWSSWGT.sum()/1000\n",
    "    d2[name]['Total, 15+'] = f'{chval:,.0f}'\n",
    "\n",
    "for sex, (agemin, agemax) in itertools.product(sex, age_groups):\n",
    "    data = df.query('@agemin <= AGE < @agemax and FEMALE == @sex')\n",
    "    data2 = df2.query('@agemin <= AGE < @agemax and FEMALE == @sex')\n",
    "    group = f'{[\"Women\" if sex==1 else \"Men\"][0]}, {agemin}--{agemax-1}'.replace('--85', '+')\n",
    "    for name, query in lf_groups:\n",
    "        tmp = data.query(query).PWSSWGT.sum()/1000\n",
    "        tmp2 = data2.query(query).PWSSWGT.sum()/1000\n",
    "        d[name][group] = f'{tmp:,.0f}'\n",
    "        d2[name][group] = f'{tmp - tmp2:,.0f}'\n",
    "        \n",
    "(pd.DataFrame(d).T.drop('query', axis=1).to_csv(data_dir / 'lfs_table1.tex', \n",
    "    sep='&', line_terminator='\\\\\\ ', quotechar=' '))\n",
    "pd.DataFrame(d2).T.to_csv(data_dir / 'lfs_table2.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rates by age, gender, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['MONTH', 'YEAR', 'LFS', 'PWSSWGT', 'AGE', 'EDUC', 'FEMALE']\n",
    "#df1 = pd.read_feather(cps_dir / 'cps2000.ft', columns=cols).query('PWSSWGT > 0')\n",
    "df1 = cps_12mo(cps_dir, cps_date() - pd.DateOffset(months=12), cols)\n",
    "df2 = cps_12mo(cps_dir, cps_date(), cols)\n",
    "\n",
    "ages = [(16, 24), (25, 34), (35, 44), (45, 54), (55, 64), (65, 74)]\n",
    "educ = [['LTHS', 'HS'], ['SC'], ['COLL', 'ADV'], ['LTHS', 'HS', 'SC', 'COLL', 'ADV']]\n",
    "sex = [0, 1]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for a, e, s in itertools.product(ages, educ, sex):\n",
    "    row_name = f'{a[0]}-{a[1]}'\n",
    "    col_name = f'{\" or \".join(e)} {[\"Female\" if s == 1 else \"Male\"][0]}'\n",
    "    for yr, df in [('Year Ago', df1), ('Latest', df2)]:\n",
    "        data = df.query('@a[0] <= AGE <= @a[1] and EDUC in @e and FEMALE == @s')\n",
    "        i = data.groupby('LFS').PWSSWGT.sum()\n",
    "        results.loc[row_name, f'{yr} {col_name}'] = (i.Employed / i.sum()) * 100\n",
    "        \n",
    "results.iloc[1:, :-4].to_csv(data_dir / 'empgroups.csv', index_label='name')\n",
    "results.iloc[:, -4:].to_csv(data_dir / 'empgroups2.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union Membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_membership_rate = lambda x: np.average(x['UNIONMEM'], weights=x['PWORWGT'])\n",
    "union_coverage_rate = lambda x: np.average(x['UNION'], weights=x['PWORWGT'])\n",
    "\n",
    "unmem, uncov = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "untot, nuntot = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "columns = ['MONTH', 'YEAR', 'LFS', 'PWORWGT', 'UNION', 'UNIONMEM']\n",
    "for year in range(1989, 2021):\n",
    "    df = (pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "        .query('LFS == \"Employed\" and UNION in [0, 1]'))\n",
    "    data1 = df.groupby(['YEAR', 'MONTH']).apply(union_membership_rate)\n",
    "    data1.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data1.index]\n",
    "    unmem = unmem.append(data1)\n",
    "    data2 = df.groupby(['YEAR', 'MONTH']).apply(union_coverage_rate)\n",
    "    data2.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data2.index]\n",
    "    uncov = uncov.append(data2)\n",
    "    df2 = df.query('UNIONMEM == 1')   \n",
    "    data3 = df2.groupby(['YEAR', 'MONTH']).PWORWGT.sum()\n",
    "    data3.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data3.index]\n",
    "    untot = untot.append(data3)\n",
    "    df3 = df.query('UNIONMEM == 0')\n",
    "    data4 = df3.groupby(['YEAR', 'MONTH']).PWORWGT.sum()\n",
    "    data4.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data4.index]\n",
    "    nuntot = nuntot.append(data4)    \n",
    "    \n",
    "data = pd.DataFrame({'Membership': unmem, 'Coverage': uncov})\n",
    "levels = pd.DataFrame({'Union': untot, 'Nonunion': nuntot})\n",
    "data['Diff'] = data['Coverage'] - data['Membership']\n",
    "final = (data.rolling(12).mean().dropna() * 100)\n",
    "final.to_csv(data_dir / 'union.csv', index_label='date', float_format='%g')\n",
    "final2 = (levels.rolling(12).mean().dropna()) / 1000000\n",
    "\n",
    "ltdate = final.index[-1].strftime('%B %Y')\n",
    "prevdate = final.index[-13].strftime('%B %Y')\n",
    "prev2date = final.index[-25].strftime('%B %Y')\n",
    "\n",
    "ltval = final['Membership'].iloc[-1]\n",
    "prevval = final['Membership'].iloc[-13]\n",
    "prev2val = final['Membership'].iloc[-25]\n",
    "\n",
    "totvallt = final2['Union'].iloc[-1]\n",
    "totnvallt = final2['Nonunion'].iloc[-1]\n",
    "\n",
    "chlt = final2['Union'].diff(12).iloc[-1] * 1000000\n",
    "chpr = final2['Union'].diff(12).iloc[-13] * 1000000\n",
    "\n",
    "chnlt = final2['Nonunion'].diff(12).iloc[-1] * 1000000\n",
    "chnpr = final2['Nonunion'].diff(12).iloc[-13] * 1000000\n",
    "\n",
    "if chlt > 10:\n",
    "    chlt_txt = f'increased by {round(chlt, -3):,.0f}'\n",
    "elif chlt <= -10:\n",
    "    chlt_txt = f'decreased by {abs(round(chlt, -3)):,.0f}'\n",
    "else:\n",
    "    chlt_txt = 'were virtually unchanged'\n",
    "    \n",
    "if chnlt > 10:\n",
    "    chnlt_txt = f'increased by {round(chnlt, -3):,.0f}'\n",
    "elif chnlt <= -10:\n",
    "    chnlt_txt = f'decreased by {abs(round(chnlt, -3)):,.0f}'\n",
    "else:\n",
    "    chnlt_txt = 'were virtually unchanged'\n",
    "    \n",
    "text = (f'Over the 12 months ending {ltdate}, the share of jobs held '+\n",
    "        f'by union and employee association members averaged {ltval:.1f} percent. '+\n",
    "        f'In levels, there were {totvallt:.1f} million union jobs, and '+\n",
    "        f'{totnvallt:.1f} million nonunion jobs, on average over the period. '+\n",
    "        f'This union membership rate averaged {prevval:.1f} percent during the 12 '+\n",
    "        f'months ending {prevdate}, and {prev2val:.1f} percent during the 12 '+\n",
    "        f'months ending {prev2date}. Union jobs {chlt_txt} '+\n",
    "        f'from {prevdate} to {ltdate}, while nonunion jobs {chnlt_txt}.')\n",
    "write_txt(text_dir / 'union.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_membership_rate = lambda x: np.average(x['UNIONMEM'], weights=x['PWORWGT']) * 100\n",
    "columns = ['MONTH', 'YEAR', 'LFS', 'PWORWGT', 'UNIONMEM', 'INDGRP']\n",
    "\n",
    "df = pd.concat([pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "                  .query('PWORWGT > 0 and UNIONMEM == UNIONMEM')\n",
    "      for year in range(1989, 2021)])\n",
    "\n",
    "df.INDGRP.cat = df.INDGRP.cat.remove_unused_categories()\n",
    "\n",
    "data = df.groupby(['YEAR', 'MONTH', 'INDGRP']).apply(union_membership_rate).unstack()\n",
    "data.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data.index]\n",
    "data.index.name = 'date'\n",
    "data.columns.name = None\n",
    "prev12 = data.iloc[-12:].mean()\n",
    "lval = data.iloc[-1]\n",
    "minval = data.min()\n",
    "maxval = data.max()\n",
    "width = maxval - minval\n",
    "final = pd.concat([lval, prev12, minval, maxval, width], axis=1)\n",
    "final.columns = ['latest', 'prev12', 'min', 'max', 'width']\n",
    "final.index.name = 'name'\n",
    "final = final[['min', 'width', 'latest']].sort_values('latest', ascending=False)\n",
    "final['y'] = [0.13, -0.87, -1.87, -2.87, -3.87, -4.87, -5.87]\n",
    "final.to_csv(data_dir / 'union_ind.csv', sep=';')\n",
    "\n",
    "dec = (maxval - lval).sort_values()\n",
    "dec1 = dec.index[-1]\n",
    "decval1 = dec[-1]\n",
    "decmaxdt = dtxt(data[dec1].idxmax())['mon1']\n",
    "decmaxval = data[dec1].max()\n",
    "decgrp = dec1.lower()\n",
    "lowgroupmaxdt = dtxt(data[final.index[-1]].idxmax())['mon1']\n",
    "lowgrp = final.index[-1].lower()\n",
    "\n",
    "\n",
    "text = (f'{final.index[0]} has the highest union membership rate, '+\n",
    "        f'at {final.latest.iloc[0]:.1f} percent as of {ltdate}, followed by '+\n",
    "        f'{final.index[1].lower()} with {final.latest.iloc[1]:.1f} percent, '+\n",
    "        f'and {final.index[2].lower()} with {final.latest.iloc[2]:.1f} percent. '+\n",
    "        f'The {decgrp} industry '+\n",
    "        'experienced the largest overall percentage point decrease '+\n",
    "        'in union membership rates over the past 30 years, and is '+\n",
    "        f'currently {decval1:.1f} percentage points below its {decmaxdt} '+\n",
    "        f'rate of {decmaxval:.1f} percent. ')\n",
    "txt2 = ('The lowest union membership rate '+\n",
    "        f'is in {lowgrp} ({final.latest.iloc[-1]:.1f} percent). '+\n",
    "        f'The union membership rate of the industry was {data[final.index[-1]].max():.1f} '+\n",
    "        f'percent at its 30-year peak in {lowgroupmaxdt}. ')\n",
    "\n",
    "mfglt = data['Manufacturing'].iloc[-1]\n",
    "mfgpr = data['Manufacturing'].iloc[-13]\n",
    "prdt = dtxt(data.index[-13])['mon1']\n",
    "mfgpr2 = data['Manufacturing'].iloc[-25]\n",
    "prdt2 = dtxt(data.index[-25])['mon1']\n",
    "\n",
    "txt3 = (f'The manufacturing industry union membership rate was {mfglt:.1f} percent in {ltdate}, '+\n",
    "        f'{mfgpr:.1f} percent in {prdt}, and {mfgpr2:.1f} percent in {prdt2}.')\n",
    "\n",
    "if lowgrp == decgrp:\n",
    "    text = text + txt3\n",
    "else:\n",
    "    text = text + txt2\n",
    "\n",
    "write_txt(text_dir / 'union_ind.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching YY -- Disability to Work Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['CPSID', 'AGE', 'FEMALE', 'WBHAO', 'NILFREASON', \n",
    "        'LFS', 'MIS', 'BASICWGT', 'PULINENO']\n",
    "\n",
    "emp = lambda x: np.where(x.LFS_y == 'Employed', 1, 0)\n",
    "\n",
    "dates = pd.date_range('1997-01-01', cps_date(), freq='MS')\n",
    "\n",
    "d = {}\n",
    "\n",
    "for dt in dates:\n",
    "    df1 = (cps_1mo(cps_dir, dt - pd.DateOffset(years=1), cols)\n",
    "           .query('NILFREASON == \"Disabled/Ill\"'))\n",
    "    df2 = cps_1mo(cps_dir, dt, cols)\n",
    "    data = (pd.merge(df1, df2, on=['CPSID', 'PULINENO', 'FEMALE', 'WBHAO'])\n",
    "              .query('25 <= AGE_y <= 54'))\n",
    "    data = (data.loc[(data.AGE_x <= data.AGE_y) & \n",
    "                     (data.AGE_y - 2 <= data.AGE_x)]).assign(EMP = emp)\n",
    "\n",
    "    d[dt] = np.average(data.EMP, weights=data.BASICWGT_y) * 100\n",
    "    \n",
    "df = pd.Series(d).rolling(12).mean().dropna().rename('Share')\n",
    "\n",
    "df.to_csv(data_dir / 'disflow.csv', index_label='date', header=True)\n",
    "write_txt(text_dir/ 'disflow_node.txt', end_node(df, 'blue'))\n",
    "\n",
    "latest = df.iloc[-1]\n",
    "valavg = df.loc['2010-12-01':'2013-12-01'].mean()\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "\n",
    "text = (f'Over the year ending {ltdate}, {latest:.1f} percent of '+\n",
    "        'persons age 25--54 who were out of the labor force due to disability or illness '+\n",
    "        'in the prior year are now employed (see {\\color{blue}\\\\textbf{---}}). '+\n",
    "        'This one-year rate of job-finding has increased '+\n",
    "        f'substantially from its 2010--2013 average of {valavg:.1f} percent')\n",
    "\n",
    "write_txt(text_dir / 'disflow.txt', text)\n",
    "\n",
    "print(text)\n",
    "df.plot(color='blue', title='Flow, Disability to Work');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPS Labor Force Nonparticipation by Reason\n",
    "\n",
    "Replication using python of a very clever chart by Ernie Tedeschi (@ernietedeschi).\n",
    "\n",
    "[Definitions](https://www.frbatlanta.org/chcs/human-capital-currents/2015/0612-measuring-labor-market-status-using-basic-data.aspx) of labor market status come from the FRB of Atlanta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cps_dir)\n",
    "\n",
    "def to_date(ym):\n",
    "    return pd.to_datetime(f'{ym[0]}-{ym[1]}-01')\n",
    "\n",
    "years = range(2000, 2021)\n",
    "ref_pd = (2001, 3)\n",
    "ref_dt = to_date(ref_pd)\n",
    "ages = '18 <= AGE <= 64'\n",
    "wgt = 'BASICWGT'\n",
    "cat = 'NILFREASON'\n",
    "dates = ['YEAR', 'MONTH']\n",
    "dems = ['FEMALE', 'AGE']\n",
    "cols = dates + dems + [wgt, cat]\n",
    "files = [f'cps{year}.ft' for year in years]\n",
    "\n",
    "# CPS Data\n",
    "df = pd.concat([pd.read_feather(file, columns=cols)\n",
    "                  .query(ages) for file in files])\n",
    "\n",
    "p = df.groupby(dates + dems)[wgt].sum().rename('ADJ')\n",
    "sh = (p / p.groupby(dates).sum())\n",
    "adj = (sh.loc[ref_pd] / sh).reset_index()\n",
    "data = (pd.merge(df, adj)\n",
    "          .assign(ADJWGT = lambda x: x.ADJ * x[wgt]))\n",
    "data.NILFREASON.cat.rename_categories({'nan': 'LF'}, \n",
    "                                      inplace=True)\n",
    "\n",
    "# Make Adjustments\n",
    "c = data.groupby(dates + [cat]).ADJWGT.sum()\n",
    "dem_res = (c / c.groupby(dates).sum()).unstack()\n",
    "dem_res.columns = dem_res.columns.to_list()\n",
    "\n",
    "c_nd = data.groupby(dates + [cat])[wgt].sum()\n",
    "nd_res = (c_nd / c_nd.groupby(dates).sum()).unstack()\n",
    "\n",
    "dem_res['Demographics'] = dem_res['LF'] - nd_res['LF']\n",
    "dem_res.index = [to_date(ym) for ym in dem_res.index]\n",
    "\n",
    "keep_cols = dem_res.columns.difference(['LF'])\n",
    "result = (dem_res.rolling(12).mean().dropna()\n",
    "                 .loc[ref_dt:, keep_cols] * 100)\n",
    "\n",
    "final = result.iloc[0] - result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/brian/Documents/uschartbook/chartbook/')\n",
    "\n",
    "final.to_csv('data/nilf.csv', index_label='date')\n",
    "\n",
    "colors = {'Disabled/Ill': 'green!80!blue', \n",
    "          'Discouraged': 'blue', \n",
    "          'Family': 'red', \n",
    "          'Retired': 'orange', \n",
    "          'School': 'cyan', \n",
    "          'Demographics': 'violet!80!purple'}\n",
    "\n",
    "adj = node_adjust(final, colors)\n",
    "\n",
    "node_file = open('text/nilf_nodes.txt', 'w')\n",
    "for series, color in colors.items():\n",
    "    if series in adj.keys():\n",
    "        offset = adj[series]\n",
    "    else:\n",
    "        offset = 0\n",
    "    node_file.write(end_node(final[series], color, percent=False, offset=offset))\n",
    "node_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltdate = dtxt(cps_date())['mon1']\n",
    "\n",
    "lt = final.iloc[-1]\n",
    "tot = abs(lt.sum())\n",
    "dem = abs(lt['Demographics'])\n",
    "demc = colors['Demographics']\n",
    "sch = abs(lt['School'])\n",
    "schc = colors['School']\n",
    "dis = abs(lt['Disabled/Ill'])\n",
    "disc = colors['Disabled/Ill']\n",
    "ret = abs(lt['Retired'])\n",
    "retc = colors['Retired']\n",
    "\n",
    "text = (f'From March 2001 to the latest available twelve months of data, '+''+\n",
    "        f'ending {ltdate}, an additional {tot:.1f} percent of the age 18--64 '+\n",
    "         'population left the labor force. Changes in the demographic '+\n",
    "         'composition of the population affect the rate of participation. '+\n",
    "         'For example, the larger-than-normal population '+\n",
    "         'cohort born after World War II is reaching retirement age in '+\n",
    "        f'this period. Changes in the age and sex distribution explain {dem:.1f} '+\n",
    "         'percentage points of the cumulative decrease since March 2001 '+\n",
    "        f'(see {{\\color{{{demc}}}\\\\textbf{{---}}}}). \\\\\\\\ \\n\\nAdditionally, '+ \n",
    "         'young people are staying in school longer, on average, '+\n",
    "        f'reducing the age 18--64 labor force by {sch:.1f} percent '+\n",
    "        f'(see {{\\color{{{schc}}}\\\\textbf{{---}}}}). '+\n",
    "         'Disability and illness reduce the labor force by '+\n",
    "        f'another {dis:.1f} percent '+\n",
    "        f'(see {{\\color{{{disc}}}\\\\textbf{{---}}}}). Less retirement among those age '+\n",
    "        f'18--64 increases the labor force by {ret:.1f} percent, over '+\n",
    "        f'the period (see {{\\color{{{retc}}}\\\\textbf{{---}}}}).')\n",
    "\n",
    "\n",
    "write_txt('text/nilf_01.txt', text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cps_dir)\n",
    "\n",
    "result, share = pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "dts = [cps_date(), cps_date() - pd.DateOffset(years=1)]\n",
    "\n",
    "for date in dts:\n",
    "    month =  date.month\n",
    "    year = date.year\n",
    "    data = (pd.read_feather(f'cps{year}.ft', columns=cols)\n",
    "              .query('YEAR == @year and MONTH == @month'))\n",
    "    \n",
    "    dt = dtxt(date)['mon1']\n",
    "\n",
    "    result[dt] = data.groupby('NILFREASON').BASICWGT.sum()\n",
    "    share[dt] = result[dt] / result[dt].sum() * 100\n",
    "    \n",
    "os.chdir(cb_dir)\n",
    "\n",
    "mo1 = dtxt(dts[0])['mon1']\n",
    "mo2 = dtxt(dts[1])['mon1']\n",
    "\n",
    "(share.drop('nan').round(1).sort_values(mo1, ascending=False)\n",
    "       .to_csv(data_dir / 'nilf_comp.csv', index_label='name'))\n",
    "\n",
    "write_txt(text_dir / 'nilf_mo1.txt', mo1)\n",
    "write_txt(text_dir / 'nilf_mo2.txt', mo2)\n",
    "\n",
    "pct = share[mo1]\n",
    "pctpr = share[mo2]\n",
    "lev = result[mo1] / 1_000_000\n",
    "\n",
    "totlev = lev.drop('nan').sum()\n",
    "totpct = pct.drop('nan').sum()\n",
    "totpctpr = pctpr.drop('nan').sum()\n",
    "retpct = pct['Retired']\n",
    "dislev = lev['Disabled/Ill']\n",
    "dispct = pct['Disabled/Ill']\n",
    "schpct = pct['School']\n",
    "carepct = pct['Family']\n",
    "\n",
    "text = ('These labor force non-participants, which do not include '+\n",
    "        f'those under the age of 15, total {totlev:.1f} million '+\n",
    "        f'in {mo1}, or {totpct:.1f} percent of the age 15 or older '+\n",
    "        f'population, compared to {totpctpr:.1f} percent in {mo2}. '+\n",
    "         'Slightly less than half of non-participants, and '+\n",
    "        f'{retpct:.1f} percent of population, are retirees in {mo1} '+\n",
    "        '(see\\cbox{green!80!blue!75!black}). A total of '+\n",
    "        f'{dislev:.1f} million people, or {dispct:.1f} percent of the age '+\n",
    "         '15 or older population, are out of the labor force due to disability '+\n",
    "        f'or illness; {schpct:.1f} percent were out of the labor force for '+\n",
    "        f'school, and {carepct:.1f} percent for family or caregiving reasons.')\n",
    "\n",
    "write_txt(text_dir / 'nilfbasic.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occs = {1   :  'Management occupations',\n",
    "        2   :  'Business and financial operations occupations',\n",
    "        3   :  'Computer and mathematical science occupations',\n",
    "        4   :  'Architecture and engineering occupations',\n",
    "        5   :  'Life, physical, and social science occupations',\n",
    "        6   :  'Community and social service occupations',\n",
    "        7   :  'Legal occupations',\n",
    "        8   :  'Education, training, and library occupations',\n",
    "        9   :  'Arts, design, entertainment, sports, and media',\n",
    "        10  :  'Healthcare practitioner and technical occupations',\n",
    "        11  :  'Healthcare support occupations',\n",
    "        12  :  'Protective service occupations',\n",
    "        13  :  'Food preparation and serving related occupations',\n",
    "        14  :  'Building and grounds cleaning and maintenance',\n",
    "        15  :  'Personal care and service occupations',\n",
    "        16  :  'Sales and related occupations',\n",
    "        17  :  'Office and administrative support occupations',\n",
    "        18  :  'Farming, fishing, and forestry occupations',\n",
    "        19  :  'Construction and extraction occupations',\n",
    "        20  :  'Installation, maintenance, and repair occupations',\n",
    "        21  :  'Production occupations',\n",
    "        22  :  'Transportation and material moving occupations'}\n",
    "\n",
    "cols = ['MONTH', 'YEAR', 'LFS', 'PWSSWGT', 'OCCD', 'OCC2D', 'WORKFT', 'COW1', 'COW2']\n",
    "\n",
    "df = cps_12mo(cps_dir, cps_date(), cols)\n",
    "\n",
    "df['OCCD'] = df['OCCD'].map(occs)\n",
    "df['OCC2D'] = df['OCC2D'].map(occs)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['FT'] = df.query('WORKFT == 1').groupby('OCCD').PWSSWGT.sum() / df.PWSSWGT.sum() * 100\n",
    "data['PT'] = df.query('WORKFT == 0').groupby('OCCD').PWSSWGT.sum() / df.PWSSWGT.sum() * 100\n",
    "data['Second'] = df.groupby('OCC2D').PWSSWGT.sum() / df.PWSSWGT.sum() * 100\n",
    "\n",
    "data['Total'] = data.sum(axis=1)\n",
    "\n",
    "data.index = data.index.str.replace('occupations', '').str.replace('and', '\\&')\n",
    "\n",
    "data = data.sort_values('Total')\n",
    "data.drop('Total', axis=1).to_csv(data_dir / 'occs.csv', sep=';', index_label='name', header=True)\n",
    "\n",
    "data.drop('Total', axis=1).plot(kind='barh', stacked=True);\n",
    "\n",
    "data1 = data.drop('Total', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlanta Fed WGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['AGE', 'HRWAGE', 'PRWERNAL', 'PRHERNAL', 'PTHR', 'PTWK', \n",
    "        'FEMALE', 'CPSID', 'WBHAO', 'PULINENO', 'PRNAGWS']\n",
    "\n",
    "filters = 'HRWAGE >= 2.13 and PTHR == 0 and PTWK == 0 and PRNAGWS == 1 and PRHERNAL < 1 and PRWERNAL < 1'\n",
    "\n",
    "dates = pd.date_range('1997-01-01', cps_date(), freq='MS')\n",
    "\n",
    "d = {}\n",
    "d2 = {}\n",
    "\n",
    "for dt in dates:\n",
    "    df1 = cps_1mo(cps_dir, dt - pd.DateOffset(years=1), cols).query(filters)\n",
    "    df2 = cps_1mo(cps_dir, dt, cols).query(filters)\n",
    "    data = (pd.merge(df1, df2, on=['CPSID', 'PULINENO', 'FEMALE', 'WBHAO']))\n",
    "    data = (data.loc[(data.AGE_x <= data.AGE_y) & \n",
    "                     (data.AGE_y - 2 <= data.AGE_x)])\n",
    "    wage_change_array = ((data['HRWAGE_y'] / data['HRWAGE_x']) - 1) * 100\n",
    "    d[dt] = wage_change_array.median()\n",
    "    zwc = (len(wage_change_array[(wage_change_array >= -0.5) & \n",
    "                                 (wage_change_array <= 0.5)]) / len(wage_change_array)) * 100\n",
    "    d2[dt] = zwc\n",
    "\n",
    "result = pd.Series(d, name='bd_cps').to_frame()\n",
    "result['3ma'] = result.rolling(3).mean()\n",
    "result['zwc'] = pd.Series(d2).rolling(3).mean()\n",
    "\n",
    "result.to_csv(data_dir/ 'atl_wgt.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(result.index[-1])['mon1']\n",
    "ltval = result['bd_cps'].iloc[-1]\n",
    "lt3m = result['3ma'].iloc[-1]\n",
    "yrdt = dtxt(result.index[-13])['mon1']\n",
    "pr3m = result['3ma'].iloc[-13]\n",
    "\n",
    "if round(lt3m) == round(pr3m):\n",
    "    also = 'also '\n",
    "\n",
    "text = ('Replication of the wage growth tracker '+\n",
    "        'using the bd CPS shows matched-observation wage growth of '+\n",
    "        f'{ltval:.1f} percent in {ltdate} '+\n",
    "        '(see {\\color{orange!60!white}\\\\textbf{---}}), and average wage '+\n",
    "        f'growth of {lt3m:.1f} percent over the three months ending {ltdate} '+\n",
    "        '(see {\\color{blue!75!cyan}\\\\textbf{---}}). '+\n",
    "        f'One year prior, in {yrdt}, three-month moving average '+\n",
    "        f'wage growth was {also}{pr3m:.1f} percent.')\n",
    "print(text)\n",
    "write_txt(text_dir / 'atl_wgt.txt', text)\n",
    "\n",
    "ltval = result['zwc'].iloc[-1]\n",
    "prval = result['zwc'].iloc[-2]\n",
    "prdate = dtxt(result.index[-2])['mon1']\n",
    "yrval = result['zwc'].iloc[-13]\n",
    "\n",
    "text = (f'In {ltdate}, {ltval:.1f} '+\n",
    "        'percent of individuals had no wage growth, compared to '+\n",
    "        f'{prval:.1f} in {prdate} '+\n",
    "        '(see {\\color{red}\\\\textbf{---}}). One year prior, '+\n",
    "        f'in {yrdt}, {yrval:.1f} '+\n",
    "        'percent of individuals had no wage growth.')\n",
    "print(text)\n",
    "write_txt(text_dir / 'atl_zwc.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment Cost Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "series = {'CIU2020000000000A': 'PrivateWS'}\n",
    "\n",
    "dates = (2001, 2020)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "\n",
    "df.to_csv(data_dir/ 'eci.csv', index_label='date')\n",
    "write_txt(text_dir/ 'eci_node.txt', end_node(df['PrivateWS'], 'green!75!blue!90!black'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltdate = dtxt(df.index[-1])['qtr2']\n",
    "ltval = inc_dec_percent(df['PrivateWS'].iloc[-1])\n",
    "prdate = dtxt(df.index[-2])['qtr1']\n",
    "prval = inc_dec_percent(df['PrivateWS'].iloc[-2], how='of')\n",
    "prdate2 = dtxt(df.index[-3])['qtr1']\n",
    "prval2 = inc_dec_percent(df['PrivateWS'].iloc[-3], how='of')\n",
    "\n",
    "text = (f'In {ltdate}, private industry wage and salary costs '+\n",
    "        f'(see {{\\color{{green!75!blue!90!black}}\\\\textbf{{---}}}}) {ltval}, '+\n",
    "        f'following {prval} in {prdate}, and {prval2} in {prdate2}.')\n",
    "\n",
    "write_txt(text_dir / 'eci.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Unemployment and Employment Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.patches import Polygon\n",
    "\n",
    "plt.rc('font', family='Lato')\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "# Map settings\n",
    "m = Basemap(llcrnrlon=-121, llcrnrlat=20, urcrnrlon=-64, urcrnrlat=49,\n",
    "            projection='lcc', lat_1=33, lat_2=45, lon_0=-95)\n",
    "m.readshapefile('shapefiles/states', 'states', drawbounds=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laus_raw_url = 'https://www.bls.gov/web/laus/ststdnsadata.txt'\n",
    "r = requests.get(laus_raw_url)\n",
    "raw_data = [line for line in r.text.split('\\n')[16:] if line[:2] != '\\r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epop, unrate = {}, {}\n",
    "\n",
    "for row in raw_data:\n",
    "    if row[:5] == '     ':\n",
    "        date_text = row.strip().replace('\\r', '')\n",
    "        date = pd.to_datetime(date_text)\n",
    "        epop[date], unrate[date] = {}, {}\n",
    "    if len(row) > 0:\n",
    "        if row[0] != ' ':\n",
    "            state = row.split('.')[0].strip()\n",
    "            unrate_val = float(row.split()[-1])\n",
    "            unrate[date][state] = unrate_val\n",
    "            epop_val = float(row.split()[-3])\n",
    "            epop[date][state] = epop_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(unrate).T\n",
    "\n",
    "states = list(set([i['STATE_NAME'] for i in m.states_info]))\n",
    "\n",
    "cmap = plt.cm.Spectral_r\n",
    "norm = Normalize(vmin=data.min().min(), vmax=data.max().max())\n",
    "\n",
    "# Draw map\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(3.5, 2.4))\n",
    "fig.tight_layout()\n",
    "\n",
    "m.drawmapboundary()\n",
    "    \n",
    "for info, shape in zip(m.states_info, m.states):\n",
    "        \n",
    "    fc = cmap(norm(data[info['STATE_NAME']].iloc[-1]))\n",
    "    # Alaska and Hawaii moved\n",
    "    if info['STATE_NAME'] == 'Hawaii':\n",
    "        shape = [(x + 5200000, y - 1400000) for x,y in shape]\n",
    "    elif info['STATE_NAME'] == 'Alaska':\n",
    "        shape = [(x*0.35 + 1100000, y*0.35 - 1300000) for x,y in shape]\n",
    "    axes.add_patch(Polygon(shape, fc=fc)) \n",
    "    \n",
    "plt.savefig('../chartbook/data/unemp_map.pgf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['BASICWGT', 'AGE', 'MONTH', 'YEAR', 'WORKFT', 'NOTATWORK', 'STATE']\n",
    "\n",
    "term = 'WORKFT == 1 and NOTATWORK == 0'\n",
    "\n",
    "ref_dates = {'latest': cps_date(),\n",
    "             'year_ago': cps_date() - pd.DateOffset(months=12)}\n",
    "\n",
    "data = {}\n",
    "\n",
    "for period, date in ref_dates.items():\n",
    "    cps_dates = [date - pd.DateOffset(months=offset) \n",
    "                 for offset in [0, 1, 2]]\n",
    "\n",
    "    df = pd.concat([cps_1mo(cps_dir, dt, cols).query('15 < AGE < 65') for dt in cps_dates])\n",
    "\n",
    "    data[period] = (df.query(term).groupby('STATE').BASICWGT.sum() / \n",
    "                    df.groupby('STATE').BASICWGT.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['latest'] - data['year_ago']).sort_values(ascending=False).plot(kind='barh', figsize=(4, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [0, 1, 2]\n",
    "for offset in offsets:\n",
    "    dt = cps_date() - pd.DateOffset(months=offset)\n",
    "    print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cps_1mo(cps_dir, dt, cols) for dt in cps_dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([cps_1mo(cps_dir, dt, cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['PWSSWGT', 'AGE', 'MONTH', 'YEAR', 'WORKFT', 'NOTATWORK', 'STATE']\n",
    "df = cps_1mo(cps_dir, cps_date(), cols)\n",
    "term = 'WORKFT == 1 and NOTATWORK == 0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(term).groupby('STATE').PWSSWGT.sum() / df.groupby('STATE').PWSSWGT.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
