{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labor Force Statistics from CPS Microdata\n",
    "\n",
    "Brian Dew, @bd_econ, brian.w.dew@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T04:40:27.030074Z",
     "start_time": "2022-03-20T04:40:26.358669Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *\n",
    "\n",
    "dt = cps_date()\n",
    "if dt > pd.to_datetime('2022-02-01'):\n",
    "    pcdt = dt - pd.DateOffset(years=3)\n",
    "else:\n",
    "    pcdt = dt - pd.DateOffset(years=2)\n",
    "def to_date(ym):\n",
    "    return pd.to_datetime(f'{ym[0]}-{ym[1]}-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFS by AGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:21:56.078752Z",
     "start_time": "2022-03-10T15:21:55.994058Z"
    }
   },
   "outputs": [],
   "source": [
    "lfs2 = lambda x: np.where(((x.AGE < 16) | (x.NILFREASON == 'School')), 'Child/Student',\n",
    "                 np.where(((x.LFS == 'Unemployed') | (x.NILFREASON == 'Discouraged') | \n",
    "                           (x.NILFREASON == 'Other')), 'Unemployed/Discouraged/Other',\n",
    "                 np.where(x.LFS == 'Employed', 'Employed', x.NILFREASON)))\n",
    "\n",
    "cols = ['YEAR', 'MONTH', 'AGE', 'NILFREASON', 'LFS', 'PWSSWGT']\n",
    "df = (cps_1mo(cps_dir, dt, cols).assign(LFS2 = lfs2))\n",
    "df2 = df.copy()\n",
    "df2.loc[:,'AGE'] = df.AGE + 1\n",
    "df3 = df.copy()\n",
    "df3.loc[:,'AGE'] = df.AGE - 1\n",
    "df = df.append(df2).append(df3)\n",
    "data = (df.groupby(['AGE', 'LFS2']).PWSSWGT.sum().unstack()\n",
    "          .divide(df.groupby('AGE').PWSSWGT.sum(), axis=0))\n",
    "data.columns.name = ''\n",
    "data = data.fillna(0) * 100\n",
    "data.to_csv(data_dir / 'lfs_age.csv', index_label='AGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:21:56.174529Z",
     "start_time": "2022-03-10T15:21:56.080084Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (cps_1mo(cps_dir, pcdt, cols).assign(LFS2 = lfs2))\n",
    "df2 = df.copy()\n",
    "df2.loc[:,'AGE'] = df.AGE + 1\n",
    "df3 = df.copy()\n",
    "df3.loc[:,'AGE'] = df.AGE - 1\n",
    "df = df.append(df2).append(df3)\n",
    "data2 = (df.groupby(['AGE', 'LFS2']).PWSSWGT.sum().unstack()\n",
    "           .divide(df.groupby('AGE').PWSSWGT.sum(), axis=0))\n",
    "data2.columns.name = ''\n",
    "data2 = data2.fillna(0) * 100\n",
    "result = (data - data2).loc[15:].rename({'Child/Student': 'Student'}, axis=1)\n",
    "result.to_csv(data_dir / 'lfs_age_ch.csv', index_label='AGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview data and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:00.255346Z",
     "start_time": "2022-03-10T15:21:56.175710Z"
    }
   },
   "outputs": [],
   "source": [
    "yr_wt = {y: 'PWSSWGT' if y > 1993 else 'BASICWGT' \n",
    "         for y in range(1989, 2023)}\n",
    "\n",
    "cols = ['LFS', 'AGE', 'MONTH', 'YEAR', 'FEMALE']\n",
    "\n",
    "df = pd.concat([(pd.read_feather(cps_dir / f'cps{y}.ft', \n",
    "                                 columns=cols + [w])\n",
    "                   .rename({w: 'WGT'}, axis=1)) \n",
    "                for y, w in yr_wt.items()], sort=False)\n",
    "df['DATE'] = pd.to_datetime(dict(year=df.YEAR, \n",
    "                                 month=df.MONTH, day=1))\n",
    "data = (df.groupby(['DATE', 'LFS']).WGT.sum()\n",
    "          .unstack().rename({'nan': 'Children'}, axis=1)\n",
    "        / 1_000_000)\n",
    "data.to_csv(data_dir/ 'cps_lfs.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:00.272154Z",
     "start_time": "2022-03-10T15:22:00.256284Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir/ 'cps_lfs.csv', \n",
    "                   index_col='date', parse_dates=True)\n",
    "\n",
    "datelt = dtxt(data.index[-1])['mon1']\n",
    "dateltsh = dtxt(data.index[-1])['mon2']\n",
    "dateyr = dtxt(data.index[-13])['mon1']\n",
    "dateprepan = dtxt(data.index[-25])['mon1']\n",
    "dateshprepan = dtxt(data.index[-25])['mon2']\n",
    "dateyrsh = dtxt(data.index[-13])['mon2']\n",
    "datepr = f\"{dateyr} to {datelt}\"\n",
    "datepr2 = f\"{dateprepan} to {datelt}\"\n",
    "\n",
    "write_txt(text_dir / 'cps_lfs_date.txt', datelt)\n",
    "write_txt(text_dir / 'cps_lfs_datesh.txt', dateltsh)\n",
    "write_txt(text_dir / 'cps_lfs_dateyr.txt', dateyr)\n",
    "write_txt(text_dir / 'cps_lfs_datepc.txt', dtxt(pcdt)['mon1'])\n",
    "write_txt(text_dir / 'cps_lfs_dateprepan.txt', dateprepan)\n",
    "write_txt(text_dir / 'cps_lfs_dateshprepan.txt', dateshprepan)\n",
    "write_txt(text_dir / 'cps_lfs_dateyrsh.txt', dateyrsh)\n",
    "write_txt(text_dir / 'cps_lfs_datepr.txt', datepr)\n",
    "write_txt(text_dir / 'cps_lfs_date2pr.txt', datepr2)\n",
    "\n",
    "epop = data[\"Employed\"].iloc[-1] / data.iloc[-1].sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:00.336459Z",
     "start_time": "2022-03-10T15:22:00.274582Z"
    }
   },
   "outputs": [],
   "source": [
    "text = (f'As of {datelt}, {data[\"Employed\"].iloc[-1]:.1f} '+\n",
    "        'million people are employed (including self-'+\n",
    "        'employment). ')\n",
    "print(text, '\\n')\n",
    "write_txt(text_dir / 'cps_lfs0.txt', text)\n",
    "\n",
    "text = ('The number of people who are employed divided by '+\n",
    "        'the total population is the employment rate or '+\n",
    "        'employment-to-population ratio, which is '+\n",
    "        f'{epop:.1f} percent as of {datelt}.')\n",
    "print(text, '\\n')\n",
    "write_txt(text_dir / 'cps_lfs.txt', text)\n",
    "\n",
    "unemp = (data[\"Unemployed\"].iloc[-1] / \n",
    "         (data[\"Unemployed\"].iloc[-1] + \n",
    "          data[\"Employed\"].iloc[-1])) * 100\n",
    "lfpr = ((data[\"Unemployed\"].iloc[-1] + \n",
    "         data[\"Employed\"].iloc[-1]) / \n",
    "         data.iloc[-1].sum()) * 100\n",
    "\n",
    "unemptot = data[\"Unemployed\"].iloc[-1]\n",
    "text = (f'As of {datelt}, there are {unemptot:.1f} million '+\n",
    "        'unemployed people. The combined group of employed '+\n",
    "        'and unemployed people is the labor force. The number '+\n",
    "        'of unemployed people divided by the number of people '+\n",
    "        'in the labor force is the unemployment rate, '+\n",
    "        f'currently {unemp:.1f} percent. The number of people '+\n",
    "        'in the labor force divided by the total population '+\n",
    "        'is the labor force participation rate, currently '+\n",
    "        f'{lfpr:.1f} percent.')\n",
    "print(text, '\\n')\n",
    "write_txt(text_dir / 'cps_lfs2.txt', text)\n",
    "    \n",
    "cols2 = ['LFS', 'AGE', 'MONTH', 'YEAR', 'FEMALE', \n",
    "         'NILFREASON', 'PWSSWGT']\n",
    "\n",
    "v = (cps_1mo(cps_dir, cps_date(), cols2)\n",
    "     .groupby('NILFREASON').PWSSWGT.sum()\n",
    "     .divide(1_000_000)\n",
    "     .apply('({:.1f} million)'.format)\n",
    "     .str.replace('.0', '', regex=False))\n",
    "\n",
    "kids = data[\"Children\"].iloc[-1]\n",
    "nilfpop = data[['NILF', 'Children']].iloc[-1].sum()\n",
    "text = ('Nonparticipants usually comprise about half '+\n",
    "        f'of the population, and total {nilfpop:.1f} million '+\n",
    "        f'in {datelt}. The category includes children '+\n",
    "        f'({kids:.1f} million), students {v[\"School\"]}, '+\n",
    "        f'unpaid caregivers {v[\"Family\"]}, those unable to '+\n",
    "        f'work due to disability or illness {v[\"Disabled/Ill\"]}, '+\n",
    "        f'those who want a job but have given up looking '+\n",
    "        f'{v[\"Discouraged\"]}, and retirees and the elderly '+\n",
    "        f'{v[\"Retired\"]}.')\n",
    "write_txt(text_dir / 'cps_lfs3.txt', text)\n",
    "    \n",
    "data['Total'] = (data[['Employed', 'Unemployed', 'NILF']]\n",
    "                 .sum(axis=1))\n",
    "result = data.drop('Children', axis=1).resample('QS').mean()\n",
    "\n",
    "gc = growth_contrib_ann(result, 'Total').dropna()\n",
    "gc.to_csv(data_dir / 'cps_lfs2.csv', index_label='date')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:00.900046Z",
     "start_time": "2022-03-10T15:22:00.337519Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['LFS', 'BASICWGT', 'AGE', 'MONTH', 'YEAR', 'MJH',\n",
    "        'FEMALE', 'NILFREASON', 'UNEMPTYPE', 'PTECON', 'WORKFT']\n",
    "\n",
    "df = cps_1mo(cps_dir, cps_date(), cols).query('AGE > 15')\n",
    "df2 = cps_1mo(cps_dir, cps_date() - pd.DateOffset(years=2), cols).query('AGE > 15')\n",
    "\n",
    "age_groups = [(16, 30), (30, 60), (60, 86)]\n",
    "sex = [0, 1]\n",
    "d = {'Population': {'query': 'BASICWGT > 0'}, \n",
    "     '\\hspace{2mm}Employed': {'query': 'LFS == \"Employed\"'}, \n",
    "     '\\hspace{4mm}Multiple jobs': {'query': 'MJH == 1'},     \n",
    "     '\\hspace{4mm}Full-time': {'query': 'WORKFT == 1'},  \n",
    "     '\\hspace{4mm}Part-time': {'query': 'WORKFT == 0'}, \n",
    "     '\\hspace{6mm}Economic reasons': {'query': 'PTECON == 1'},\n",
    "     '\\hspace{2mm}Unemployed': {'query': 'LFS == \"Unemployed\"'}, \n",
    "     '\\hspace{2mm}Not in Labor Force': {'query': 'LFS == \"NILF\"'}, \n",
    "     '\\hspace{4mm}Discouraged': {'query': 'NILFREASON == \"Discouraged\"'}, \n",
    "     '\\hspace{4mm}Disabled/Ill': {'query': 'NILFREASON == \"Disabled/Ill\"'}, \n",
    "     '\\hspace{4mm}Family/Care': {'query': 'NILFREASON == \"Family\"'}, \n",
    "     '\\hspace{4mm}School': {'query': 'NILFREASON == \"School\"'}, \n",
    "     '\\hspace{4mm}Retirement': {'query': 'NILFREASON == \"Retired\"'}}\n",
    "\n",
    "d2 = {k: {} for k, v in d.items()}\n",
    "\n",
    "lf_groups = list(zip(d.keys(), [d[i]['query'] for i in d.keys()])) \n",
    "\n",
    "for name, query in lf_groups:\n",
    "    totval = df.query(query).BASICWGT.sum()/1000\n",
    "    d[name]['Total, 16+'] = f'{totval:,.0f}'\n",
    "    chval = totval - df2.query(query).BASICWGT.sum()/1000\n",
    "    d2[name]['Total, 16+'] = f'{chval:,.0f}'\n",
    "\n",
    "for sex, (agemin, agemax) in itertools.product(sex, age_groups):\n",
    "    data = df.query('@agemin <= AGE < @agemax and FEMALE == @sex')\n",
    "    data2 = df2.query('@agemin <= AGE < @agemax and FEMALE == @sex')\n",
    "    group = f'{[\"Women\" if sex==1 else \"Men\"][0]}, {agemin}--{agemax-1}'.replace('--85', '+')\n",
    "    for name, query in lf_groups:\n",
    "        tmp = data.query(query).BASICWGT.sum()/1000\n",
    "        tmp2 = data2.query(query).BASICWGT.sum()/1000\n",
    "        d[name][group] = f'{tmp:,.0f}'\n",
    "        d2[name][group] = f'{tmp - tmp2:,.0f}'\n",
    "        \n",
    "(pd.DataFrame(d).T.drop('query', axis=1).to_csv(data_dir / 'lfs_table1.tex', \n",
    "    sep='&', line_terminator='\\\\\\ ', quotechar=' '))\n",
    "pd.DataFrame(d2).T.to_csv(data_dir / 'lfs_table2.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:01.456095Z",
     "start_time": "2022-03-10T15:22:00.901723Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# One year change\n",
    "cols = ['LFS', 'BASICWGT', 'AGE', 'MONTH', 'YEAR', 'MJH',\n",
    "        'FEMALE', 'NILFREASON', 'UNEMPTYPE', 'PTECON', 'WORKFT']\n",
    "\n",
    "df = cps_1mo(cps_dir, cps_date(), cols).query('AGE > 15')\n",
    "df2 = cps_1mo(cps_dir, cps_date() - pd.DateOffset(years=1), cols).query('AGE > 15')\n",
    "\n",
    "age_groups = [(16, 30), (30, 60), (60, 86)]\n",
    "sex = [0, 1]\n",
    "d = {'Population': {'query': 'BASICWGT > 0'}, \n",
    "     '\\hspace{2mm}Employed': {'query': 'LFS == \"Employed\"'}, \n",
    "     '\\hspace{4mm}Multiple jobs': {'query': 'MJH == 1'},     \n",
    "     '\\hspace{4mm}Full-time': {'query': 'WORKFT == 1'},  \n",
    "     '\\hspace{4mm}Part-time': {'query': 'WORKFT == 0'}, \n",
    "     '\\hspace{6mm}Economic reasons': {'query': 'PTECON == 1'},\n",
    "     '\\hspace{2mm}Unemployed': {'query': 'LFS == \"Unemployed\"'}, \n",
    "     '\\hspace{2mm}Not in Labor Force': {'query': 'LFS == \"NILF\"'}, \n",
    "     '\\hspace{4mm}Discouraged': {'query': 'NILFREASON == \"Discouraged\"'}, \n",
    "     '\\hspace{4mm}Disabled/Ill': {'query': 'NILFREASON == \"Disabled/Ill\"'}, \n",
    "     '\\hspace{4mm}Family/Care': {'query': 'NILFREASON == \"Family\"'}, \n",
    "     '\\hspace{4mm}School': {'query': 'NILFREASON == \"School\"'}, \n",
    "     '\\hspace{4mm}Retirement': {'query': 'NILFREASON == \"Retired\"'}}\n",
    "\n",
    "d2 = {k: {} for k, v in d.items()}\n",
    "\n",
    "lf_groups = list(zip(d.keys(), [d[i]['query'] for i in d.keys()])) \n",
    "\n",
    "for name, query in lf_groups:\n",
    "    totval = df.query(query).BASICWGT.sum()/1000\n",
    "    d[name]['Total, 16+'] = f'{totval:,.0f}'\n",
    "    chval = totval - df2.query(query).BASICWGT.sum()/1000\n",
    "    d2[name]['Total, 16+'] = f'{chval:,.0f}'\n",
    "\n",
    "for sex, (agemin, agemax) in itertools.product(sex, age_groups):\n",
    "    data = df.query('@agemin <= AGE < @agemax and FEMALE == @sex')\n",
    "    data2 = df2.query('@agemin <= AGE < @agemax and FEMALE == @sex')\n",
    "    group = f'{[\"Women\" if sex==1 else \"Men\"][0]}, {agemin}--{agemax-1}'.replace('--85', '+')\n",
    "    for name, query in lf_groups:\n",
    "        tmp = data.query(query).BASICWGT.sum()/1000\n",
    "        tmp2 = data2.query(query).BASICWGT.sum()/1000\n",
    "        d[name][group] = f'{tmp:,.0f}'\n",
    "        d2[name][group] = f'{tmp - tmp2:,.0f}'\n",
    "        \n",
    "print(datepr)\n",
    "pd.DataFrame(d2).T        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rates by age, gender, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:03.360749Z",
     "start_time": "2022-03-10T15:22:01.457485Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['MONTH', 'YEAR', 'LFS', 'PWSSWGT', 'AGE', 'EDUC', 'FEMALE']\n",
    "df1 = cps_3mo(cps_dir, cps_date() - pd.DateOffset(months=24), cols)\n",
    "df2 = cps_3mo(cps_dir, cps_date(), cols)\n",
    "\n",
    "ages = [(16, 24), (25, 34), (35, 44), (45, 54), (55, 64), (65, 74)]\n",
    "educ = [['LTHS', 'HS'], ['SC'], ['COLL', 'ADV'], ['LTHS', 'HS', 'SC', 'COLL', 'ADV']]\n",
    "sex = [0, 1]\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for a, e, s in itertools.product(ages, educ, sex):\n",
    "    row_name = f'{a[0]}-{a[1]}'\n",
    "    col_name = f'{\" or \".join(e)} {[\"Female\" if s == 1 else \"Male\"][0]}'\n",
    "    for yr, df in [('Year Ago', df1), ('Latest', df2)]:\n",
    "        data = df.query('@a[0] <= AGE <= @a[1] and EDUC in @e and FEMALE == @s')\n",
    "        i = data.groupby('LFS').PWSSWGT.sum()\n",
    "        results.loc[row_name, f'{yr} {col_name}'] = (i.Employed / i.sum()) * 100\n",
    "        \n",
    "results.iloc[1:, :-4].to_csv(data_dir / 'empgroups.csv', index_label='name')\n",
    "results.iloc[:, -4:].to_csv(data_dir / 'empgroups2.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union Membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:06.640364Z",
     "start_time": "2022-03-10T15:22:03.362107Z"
    }
   },
   "outputs": [],
   "source": [
    "union_membership_rate = lambda x: np.average(x['UNIONMEM'], weights=x['PWORWGT'])\n",
    "union_coverage_rate = lambda x: np.average(x['UNION'], weights=x['PWORWGT'])\n",
    "\n",
    "unmem, uncov = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "untot, nuntot = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "\n",
    "columns = ['MONTH', 'YEAR', 'LFS', 'PWORWGT', 'UNION', 'UNIONMEM']\n",
    "for year in range(1989, 2023):\n",
    "    df = (pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "        .query('LFS == \"Employed\" and UNION in [0, 1]'))\n",
    "    data1 = df.groupby(['YEAR', 'MONTH']).apply(union_membership_rate)\n",
    "    data1.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data1.index]\n",
    "    unmem = unmem.append(data1)\n",
    "    data2 = df.groupby(['YEAR', 'MONTH']).apply(union_coverage_rate)\n",
    "    data2.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data2.index]\n",
    "    uncov = uncov.append(data2)\n",
    "    df2 = df.query('UNIONMEM == 1')   \n",
    "    data3 = df2.groupby(['YEAR', 'MONTH']).PWORWGT.sum()\n",
    "    data3.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data3.index]\n",
    "    untot = untot.append(data3)\n",
    "    df3 = df.query('UNIONMEM == 0')\n",
    "    data4 = df3.groupby(['YEAR', 'MONTH']).PWORWGT.sum()\n",
    "    data4.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data4.index]\n",
    "    nuntot = nuntot.append(data4)    \n",
    "    \n",
    "data = pd.DataFrame({'Membership': unmem, 'Coverage': uncov})\n",
    "levels = pd.DataFrame({'Union': untot, 'Nonunion': nuntot})\n",
    "data['Diff'] = data['Coverage'] - data['Membership']\n",
    "final = (data.rolling(12).mean().dropna() * 100)\n",
    "final.to_csv(data_dir / 'union.csv', index_label='date', float_format='%g')\n",
    "final2 = (levels.rolling(12).mean().dropna()) / 1000000\n",
    "\n",
    "ltdate = final.index[-1].strftime('%B %Y')\n",
    "prevdate = final.index[-13].strftime('%B %Y')\n",
    "prev2date = final.index[-25].strftime('%B %Y')\n",
    "\n",
    "ltval = final['Membership'].iloc[-1]\n",
    "prevval = final['Membership'].iloc[-13]\n",
    "prev2val = final['Membership'].iloc[-25]\n",
    "\n",
    "totvallt = final2['Union'].iloc[-1]\n",
    "totnvallt = final2['Nonunion'].iloc[-1]\n",
    "\n",
    "chlt = final2['Union'].diff(12).iloc[-1] * 1000000\n",
    "chpr = final2['Union'].diff(12).iloc[-13] * 1000000\n",
    "\n",
    "chnlt = final2['Nonunion'].diff(12).iloc[-1] * 1000000\n",
    "chnpr = final2['Nonunion'].diff(12).iloc[-13] * 1000000\n",
    "\n",
    "if chlt > 10:\n",
    "    chlt_txt = f'increased by {round(chlt, -3):,.0f}'\n",
    "elif chlt <= -10:\n",
    "    chlt_txt = f'decreased by {abs(round(chlt, -3)):,.0f}'\n",
    "else:\n",
    "    chlt_txt = 'were virtually unchanged'\n",
    "    \n",
    "if chnlt > 10:\n",
    "    chnlt_txt = f'increased by {round(chnlt, -3):,.0f}'\n",
    "elif chnlt <= -10:\n",
    "    chnlt_txt = f'decreased by {abs(round(chnlt, -3)):,.0f}'\n",
    "else:\n",
    "    chnlt_txt = 'were virtually unchanged'\n",
    "    \n",
    "text = (f'Over the 12 months ending {ltdate}, the share of jobs held '+\n",
    "        f'by union and employee association members averaged {ltval:.1f} percent. '+\n",
    "        f'In levels, there were {totvallt:.1f} million union jobs, and '+\n",
    "        f'{totnvallt:.1f} million nonunion jobs, on average over the period. '+\n",
    "        f'This union membership rate averaged {prevval:.1f} percent during the 12 '+\n",
    "        f'months ending {prevdate}, and {prev2val:.1f} percent during the 12 '+\n",
    "        f'months ending {prev2date}. Union jobs {chlt_txt} '+\n",
    "        f'from {prevdate} to {ltdate}, while nonunion jobs {chnlt_txt}.')\n",
    "write_txt(text_dir / 'union.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:10.289049Z",
     "start_time": "2022-03-10T15:22:06.641417Z"
    }
   },
   "outputs": [],
   "source": [
    "union_membership_rate = lambda x: np.average(x['UNIONMEM'], weights=x['PWORWGT']) * 100\n",
    "columns = ['MONTH', 'YEAR', 'LFS', 'PWORWGT', 'UNIONMEM', 'INDGRP']\n",
    "\n",
    "df = pd.concat([pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "                  .query('PWORWGT > 0 and UNIONMEM == UNIONMEM')\n",
    "      for year in range(1989, 2023)])\n",
    "\n",
    "df.INDGRP.cat = df.INDGRP.cat.remove_unused_categories()\n",
    "\n",
    "data = df.groupby(['YEAR', 'MONTH', 'INDGRP']).apply(union_membership_rate).unstack()\n",
    "data.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data.index]\n",
    "data.index.name = 'date'\n",
    "data.columns.name = None\n",
    "prev12 = data.iloc[-12:].mean()\n",
    "lval = data.iloc[-1]\n",
    "minval = data.min()\n",
    "maxval = data.max()\n",
    "width = maxval - minval\n",
    "final = pd.concat([lval, prev12, minval, maxval, width], axis=1)\n",
    "final.columns = ['latest', 'prev12', 'min', 'max', 'width']\n",
    "final.index.name = 'name'\n",
    "final = final[['min', 'width', 'latest']].sort_values('latest', ascending=False)\n",
    "final['y'] = [0.13, -0.87, -1.87, -2.87, -3.87, -4.87, -5.87]\n",
    "final.to_csv(data_dir / 'union_ind.csv', sep=';')\n",
    "\n",
    "dec = (maxval - lval).sort_values()\n",
    "dec1 = dec.index[-1]\n",
    "decval1 = dec[-1]\n",
    "decmaxdt = dtxt(data[dec1].idxmax())['mon1']\n",
    "decmaxval = data[dec1].max()\n",
    "decgrp = dec1.lower()\n",
    "lowgroupmaxdt = dtxt(data[final.index[-1]].idxmax())['mon1']\n",
    "lowgrp = final.index[-1].lower()\n",
    "\n",
    "\n",
    "text = (f'{final.index[0]} has the highest union membership rate, '+\n",
    "        f'at {final.latest.iloc[0]:.1f} percent as of {ltdate}, followed by '+\n",
    "        f'{final.index[1].lower()} with {final.latest.iloc[1]:.1f} percent, '+\n",
    "        f'and {final.index[2].lower()} with {final.latest.iloc[2]:.1f} percent. '+\n",
    "        f'The {decgrp} industry '+\n",
    "        'experienced the largest overall percentage point decrease '+\n",
    "        'in union membership rates over the past 30 years, and is '+\n",
    "        f'currently {decval1:.1f} percentage points below its {decmaxdt} '+\n",
    "        f'rate of {decmaxval:.1f} percent. ')\n",
    "txt2 = ('The lowest union membership rate '+\n",
    "        f'is in {lowgrp} ({final.latest.iloc[-1]:.1f} percent). '+\n",
    "        f'The union membership rate of the industry was {data[final.index[-1]].max():.1f} '+\n",
    "        f'percent at its 30-year peak in {lowgroupmaxdt}. ')\n",
    "\n",
    "mfglt = data['Manufacturing'].iloc[-1]\n",
    "mfgpr = data['Manufacturing'].iloc[-13]\n",
    "prdt = dtxt(data.index[-13])['mon1']\n",
    "mfgpr2 = data['Manufacturing'].iloc[-25]\n",
    "prdt2 = dtxt(data.index[-25])['mon1']\n",
    "\n",
    "txt3 = (f'The manufacturing industry union membership rate was {mfglt:.1f} percent in {ltdate}, '+\n",
    "        f'{mfgpr:.1f} percent in {prdt}, and {mfgpr2:.1f} percent in {prdt2}.')\n",
    "\n",
    "if lowgrp == decgrp:\n",
    "    text = text + txt3\n",
    "else:\n",
    "    text = text + txt2\n",
    "\n",
    "write_txt(text_dir / 'union_ind.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching YY -- Disability to Work Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:47.783009Z",
     "start_time": "2022-03-10T15:22:10.290211Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate monthly rate and store as raw file\n",
    "cols = ['CPSID', 'AGE', 'FEMALE', 'WBHAO', 'NILFREASON', \n",
    "        'LFS', 'MIS', 'BASICWGT', 'LINENO']\n",
    "emp = lambda x: np.where(x.LFS_y == 'Employed', 1, 0)\n",
    "dates = pd.date_range('1997-01-01', cps_date(), freq='MS')\n",
    "d = {}\n",
    "for dt in dates:\n",
    "    df1 = (cps_1mo(cps_dir, dt - pd.DateOffset(years=1), cols)\n",
    "           .query('NILFREASON == \"Disabled/Ill\"'))\n",
    "    df2 = cps_1mo(cps_dir, dt, cols)\n",
    "    data = (pd.merge(df1, df2, on=['CPSID', 'LINENO', 'FEMALE', \n",
    "                                   'WBHAO'])\n",
    "              .query('25 <= AGE_y <= 54'))\n",
    "    data = ((data.loc[(data.AGE_x <= data.AGE_y) & \n",
    "                      (data.AGE_y - 2 <= data.AGE_x)])\n",
    "                 .assign(EMP = emp))\n",
    "    d[dt] = np.average(data.EMP, weights=data.BASICWGT_y) * 100\n",
    "s = pd.Series(d).rename('Share')\n",
    "s.to_csv(data_dir / 'disflow_raw.csv', index_label='date', \n",
    "         header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:47.799410Z",
     "start_time": "2022-03-10T15:22:47.784043Z"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.read_csv(data_dir / 'disflow_raw.csv', \n",
    "                index_col='date', parse_dates=True)\n",
    "df = s.rolling(12).mean().dropna()['Share']\n",
    "df.to_csv(data_dir / 'disflow.csv', index_label='date', \n",
    "          header=True)\n",
    "color = 'blue'\n",
    "node = end_node(df, color, date='m', percent=True, \n",
    "                offset=True, size=1.2)\n",
    "write_txt(text_dir/ 'disflow_node.txt', node)\n",
    "\n",
    "latest = df.iloc[-1]\n",
    "valavg = df.loc['2010-12-01':'2013-12-01'].mean()\n",
    "val19 = df.loc['2019'].mean()\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "\n",
    "text = (f'Over the year ending {ltdate}, {latest:.1f} '+\n",
    "        'percent of 25 to 54 year olds who were out of '+\n",
    "        'the labor force due to disability or illness '+\n",
    "        f'one year prior became employed {c_line(color)}. '+\n",
    "        f'Pre-pandemic, in 2019, {val19:.1f} percent of '+\n",
    "        'those in the category found a job. '+\n",
    "        'The one-year rate of job-finding has increased '+\n",
    "        'substantially from its 2010--2013 average of '+\n",
    "        f'{valavg:.1f} percent.')\n",
    "write_txt(text_dir / 'disflow.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job switching rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:51.439652Z",
     "start_time": "2022-03-10T15:22:47.800355Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['YEAR', 'MONTH', 'SAMEEMP', 'BASICWGT', 'LFS']\n",
    "df = pd.concat([pd.read_feather(cps_dir / f'cps{year}.ft', columns=cols)\n",
    "                  .query('LFS == \"Employed\" and SAMEEMP in [0, 1]') \n",
    "                for year in range(1994, 2023)])\n",
    "newemp = (lambda x: x.query('SAMEEMP == 0').BASICWGT.sum()\n",
    "                 / x.BASICWGT.sum())\n",
    "\n",
    "data = (df.groupby(['YEAR', 'MONTH']).apply(newemp)).reset_index()\n",
    "data['date'] = pd.to_datetime(dict(year=data.YEAR, month=data.MONTH, day=1))\n",
    "data = data.set_index('date').drop(['YEAR', 'MONTH'], axis=1) * 100\n",
    "sm = x13_arima_analysis(data)\n",
    "res = pd.concat([sm.seasadj.rename('Monthly'), \n",
    "           sm.seasadj.rolling(3).mean().rename('MA3')], axis=1)\n",
    "res.to_csv(data_dir / 'jobswitch.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:51.449471Z",
     "start_time": "2022-03-10T15:22:51.441251Z"
    }
   },
   "outputs": [],
   "source": [
    "res = pd.read_csv(data_dir / 'jobswitch.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "qcol = 'blue!80!black'\n",
    "mcol = 'green!90!blue'\n",
    "node = end_node(res['Monthly'], mcol, date='m', percent=True)\n",
    "write_txt(text_dir/ 'jobswitch_node.txt', node)\n",
    "ltdate = dtxt(res.index[-1])['mon1']\n",
    "ltval = f'{res[\"Monthly\"].iloc[-1]:.1f} percent'\n",
    "ltqval = f'{res[\"MA3\"].iloc[-1]:.1f} percent'\n",
    "also = 'also ' if ltval == ltqval else ''\n",
    "ltq = f'the three months ending {ltdate}'\n",
    "pcdate = '2019-12-01'\n",
    "pcqval = f'{res[\"MA3\"].loc[pcdate]:.1f} percent'\n",
    "text = ('More recent data show a slight increase in job switching rates. '+\n",
    "        f'In {ltdate}, {ltval} of the workforce had a '+\n",
    "        'different employer than the previous month, after seasonal '+\n",
    "        f'adjustment {c_line(mcol)}. Smoothed data {also}show an average '+\n",
    "        f'of {ltqval} of the workforce with a new employer during {ltq} '+\n",
    "        f'{c_line(qcol)}. Prior to COVID-19, in {dtxt(pcdate)[\"qtr1\"]}, '+\n",
    "        f'a monthly average of {pcqval} of the workforce switched jobs.')\n",
    "write_txt(text_dir / 'jobswitch.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Young adults school/NILF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:22:54.277248Z",
     "start_time": "2022-03-10T15:22:51.450526Z"
    }
   },
   "outputs": [],
   "source": [
    "sch_stat = lambda x: np.where(x.NILFREASON == 'School', 'School',\n",
    "                     np.where(x.LFS == 'NILF', 'Other', 'LF'))\n",
    "age_grp = lambda x: np.where(x.AGE < 22, '19-21', '22-24')\n",
    "date = lambda x: pd.to_datetime(dict(year=x.YEAR, month=x.MONTH, day=1))\n",
    "\n",
    "datecol = ['YEAR', 'MONTH']\n",
    "cols = ['AGE', 'NILFREASON', 'BASICWGT', 'LFS'] + datecol\n",
    "\n",
    "df = pd.concat([pd.read_feather(cps_dir / f'cps{year}.ft', columns=cols)\n",
    "                  .query('18 < AGE < 25').assign(SCH_STAT = sch_stat, \n",
    "                                                 AGE_GRP = age_grp,\n",
    "                                                 DATE = date) \n",
    "                for year in range(1994, 2023)])\n",
    "\n",
    "res = pd.DataFrame()\n",
    "for ag in ['19-21', '22-24']:\n",
    "    td = df.query('AGE_GRP == @ag')\n",
    "    data = ((td.groupby(['DATE', 'SCH_STAT']).BASICWGT.sum() / \n",
    "             td.groupby('DATE').BASICWGT.sum()) * 100).unstack()\n",
    "    data.columns = [i + '_' + ag for i in data.columns]\n",
    "    data.columns.name = ''\n",
    "    data['Total_' + ag] = 100 - data['LF_' + ag]\n",
    "    data = data.drop('LF_' + ag, axis=1)\n",
    "    res = res.join(data, how='right')\n",
    "    \n",
    "ma = res.rolling(12).mean().dropna()\n",
    "ma.to_csv(data_dir/ 'young_school.csv', index_label='date')\n",
    "\n",
    "colors = [('School_', 'blue!50!cyan'),\n",
    "          ('Other_', 'violet!85!black')]\n",
    "\n",
    "for ag in ['19-21', '22-24']:\n",
    "    node_dt = None if ag == '22-24' else 'm'\n",
    "    nodeadj = 0 if ag == '22-24' else -0.25\n",
    "    node = end_node(ma['Total_' + ag], 'orange!90!yellow', percent=True,\n",
    "                    date=node_dt, offset=nodeadj, full_year=True)\n",
    "    nodes = '\\n'.join([node] + [end_node(ma[name + ag], color, percent=True) \n",
    "                       for name, color in colors])\n",
    "    write_txt(text_dir/ f'young_nilf{ag}_node.txt', nodes)\n",
    "    \n",
    "t0019 = f'{ma.loc[\"2000-12-01\", \"Total_19-21\"]:.1f}'\n",
    "t0022 = f'{ma.loc[\"2000-12-01\", \"Total_22-24\"]:.1f}'\n",
    "t1119 = f'{ma.loc[\"2014-12-01\", \"Total_19-21\"]:.1f}'\n",
    "t1122 = f'{ma.loc[\"2014-12-01\", \"Total_22-24\"]:.1f}'\n",
    "t1919 = f'{ma.loc[\"2020-02-01\", \"Total_19-21\"]:.1f}'\n",
    "t1922 = f'{ma.loc[\"2020-02-01\", \"Total_22-24\"]:.1f}'\n",
    "tlt19 = f'{ma.loc[cps_date(), \"Total_19-21\"]:.1f}'\n",
    "tlt22 = f'{ma.loc[cps_date(), \"Total_22-24\"]:.1f}'\n",
    "ltdate = dtxt(cps_date())['mon1']    \n",
    "text = ('From 1994 to 2000, labor force participation among young people '+\n",
    "        'increased slightly. Following the recession of 2001, and carrying '+\n",
    "        'through the great recession, participation rates dropped sharply. '+\n",
    "        'From 2000 to 2014, annual labor force non-participation increased '+\n",
    "        f'from {t0019} percent to {t1119} percent for 19 to 21 year olds '+\n",
    "        f'and from {t0022} percent to {t1122} percent for 22 to 24 year olds '+\n",
    "        '(see {\\color{orange!90!yellow}\\\\textbf{---}}). The overall '+\n",
    "        'increase is nearly entirely accounted for by increased college '+\n",
    "        'enrollment (see {\\color{blue!50!cyan}\\\\textbf{---}}).\\n\\nBy February '+\n",
    "        '2020, the labor market had improved and the annual non-participation '+\n",
    "        f'rate was {t1919} percent for 19 to 21 year olds and {t1922} '+\n",
    "        f'percent for 22 to 24 year olds. In the latest data, covering the '+\n",
    "        f'12 months ending {ltdate}, the rate of non-participation is {tlt19} '+\n",
    "        f'percent for 19 to 21 year olds and {tlt22} percent for 22 to 24 '+\n",
    "        'year olds. ')\n",
    "write_txt(text_dir / 'young_nilf.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPS Labor Force Nonparticipation by Reason\n",
    "\n",
    "Replication using python of a very clever chart by Ernie Tedeschi (@ernietedeschi).\n",
    "\n",
    "[Definitions](https://www.frbatlanta.org/chcs/human-capital-currents/2015/0612-measuring-labor-market-status-using-basic-data.aspx) of labor market status come from the FRB of Atlanta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:00.766251Z",
     "start_time": "2022-03-10T15:22:54.278272Z"
    }
   },
   "outputs": [],
   "source": [
    "years = range(2000, 2023)\n",
    "ref_pd = (2001, 3)\n",
    "ref_dt = to_date(ref_pd)\n",
    "ages = '18 <= AGE <= 64'\n",
    "wgt = 'BASICWGT'\n",
    "cat = 'NILFREASON'\n",
    "dates = ['YEAR', 'MONTH']\n",
    "dems = ['FEMALE', 'AGE']\n",
    "cols = dates + dems + [wgt, cat]\n",
    "files = [f'cps{year}.ft' for year in years]\n",
    "\n",
    "# CPS Data\n",
    "df = pd.concat([pd.read_feather(cps_dir / file, columns=cols)\n",
    "                  .query(ages) for file in files])\n",
    "\n",
    "p = df.groupby(dates + dems)[wgt].sum().rename('ADJ')\n",
    "sh = (p / p.groupby(dates).sum())\n",
    "adj = (sh.loc[ref_pd] / sh).reset_index()\n",
    "data = (pd.merge(df, adj)\n",
    "          .assign(ADJWGT = lambda x: x.ADJ * x[wgt]))\n",
    "data.NILFREASON.cat.rename_categories({'nan': 'LF'}, \n",
    "                                      inplace=True)\n",
    "\n",
    "# Make Adjustments\n",
    "c = data.groupby(dates + [cat]).ADJWGT.sum()\n",
    "dem_res = (c / c.groupby(dates).sum()).unstack()\n",
    "dem_res.columns = dem_res.columns.to_list()\n",
    "\n",
    "c_nd = data.groupby(dates + [cat])[wgt].sum()\n",
    "nd_res = (c_nd / c_nd.groupby(dates).sum()).unstack()\n",
    "\n",
    "dem_res['Demographics'] = dem_res['LF'] - nd_res['LF']\n",
    "dem_res.index = [to_date(ym) for ym in dem_res.index]\n",
    "\n",
    "keep_cols = dem_res.columns.difference(['LF'])\n",
    "result = (dem_res.rolling(12).mean().dropna()\n",
    "                 .loc[ref_dt:, keep_cols] * 100)\n",
    "\n",
    "final = result.iloc[0] - result\n",
    "final.to_csv(data_dir / 'nilf.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:00.805040Z",
     "start_time": "2022-03-10T15:23:00.767236Z"
    }
   },
   "outputs": [],
   "source": [
    "final = pd.read_csv(data_dir / 'nilf.csv', index_col='date', \n",
    "                    parse_dates=True)\n",
    "colors = {'Disabled/Ill': 'green!80!blue', \n",
    "          'Discouraged': 'blue', \n",
    "          'Family': 'red', \n",
    "          'Retired': 'orange', \n",
    "          'School': 'cyan', \n",
    "          'Demographics': 'violet!80!purple'}\n",
    "\n",
    "adj = node_adj(final)\n",
    "node_file = open(text_dir / 'nilf_nodes.txt', 'w')\n",
    "for series, color in colors.items():\n",
    "    if series in adj.keys():\n",
    "        offset = adj[series] / 2\n",
    "    else:\n",
    "        offset = 0\n",
    "    node_file.write(end_node(final[series], color, \n",
    "                             size=1.2, offset=offset))\n",
    "node_file.close()\n",
    "\n",
    "ltdate = dtxt(cps_date())['mon1']\n",
    "lt = final.iloc[-1]\n",
    "tot = abs(lt.sum())\n",
    "dem = abs(lt['Demographics'])\n",
    "demc = c_line(colors['Demographics'])\n",
    "sch = abs(lt['School'])\n",
    "schc = c_line(colors['School'])\n",
    "dis = abs(lt['Disabled/Ill'])\n",
    "disc = c_line(colors['Disabled/Ill'])\n",
    "ret = abs(lt['Retired'])\n",
    "retc = c_line(colors['Retired'])\n",
    "\n",
    "text = (f'From March 2001 to the latest available twelve months '+\n",
    "        f'of data, ending {ltdate}, an additional {tot:.1f} percent '+\n",
    "         'of the age 18--64 population left the labor force. Changes '+\n",
    "         'in the demographic composition of the population affect the '+\n",
    "         'rate of participation. For example, the larger-than-normal '+\n",
    "         'population cohort born after World War II is reaching '+\n",
    "         'retirement age in this period. Changes in the age and '+\n",
    "        f'sex distribution within the age group explain {dem:.1f} '+\n",
    "        f'percentage points of the cumulative decrease in participation '+ \n",
    "        f'since March 2001 {demc}. \\n\\nAdditionally, young people are '+\n",
    "        f'staying in school longer, on average, reducing the age 18--64 '+\n",
    "        f'labor force by {sch:.1f} percent {schc}. Disability and '+\n",
    "        f'illness reduce the labor force by another {dis:.1f} percent '+\n",
    "        f'{disc}. Less retirement among those age 18--64 increases the '+\n",
    "        f'labor force by {ret:.1f} percent, over the period {retc}.')\n",
    "write_txt(text_dir / 'nilf_01.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:00.934932Z",
     "start_time": "2022-03-10T15:23:00.806023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bar chart with NILF categories latest and pre-COVID\n",
    "result, share = pd.DataFrame(), pd.DataFrame()\n",
    "dts = [cps_date(), cps_date() - pd.DateOffset(years=2)]\n",
    "for i, date in enumerate(dts):\n",
    "    m = cps_1mo(cps_dir, date, cols + ['PWSSWGT']).query('AGE > 15')\n",
    "    dt = dtxt(date)['mon1']\n",
    "    result[dt] = m.groupby('NILFREASON').PWSSWGT.sum()\n",
    "    share[dt] = result[dt] / result[dt].sum() * 100\n",
    "    write_txt(text_dir / f'nilf_mo{i+1}.txt', dtxt(date)['mon2'])\n",
    "    \n",
    "(share.drop('nan').sort_values(share.columns[0], ascending=False)\n",
    " .round(1).to_csv(data_dir / 'nilf_comp.csv', index_label='name'))\n",
    "\n",
    "sh = share.applymap('{:.1f} percent'.format)\n",
    "res = result.applymap(lambda x: f'{x / 1_000_000:.1f} million')\n",
    "mo1, mo2 = sh.columns\n",
    "totlt = result[mo1].drop('nan').sum() / 1_000_000\n",
    "totsh = share[mo1].drop('nan').sum()\n",
    "shpr = share[mo2].drop('nan').sum()\n",
    "\n",
    "color = 'green!80!blue!72!black'\n",
    "color2 = 'green!80!blue!60!lime'\n",
    "\n",
    "ret = 'Retired'\n",
    "di = 'Disabled/Ill'\n",
    "fm = 'Family'\n",
    "sc = 'School'\n",
    "\n",
    "text = (f'Nonparticipants aged 16 and older total {totlt:.1f} '+\n",
    "        f'million in {mo1}, and make up {totsh:.1f} percent of the '+\n",
    "        f'age 16 or older population, compared to {shpr:.1f} '+\n",
    "        f'percent in {mo2}. About half of nonparticipants, and '+\n",
    "        f'{sh.loc[ret, mo1]} of the population, are '+\n",
    "        f'retirees in {mo1} {c_box(color)}, compared to '+\n",
    "        f'{sh.loc[ret, mo2]} percent in '+\n",
    "        f'{mo2} {c_box(color2)}.\\n\\nDisability or illness keeps an '+\n",
    "        f'additional {sh.loc[di, mo1]} '+\n",
    "        f'out of the labor force in {mo1}, compared to '+\n",
    "        f'{sh.loc[di, mo2]} in {mo2}. Students who are out of the '+\n",
    "        f'labor force make up {sh.loc[sc, mo1]} '+\n",
    "        f'in {mo1} and {sh.loc[sc, mo2]} in {mo2}, '+\n",
    "        f'while unpaid caregivers are {sh.loc[fm, mo1]} in {mo1} and '+\n",
    "        f'{sh.loc[fm, mo2]} in {mo2}.')\n",
    "write_txt(text_dir / 'nilfbasic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:01.463575Z",
     "start_time": "2022-03-10T15:23:00.935963Z"
    }
   },
   "outputs": [],
   "source": [
    "occs = {1   :  'Management occupations',\n",
    "        2   :  'Business and financial operations occupations',\n",
    "        3   :  'Computer and mathematical science occupations',\n",
    "        4   :  'Architecture and engineering occupations',\n",
    "        5   :  'Life, physical, and social science occupations',\n",
    "        6   :  'Community and social service occupations',\n",
    "        7   :  'Legal occupations',\n",
    "        8   :  'Education, training, and library occupations',\n",
    "        9   :  'Arts, design, entertainment, sports, and media',\n",
    "        10  :  'Healthcare practitioner and technical occupations',\n",
    "        11  :  'Healthcare support occupations',\n",
    "        12  :  'Protective service occupations',\n",
    "        13  :  'Food preparation and serving related occupations',\n",
    "        14  :  'Building and grounds cleaning and maintenance',\n",
    "        15  :  'Personal care and service occupations',\n",
    "        16  :  'Sales and related occupations',\n",
    "        17  :  'Office and administrative support occupations',\n",
    "        18  :  'Farming, fishing, and forestry occupations',\n",
    "        19  :  'Construction and extraction occupations',\n",
    "        20  :  'Installation, maintenance, and repair occupations',\n",
    "        21  :  'Production occupations',\n",
    "        22  :  'Transportation and material moving occupations'}\n",
    "\n",
    "cols = ['MONTH', 'YEAR', 'LFS', 'PWSSWGT', 'OCC03D', 'OCC203D', 'WORKFT', 'COW1', 'COW2']\n",
    "\n",
    "df = cps_3mo(cps_dir, cps_date(), cols)\n",
    "df2 = cps_3mo(cps_dir, cps_date() - pd.DateOffset(months=24), cols)\n",
    "\n",
    "df['OCC03D'] = df['OCC03D'].map(occs)\n",
    "df2['OCC03D'] = df2['OCC03D'].map(occs)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['FT'] = (((df.query('WORKFT == 1').groupby('OCC03D').PWSSWGT.sum() / df.PWSSWGT.sum()) - \n",
    "              (df2.query('WORKFT == 1').groupby('OCC03D').PWSSWGT.sum() / df.PWSSWGT.sum())) * 100)\n",
    "data['PT'] = (((df.query('WORKFT == 0').groupby('OCC03D').PWSSWGT.sum() / df.PWSSWGT.sum()) - \n",
    "              (df2.query('WORKFT == 0').groupby('OCC03D').PWSSWGT.sum() / df.PWSSWGT.sum())) * 100)\n",
    "data['Total'] = data.sum(axis=1)\n",
    "\n",
    "data.index = data.index.str.replace('occupations', '').str.replace('and', '\\&')\n",
    "\n",
    "data = data.sort_values('Total')\n",
    "data.drop('Total', axis=1).to_csv(data_dir / 'occs.csv', sep=';', index_label='name', header=True)\n",
    "\n",
    "data.drop('Total', axis=1).plot(kind='barh', stacked=True);\n",
    "\n",
    "data1 = data.drop('Total', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlanta Fed WGT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:32.773245Z",
     "start_time": "2022-03-10T15:23:01.464732Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['AGE', 'HRWAGE', 'ATLFLG', 'FEMALE', 'CPSID', 'WBHAO', \n",
    "        'LINENO', 'WKEARN']\n",
    "mergecol = ['CPSID', 'LINENO', 'FEMALE', 'WBHAO']\n",
    "filters = 'HRWAGE >= 2.13 and ATLFLG == 1'\n",
    "dates = pd.date_range('1997-01-01', cps_date(), freq='MS')\n",
    "d, d2, d3 = {}, {}, {}\n",
    "for dt in dates:\n",
    "    df1 = cps_1mo(cps_dir, dt - pd.DateOffset(years=1), \n",
    "                  cols).query(filters)\n",
    "    df2 = cps_1mo(cps_dir, dt, cols).query(filters)\n",
    "    data = (pd.merge(df1, df2, on=mergecol))\n",
    "    data = (data.loc[(data.AGE_x <= data.AGE_y) & \n",
    "                     (data.AGE_y - 2 <= data.AGE_x)])\n",
    "    wage_change_array = ((data['HRWAGE_y'] / data['HRWAGE_x']) - 1) * 100\n",
    "    wkpy_change_array = ((data['WKEARN_y'] / data['WKEARN_x']) - 1) * 100\n",
    "    d[dt] = wage_change_array.median()\n",
    "    d3[dt] = wkpy_change_array.median()\n",
    "    zwc = (len(wage_change_array[(wage_change_array >= -0.5) & \n",
    "                                 (wage_change_array <= 0.5)]) / \n",
    "           len(wage_change_array)) * 100\n",
    "    d2[dt] = zwc\n",
    "\n",
    "result = pd.Series(d, name='bd_cps').to_frame()\n",
    "result['3ma'] = result.rolling(3).mean()\n",
    "result['wk'] = pd.Series(d3, name='wkpy').to_frame()\n",
    "result['wk3ma'] = result['wk'].rolling(3).mean()\n",
    "result['zwc'] = pd.Series(d2).rolling(3).mean()\n",
    "result.to_csv(data_dir/ 'atl_wgt.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:32.786591Z",
     "start_time": "2022-03-10T15:23:32.774213Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'atl_wgt.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "ltval = df['bd_cps'].iloc[-1]\n",
    "lt3m = df['3ma'].iloc[-1]\n",
    "yrdt = dtxt(df.index[-13])['mon1']\n",
    "pr3m = df['3ma'].iloc[-13]\n",
    "also = 'also' if round(lt3m) == round(pr3m) else ''\n",
    "\n",
    "col = 'orange!60!white'\n",
    "col3 = 'blue!75!cyan'\n",
    "wval = value_text(df.wk.iloc[-1])\n",
    "text = ('Replication of the wage growth tracker '+\n",
    "        'shows matched-observation hourly wage '+\n",
    "        f'growth of {ltval:.1f} percent in {ltdt} {c_line(col)}, '+\n",
    "        f'and average wage growth of {lt3m:.1f} percent over '+\n",
    "        f'the three months ending {ltdt} {c_line(col3)}. '+\n",
    "        f'One year prior, in {yrdt}, three-month moving average '+\n",
    "        f'wage growth was {also}{pr3m:.1f} percent. Matched '+\n",
    "        'observation weekly wage growth, which is affected '+\n",
    "        f'by changes in hours worked, {wval} over the year '+\n",
    "        f'ending {ltdt} (see right chart).')\n",
    "write_txt(text_dir / 'atl_wgt.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval = df['zwc'].iloc[-1]\n",
    "prval = df['zwc'].iloc[-2]\n",
    "prdate = dtxt(df.index[-2])['mon1']\n",
    "yrval = df['zwc'].iloc[-13]\n",
    "\n",
    "zcol = 'red'\n",
    "node = end_node(df['zwc'], zcol, date='m', \n",
    "                full_year=True, percent=True)\n",
    "write_txt(text_dir/ 'zwc_node.txt', node)\n",
    "\n",
    "text = (f'In {ltdt}, {ltval:.1f} '+\n",
    "        'percent of individuals had no hourly wage growth, '+\n",
    "        f'compared to {prval:.1f} in {prdate} {c_line(zcol)}. '+\n",
    "        f'One year prior, in {yrdt}, {yrval:.1f} percent of '+\n",
    "        'individuals had no wage growth.')\n",
    "write_txt(text_dir / 'atl_zwc.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment Rate for Smaller Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:33.137473Z",
     "start_time": "2022-03-10T15:23:32.788324Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['YEAR', 'MONTH', 'WBHAOM', 'BASICWGT', 'LFS', 'AGE', 'FEMALE']\n",
    "groups = ['White', 'Black', 'Hispanic', 'Asian', 'Native American', 'More than one']\n",
    "\n",
    "unrate = lambda x: np.average(x['UNEMP'], weights=x['BASICWGT']) * 100\n",
    "unsh = lambda x: (x['UNEMP'] * x['BASICWGT']).sum()\n",
    "unemp = lambda x: np.where(x['LFS'] == 'Unemployed', 1, \n",
    "                  np.where(x['LFS'] == 'Employed', 0, np.nan))\n",
    "\n",
    "\n",
    "df, df2, df3 = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "for dt in [cps_date(), cps_date() - pd.DateOffset(months=24)]:\n",
    "    data = (cps_6mo(cps_dt=pd.to_datetime(dt), cols=cols, cps_dir=cps_dir)\n",
    "            .assign(UNEMP = unemp)\n",
    "            .query('AGE > 15 and AGE < 65 and LFS != \"NILF\"'))\n",
    "    \n",
    "    srs = data.groupby('WBHAOM').apply(unrate)\n",
    "    df[dtxt(dt)['mon2']] = srs.loc[groups]\n",
    "    \n",
    "    unemptot = (data['UNEMP'] * data['BASICWGT']).sum()\n",
    "    srs2 = (data.groupby('WBHAOM').apply(unsh) / unemptot) * 100\n",
    "    df2[dtxt(dt)['mon2']] = srs2.loc[groups]\n",
    "    pop = data.BASICWGT.sum()\n",
    "    popsh = (data.groupby('WBHAOM').BASICWGT.sum() / pop) * 100\n",
    "    df3[dtxt(dt)['mon2']] = popsh.loc[groups]\n",
    "\n",
    "df.index.name = ''\n",
    "df.to_csv(data_dir / 'unemp_grp.csv', index_label='name', header=True)\n",
    "df2.index.name = ''\n",
    "df2['pop'] = df3.mean(axis=1)\n",
    "df2.to_csv(data_dir / 'unemp_grpsh.csv', index_label='name', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:39.945132Z",
     "start_time": "2022-03-10T15:23:33.138478Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['MONTH', 'YEAR', 'LFS', 'PWSSWGT', 'AGE', 'WBHAOM', 'FEMALE']\n",
    "df1 = cps_6mo(cps_dir, cps_date() - pd.DateOffset(months=24), cols)\n",
    "df2 = cps_6mo(cps_dir, cps_date(), cols)\n",
    "\n",
    "ages = [(18, 64), (25, 54), (16, 24), (25, 34), (35, 44), (45, 54), (55, 64), (65, 74)]\n",
    "groups = ['White', 'Black', 'Hispanic', 'Asian', 'Native American', 'More than one']\n",
    "sex = [[0], [1], [0, 1]] \n",
    "\n",
    "results = pd.DataFrame()\n",
    "for a, g, s in itertools.product(ages, groups, sex):\n",
    "    row_name = f'{a[0]}--{a[1]}'\n",
    "    col_name = f'{g} {[\"Female\" if s == [1] else \"Male\" if s == [0] else \"Total\"][0]}'\n",
    "    for yr, df in [('Year Ago', df1), ('Latest', df2)]:\n",
    "        data = df.query('@a[0] <= AGE <= @a[1] and WBHAOM == @g and FEMALE in @s')\n",
    "        i = data.groupby('LFS').PWSSWGT.sum()\n",
    "        results.loc[row_name, f'{yr} {col_name}'] = (i.Unemployed / (i.Unemployed + i.Employed)) * 100\n",
    "        \n",
    "results.iloc[:, :-12].to_csv(data_dir / 'unempgroups.csv', index_label='name')\n",
    "results.iloc[:2, -12:].to_csv(data_dir / 'unempgroups2.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:40.978583Z",
     "start_time": "2022-03-10T15:23:39.946165Z"
    }
   },
   "outputs": [],
   "source": [
    "ages = [(18, 64), (25, 54), (16, 24), (25, 34), (35, 44), (45, 54), (55, 64), (65, 74)]\n",
    "sex = [[0], [1], [0, 1]] \n",
    "\n",
    "results = pd.DataFrame()\n",
    "for a, s in itertools.product(ages, sex):\n",
    "    row_name = f'{a[0]}--{a[1]}'\n",
    "    col_name = f'{[\"Female\" if s == [1] else \"Male\" if s == [0] else \"Total\"][0]}'\n",
    "    for yr, df in [('Year Ago', df1), ('Latest', df2)]:\n",
    "        data = df.query('@a[0] <= AGE <= @a[1] and FEMALE in @s')\n",
    "        i = data.groupby('LFS').PWSSWGT.sum()\n",
    "        results.loc[row_name, f'{yr} {col_name}'] = (i.Unemployed / (i.Unemployed + i.Employed)) * 100\n",
    "        \n",
    "results.to_csv(data_dir / 'unempgroups3.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usual hours worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:23:41.707996Z",
     "start_time": "2022-03-10T15:23:40.979474Z"
    }
   },
   "outputs": [],
   "source": [
    "hrs = lambda x: np.where(x.HRSUSL1 == -4, x.HRSUSL1I,\n",
    "                np.where(x.HRSUSL1 > 0, x.HRSUSL1,\n",
    "                         np.nan))\n",
    "\n",
    "wgt_avg = lambda x: np.average(x.HRS, weights=x.BASICWGT)\n",
    "\n",
    "cols = ['HRSUSL1', 'HRSUSL1I', 'BASICWGT', 'LFS', 'YEAR', 'MONTH']\n",
    "\n",
    "data = pd.concat([(pd.read_feather(f'{cps_dir}/cps{year}.ft', columns=cols)\n",
    "                     .assign(HRS = hrs).query('HRS > 0'))\n",
    "                  for year in range(2018, 2023)])\n",
    "\n",
    "grp_data = data.groupby(['YEAR', 'MONTH']).apply(wgt_avg)\n",
    "grp_data.index = [to_date(ym) for ym in grp_data.index]\n",
    "\n",
    "sa_cps = x13_arima_analysis(grp_data).seasadj\n",
    "\n",
    "sa_cps.to_csv(data_dir / 'uslhrs.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:24:14.109304Z",
     "start_time": "2022-03-10T15:23:41.709327Z"
    }
   },
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "years = range(1989, 2023)\n",
    "compdt = (2000, 1)\n",
    "dates = ['YEAR', 'MONTH']\n",
    "dems = ['AGE', 'FEMALE']\n",
    "cols = dates + ['AGE', 'FEMALE', 'BASICWGT', 'LFS']\n",
    "files = [f'cps{year}.ft' for year in years]\n",
    "sex = [('Men', [0]), ('Women', [1]), ('Total', [0, 1])]\n",
    "for name, grp in sex:\n",
    "    query = 'AGE >= 16 and FEMALE in @grp'\n",
    "    # CPS Data\n",
    "    df = pd.concat([pd.read_feather(cps_dir / file, columns=cols)\n",
    "                      .query(query) for file in files])\n",
    "    p = df.groupby(dates + dems)[wgt].sum().rename('ADJ')\n",
    "    sh = (p / p.groupby(dates).sum())\n",
    "    adj = (sh.loc[compdt] / sh).reset_index()\n",
    "    data = (pd.merge(df, adj)\n",
    "              .assign(ADJWGT = lambda x: x.ADJ * x[wgt]))\n",
    "    wgts = ['BASICWGT', 'ADJWGT']\n",
    "    res = pd.DataFrame({wgt: (1 - (data.groupby(dates + ['LFS'])[wgt].sum() / \n",
    "                                   data.groupby(dates)[wgt].sum())\n",
    "                              .unstack()['NILF']\n",
    "                             ).multiply(100).dropna()\n",
    "                  for wgt in wgts})\n",
    "    res.index = [to_date(ym) for ym in res.index]\n",
    "    sa = pd.DataFrame({f'{i}_{name}': x13_arima_analysis(res[i]).seasadj \n",
    "                       for i in wgts})    \n",
    "    final = pd.concat([final, sa], axis=1)\n",
    "final.to_csv(data_dir / 'lfpr_adj.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T15:24:14.123142Z",
     "start_time": "2022-03-10T15:24:14.111018Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'lfpr_adj.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "write_txt(text_dir / 'lfpr_cpsdate.txt', ltdt)\n",
    "colors = {'Total': 'green!70!lime', 'Men': 'blue!40!cyan', \n",
    "          'Women': 'orange!40!yellow'}\n",
    "nodes = (end_node(df['ADJWGT_Men'], colors['Men'], \n",
    "                  percent=True, date='m', full_year=True, \n",
    "                  offset=0.35) + '\\n' + \n",
    "         '\\n'.join(end_node(df[f'ADJWGT_{name}'], color, \n",
    "                            percent=True) \n",
    "                   for name, color in colors.items() \n",
    "                   if name != 'Men'))\n",
    "write_txt(text_dir / 'lfpr_nodes_adj.txt', nodes)\n",
    "\n",
    "lt = final.iloc[-1]\n",
    "diffval = lt['ADJWGT_Total'] - lt['BASICWGT_Total']\n",
    "text = ('Reweighting the population to match the '+\n",
    "        f'age composition in {compdt[0]} suggests the aging '+\n",
    "        f'of the US population since {compdt[0]} has reduced '+\n",
    "        f'total labor force participation by {diffval:.1f} '+\n",
    "        f'percentage points. ')\n",
    "write_txt(text_dir / 'lfpr_adj.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:02:24.796172Z",
     "start_time": "2022-03-14T23:02:24.793873Z"
    }
   },
   "source": [
    "### Self Employment pre-2000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-14T23:35:46.206938Z",
     "start_time": "2022-03-14T23:35:45.019789Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['MONTH', 'YEAR', 'AGE', 'LFS', 'COW1', 'BASICWGT']\n",
    "data = pd.concat([(pd.read_feather(f'{cps_dir}/cps{year}.ft', columns=cols)\n",
    "                     .query('LFS in [\"Employed\", \"Unemployed\"]'))\n",
    "                  for year in range(1989, 2001)])\n",
    "inc = lambda x: np.where((x.COW1 == \"Self-employed Incorporated\") \n",
    "                         & (x.LFS == \"Employed\"), x.BASICWGT, 0)\n",
    "data = data.assign(INC = inc)\n",
    "grp_data = data.groupby(['YEAR', 'MONTH']).INC.sum()\n",
    "grp_data.index = [to_date(ym) for ym in grp_data.index]\n",
    "grp_data.to_csv(data_dir / 'se_inc_hist.csv', index_label='date', \n",
    "                header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wages and Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T04:44:06.944116Z",
     "start_time": "2022-03-20T04:43:54.919911Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['MONTH', 'YEAR', 'AGE', 'EDUC', 'PWORWGT', 'WKEARN', 'WORKFT', \n",
    "        'PRICEADJ']\n",
    "edgrp = lambda x: np.where((x.EDUC.isin(['LTHS', 'HS'])), 'LTHS/HS',\n",
    "                  np.where((x.EDUC == 'SC'), 'SC', 'COLL/ADV'))\n",
    "rw = lambda x: x.WKEARN * x.PRICEADJ\n",
    "df = pd.concat([(pd.read_feather(f'{cps_dir}/cps{year}.ft', columns=cols)\n",
    "                     .query('WKEARN > 0 and WORKFT == 1 and 25 <= AGE <= 54')\n",
    "                     .assign(EDGRP = edgrp, RW = rw))\n",
    "                  for year in range(1989, 2023)])\n",
    "\n",
    "ed = df.groupby(['YEAR', 'MONTH', 'EDGRP']).PWORWGT.sum().unstack()\n",
    "ed.index = [pd.to_datetime(f'{i[0]}-{i[1]}-01') for i in ed.index]\n",
    "ed = ed.divide(ed.sum(axis=1), axis=0)\n",
    "df = df.merge((ed.loc['2019'].mean() / ed.iloc[-1]).reset_index())\n",
    "df['ADJWGT'] = df['PWORWGT'] * df[0]\n",
    "\n",
    "data = (df.groupby(['YEAR', 'MONTH', 'EDGRP'])\n",
    "          .apply(binned_wage, wage_var='RW', percentile=0.5).unstack())\n",
    "data.index = [pd.to_datetime(f'{i[0]}-{i[1]}-01') for i in data.index]\n",
    "data2 = (df.groupby(['YEAR', 'MONTH'])\n",
    "           .apply(binned_wage, wage_var='RW', percentile=0.5))\n",
    "data2.index = [pd.to_datetime(f'{i[0]}-{i[1]}-01') for i in data2.index]\n",
    "data['Total'] = data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-20T22:25:48.229490Z",
     "start_time": "2022-03-20T22:25:48.185442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the three months ending February 2022, the median usual earnings of full-time wage and salary workers age 25--54 averaged \\$1,095 per week. After adjusting for inflation, these earnings have increased by 11.5 percent, in total, since 1989. Digging deeper, the workforce is split into three groups by highest level of education attained. Real earnings increased 8.6 percent over the same period for workers with bachelor's degree or more, decreased 8.2 percent for workers with some college or an associate degree, and decreased 0.6 percent for those with a high school degree or less.\n",
      "Real wage growth is tied to changes in education, even in the short-term. While real wage growth since 2019 has been uneven, the majority of the overall increase can be explained by increases in the education level of the workforce.\n",
      "Since 2019, real wage growth was strongest for workers with a high school degree or less. The real wages of full-time wage and salary workers age 25--54 with a high school degree or less increased 3.6 percent, in total, from 2019 to February 2022 (see\\cbox{green!70!blue}). Real wages of the equivalent group with a bachelor's degree or more increased three percent. Real wages decreased 0.5 percent for those with some college and no degree or an associate degree. \n",
      "\n",
      "Combining the education groups, total real wage growth for full-time workers age 25--54 with any education level was 5.5 percent. Of this, 3.2 percentage points are explained by increases in the \\textbf{education-level composition} of the overall group. \n"
     ]
    }
   ],
   "source": [
    "cdt = pd.read_csv(data_dir / 'cpi.csv', index_col='date', parse_dates=True).index[-1]\n",
    "data = data.loc[:cdt]\n",
    "cq = f'MONTH == {cdt.month} and YEAR == {cdt.year}'\n",
    "rwe = binned_wage(df.query(cq), wage_var='RW', percentile=0.5, wgt_var='ADJWGT')\n",
    "val19 = data.loc['2019'].mean()\n",
    "vallt = data.iloc[-1]\n",
    "res = (((vallt / val19) - 1) * 100).rename('Total').to_frame()\n",
    "res['Composition'] = 0\n",
    "rev = (((rwe / val19.Total) - 1) * 100)\n",
    "res.loc['Total', 'Composition'] = res.loc['Total', 'Total'] - rev\n",
    "res['Value'] = res['Total'] - res['Composition']\n",
    "names = {'COLL/ADV': \"Bachelor's degree or more\",\n",
    "         'LTHS/HS': 'High school degree or less',\n",
    "         'SC': 'Some college or associate degree',\n",
    "         'Total': 'Any education level'}\n",
    "res.rename(names).to_csv(data_dir / 'educ_wage_bar.csv', index_label='group')\n",
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "write_txt(text_dir / 'rw_cpsdate.txt', ltdt)\n",
    "\n",
    "d3m = data.rolling(3).mean().dropna()\n",
    "d3m.to_csv(data_dir / 'educ_wage.csv', index_label='date')\n",
    "adj = node_adj(d3m)\n",
    "smax = d3m.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "cols = {'COLL/ADV': 'green!80!blue', \n",
    "        'LTHS/HS': 'blue!90!cyan',\n",
    "        'SC': 'cyan',\n",
    "        'Total': 'orange!70!yellow'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in cols.keys()}\n",
    "nodes  ='\\n'.join([end_node(d3m[series], color, \n",
    "                            date=date[series], \n",
    "                            full_year=True, dollar=True,\n",
    "                            digits='comma',\n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in cols.items()])\n",
    "write_txt(text_dir / 'educ_wage_nodes.txt', nodes) \n",
    "ch = ((d3m / d3m.iloc[0]) - 1) * 100\n",
    "ltdt = dtxt(cdt)['mon1']\n",
    "chlt = ch.iloc[-1]\n",
    "totlt = d3m.Total.iloc[-1]\n",
    "\n",
    "totch = value_text(chlt.Total, 'increase_by')\n",
    "bach = value_text(chlt['COLL/ADV'])\n",
    "scch = value_text(chlt['SC'])\n",
    "hsch = value_text(chlt['LTHS/HS'])\n",
    "\n",
    "text = (f'Over the three months ending {ltdt}, the median '+\n",
    "        'usual earnings of full-time wage and salary workers '+\n",
    "        f'age 25--54 averaged \\${totlt:,.0f} per week. After '+\n",
    "        f'adjusting for inflation, these earnings have {totch}, '+\n",
    "        'in total, since 1989. Digging deeper, the workforce is split '+\n",
    "        'into three groups by highest level of education attained. '+\n",
    "        f'Real earnings {bach} over the same period for workers '+\n",
    "        f\"with bachelor's degree or more, {scch} for workers with \"+\n",
    "        f'some college or an associate degree, and {hsch} for '+\n",
    "        'those with a high school degree or less.')\n",
    "write_txt(text_dir / 'educ_wage1.txt', text)\n",
    "print(text)\n",
    "\n",
    "size = ('the majority' \n",
    "        if res.loc['Total', 'Composition'] > res.loc['Total', 'Value'] \n",
    "        else 'much')\n",
    "even = ('While real wage growth since 2019 has been uneven' \n",
    "        if (res.drop('Total').Total.max() - res.drop('Total').Total.min()) > 2\n",
    "        else ('While wage growth since 2019 has been fairly even '+\n",
    "        'among education groups,'))\n",
    "text = ('Real wage growth is tied to changes in education, even in '+\n",
    "        f'the short-term. {even}, {size} of the overall '+\n",
    "        'increase can be explained by increases in the education '+\n",
    "        'level of the workforce.')\n",
    "write_txt(text_dir / 'educ_wage2.txt', text)\n",
    "print(text)\n",
    "\n",
    "names2 = {'COLL/ADV': \"a bachelor's degree or more\",\n",
    "          'LTHS/HS': 'a high school degree or less',\n",
    "          'SC': 'some college and no degree or an associate degree'}\n",
    "tot = res.drop('Total').rename(names2).Total.sort_values()\n",
    "cat1 = tot.index[2]\n",
    "cat1ch = value_text(tot.iloc[2])\n",
    "cat2 = tot.index[1]\n",
    "cat2ch = value_text(tot.iloc[1])\n",
    "cat3 = tot.index[0]\n",
    "cat3ch = value_text(tot.iloc[0])\n",
    "tot = res.loc['Total', 'Total']\n",
    "comp = res.loc['Total', 'Composition']\n",
    "text = (f'Since 2019, real wage growth was strongest for workers with {cat1}. '+\n",
    "        'The real wages of full-time wage and salary workers age 25--54 '+\n",
    "        f'with {cat1} {cat1ch}, in total, from 2019 to '+\n",
    "        f'{ltdt} {c_box(\"green!70!blue\")}. Real wages of the equivalent '+\n",
    "        f'group with {cat2} {cat2ch}. Real wages {cat3ch} for those '+\n",
    "        f'with {cat3}. '+\n",
    "        '\\n\\nCombining the education groups, total real wage growth for '+\n",
    "        'full-time workers age 25--54 with any education level was '+\n",
    "        f'{tot:.1f} percent. Of this, {comp:.1f} percentage points are '+\n",
    "        'explained by increases in the \\\\textbf{education-level '+\n",
    "        'composition} of the overall group. ')\n",
    "write_txt(text_dir / 'educ_wage3.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
