{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import requests\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/brian/Documents/CPS/data/clean/'\n",
    "\n",
    "cols = ['LFS', 'BASICWGT', 'PWSSWGT', 'AGE', 'MONTH', 'YEAR', 'FEMALE']\n",
    "\n",
    "df = pd.concat([pd.read_feather(f'{path}cps{year}.ft', columns=cols) \n",
    "                for year in range(1989, 2020)], sort=False)\n",
    "\n",
    "df['WGT'] = np.where(df['YEAR'] > 1993, df['PWSSWGT'], df['BASICWGT'])\n",
    "df['DATE'] = pd.to_datetime(dict(year=df.YEAR, month=df.MONTH, day=1))\n",
    "data = df.groupby(['DATE', 'LFS']).WGT.sum().unstack().rename({'nan': 'Children'}, axis=1) / 1000000\n",
    "file = '/home/brian/Documents/uschartbook/chartbook/data/cps_lfs.csv'\n",
    "data.to_csv(file, index_label='date')\n",
    "\n",
    "datelt = data.index[-1].strftime('%B %Y')\n",
    "\n",
    "datepr = f\"{data.index[-13].strftime('%B %Y')} to {datelt}\"\n",
    "\n",
    "write_txt(text_dir / 'cps_lfs_date.txt', datelt)\n",
    "\n",
    "write_txt(text_dir / 'cps_lfs_datepr.txt', datepr)\n",
    "\n",
    "epop = data[\"Employed\"].iloc[-1] / data.iloc[-1].sum() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of December 2019, there are 5.6 million unemployed people. The combined group of employed and unemployed people is the labor force. The number of unemployed people divided by the number of people in the labor force is the unemployment rate, currently 3.4 percent. The number of people in the labor force divided by the total population is the labor force participation rate, currently 50.8 percent.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (f'As of {datelt}, {data[\"Employed\"].iloc[-1]:.1f} million '+\n",
    "        'people are employed (including self-employment). ')\n",
    "\n",
    "file = '/home/brian/Documents/uschartbook/chartbook/text/cps_lfs0.txt'\n",
    "with open(file, 'w') as wf:\n",
    "    wf.write(text)\n",
    "\n",
    "\n",
    "text = ('Labor provided within a household is not captured by GDP compilation '+\n",
    "        'methods (expenditures, output, or income), though household surveys '+\n",
    "        'offer some insight into this important category of labor. The '+\n",
    "        'number of people who are considered employed divided by the total '+\n",
    "        'population is the employment rate or employment-to-population ratio, '+\n",
    "        f'which is {epop:.1f} percent as of {datelt}.')\n",
    "\n",
    "\n",
    "file = '/home/brian/Documents/uschartbook/chartbook/text/cps_lfs.txt'\n",
    "with open(file, 'w') as wf:\n",
    "    wf.write(text)\n",
    "\n",
    "unemp = (data[\"Unemployed\"].iloc[-1] / (data[\"Unemployed\"].iloc[-1] + data[\"Employed\"].iloc[-1])) * 100\n",
    "lfpr = (data[\"Unemployed\"].iloc[-1] + data[\"Employed\"].iloc[-1]) / data.iloc[-1].sum() * 100\n",
    "\n",
    "text = (f'As of {datelt}, there are {data[\"Unemployed\"].iloc[-1]:.1f} million '+\n",
    "        'unemployed people. The combined group of employed and unemployed people '+\n",
    "        'is the labor force. The number of unemployed people divided by the number '+\n",
    "        f'of people in the labor force is the unemployment rate, currently {unemp:.1f} percent. '+\n",
    "        'The number of people in the labor force divided by the total population is the '+\n",
    "        f'labor force participation rate, currently {lfpr:.1f} percent.')\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/brian/Documents/uschartbook/chartbook/text/cps_lfs2.txt'\n",
    "with open(file, 'w') as wf:\n",
    "    wf.write(text)\n",
    "    \n",
    "cols2 = cols + ['NILFREASON']\n",
    "\n",
    "datalt = pd.read_feather(f'{path}cps2019.ft', columns=cols2)\n",
    "\n",
    "student = (datalt.query('MONTH == 12 and NILFREASON == \"School\"').PWSSWGT.sum() / 1000000)\n",
    "care = (datalt.query('MONTH == 12 and NILFREASON == \"Family\"').PWSSWGT.sum() / 1000000)\n",
    "disill = (datalt.query('MONTH == 12 and NILFREASON == \"Disabled/Ill\"').PWSSWGT.sum() / 1000000)\n",
    "disc = (datalt.query('MONTH == 12 and NILFREASON == \"Discouraged\"').PWSSWGT.sum() / 1000000)\n",
    "ret = (datalt.query('MONTH == 12 and NILFREASON == \"Retired\"').PWSSWGT.sum() / 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This category is about half of the population, on average, and totals 159.9 million in December 2019. The category is comprised of children (60.7 million), students (19.0 million), unpaid caregivers (12.0 million), those unable to work due to disability or illness (14.6 million), those who want a job but have given up looking (4.3 million), and retirees and the elderly (47.3 million).\n"
     ]
    }
   ],
   "source": [
    "nilfpop = data[['NILF', 'Children']].iloc[-1].sum()\n",
    "text = ('This category is about half of the population, on average, and '+\n",
    "        f'totals {nilfpop:.1f} million in {datelt}. The '+\n",
    "        f'category is comprised of children ({data[\"Children\"].iloc[-1]:.1f}'+\n",
    "        f' million), students ({student:.1f} million), unpaid caregivers '+\n",
    "        f'({care:.1f} million), those unable to work due to disability or illness '+\n",
    "        f'({disill:.1f} million), those who want a job but have given up looking ({disc:.1f} '+\n",
    "        f'million), and retirees and the elderly ({ret:.1f} million).')\n",
    "\n",
    "file = '/home/brian/Documents/uschartbook/chartbook/text/cps_lfs3.txt'\n",
    "with open(file, 'w') as wf:\n",
    "    wf.write(text)\n",
    "    \n",
    "data['Total'] = data[['Employed', 'Unemployed', 'NILF']].sum(axis=1)\n",
    "result = data.drop('Children', axis=1).resample('QS').mean()\n",
    "\n",
    "file = '/home/brian/Documents/uschartbook/chartbook/data/cps_lfs2.csv'\n",
    "growth_contrib_ann(result, 'Total').to_csv(file, index_label='date')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LFS Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['LFS', 'PWSSWGT', 'PWSSWGT', 'AGE', 'MONTH', 'YEAR', 'MJH',\n",
    "        'FEMALE', 'NILFREASON', 'UNEMPTYPE', 'PTECON', 'WORKFT']\n",
    "\n",
    "df = pd.read_feather(f'{path}cps2019.ft', columns=cols).query('AGE >= 15 and MONTH == 12')\n",
    "df2 = pd.read_feather(f'{path}cps2018.ft', columns=cols).query('AGE >= 15 and MONTH == 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups = [(15, 30), (30, 60), (60, 86)]\n",
    "sex = [0, 1]\n",
    "d = {'Population': {'query': 'PWSSWGT > 0'}, \n",
    "     '\\hspace{2mm}Employed': {'query': 'LFS == \"Employed\"'}, \n",
    "     '\\hspace{4mm}Multiple jobs': {'query': 'MJH == 1'},     \n",
    "     '\\hspace{4mm}Full-time': {'query': 'WORKFT == 1'},  \n",
    "     '\\hspace{4mm}Part-time': {'query': 'WORKFT == 0'}, \n",
    "     '\\hspace{6mm}Economic reasons': {'query': 'PTECON == 1'},\n",
    "     '\\hspace{2mm}Unemployed': {'query': 'LFS == \"Unemployed\"'}, \n",
    "     '\\hspace{2mm}Not in Labor Force': {'query': 'LFS == \"NILF\"'}, \n",
    "     '\\hspace{4mm}Discouraged': {'query': 'NILFREASON == \"Discouraged\"'}, \n",
    "     '\\hspace{4mm}Disabled/Ill': {'query': 'NILFREASON == \"Disabled/Ill\"'}, \n",
    "     '\\hspace{4mm}Family/Care': {'query': 'NILFREASON == \"Family\"'}, \n",
    "     '\\hspace{4mm}School': {'query': 'NILFREASON == \"School\"'}, \n",
    "     '\\hspace{4mm}Retirement': {'query': 'NILFREASON == \"Retired\"'}}\n",
    "\n",
    "d2 = {k: {} for k, v in d.items()}\n",
    "\n",
    "lf_groups = list(zip(d.keys(), [d[i]['query'] for i in d.keys()])) \n",
    "\n",
    "for name, query in lf_groups:\n",
    "    totval = df.query(query).PWSSWGT.sum()/1000\n",
    "    d[name]['Total, 15+'] = f'{totval:,.0f}'\n",
    "    chval = totval - df2.query(query).PWSSWGT.sum()/1000\n",
    "    d2[name]['Total, 15+'] = f'{chval:,.0f}'\n",
    "\n",
    "for sex, (agemin, agemax) in itertools.product(sex, age_groups):\n",
    "    data = df.query('@agemin <= AGE < @agemax and FEMALE == @sex')\n",
    "    data2 = df2.query('@agemin <= AGE < @agemax and FEMALE == @sex')\n",
    "    group = f'{[\"Women\" if sex==1 else \"Men\"][0]}, {agemin}--{agemax-1}'.replace('--85', '+')\n",
    "    for name, query in lf_groups:\n",
    "        tmp = data.query(query).PWSSWGT.sum()/1000\n",
    "        tmp2 = data2.query(query).PWSSWGT.sum()/1000\n",
    "        d[name][group] = f'{tmp:,.0f}'\n",
    "        d2[name][group] = f'{tmp - tmp2:,.0f}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/home/brian/Documents/uschartbook/chartbook/data/lfs_table1.tex'\n",
    "(pd.DataFrame(d).T.drop('query', axis=1).to_csv(file, \n",
    "    sep='&', line_terminator='\\\\\\ ', quotechar=' '))\n",
    "file = '/home/brian/Documents/uschartbook/chartbook/data/lfs_table2.tex'\n",
    "pd.DataFrame(d2).T.to_csv(file, sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rates by age, gender, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['MONTH', 'YEAR', 'LFS', 'PWSSWGT', 'AGE', 'EDUC', 'FEMALE']\n",
    "df1 = pd.read_feather(cps_dir / 'cps2000.ft', columns=cols).query('PWSSWGT > 0')\n",
    "df2 = pd.read_feather(cps_dir / 'cps2019.ft', columns=cols).query('PWSSWGT > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = [(16, 24), (25, 34), (35, 44), (45, 54), (55, 64), (65, 74)]\n",
    "educ = [['LTHS', 'HS'], ['SC'], ['COLL', 'ADV'], ['LTHS', 'HS', 'SC', 'COLL', 'ADV']]\n",
    "sex = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for a, e, s in itertools.product(ages, educ, sex):\n",
    "    row_name = f'{a[0]}-{a[1]}'\n",
    "    for yr, df in [('2000', df1), ('Latest', df2)]:\n",
    "        col_name = f'{yr} {\" or \".join(e)} {[\"Female\" if s == 1 else \"Male\"][0]}'\n",
    "        data = df.query('@a[0] <= AGE <= @a[1] and EDUC in @e and FEMALE == @s')\n",
    "        i = data.groupby('LFS').PWSSWGT.sum()\n",
    "        results.loc[row_name, col_name] = (i.Employed / i.sum()) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.iloc[1:, :-4].to_csv(data_dir / 'empgroups.csv', index_label='name')\n",
    "results.iloc[:, -4:].to_csv(data_dir / 'empgroups2.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union Membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_membership_rate = lambda x: np.average(x['UNIONMEM'], weights=x['PWORWGT'])\n",
    "union_coverage_rate = lambda x: np.average(x['UNION'], weights=x['PWORWGT'])\n",
    "\n",
    "unmem, uncov = pd.Series(), pd.Series()\n",
    "\n",
    "untot, nuntot = pd.Series(), pd.Series()\n",
    "\n",
    "columns = ['MONTH', 'YEAR', 'LFS', 'PWORWGT', 'UNION', 'UNIONMEM']\n",
    "for year in range(1989, 2020):\n",
    "    df = (pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "        .query('LFS == \"Employed\" and UNION in [0, 1]'))\n",
    "    data1 = df.groupby(['YEAR', 'MONTH']).apply(union_membership_rate)\n",
    "    data1.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data1.index]\n",
    "    unmem = unmem.append(data1)\n",
    "    data2 = df.groupby(['YEAR', 'MONTH']).apply(union_coverage_rate)\n",
    "    data2.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data2.index]\n",
    "    uncov = uncov.append(data2)\n",
    "    df2 = df.query('UNIONMEM == 1')   \n",
    "    data3 = df2.groupby(['YEAR', 'MONTH']).PWORWGT.sum()\n",
    "    data3.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data3.index]\n",
    "    untot = untot.append(data3)\n",
    "    df3 = df.query('UNIONMEM == 0')\n",
    "    data4 = df3.groupby(['YEAR', 'MONTH']).PWORWGT.sum()\n",
    "    data4.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data4.index]\n",
    "    nuntot = nuntot.append(data4)    \n",
    "    \n",
    "data = pd.DataFrame({'Membership': unmem, 'Coverage': uncov})\n",
    "levels = pd.DataFrame({'Union': untot, 'Nonunion': nuntot})\n",
    "data['Diff'] = data['Coverage'] - data['Membership']\n",
    "final = (data.rolling(12).mean().dropna() * 100)\n",
    "final.to_csv(data_dir / 'union.csv', index_label='date', float_format='%g')\n",
    "final2 = (levels.rolling(12).mean().dropna()) / 1000000\n",
    "\n",
    "ltdate = final.index[-1].strftime('%B %Y')\n",
    "prevdate = final.index[-13].strftime('%B %Y')\n",
    "prev2date = final.index[-25].strftime('%B %Y')\n",
    "\n",
    "ltval = final['Membership'].iloc[-1]\n",
    "prevval = final['Membership'].iloc[-13]\n",
    "prev2val = final['Membership'].iloc[-25]\n",
    "\n",
    "totvallt = final2['Union'].iloc[-1]\n",
    "totnvallt = final2['Nonunion'].iloc[-1]\n",
    "\n",
    "chlt = final2['Union'].diff(12).iloc[-1] * 1000000\n",
    "chpr = final2['Union'].diff(12).iloc[-13] * 1000000\n",
    "\n",
    "chnlt = final2['Nonunion'].diff(12).iloc[-1] * 1000000\n",
    "chnpr = final2['Nonunion'].diff(12).iloc[-13] * 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if chlt > 10:\n",
    "    chlt_txt = f'increased by {round(chlt, -3):,.0f}'\n",
    "elif chlt <= -10:\n",
    "    chlt_txt = f'decreased by {abs(round(chlt, -3)):,.0f}'\n",
    "else:\n",
    "    chlt_txt = 'were virtually unchanged'\n",
    "    \n",
    "if chnlt > 10:\n",
    "    chnlt_txt = f'increased by {round(chnlt, -3):,.0f}'\n",
    "elif chnlt <= -10:\n",
    "    chnlt_txt = f'decreased by {abs(round(chnlt, -3)):,.0f}'\n",
    "else:\n",
    "    chnlt_txt = 'were virtually unchanged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over the 12 months ending December 2019, the share of jobs held by union and employee association members averaged 10.3 percent. In levels, there were 14.6 million union jobs, and 127.2 million nonunion jobs, on average over the period. This union membership rate averaged 10.5 percent during the 12 months ending December 2018, and 10.7 percent during the 12 months ending December 2017. Union jobs decreased by 174,000 from December 2018 to December 2019, while nonunion jobs increased by 1,811,000.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (f'Over the 12 months ending {ltdate}, the share of jobs held '+\n",
    "        f'by union and employee association members averaged {ltval:.1f} percent. '+\n",
    "        f'In levels, there were {totvallt:.1f} million union jobs, and '+\n",
    "        f'{totnvallt:.1f} million nonunion jobs, on average over the period. '+\n",
    "        f'This union membership rate averaged {prevval:.1f} percent during the 12 '+\n",
    "        f'months ending {prevdate}, and {prev2val:.1f} percent during the 12 '+\n",
    "        f'months ending {prev2date}. Union jobs {chlt_txt} '+\n",
    "        f'from {prevdate} to {ltdate}, while nonunion jobs {chnlt_txt}.')\n",
    "\n",
    "write_txt(text_dir / 'union.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_membership_rate = lambda x: np.average(x['UNIONMEM'], weights=x['PWORWGT']) * 100\n",
    "columns = ['MONTH', 'YEAR', 'LFS', 'PWORWGT', 'UNIONMEM', 'INDGRP']\n",
    "\n",
    "df = pd.concat([pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "                  .query('PWORWGT > 0 and UNIONMEM == UNIONMEM')\n",
    "      for year in range(1989, 2020)])\n",
    "\n",
    "df.INDGRP.cat = df.INDGRP.cat.remove_unused_categories()\n",
    "\n",
    "data = df.groupby(['YEAR', 'MONTH', 'INDGRP']).apply(union_membership_rate).round(1).unstack()\n",
    "data.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data.index]\n",
    "data.index.name = 'date'\n",
    "data.columns.name = None\n",
    "prev12 = data.iloc[-12:].mean()\n",
    "lval = data.iloc[-1]\n",
    "minval = data.min()\n",
    "maxval = data.max()\n",
    "width = maxval - minval\n",
    "final = pd.concat([lval, prev12, minval, maxval, width], axis=1)\n",
    "final.columns = ['latest', 'prev12', 'min', 'max', 'width']\n",
    "final.index.name = 'name'\n",
    "final = final[['min', 'width', 'latest']].sort_values('latest', ascending=False)\n",
    "final['y'] = [0.13, -0.87, -1.87, -2.87, -3.87, -4.87, -5.87]\n",
    "final.to_csv(data_dir / 'union_ind.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1989-01-01 00:00:00')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Leisure and hospitality'].idxmax()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
