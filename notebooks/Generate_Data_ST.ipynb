{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:23.482855Z",
     "start_time": "2020-12-01T01:49:22.600811Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import time\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:25.600155Z",
     "start_time": "2020-12-01T01:49:25.228689Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The S\\&P 500 closed at 3622 on November 30, 2020. The index is currently 0.7 percent below its one-year high of 3646 on November 9, 2020, and 65.2 percent above its one-year low of 2192 on March 23, 2020. The average over the past year is 3173; the index is 14.2 percent above its one-year moving average (see {\\color{black!18!white}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "ltdate = int(time.time())\n",
    "\n",
    "url = ('https://query1.finance.yahoo.com/v7/finance/download/%5EGSPC?'+\n",
    "       f'period1=599616000&period2={ltdate}&interval=1d&events=history')\n",
    "\n",
    "df = pd.read_csv(url).set_index('Date')\n",
    "\n",
    "close = df['Adj Close']\n",
    "close.index = pd.to_datetime(close.index)\n",
    "\n",
    "final = close.resample('MS').mean().append(pd.Series({close.index[-1]: close[-1]}))\n",
    "final.name = 'GSPC'\n",
    "final.to_csv(data_dir / 'sp500.csv', index_label='date', float_format='%g') \n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['GSPC'] = close.loc['2017':]\n",
    "data['MA'] = close.rolling(253).mean().loc['2017':]\n",
    "data.to_csv(data_dir / 'sp500_recent.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ltdate = dtxt(close.index[-1])['day1']\n",
    "ltval = close.iloc[-1]\n",
    "hival = df.High.iloc[-253:].max()\n",
    "chhi = (1 - ltval/hival) * 100\n",
    "hidt = dtxt(df.High.iloc[-253:].idxmax())['day1']\n",
    "loval = df.Low.iloc[-253:].min()\n",
    "chlo = abs((1 - ltval/loval) * 100)\n",
    "lodt = dtxt(df.Low.iloc[-253:].idxmin())['day1']\n",
    "avval = df['Adj Close'].iloc[-253:].mean()\n",
    "chav = (1 - ltval/avval) * 100\n",
    "chavabs = abs(chav)\n",
    "chtype = 'below' if chav > 0 else 'above'\n",
    "\n",
    "text = (f'The S\\&P 500 closed at {ltval:.0f} on {ltdate}. The index is currently '+\n",
    "        f'{chhi:.1f} percent below its one-year high of {hival:.0f} on {hidt}, and '+\n",
    "        f'{chlo:.1f} percent above its one-year low of {loval:.0f} on {lodt}. The '+\n",
    "        f'average over the past year is {avval:.0f}; the index is {chavabs:.1f} percent '+\n",
    "        f'{chtype} its one-year moving average '+\n",
    "         '(see {\\color{black!18!white}\\\\textbf{---}}).')\n",
    "write_txt(text_dir / 'sp500.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Interest Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:33.966876Z",
     "start_time": "2020-12-01T01:49:28.366236Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H15&series=df361c47287a0589560a46dad7d610cb&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, clean_data = clean_fed_data(url)\n",
    "\n",
    "n = {'RIFLGFCY10_XII_N.B': 'Ten-year',\n",
    "     'RIFLGFCY05_XII_N.B': 'Five-year'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Ten-year'])\n",
    "\n",
    "data = (df.resample('MS').mean().iloc[:-1].append(df.iloc[-1]))\n",
    "data.to_csv(data_dir / 'real_rates.csv', index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:33.972488Z",
     "start_time": "2020-12-01T01:49:33.968038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US Treasury inflation-indexed securities are used to measure real interest rates. Treasury yields in general are a good proxy for low-risk rates, and the treasury offers specific securities that have interest payments indexed to the consumer price index (CPI) rate of inflation. \n",
      "\n",
      " The real yield for such treasuries with ten years to maturity is -0.91 percent, as of November 27, 2020 (see {\\color{red}\\textbf{---}}), compared to -0.92 percent on October 27, 2020 . For a five-year maturity, the real yield is -1.30 percent in the latest data (see {\\color{violet}\\textbf{---}}), compared to -1.30 percent a month prior. \n"
     ]
    }
   ],
   "source": [
    "ltdate = dtxt(df.index[-1])['day1']\n",
    "prdate = dtxt(df.index[-22])['day1']\n",
    "ltval = df['Ten-year'].iloc[-1]\n",
    "ltval5 = df['Five-year'].iloc[-1]\n",
    "prval = df['Ten-year'].iloc[-22]\n",
    "prval5 = df['Five-year'].iloc[-22]\n",
    "\n",
    "text = ('US Treasury inflation-indexed securities are used to measure real '+\n",
    "        'interest rates. Treasury yields in general are a good proxy for '+\n",
    "        'low-risk rates, and the treasury offers specific securities that '+\n",
    "        'have interest payments indexed to the consumer price index (CPI) rate '+\n",
    "        'of inflation. \\n\\n The real yield for such treasuries with ten years '+\n",
    "        f'to maturity is {ltval:.2f} percent, as of {ltdate} '+\n",
    "        '(see {\\color{red}\\\\textbf{---}}), '+\n",
    "        f'compared to {prval:.2f} '+\n",
    "        f'percent on {prdate} . For a five-year maturity, the real yield is '+\n",
    "        f'{ltval5:.2f} percent in the latest data '+\n",
    "        '(see {\\color{violet}\\\\textbf{---}}), compared to '+\n",
    "        f'{prval5:.2f} percent a month prior. ')\n",
    "write_txt(text_dir / 'real_rates_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:37.325918Z",
     "start_time": "2020-12-01T01:49:35.710066Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taylor Rule suggested Fed Funds rate\n",
    "p = (pd.read_csv(data_dir / 'pce_pi.csv', parse_dates=['date'])\n",
    "       .set_index('date')['CORE']).resample('QS').mean() * 0.5\n",
    "\n",
    "y = ((nipa_df(retrieve_table('T10106')['Data'], ['A191RX']))\n",
    "      .loc['1989':, 'A191RX'])\n",
    "\n",
    "y_p = fred_df('GDPPOT')['VALUE'] * 1_000\n",
    "\n",
    "o = (y - (y_p)).divide(y_p).dropna()\n",
    "\n",
    "taylor_ff = (p + 3 + (0.5*(p - 2)) + (1*(o*100)))\n",
    "\n",
    "taylor_ff.name = 'Value'\n",
    "\n",
    "taylor_ff.dropna().to_csv(data_dir / 'taylor.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:45.016903Z",
     "start_time": "2020-12-01T01:49:39.202544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 27, 2020, the constant maturity yield for a ten-year US Treasury bond (see {\\color{red!90}\\textbf{---}}) is 0.84 percent, compared to 1.74 percent one year prior. The yield for a two-year Treasury (see {\\color{blue}\\textbf{---}}) is 0.16 percent, compared to 1.58 percent a year prior.\n",
      "The effective fed funds rate (see {\\color{blue!60!black}\\textbf{---}}) is 0.08 percent, as of November 27, 2020.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nov 27, 2020</th>\n",
       "      <th>Nov 25, 2020</th>\n",
       "      <th>Nov 20, 2020</th>\n",
       "      <th>Oct 27, 2020</th>\n",
       "      <th>Aug 26, 2020</th>\n",
       "      <th>May 28, 2020</th>\n",
       "      <th>Nov 26, 2019</th>\n",
       "      <th>Nov 27, 2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Three-month</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Two-year</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Five-year</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ten-year</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.74</td>\n",
       "      <td>2.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thirty-year</th>\n",
       "      <td>1.57</td>\n",
       "      <td>1.62</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.47</td>\n",
       "      <td>2.18</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Nov 27, 2020  Nov 25, 2020  Nov 20, 2020  Oct 27, 2020  \\\n",
       "Three-month          0.09          0.09          0.07          0.10   \n",
       "Two-year             0.16          0.17          0.16          0.16   \n",
       "Five-year            0.37          0.39          0.38          0.34   \n",
       "Ten-year             0.84          0.88          0.83          0.79   \n",
       "Thirty-year          1.57          1.62          1.53          1.57   \n",
       "\n",
       "             Aug 26, 2020  May 28, 2020  Nov 26, 2019  Nov 27, 2015  \n",
       "Three-month          0.11          0.15          1.60          0.18  \n",
       "Two-year             0.16          0.17          1.58          0.92  \n",
       "Five-year            0.28          0.34          1.58          1.64  \n",
       "Ten-year             0.69          0.70          1.74          2.22  \n",
       "Thirty-year          1.41          1.47          2.18          3.00  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H15&series=a2738d013c65f34c46f905d1d7913f78&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, clean_data = clean_fed_data(url)\n",
    "\n",
    "n = {'RIFLGFCY10_N.B': 'Ten-year',\n",
    "    'RIFLGFCY30_N.B': 'Thirty-year',\n",
    "    'RIFSPFF_N.B': 'Fed Funds',\n",
    "    'RIFLGFCM03_N.B': 'Three-month',\n",
    "    'RIFLGFCY05_N.B': 'Five-year',\n",
    "    'RIFLGFCY02_N.B': 'Two-year',\n",
    "    'RIFLGFCM01_N.B': 'One-month',\n",
    "    'RIFLGFCY01_N.B': 'One-year',\n",
    "    'RIFLGFCY20_N.B': 'Twenty-year'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Ten-year'])\n",
    "\n",
    "data = (df.resample('MS').mean().iloc[:-1].append(df.iloc[-1]))\n",
    "data.to_csv(data_dir / 'rates.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ldate = dtxt(data.index[-1])['day1']\n",
    "tenlt = df['Ten-year'].iloc[-1]\n",
    "tenpr = df['Ten-year'].iloc[-252]\n",
    "twolt = df['Two-year'].iloc[-1]\n",
    "twopr = df['Two-year'].iloc[-252]\n",
    "\n",
    "text = (f'As of {ldate}, the constant maturity yield for a ten-year '+\n",
    "        'US Treasury bond (see {\\color{red!90}\\\\textbf{---}}) '+\n",
    "        f'is {tenlt} percent, compared to {tenpr:.2f} percent one year prior. '+\n",
    "        'The yield for a two-year Treasury (see {\\color{blue}\\\\textbf{---}}) '\n",
    "        +f'is {twolt} percent, compared to {twopr:.2f} '+\n",
    "        f'percent a year prior.')\n",
    "write_txt(text_dir / 'rates_basic.txt', text)\n",
    "print(text)\n",
    "\n",
    "text = ('The effective fed funds rate (see {\\color{blue!60!black}\\\\textbf{---}}) '+\n",
    "        f'is {data[\"Fed Funds\"].iloc[-1]} percent, as of {ldate}.')\n",
    "write_txt(text_dir / 'rates_ff.txt', text)\n",
    "print(text)\n",
    "\n",
    "rows = ['Three-month', 'Two-year', 'Five-year', 'Ten-year', 'Thirty-year']\n",
    "columns = [-1, -2, -5, -22, -64, -127, -252, -1251]\n",
    "data2 = df[rows].iloc[columns].T\n",
    "data2.columns = [dtxt(i)['day2'] for i in pd.to_datetime(data2.keys())]\n",
    "\n",
    "(data2.applymap('{:,.2f}'.format)\n",
    "      .to_csv(data_dir / 'treasury_rates.tex', sep='&', \n",
    "           line_terminator='\\\\\\ ', quotechar=' '))\n",
    "\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:37:54.210618Z",
     "start_time": "2020-09-18T17:37:54.206641Z"
    }
   },
   "source": [
    "### Yield Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:45.027333Z",
     "start_time": "2020-12-01T01:49:45.018195Z"
    }
   },
   "outputs": [],
   "source": [
    "i = {'One-month': 1, 'Three-month': 2, 'One-year': 3, 'Two-year': 4, \n",
    "     'Five-year': 5, 'Ten-year': 6, 'Twenty-year': 7, 'Thirty-year': 8}\n",
    "tbl = pd.DataFrame()\n",
    "for v, c in [(-1, 'value'), (-252, 'oneyear'), (-252*5, 'fiveyear')]:\n",
    "    col = df[i.keys()].iloc[v]\n",
    "    col.index = col.index.map(i)\n",
    "    tbl[c] = col\n",
    "tbl.index.name = 'number'\n",
    "tbl['alignment'] = 270\n",
    "\n",
    "tbl.to_csv(data_dir / 'yc.csv', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:46.100988Z",
     "start_time": "2020-12-01T01:49:46.054953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 27, 2020, the spread between a 10-year treasury bond and a three-month treasury bill is 0.75 percentage point (see {\\color{cyan!60!blue}\\textbf{---}}), compared to 0.14 percentage point one year prior. The spread between 10-year and 2-year treasuries (see {\\color{orange}\\textbf{---}}) was 0.68 percentage point on November 27, 2020, and 0.16 percentage point one year prior.\n"
     ]
    }
   ],
   "source": [
    "data = df[df['Ten-year'] != 'ND'].astype('float')\n",
    "spread = pd.DataFrame()\n",
    "spread['Ten-3M'] = data['Ten-year'] - data['Three-month']\n",
    "spread['Ten-2Y'] = data['Ten-year'] - data['Two-year']\n",
    "spread.loc['2012':].to_csv(data_dir / 'spread.csv', index_label='date', float_format='%g', header=True)\n",
    "\n",
    "node = end_node(spread['Ten-3M'], 'cyan!60!blue').replace('\\\\%', '')\n",
    "write_txt(text_dir / 'spread_node.txt', node)\n",
    "\n",
    "node = end_node(spread['Ten-2Y'], 'orange', ).replace('\\\\%', '')\n",
    "write_txt(text_dir / 'spread_node2.txt', node)\n",
    "\n",
    "lt3 = spread['Ten-3M'].iloc[-1]\n",
    "lt3t = f'{lt3:.2f} {[\"percentage points\" if lt3 > 1.05 else \"percentage point\"][0]}'\n",
    "pr3 = spread['Ten-3M'].iloc[-252]\n",
    "pr3t = f'{pr3:.2f} {[\"percentage points\" if pr3 > 1.05 else \"percentage point\"][0]}'\n",
    "lt2 = spread['Ten-2Y'].iloc[-1]\n",
    "lt2t = f'{lt2:.2f} {[\"percentage points\" if lt2 > 1.05 else \"percentage point\"][0]}'\n",
    "pr2 = spread['Ten-2Y'].iloc[-252]\n",
    "pr2t = f'{pr2:.2f} {[\"percentage points\" if pr2 > 1.05 else \"percentage point\"][0]}'\n",
    "\n",
    "text = (f'As of {ldate}, the spread between a 10-year treasury bond and '+\n",
    "        f'a three-month treasury bill is {lt3t} '+\n",
    "        '(see {\\color{cyan!60!blue}\\\\textbf{---}}), compared to '+\n",
    "        f'{pr3t} one year prior. The spread between 10-year '+\n",
    "        'and 2-year treasuries (see {\\color{orange}\\\\textbf{---}}) '+\n",
    "        f'was {lt2t} on {ldate}, and '+\n",
    "        f'{pr2t} one year prior.')\n",
    "\n",
    "write_txt(text_dir / 'spread_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:50.852252Z",
     "start_time": "2020-12-01T01:49:48.974259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 27, 2020, one troy ounce of gold sells for \\$1,808.05 (see {\\color{orange!40!yellow}\\textbf{---}}), compared to an average of \\$1,471.92 per ounce during November 2019. Following the great recession, the monthly average price of gold reached \\$1,780.65 per ounce, in September 2011.\n"
     ]
    }
   ],
   "source": [
    "df = fred_df('GOLDAMGBD228NLBM').dropna()\n",
    "data = (df.resample('M').mean().iloc[:-1].append(df.iloc[-1]))\n",
    "data.to_csv(data_dir / 'gold.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(data.index[-1])['day1']\n",
    "ltval = data.VALUE.iloc[-1]\n",
    "prdate = dtxt(data.index[-13])['mon1']\n",
    "prval = data.VALUE.iloc[-13]\n",
    "grdate = dtxt(data.loc['2006':'2011', 'VALUE'].idxmax())['mon1']\n",
    "grval = data.loc['2006':'2011', 'VALUE'].max()\n",
    "\n",
    "text = (f'As of {ltdate}, one troy ounce of gold sells for \\${ltval:,.2f} '+\n",
    "        '(see {\\color{orange!40!yellow}\\\\textbf{---}}), '\n",
    "        f'compared to an average of \\${prval:,.2f} per ounce during {prdate}. '+\n",
    "        'Following the great recession, the monthly average price '+\n",
    "        f'of gold reached \\${grval:,.2f} per ounce, in {grdate}.')\n",
    "print(text)\n",
    "write_txt(text_dir / 'gold.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fed Balance Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:52.886716Z",
     "start_time": "2020-12-01T01:49:52.617067Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H41&series=38d757c01cb3b550176f371352643679&lastobs=&'\n",
    "dt = 'from=01/01/2002&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split(';')[0]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "clean_data = clean_data / 1_000_000\n",
    "\n",
    "clean_data.to_csv(data_dir / 'fed_assets.csv', index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:49:55.348834Z",
     "start_time": "2020-12-01T01:49:55.343971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balance sheet normalization ended in September 2019 when the Fed increased operations in overnight and term repurchase agreement (repo) markets, following a sharp increase in rates in these markets. The Fed balance sheet increased to \\$4.1 trillion by December 2019. More recently, in response to worsening financial conditions, the Fed began to purchase commercial bonds and to offer currency swaps with major US trading partners. The Fed balance sheet increased from \\$4.2 trillion in February 2020 to \\$7.2 trillion, as of the latest data, covering November 25, 2020. The total value of Fed assets decreased by \\$27 billion from the value one week prior.\n"
     ]
    }
   ],
   "source": [
    "ltval = clean_data['RESPPMA_N.WW'].iloc[-1].round(1)\n",
    "ltdate = dtxt(clean_data.index[-1])['day1']\n",
    "n = (clean_data.iloc[-1] - clean_data.iloc[-2])['RESPPMA_N.WW'] * 1000\n",
    "chval = (f'increased by \\${abs(n):.0f} billion' if n >= 10 \n",
    "         else f'decreased by \\${abs(n):.0f} billion' \n",
    "         if n <= -10 else 'was largely unchanged')\n",
    "\n",
    "text = ('In response to the collapse of the housing bubble, the Fed purchased '+\n",
    "        'U.S. Treasury bonds and mortgage-backed securities. Total assets held by '+\n",
    "        'the Federal Reserve (see {\\color{blue!80!black}\\\\textbf{---}}) '+\n",
    "        'increased from \\$0.9 trillion in August 2008 to '+\n",
    "        '\\$2.2 trillion in November 2008. Additional rounds of asset purchases, '+\n",
    "        'referred to as quantitative easing, increased the balance sheet to '+\n",
    "        '\\$4.5 trillion by January 2014. As bonds mature they were replaced '+\n",
    "        'until October 2017, when the Fed allowed the size of its balance '+\n",
    "        'sheet to normalize. Total assets fell below \\$3.8 trillion in August 2019.')\n",
    "\n",
    "write_txt(text_dir / 'fed_assets1.txt', text)\n",
    "        \n",
    "        \n",
    "txt2 = ('Balance sheet normalization ended in September 2019 when the Fed increased '+\n",
    "        'operations in overnight and term repurchase agreement (repo) markets, following '+\n",
    "        'a sharp increase in rates in these markets. The Fed balance sheet '+\n",
    "        'increased to \\$4.1 trillion by December 2019. More recently, in response to '+\n",
    "        'worsening financial conditions, the Fed began to purchase commercial bonds '+\n",
    "        'and to offer currency swaps with major US trading partners. '+\n",
    "        'The Fed balance sheet increased from \\$4.2 trillion in February 2020 to '+\n",
    "        f'\\${ltval} trillion, as of the latest data, covering {ltdate}. The total value of '+\n",
    "        f'Fed assets {chval} from the value one week prior.')\n",
    "\n",
    "write_txt(text_dir / 'fed_assets2.txt', txt2)\n",
    "\n",
    "print(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fed Balance Sheet Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T01:54:54.864951Z",
     "start_time": "2020-11-30T01:54:49.503638Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H41&series=bbb7b50f663fe933c8cce7e3707e3998&lastobs=&'\n",
    "dt = 'from=01/01/2002&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, clean_data = clean_fed_data(url)\n",
    "\n",
    "d2 = {'RESPPA_N.WW': '\\\\textbf{Total} (see {\\color{blue!80!black}\\\\textbf{---}})',\n",
    "      'RESPPALGUO_N.WW': '\\hspace{2mm}U.S. Treasury securities',\n",
    "      'RESPPALGASMO_N.WW': '\\hspace{2mm}Mortgage-backed securities',\n",
    "      'RESH4SCS_N.WW': '\\hspace{2mm}Central bank liquidity swaps',\n",
    "      'RESPPALGTR_N.WW': '\\hspace{2mm}Repurchase agreements',\n",
    "      'RESPPALD_N.WW': '\\hspace{2mm}Loans',\n",
    "      'RESPPALDJ_N.WW': '\\hspace{4mm}Payroll Protection Program',\n",
    "      'NetPremDisc': '\\hspace{2mm}Net unamortized premium',\n",
    "      'Other': '\\hspace{2mm}Other'}\n",
    "\n",
    "pr_di = ['RESPPALSD_N.WW', 'RESPPALSP_N.WW']\n",
    "\n",
    "data = clean_data.copy()\n",
    "data['Other'] = (data['RESPPA_N.WW'] - \n",
    "                             data.drop('RESPPA_N.WW', axis=1).sum(axis=1))\n",
    "data['NetPremDisc'] = data[pr_di].sum(axis=1)\n",
    "\n",
    "data = data.rename(d2, axis=1).drop(pr_di, axis=1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in [-1, -2, -5, -14, -53]:\n",
    "    df[dtxt(data.index[i])['day2']] = data.iloc[i]\n",
    "    \n",
    "(df.loc[list(d2.values()), :].div(1000)\n",
    "   .applymap('{:,.1f}'.format)\n",
    "   .to_csv(data_dir / 'fed_bal_sheet.tex', sep='&', \n",
    "           line_terminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Money Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T01:55:00.879643Z",
     "start_time": "2020-11-30T01:54:54.866314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the first three weeks of November 2020, the M2 plus institutional money funds measure increased over the equivalent previous year value by 25.0 percent. \n",
      "\n",
      "In the week of November 16, 2020, the M2 measure of money averaged \\$19.1 trillion, equivalent to 90.3 percent of GDP. Institution money market accounts, which are not included in M2, can be combined with M2 to create a slightly-broader-than-M2 measure of the money stock. These funds averaged \\$2.8 trillion in the same week, equivalent to 13.5 percent of GDP. \n"
     ]
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H6&series=fafc1295c552e99d2b907eb62278e4ca&lastobs=&'\n",
    "dt = 'from=01/01/1988&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "final2 = {}\n",
    "data = clean_data[['M2_N.WM', 'MMFIN_N.WM']].sum(axis=1)\n",
    "month_list = clean_data.resample('MS').mean().pct_change(12).dropna().index\n",
    "short_month = ''\n",
    "for date in month_list:\n",
    "    month_len = len(data.loc[date.strftime('%Y-%m')])\n",
    "    prevyr = f'{date.year - 1}-{date.month}'\n",
    "    weeks_in_short_month = 4\n",
    "    end_date = date\n",
    "    if month_len < 4:\n",
    "        end_date = date\n",
    "        short_month = date.strftime('%B %Y')\n",
    "        val = data.loc[date.strftime('%Y-%m')].mean()\n",
    "        prv = data.loc[prevyr].iloc[:month_len]\n",
    "        prev = prv.mean()\n",
    "        weeks_in_short_month = len(prv)\n",
    "    elif month_len >= 4:\n",
    "        val = data.loc[date.strftime('%Y-%m')].mean()\n",
    "        prev = data.loc[prevyr].mean()\n",
    "        end_full = date\n",
    "    final2[date] = (val / prev - 1) * 100\n",
    "    \n",
    "final = pd.Series(final2, name='value')\n",
    "final.to_csv(data_dir / 'm2imf.csv', index_label='date', header='True')\n",
    "\n",
    "s = series_info(final)\n",
    "\n",
    "node = end_node(final, 'green!80!blue')\n",
    "write_txt(text_dir / 'm2imf_node.txt', node)\n",
    "\n",
    "week_conv = {1: f'the first week of {short_month}', \n",
    "             2: f'the first two weeks of {short_month}', \n",
    "             3: f'the first three weeks of {short_month}',\n",
    "             4: end_full.strftime('%B %Y')}\n",
    "\n",
    "if final.iloc[-1] >= 0.1:\n",
    "    txt = f'increased over the equivalent previous year value by {final.iloc[-1]:.1f} percent'\n",
    "elif final.iloc[-1] <= -0.1:\n",
    "    txt = f'decreased over the equivalent previous year value by {abs(final.iloc[-1]):.1f} percent'   \n",
    "else:\n",
    "    txt = 'was virtually unchanged over the previous year value'\n",
    "    \n",
    "if s['days_since_match'] > 300:\n",
    "    txt2 = f\", {s['last_matched'].replace('highest level', 'fastest growth rate')}.\"\n",
    "else:\n",
    "    txt2 = '.'\n",
    "    \n",
    "text = (f'In {week_conv[weeks_in_short_month]}, '+\n",
    "        f'the M2 plus institutional money funds measure {txt}{txt2}')\n",
    "\n",
    "write_txt(text_dir / 'm2imf.txt', text)\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "m2sh = (clean_data['M2_N.WM'].iloc[-1] / (gdp.iloc[-1] / 1000)) * 100\n",
    "imfsh = (clean_data['MMFIN_N.WM'].iloc[-1] / (gdp.iloc[-1] / 1000)) * 100\n",
    "\n",
    "text2 = (f'In the week of {clean_data.index[-1].strftime(\"%B %-d, %Y\")}, '+\n",
    "         f'the M2 measure of money averaged \\${clean_data[\"M2_N.WM\"].iloc[-1] / 1000:.1f} '+\n",
    "         f'trillion, equivalent to {m2sh:.1f} percent of GDP. Institution money market '\n",
    "         +f'accounts, which are not included in M2, can be combined with M2 to create a '+\n",
    "         f'slightly-broader-than-M2 measure of the money stock. These funds averaged '+\n",
    "         f'\\${clean_data[\"MMFIN_N.WM\"].iloc[-1] / 1000:.1f} trillion in the same week, '+\n",
    "         f'equivalent to {imfsh:.1f} percent of GDP. ')\n",
    "\n",
    "write_txt(text_dir / 'm2imf2.txt', text2)\n",
    "print(text, '\\n')\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:50:12.937909Z",
     "start_time": "2020-12-01T01:50:06.702762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest index value, as of November 1, 2020, is 114.5, an increase of 14.5 percent since inception in 2006. Over the past three years, the index value has averaged 115.0, compared to an average of 110.4 over the previous three-year period.\n"
     ]
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H10&series=ad1712193ad5bad7b424e3ae5eb101a5&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split(';')[0]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "for cc in ['EU', 'UK', 'AL', 'NZ']:\n",
    "    clean_data[f'RXI_N.B.{cc}'] = 1 / clean_data[f'RXI$US_N.B.{cc}'] \n",
    "clean_data['RXI_N.B.JA'] = clean_data['RXI_N.B.JA'] / 100.0\n",
    "\n",
    "latest = clean_data.iloc[-1]\n",
    "major = ['RXI_N.B.EU', 'RXI_N.B.UK', 'RXI_N.B.CA', 'RXI_N.B.JA']\n",
    "twidx = clean_data.resample('MS').mean().append(latest)['JRXWTFB_N.B'].dropna()\n",
    "clean_data.resample('MS').mean().append(latest)[major].to_csv(data_dir / 'fx1.csv', index_label='date', float_format='%g')\n",
    "twidx.to_csv(data_dir / 'fx_idx.csv', index_label='date', float_format='%g', header=True)\n",
    "\n",
    "ldate = dtxt(twidx.index[-1])['day1']\n",
    "lval = twidx.iloc[-1]\n",
    "totch = ((lval / 100) - 1) * 100\n",
    "threeyr = twidx.iloc[-38:].mean()\n",
    "prev3yr = twidx.iloc[-74:-38].mean()\n",
    "\n",
    "text = (f'The latest index value, as of {ldate}, is {lval:.1f}, an increase '+\n",
    "        f'of {totch:.1f} percent since inception in 2006. Over the past three years, '+\n",
    "        f'the index value has averaged {threeyr:.1f}, compared to an average '+\n",
    "        f'of {prev3yr:.1f} over the previous three-year period.')\n",
    "write_txt(text_dir / 'twdbasic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:50:13.046651Z",
     "start_time": "2020-12-01T01:50:12.939109Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'November 1, 2020'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1604188800000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2020-11-01 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2020-11-01 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-0e46fcf4bf92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mldate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RXI_N.B.CA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mjpy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mldate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RXI_N.B.JA'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mldate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RXI_N.B.EU'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mldate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RXI_N.B.UK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcadpc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minc_dec_percent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'RXI_N.B.CA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpct_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m262\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;31m# We don't need to check for tuples here because those are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m                 \u001b[0;31m#  caught by the _is_nested_tuple_indexer check above.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m                 \u001b[0msection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;31m# We should never have a scalar section here, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;31m# GH#5667 this will fail if the label is not present in the axis.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_lowerdim_multi_index_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   3489\u001b[0m             \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3491\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_cast_for_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'November 1, 2020'"
     ]
    }
   ],
   "source": [
    "cad = clean_data.loc[ldate, 'RXI_N.B.CA']\n",
    "jpy = clean_data.loc[ldate, 'RXI_N.B.JA'] * 100\n",
    "eur = clean_data.loc[ldate, 'RXI_N.B.EU']\n",
    "gbp = clean_data.loc[ldate, 'RXI_N.B.UK']\n",
    "cadpc = inc_dec_percent(clean_data['RXI_N.B.CA'].pct_change(262).iloc[-1] * 100)\n",
    "jpypc = inc_dec_percent(clean_data['RXI_N.B.JA'].pct_change(262).iloc[-1] * 100)\n",
    "gbppc = inc_dec_percent(clean_data['RXI_N.B.UK'].pct_change(262).iloc[-1] * 100)\n",
    "eurpc = inc_dec_percent(clean_data['RXI_N.B.EU'].pct_change(262).iloc[-1] * 100)\n",
    "\n",
    "\n",
    "text = (f'As of {ldate}, one US dollar buys approximately: {cad:.2f} Canadian dollars '+\n",
    "        f'(see {{\\color{{green!85!blue}}\\\\textbf{{---}}}}), {jpy:.0f} Japanese Yen '+\n",
    "        f'(see {{\\color{{red}}\\\\textbf{{---}}}}), {eur:.2f} Euros '+\n",
    "        f'(see {{\\color{{cyan!90!white}}\\\\textbf{{---}}}}), and {gbp:.2f} British Pounds '+\n",
    "         '(see {\\color{blue!90!cyan}\\\\textbf{---}}). Over the past three years, the nominal '+\n",
    "        f'exchange rate between the US dollar and the Canadian dollar {cadpc}, the USD-JPY rate '+\n",
    "        f'{jpypc}, the USD-EUR rate {eurpc}, and the USD-GBP rate {gbppc}.')\n",
    "write_txt(text_dir / 'selcurr_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange Rates Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:50:13.047748Z",
     "start_time": "2020-12-01T01:50:11.723Z"
    }
   },
   "outputs": [],
   "source": [
    "fx = {'RXI_N.B.EU': 'EUR',\n",
    "      'RXI_N.B.UK': 'GBP',\n",
    "      'RXI_N.B.JA': 'JPY',\n",
    "      'RXI_N.B.CA': 'CAD',\n",
    "      'RXI_N.B.MX': 'MXN',\n",
    "      'RXI_N.B.CH': 'CNY',\n",
    "      'RXI_N.B.SZ': 'CHF',\n",
    "      'RXI_N.B.HK': 'HKD',\n",
    "      'RXI_N.B.IN': 'INR',\n",
    "      'RXI_N.B.AL': 'AUD',\n",
    "      'RXI_N.B.NZ': 'NZD',\n",
    "      'RXI_N.B.BZ': 'BRL',\n",
    "      'RXI_N.B.KO': 'KRW',\n",
    "      'RXI_N.B.MA': 'MYR',\n",
    "      'RXI_N.B.DN': 'DKK',\n",
    "      'RXI_N.B.NO': 'NOK',\n",
    "      'RXI_N.B.SD': 'SEK',\n",
    "      'RXI_N.B.SF': 'ZAR',\n",
    "      'RXI_N.B.SI': 'SGD',\n",
    "      'RXI_N.B.TA': 'TWD'}\n",
    "\n",
    "tbl_data = clean_data[fx.keys()]\n",
    "tbl_data.columns = fx.values()\n",
    "tbl_data.loc[:,'JPY'] *= 100\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table[dtxt(tbl_data.index[-1])['day2']] = tbl_data.iloc[-1]\n",
    "table['1-month moving average'] = tbl_data.iloc[-22:].mean()\n",
    "table['1-year moving average'] = tbl_data.iloc[-262:].mean()\n",
    "dec1 = ['JPY', 'KRW']\n",
    "table.loc[['JPY', 'KRW'],:] = table.loc[['JPY', 'KRW'],:].applymap(\"{0:.1f}\".format)\n",
    "dec3 = ['GBP', 'EUR', 'CHF', 'AUD', 'NZD', 'CAD', 'SGD']\n",
    "table.loc[dec3,:] = table.loc[dec3,:].applymap(\"{0:.3f}\".format)\n",
    "table.loc[~table.index.isin(dec3+dec1)] = table.loc[~table.index.isin(dec3+dec1)].applymap(\"{0:.2f}\".format)\n",
    "table['1-month percent change'] = (tbl_data.pct_change(22) * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "table['1-year percent change'] = (tbl_data.pct_change(262) * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "table['5-year percent change'] = (tbl_data.pct_change(262*5) * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "\n",
    "table.index = [f'\\includegraphics[width=.03\\\\textwidth]{{data/flags/{cc}}} \\ {cc}' for cc in table.index]\n",
    "\n",
    "(table.to_csv(data_dir / 'fx_table.tex', sep='&', \n",
    "              line_terminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-08T22:17:48.985435Z",
     "start_time": "2020-09-08T22:17:48.956936Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobless claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:50:18.876616Z",
     "start_time": "2020-12-01T01:50:15.536990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{report}} 827,710 actual new claims for unemployment insurance (UI) under state programs (see {\\color{cyan!80!blue}\\textbf{---}}) during the week ending November 21, 2020, a one-week increase of 78,400. Over the past four weeks, new claims have averaged 761,600 per week. During the same four-week period last year, there were an average of 231,200 new claims per week.\n",
      "For the week ending November 14, 2020, the Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{reports}} 5,911,965 continued claims for unemployment insurance (insured unemployed) under state programs (see {\\color{green!90!blue}\\textbf{---}}), a one-week decrease of 167,600. One year prior, during the week of November 16, 2019, there were an average of 1,545,000 insured unemployed.\n"
     ]
    }
   ],
   "source": [
    "data = fred_df('ICNSA', start='2017') / 1000 \n",
    "\n",
    "data['1M'] = data['VALUE'].rolling(4).mean()\n",
    "\n",
    "data.div(1000).to_csv(data_dir / 'icsa.csv', index_label='date', float_format='%g')\n",
    "\n",
    "totval = data['VALUE'].iloc[-1]*1000\n",
    "datelt = dtxt(data.index[-1])['day1']\n",
    "latest1m = data[\"1M\"].iloc[-1]*1000\n",
    "prev1m = data[\"1M\"].iloc[-53]*1000\n",
    "\n",
    "chval = totval - data['VALUE'].iloc[-2]*1000\n",
    "chtxt = f'{round(abs(chval),-2):,.0f}'\n",
    "if chval > 1000:\n",
    "    change = f'a one-week increase of {chtxt}'\n",
    "elif chval < -1000:\n",
    "    change = f'a one-week decrease of {chtxt}'\n",
    "else:\n",
    "    change = 'virtually unchanged from the previous week'\n",
    "\n",
    "text = ('The Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{report}} '+\n",
    "        f'{totval:,.0f} actual new claims for unemployment '+\n",
    "        'insurance (UI) under state programs (see {\\color{cyan!80!blue}\\\\textbf{---}}) '+\n",
    "        f'during the week ending {datelt}, {change}. Over the past four weeks, '+\n",
    "        f'new claims have averaged {round(latest1m,-2):,.0f} per week. During the same '+\n",
    "        f'four-week period last year, there were an average of {round(prev1m,-2):,.0f} '+\n",
    "        'new claims per week.')\n",
    "\n",
    "write_txt(text_dir / 'icsa.txt', text)\n",
    "print(text)\n",
    "\n",
    "data = fred_df('CCNSA', start='2017') / 1000 \n",
    "data.div(1000).to_csv(data_dir / 'ccsa.csv', index_label='date', float_format='%g')\n",
    "\n",
    "\n",
    "totval = data['VALUE'].iloc[-1]*1000\n",
    "prval = data['VALUE'].iloc[-2]*1000\n",
    "datelt = dtxt(data.index[-1])['day1']\n",
    "prevyrval = data['VALUE'].iloc[-53]*1000\n",
    "prmoval = data['VALUE'].iloc[-4]*1000\n",
    "datepr = dtxt(data.index[-53])['day1']\n",
    "\n",
    "chval = totval - prval\n",
    "chtxt = f'{round(abs(chval),-2):,.0f}'\n",
    "if chval > 1000:\n",
    "    change = f'a one-week increase of {chtxt}'\n",
    "elif chval < -1000:\n",
    "    change = f'a one-week decrease of {chtxt}'\n",
    "else:\n",
    "    change = 'virtually unchanged from the previous week'\n",
    "\n",
    "text = (f'For the week ending {datelt}, the Department of Labor '+\n",
    "        '\\href{{https://www.dol.gov/ui/data.pdf}}{{reports}} '+\n",
    "        f'{totval:,.0f} continued claims for unemployment '+\n",
    "        'insurance (insured unemployed) under state programs '+\n",
    "        '(see {\\color{green!90!blue}\\\\textbf{---}})'+\n",
    "        f', {change}. One year prior, during the week of {datepr}, '+\n",
    "        f'there were an average of {round(prevyrval,-2):,.0f} '+\n",
    "        'insured unemployed.')\n",
    "\n",
    "write_txt(text_dir / 'ccsa.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:50:20.248066Z",
     "start_time": "2020-12-01T01:50:19.553298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the week ending November 14, 2020, there were 320,200 initial UI \\href{https://oui.doleta.gov/unemploy/DataDashboard.asp}{claims} under the Pandemic Unemployment Assistance (PUA) program (see {\\color{blue!50!purple!80!black}\\textbf{---}}), compared to 296,400 during the prior week, and an average of 334,400 initial claims per week over the past four weeks. \n",
      "\n",
      "Federal program continuing claims total 13,058,494 in November 7, 2020 (see {\\color{green!50!blue}\\textbf{---}}). These include both claims under the PUA program and claims under the Pandemic Emergency Unemployment Compensation (PEUC) program. Combining federal program claims with state program claims indicates there are a total of 19.0 million insured unemployed persons during the week ending November 7, 2020, compared to 21.2 million one month prior, during the week ending October 17, 2020. \n"
     ]
    }
   ],
   "source": [
    "file = 'https://oui.doleta.gov/unemploy/docs/weekly_pandemic_claims.xlsx'\n",
    "fed_raw = pd.read_excel(file).iloc[1:]\n",
    "pua_ic = fed_raw.groupby('Rptdate')['PUA IC'].sum()\n",
    "pua_ic.index = pd.to_datetime(pua_ic.index)\n",
    "pua_ic.index.name = 'date'\n",
    "pua_ic.name = 'pua_ic'\n",
    "cc_raw = fed_raw.dropna(subset=['PUA CC'])\n",
    "pua_cc = cc_raw.groupby('Rptdate')['PUA CC'].sum()\n",
    "peuc_cc = cc_raw.groupby('Rptdate')['PEUC CC'].sum()\n",
    "fed_cc = pua_cc + peuc_cc\n",
    "fed_cc.index = pd.to_datetime(fed_cc.index)\n",
    "fed_cc.index.name = 'date'\n",
    "fed_cc.name = 'fed_cc'\n",
    "\n",
    "d1 = pd.DataFrame([pua_ic, fed_cc]).T / 1000\n",
    "d1.div(1000).to_csv(data_dir / 'fed_uic.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ltdate = dtxt(d1.index[-1])['day1']\n",
    "prdatecc = dtxt(d1.dropna().index[-4])['day1']\n",
    "ltdatecc = dtxt(d1.dropna().index[-1])['day1']\n",
    "pua_ic_lt = f\"{round(d1['pua_ic'].iloc[-1] * 1000, -2):,.0f}\"\n",
    "pua_ic_pr = f\"{round(d1['pua_ic'].iloc[-2] * 1000, -2):,.0f}\"\n",
    "pua_ic_1m = f\"{round(d1['pua_ic'].iloc[-4:].mean() * 1000, -2):,.0f}\"\n",
    "fed_cc_lt = d1.dropna()['fed_cc'].iloc[-1] * 1_000\n",
    "fed_cc_mo = d1.dropna()['fed_cc'].iloc[-4] * 1_000\n",
    "fed_cc_ltt = f\"{fed_cc_lt:,.0f}\"\n",
    "tot_cc = fed_cc_lt + totval\n",
    "tot_lt = f\"{tot_cc / 1_000_000:,.1f} million\"\n",
    "tot_cc_pr = fed_cc_mo + prmoval\n",
    "tot_pr = f\"{tot_cc_pr / 1_000_000:,.1f} million\"\n",
    "\n",
    "text = (f'Over the week ending {ltdate}, there were {pua_ic_lt} '+\n",
    "        'initial UI \\href{https://oui.doleta.gov/unemploy/DataDashboard.asp}{claims} '+\n",
    "        'under the Pandemic Unemployment Assistance '+\n",
    "        '(PUA) program (see {\\color{blue!50!purple!80!black}\\\\textbf{---}}), '+\n",
    "        f'compared to {pua_ic_pr} during the prior week, '+\n",
    "        f'and an average of {pua_ic_1m} initial claims per week over the '+\n",
    "        'past four weeks. \\n\\n'+\n",
    "        f'Federal program continuing claims total {fed_cc_ltt} '+\n",
    "        f'in {ltdatecc} '+\n",
    "        '(see {\\color{green!50!blue}\\\\textbf{---}}). These include both ' +\n",
    "        'claims under the PUA program and claims under the Pandemic Emergency '+\n",
    "        'Unemployment Compensation (PEUC) program. Combining federal program '+\n",
    "        f'claims with state program claims indicates there are a total '+\n",
    "        f'of {tot_lt} insured unemployed persons during the week ending {ltdatecc}, '+\n",
    "        f'compared to {tot_pr} one month prior, during the week ending {prdatecc}. ')\n",
    "\n",
    "write_txt(text_dir / 'fed_uic.txt', text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIX (SP500 volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:50:23.951115Z",
     "start_time": "2020-12-01T01:50:23.498074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This volatility measure, the VIX index (see {\\color{magenta}\\textbf{---}}), was 20.6 on November 30, 2020, in line with the average index value of 20.1 over the past three years.\n"
     ]
    }
   ],
   "source": [
    "prev = pd.read_excel(data_dir/ 'vixarchive.xls', skiprows=1, index_col='Date')\n",
    "VIX = 'http://www.cboe.com/publish/scheduledtask/mktdata/datahouse/vixcurrent.csv'\n",
    "curr = pd.read_csv(VIX, skiprows=1, index_col='Date', parse_dates=True)\n",
    "df = (prev.append(curr)['VIX Close'].resample('MS').mean()\n",
    "      .append(curr['VIX Close'].iloc[-1:]).rename('value'))\n",
    "df.to_csv(data_dir / 'vix.csv', index_label='date', header='True')\n",
    "\n",
    "node = end_node(df, 'magenta', percent=False)\n",
    "write_txt(text_dir / 'vix_node.txt', node)\n",
    "\n",
    "ldate = dtxt(df.index[-1])['day1']\n",
    "vallt = df.iloc[-1]\n",
    "val3y = df.iloc[-37:].mean()\n",
    "\n",
    "compare = compare_text(vallt, val3y, [3, 15, 30])\n",
    "\n",
    "text = ('This volatility measure, the VIX index (see {\\color{magenta}\\\\textbf{---}}), '+\n",
    "        f'was {vallt:.1f} on {ldate}, '+\n",
    "        f'{compare} the average index value of {val3y:.1f} over the '+\n",
    "        'past three years.')\n",
    "write_txt(text_dir / 'vixbasic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil prices (WTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:50:28.678088Z",
     "start_time": "2020-12-01T01:50:26.786088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 23, 2020, a barrel of west Texas intermediate (WTI) \\textbf{crude oil} sells for \\$42.91 (see {\\color{red!80!purple}\\textbf{---}}). Over the past year, this measure of oil prices fell 24.8 percent. Over the past three years, the price decreased 24.2 percent. Currently, the WTI price is \\$90.97 per barrel below its peak price in June 2008.\n"
     ]
    }
   ],
   "source": [
    "df = fred_df('DCOILWTICO')\n",
    "\n",
    "latest = df.iloc[-1]\n",
    "\n",
    "ma = df.resample('MS').mean()\n",
    "\n",
    "p = ma.append(latest)['VALUE']\n",
    "\n",
    "(p.to_csv(data_dir / 'wti.csv', index_label='date', header=True))\n",
    "\n",
    "oneyr = p.pct_change(13).iloc[-1] * 100\n",
    "\n",
    "threeyr = p.pct_change(37).iloc[-1] * 100\n",
    "\n",
    "oyt = value_text(oneyr, casual=True)\n",
    "tyt = value_text(threeyr)\n",
    "    \n",
    "ltch = p.loc['2008-06-01'] - p.iloc[-1]\n",
    "\n",
    "ldate = dtxt(p.index[-1])['day1']\n",
    "\n",
    "text = (f'As of {ldate}, a barrel of west Texas '+\n",
    "        f'intermediate (WTI) \\\\textbf{{crude oil}} sells for \\${p.iloc[-1]:.2f} '+\n",
    "        '(see {\\color{red!80!purple}\\\\textbf{---}}). Over the past '+\n",
    "        f'year, this measure of oil prices {oyt}. Over the past three years, '+\n",
    "        f'the price {tyt}. Currently, the WTI price is \\${ltch:.2f} per barrel '+\n",
    "        'below its peak price in June 2008.')\n",
    "\n",
    "write_txt(text_dir / 'wti.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflation Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T01:50:36.235326Z",
     "start_time": "2020-12-01T01:50:34.176140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 2020, consumers expect an average inflation rate of 2.5 percent over the next five years, (see {\\color{violet!60!magenta}\\textbf{---}}), compared to an expected rate of 2.5 percent in November 2019. Consumers had expected inflation to average 2.6 percent over the past five years, while actual inflation over the period was 1.8 percent.\n",
      "As of November 30, 2020, markets expect an average inflation rate of 1.68 percent over the next five years (see {\\color{blue!70!black}\\textbf{---}}), compared to an expected rate of 1.5 percent on November 29, 2019. Markets had expected inflation to average 1.33 percent over the past five years, five years ago.\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.sca.isr.umich.edu/files/tbmpx1px5.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.index = pd.to_datetime(df['Month'] + ' ' + df['YYYY'].astype('str'))\n",
    "data = df['PX5_MD'].loc['2015':]\n",
    "\n",
    "data.to_csv(data_dir / 'infumich.csv', index_label='date', header='VALUE')\n",
    "\n",
    "node = end_node(data, 'violet')\n",
    "write_txt(text_dir / 'infumich_node.txt', node)\n",
    "\n",
    "data1 = fred_df('T5YIE').loc['2015':,'VALUE']\n",
    "data1.to_csv(data_dir / 'infbreak.csv', index_label='date', header=True)\n",
    "\n",
    "node = end_node(data1, 'blue!70!black')\n",
    "write_txt(text_dir / 'infbreak_node.txt', node)\n",
    "\n",
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "pdate = dtxt(data.index[-13])['mon1']\n",
    "p5val = data.iloc[-61]\n",
    "lval = data.iloc[-1]\n",
    "pval = data.iloc[-13]\n",
    "\n",
    "ldatem = dtxt(data1.index[-1])['day1']\n",
    "lvalm = data1.iloc[-1]\n",
    "pdatem = dtxt(data1.index[-262])['day1']\n",
    "pvalm = data1.iloc[-262]\n",
    "p5valm = data1.iloc[-(262*5)]\n",
    "\n",
    "inf_act = pd.read_csv(data_dir / 'cpi.csv')['ALL'].iloc[-60:].mean()\n",
    "\n",
    "text = (f'As of {ldate}, consumers expect an average inflation rate of {lval} '+\n",
    "        'percent over the next five years, (see {\\color{violet!60!magenta}\\\\textbf{---}}), '+\n",
    "        f'compared to an expected rate of {pval} percent '+\n",
    "        f'in {pdate}. Consumers had expected inflation to average {p5val} percent over the past '+\n",
    "        f'five years, while actual inflation over the period was {inf_act:.1f} percent.')\n",
    "write_txt(text_dir / 'inf_exp_cons.txt', text)\n",
    "print(text)\n",
    "\n",
    "text2 = (f'As of {ldatem}, markets expect an average inflation rate of {lvalm} percent ' + \n",
    "         'over the next five years (see {\\color{blue!70!black}\\\\textbf{---}}), '\n",
    "         +f'compared to an expected rate of {pvalm} percent on '+\n",
    "         f'{pdatem}. Markets had expected inflation to average {p5valm} percent over the '+\n",
    "         f'past five years, five years ago.')\n",
    "write_txt(text_dir / 'inf_exp_mkts.txt', text2)\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
