{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T05:00:33.402361Z",
     "start_time": "2022-03-25T05:00:32.322910Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import time\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equities Index Data from Yahoo! Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:33.358979Z",
     "start_time": "2022-03-25T04:25:31.389447Z"
    }
   },
   "outputs": [],
   "source": [
    "ltdate = int(time.time())\n",
    "indices = ['GSPC', 'IXIC', 'DJI', 'RUT']\n",
    "raw = pd.DataFrame()\n",
    "for s in indices:\n",
    "    url = ('https://query1.finance.yahoo.com/v7/finance/download/'+\n",
    "           f'%5E{s}?period1=599616000&period2={ltdate}&'+\n",
    "           'interval=1d&events=history')\n",
    "    df = pd.read_csv(url, index_col='Date', parse_dates=True)\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    raw[f'{s}_close'] = df['Adj Close']\n",
    "    raw[f'{s}_volume'] = df['Volume']\n",
    "raw.to_csv(data_dir / 'equity_indices_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:33.485037Z",
     "start_time": "2022-03-25T04:25:33.360256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90747/3309950994.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = raw.resample('MS').mean().append(raw.iloc[-1])\n",
      "/tmp/ipykernel_90747/3309950994.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ch = ch.append(s)\n",
      "/tmp/ipykernel_90747/3309950994.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ch = ch.append(s)\n",
      "/tmp/ipykernel_90747/3309950994.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ch = ch.append(s)\n",
      "/tmp/ipykernel_90747/3309950994.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ch = ch.append(s)\n",
      "/tmp/ipykernel_90747/3309950994.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ch = ch.append(s)\n",
      "/tmp/ipykernel_90747/3309950994.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ch = ch.append(s)\n",
      "/tmp/ipykernel_90747/3309950994.py:30: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ch = ch.append((raw.iloc[-252:].mean() * 1000).rename('1-year moving average').apply('{:,.0f}'.format))#\n",
      "/tmp/ipykernel_90747/3309950994.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  ch = ch.append((raw.iloc[-1] * 1000).rename(dtxt(raw.index[-1])['day2']).apply('{:,.0f}'.format))#\n"
     ]
    }
   ],
   "source": [
    "closecol = [f'{s}_close' for s in indices]\n",
    "raw = pd.read_csv(data_dir / 'equity_indices_raw.csv', \n",
    "                  index_col='date', parse_dates=True)[closecol] / 1_000\n",
    "\n",
    "rename = {f'{s}_close': f'{s}_MA' for s in indices}\n",
    "(raw.join(raw.loc['2017':]\n",
    "          .rolling(252).mean()\n",
    "          .rename(rename, axis=1))\n",
    "    .loc['2018':]\n",
    "    .to_csv(data_dir / 'equity_indices_lt.csv', \n",
    "            index_label='date', float_format='%g'))\n",
    "data = raw.resample('MS').mean().append(raw.iloc[-1])\n",
    "res = data.rename({f'{s}_close': s for s in indices}, axis=1)\n",
    "res.to_csv(data_dir / 'equity_indices.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "rename = {f'{s}_close': f'{s}_MA' for s in indices}\n",
    "(raw.join(raw.loc['2017':]\n",
    "          .rolling(252).mean()\n",
    "          .rename(rename, axis=1))\n",
    "    .loc['2018':]\n",
    "    .to_csv(data_dir / 'equity_indices_lt.csv', \n",
    "            index_label='date', float_format='%g'))\n",
    "ch = pd.DataFrame()\n",
    "for year in range(2017, 2023):\n",
    "    yr = str(year)\n",
    "    py = str(year - 1)\n",
    "    s = (((raw.loc[yr].iloc[-1] / \n",
    "               raw.loc[py].iloc[-1]) - 1) * 100).rename(yr).apply('{:.1f}'.format)\n",
    "    ch = ch.append(s)\n",
    "ch = ch.append((raw.iloc[-252:].mean() * 1000).rename('1-year moving average').apply('{:,.0f}'.format))#\n",
    "ch = ch.append((raw.iloc[-1] * 1000).rename(dtxt(raw.index[-1])['day2']).apply('{:,.0f}'.format))#\n",
    "names = {'GSPC_close': '\\hspace{0.1mm} {\\color{green!80!blue!90!black}\\\\textbf{---}} \\ S\\&P 500', \n",
    "         'IXIC_close': '\\hspace{0.1mm} {\\color{blue}\\\\textbf{---}} \\ Nasdaq', \n",
    "         'DJI_close': '\\hspace{0.1mm} {\\color{red}\\\\textbf{---}} \\ Dow 30', \n",
    "         'RUT_close': '\\hspace{0.1mm} {\\color{violet}\\\\textbf{---}} \\ Russell 3000', }\n",
    "ch = (ch.rename({'2022': '2022 YTD'}).iloc[::-1].T)\n",
    "ch = (ch.reindex(list(names.keys())).rename(names))\n",
    "ch.to_csv(data_dir / 'equities.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:33.499307Z",
     "start_time": "2022-03-25T04:25:33.486162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of March 24, 2022, the S\\&P 500 has increased 210.6 percent since 2000, and increased 67.7 percent since 2018.\n",
      "The Nasdaq index increased 243.5 percent since 2000, and increased 102.5 percent since 2018.\n",
      "increased 205.6 percent since 2000 and increased 39.8 percent since 2018. \n",
      "Since 2000, the Russell 3000 has increased 318.1 percent. Since 2018, the measure increased 33.9 percent. \n"
     ]
    }
   ],
   "source": [
    "ltdt = dtxt(raw.index[-1])['day1']\n",
    "sp00 = ((raw['GSPC_close'].iloc[-1] / raw.loc['2000', 'GSPC_close'].iloc[0]) - 1) * 100\n",
    "sp00t = value_text(sp00)\n",
    "sp18 = ((raw['GSPC_close'].iloc[-1] / raw.loc['2018', 'GSPC_close'].iloc[0]) - 1) * 100\n",
    "sp18t = value_text(sp18)\n",
    "text = (f'As of {ltdt}, the S\\&P 500 has {sp00t} since 2000, and {sp18t} since 2018.')\n",
    "write_txt(text_dir / 'eq_sp500.txt', text)  \n",
    "print(text)\n",
    "ns00 = ((raw['IXIC_close'].iloc[-1] / raw.loc['2000', 'IXIC_close'].iloc[0]) - 1) * 100\n",
    "ns00t = value_text(ns00)\n",
    "ns18 = ((raw['IXIC_close'].iloc[-1] / raw.loc['2018', 'IXIC_close'].iloc[0]) - 1) * 100\n",
    "ns18t = value_text(ns18)\n",
    "text = (f'The Nasdaq index {ns00t} since 2000, and {ns18t} since 2018.')\n",
    "write_txt(text_dir / 'eq_nasdaq.txt', text)  \n",
    "print(text)\n",
    "dow00 = ((raw['DJI_close'].iloc[-1] / raw.loc['2000', 'DJI_close'].iloc[0]) - 1) * 100\n",
    "dow00t = value_text(dow00)\n",
    "dow18 = ((raw['DJI_close'].iloc[-1] / raw.loc['2018', 'DJI_close'].iloc[0]) - 1) * 100\n",
    "dow18t = value_text(dow18)\n",
    "text = (f'{dow00t} since 2000 and {dow18t} since 2018. ')\n",
    "write_txt(text_dir / 'eq_dow.txt', text)  \n",
    "print(text)\n",
    "ru00 = ((raw['RUT_close'].iloc[-1] / raw.loc['2000', 'RUT_close'].iloc[0]) - 1) * 100\n",
    "ru00t = value_text(ru00)\n",
    "ru18 = ((raw['RUT_close'].iloc[-1] / raw.loc['2018', 'RUT_close'].iloc[0]) - 1) * 100\n",
    "ru18t = value_text(ru18)\n",
    "text = (f'Since 2000, the Russell 3000 has {ru00t}. Since 2018, the measure {ru18t}. ')\n",
    "write_txt(text_dir / 'eq_russell.txt', text)  \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rates Data From Fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:39.157827Z",
     "start_time": "2022-03-25T04:25:33.500589Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.federalreserve.gov/datadownload/Output.aspx?'+\n",
    "       'rel=H15&series=4216503bb3a25c994952047659b79297&lastobs=&'+\n",
    "       'from=01/01/1988&to=12/31/2022&filetype=csv&label=include&'+\n",
    "       'layout=seriescolumn')\n",
    "d, df = clean_fed_data(url)\n",
    "df.to_csv(data_dir / 'fed_rates_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:39.246238Z",
     "start_time": "2022-03-25T04:25:39.158814Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(data_dir / 'fed_rates_raw.csv', \n",
    "                         index_col='date', parse_dates=True)\n",
    "\n",
    "n = {'RIFLGFCY10_N.B': 'Ten-year',\n",
    "    'RIFLGFCY30_N.B': 'Thirty-year',\n",
    "    'RIFSPFF_N.B': 'Fed Funds',\n",
    "    'RIFLGFCM03_N.B': 'Three-month',\n",
    "    'RIFLGFCY05_N.B': 'Five-year',\n",
    "    'RIFLGFCY02_N.B': 'Two-year',\n",
    "    'RIFLGFCM01_N.B': 'One-month',\n",
    "    'RIFLGFCY01_N.B': 'One-year',\n",
    "    'RIFLGFCY20_N.B': 'Twenty-year',\n",
    "    'RIFLGFCM06_N.B': 'Six-month',\n",
    "    'RIFLGFCY03_N.B': 'Three-year',\n",
    "    'RIFLGFCY07_N.B': 'Seven-year'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Ten-year'])\n",
    "df.to_csv(data_dir / 'treas_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T05:00:58.808266Z",
     "start_time": "2022-03-25T05:00:58.176490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taylor Rule suggested Fed Funds rate\n",
    "p = (pd.read_csv(data_dir / 'pce_pi.csv', parse_dates=['date'])\n",
    "       .set_index('date')['CORE']).resample('QS').mean() * 0.5\n",
    "\n",
    "y = ((nipa_df(retrieve_table('T10106')['Data'], ['A191RX']))\n",
    "      .loc['1989':, 'A191RX'])\n",
    "\n",
    "y_p = fred_df('GDPPOT')['VALUE'] * 1_000\n",
    "\n",
    "o = (y - (y_p)).divide(y_p).dropna()\n",
    "\n",
    "taylor_ff = (p + 3 + (0.5*(p - 2)) + (1*(o*100))).dropna()\n",
    "\n",
    "taylor_ff.name = 'Value'\n",
    "\n",
    "taylor_ff.to_csv(data_dir / 'taylor.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T05:00:59.818638Z",
     "start_time": "2022-03-25T05:00:59.139566Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_97777/3570789723.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = (df.resample('MS').mean().iloc[:-1].append(df.iloc[-1]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States Treasury securities, or \\textbf{treasuries}, are the asset created by federal government borrowing. The treasuries market is traditionally considered both very low risk and fairly liquid. The yield on these securities has fallen over time, from an average 10-year treasury bond annual yield of 8.5 percent in 1989 to an average of 0.62 percent in July 2020. As of March 23, 2022, the constant maturity yield for 10-year treasury bonds is 2.32 percent (see {\\color{blue!70!black}\\textbf{---}}), compared to 1.62 percent one year prior. \n",
      "\n",
      "Shorter-duration treasury yield have also fallen since 1989, though shorter-duration treasuries are more acutely affected by changes in the key interest rate set by the Federal Reserve. Over the past year, two-year treasury yields have increased by two percentage points, as the Federal Reserve is expected to raise interest rates. As of March 23, 2022, the annual yield on two-year treasuries is 2.13 percent (see {\\color{blue!60!black}\\textbf{---}}).  \n",
      "\n",
      "The effective fed funds rate is 0.33 percent, as of March 23, 2022 (see {\\color{blue!60!black}\\textbf{---}}).\n",
      "As of the fourth quarter of 2021, the modified Taylor rule suggests a federal funds rate of 5.0 percent, 4.67 percentage points above the current rate.\n",
      "\n",
      "FOMC meeting participants provide \\href{https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm}{projections} which can be used to summarize policymaker views on the future path of the federal funds rate, as seen by the people who set it. As of March 16, 2022, the median projected federal funds rate rate is 1.9 percent for 2022, 2.8 percent for 2023, and 2.8 percent for 2024 (see\\cbox{purple}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'treas_raw.csv', index_col='date', \n",
    "                 parse_dates=True).loc['1989':]\n",
    "\n",
    "data = (df.resample('MS').mean().iloc[:-1].append(df.iloc[-1]))\n",
    "data.to_csv(data_dir / 'rates.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ldate = dtxt(data.index[-1])['day1']\n",
    "tenlt = df['Ten-year'].iloc[-1]\n",
    "tenpr = df['Ten-year'].iloc[-252]\n",
    "twolt = df['Two-year'].iloc[-1]\n",
    "twopr = df['Two-year'].iloc[-252]\n",
    "val89 = df['Ten-year'].loc['1989'].mean()\n",
    "lowval = data['Ten-year'].min()\n",
    "lowmon = dtxt(data['Ten-year'].idxmin())['mon1']\n",
    "cline10 = c_line('blue!70!black')\n",
    "cline2 = c_line('cyan!90!white')\n",
    "ch2yr = value_text(df['Two-year'].diff(252).iloc[-1], \n",
    "                   'increase_by', ptype='pp')\n",
    "ff = fred_df('FEDTARMD')['VALUE']\n",
    "ffd = ff.diff(2).iloc[-1]\n",
    "fv = 'raise' if ffd > 0.3 else 'lower' if ffd <0.3 else 'maintain'\n",
    "cline = c_line('blue!60!black')\n",
    "text = ('United States Treasury securities, or \\\\textbf{treasuries}, are the '+\n",
    "        'asset created by federal government borrowing. The treasuries '+\n",
    "        'market is traditionally considered both very low risk and fairly '+\n",
    "        'liquid. The yield on these securities has fallen over time, '+\n",
    "        'from an average 10-year treasury bond annual yield of '+\n",
    "        f'{val89:.1f} percent in 1989 to an average of {lowval:.2f} '+\n",
    "        f'percent in {lowmon}. As of {ldate}, the constant maturity yield '+\n",
    "        f'for 10-year treasury bonds is {tenlt} percent {cline10}, '+\n",
    "        f'compared to {tenpr:.2f} percent one year prior. \\n\\nShorter-'+\n",
    "        'duration treasury yield have also fallen since 1989, '+\n",
    "        f'though shorter-duration treasuries are more acutely affected '+\n",
    "        'by changes in the key interest rate set by the Federal Reserve. '+\n",
    "        f'Over the past year, two-year treasury yields have {ch2yr}, '+\n",
    "        f'as the Federal Reserve is expected to {fv} interest rates. '+\n",
    "        f'As of {ldate}, the annual yield on two-year treasuries is '+\n",
    "        f'{twolt} percent {cline}. ')\n",
    "write_txt(text_dir / 'rates_basic.txt', text)\n",
    "print(text, '\\n')\n",
    "val = f'{data[\"Fed Funds\"].iloc[-1]:.2f} percent'\n",
    "text = (f'The effective fed funds rate is {val}, as of {ldate} {cline}.')\n",
    "write_txt(text_dir / 'rates_ff.txt', text)\n",
    "print(text)\n",
    "\n",
    "rows = ['One-month', 'Three-month', 'Six-month', 'One-year', \n",
    "        'Two-year', 'Three-year', 'Five-year', 'Seven-year', \n",
    "        'Ten-year', 'Twenty-year', 'Thirty-year']\n",
    "columns = [-1, -2, -5]\n",
    "data2 = df[rows].iloc[columns].T\n",
    "data2.columns = [dtxt(i)['day2'] for i in data2.keys()]\n",
    "curmo = pd.to_datetime(f\"{dtxt(df.index[-1])['mon5']}-01\")\n",
    "prmo = (curmo - pd.DateOffset(months=1))\n",
    "prmov = dtxt(prmo)['mon5']\n",
    "prmot = dtxt(prmo)['mon2']\n",
    "data2[prmot] = df.loc[prmov].mean()\n",
    "pryr = (curmo - pd.DateOffset(years=1))\n",
    "pryrv = dtxt(pryr)['mon5']\n",
    "pryrt = dtxt(pryr)['mon2']\n",
    "data2[pryrt] = df.loc[pryrv].mean()\n",
    "data2['2019'] = df.loc['2019'].mean()\n",
    "data2['2010 --`13'] = df.loc['2010': '2013'].mean()\n",
    "data2['1998 --`00'] = df.loc['1998': '2000'].mean()\n",
    "data2['1989'] = df.loc['1989'].mean()\n",
    "(data2.applymap('{:,.2f}'.format).replace('nan', '--')\n",
    "      .to_csv(data_dir / 'treasury_rates.tex', sep='&', \n",
    "           line_terminator='\\\\\\ ', quotechar=' '))\n",
    "\n",
    "sep = ff.loc[str(pd.to_datetime('today').year):]\n",
    "sep.index = sep.index + pd.DateOffset(months=6)\n",
    "sep.to_csv(data_dir / 'sep.csv', index_label='date', header=True)\n",
    "dt = dtxt(data.index[-1])['datetime']\n",
    "text = (f'\\draw [dashed, black!16] (axis cs:{{{dt}}},'+\n",
    "        '\\pgfkeysvalueof{/pgfplots/ymin}) -- '+\n",
    "        f'(axis cs:{{{dt}}}, \\pgfkeysvalueof{{'+\n",
    "        '/pgfplots/ymax});')\n",
    "write_txt(text_dir / 'ff_proj_bar.txt', text)\n",
    "\n",
    "url = ('https://api.stlouisfed.org/fred/series?'+\n",
    "       f'series_id=FEDTARMD&api_key={fred_key}&file_type=json')\n",
    "r = requests.get(url)\n",
    "mdt = dtxt(pd.to_datetime(r.json()['seriess'][0]['last_updated']))['day1']\n",
    "\n",
    "tffdt = dtxt(taylor_ff.index[-1])['qtr2']\n",
    "tfflt = taylor_ff.iloc[-1]\n",
    "fflt = data['Fed Funds'].iloc[-1]\n",
    "tffdiff = tfflt - fflt\n",
    "difftxt = value_text(tffdiff, 'above_below', ptype='pp', digits=2)\n",
    "url = 'https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm'\n",
    "sepcol = 'purple'\n",
    "text = (f'As of {tffdt}, the modified Taylor rule suggests a federal '+\n",
    "        f'funds rate of {tfflt:.1f} percent, {difftxt} the current '+\n",
    "        f'rate.\\n\\nFOMC meeting participants provide \\href{{{url}}}'+\n",
    "        '{projections} which can be used to summarize policymaker '+\n",
    "        'views on the future path of the federal funds rate, as seen '+\n",
    "        f'by the people who set it. As of {mdt}, the median projected '+\n",
    "        f'federal funds rate rate is {sep.iloc[-3]} percent for '+\n",
    "        f'{sep.index[-3].year}, {sep.iloc[-2]} percent for '+\n",
    "        f'{sep.index[-2].year}, and {sep.iloc[-1]} percent for '+\n",
    "        f'{sep.index[-1].year} {c_box(sepcol)}.')\n",
    "write_txt(text_dir / 'rates_ff_proj.txt', text)\n",
    "print(text)\n",
    "\n",
    "text = ('\\\\node[text width=7.8cm, anchor=west, fill=white] at (axis '+\n",
    "        'description cs: 0.01, 0.08){\\scriptsize Summary of Economic '+\n",
    "        f'Projections (\\color{{{sepcol}}}\\\\textbf{{SEP}}\\\\normalcolor) '+\n",
    "        f'as of {mdt}}};')\n",
    "write_txt(text_dir / 'rates_ff_proj_date.txt', text)\n",
    "\n",
    "node = (end_node(sep, sepcol, date='y', full_year=True, anchor='south', \n",
    "               align='center', colon=False, percent=True, offset=0.15))\n",
    "write_txt(text_dir / 'rates_ff_proj_node.txt', node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:37:54.210618Z",
     "start_time": "2020-09-18T17:37:54.206641Z"
    }
   },
   "source": [
    "### Yield Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:40.421061Z",
     "start_time": "2022-03-25T04:25:40.402608Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'treas_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "\n",
    "i = {'One-month': 1, 'Three-month': 2, 'One-year': 3, 'Two-year': 4, \n",
    "     'Five-year': 5, 'Ten-year': 6, 'Twenty-year': 7, 'Thirty-year': 8}\n",
    "tbl = pd.DataFrame()\n",
    "for v, c in [(-1, 'value'), (-252, 'oneyear'), (-252*5, 'fiveyear')]:\n",
    "    col = df[i.keys()].iloc[v]\n",
    "    col.index = col.index.map(i)\n",
    "    tbl[c] = col\n",
    "tbl.index.name = 'number'\n",
    "tbl['alignment'] = 270\n",
    "\n",
    "tbl.to_csv(data_dir / 'yc.csv', float_format='%g')\n",
    "dt = dtxt(df.index[-1])['day1']\n",
    "date = ('\\\\node[text width=3.8cm, anchor=west] at (axis description cs: '+\n",
    "        f'0, 0.95) {{\\small As of {{{dt}}}:}};')\n",
    "write_txt(text_dir / 'yc_date.txt', date)\n",
    "#print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:40.455267Z",
     "start_time": "2022-03-25T04:25:40.422114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of March 23, 2022, the spread between a 10-year treasury bond and a three-month treasury bill is 1.82 percentage points (see {\\color{blue!70!cyan!80!white}\\textbf{---}}), compared to 1.60 percentage points one year prior. The spread between 10-year and 2-year treasuries (see {\\color{red!60!violet!90!white}\\textbf{---}}) is 0.19 percentage point on March 23, 2022, and 1.48 percentage points one year prior.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'treas_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "\n",
    "data = df[df['Ten-year'] != 'ND'].astype('float')\n",
    "ldate = dtxt(data.index[-1])['day1']\n",
    "spread = pd.DataFrame()\n",
    "spread['Ten-3M'] = data['Ten-year'] - data['Three-month']\n",
    "spread['Ten-2Y'] = data['Ten-year'] - data['Two-year']\n",
    "spread.loc['2017':].to_csv(data_dir / 'spread.csv', index_label='date', \n",
    "                           float_format='%g', header=True)\n",
    "\n",
    "col103 = 'blue!70!cyan!80!white'\n",
    "col102 = 'red!60!violet!90!white'\n",
    "\n",
    "node = end_node(spread['Ten-3M'], col103, digits=2, date='d', full_year=True)\n",
    "write_txt(text_dir / 'spread_node.txt', node)\n",
    "\n",
    "node = end_node(spread['Ten-2Y'], col102, digits=2, date='d', full_year=True)\n",
    "write_txt(text_dir / 'spread_node2.txt', node)\n",
    "\n",
    "def pp(value):\n",
    "    return 'percentage points' if value > 1.01 else 'percentage point'\n",
    "\n",
    "lt3 = spread['Ten-3M'].iloc[-1]\n",
    "lt3t = f'{lt3:.2f} {pp(lt3)}'\n",
    "pr3 = spread['Ten-3M'].iloc[-252]\n",
    "pr3t = f'{pr3:.2f} {pp(pr3)}'\n",
    "lt2 = spread['Ten-2Y'].iloc[-1]\n",
    "lt2t = f'{lt2:.2f} {pp(lt2)}'\n",
    "pr2 = spread['Ten-2Y'].iloc[-252]\n",
    "pr2t = f'{pr2:.2f} {pp(pr2)}'\n",
    "\n",
    "text = (f'As of {ldate}, the spread between a 10-year treasury bond and '+\n",
    "        f'a three-month treasury bill is {lt3t} {c_line(col103)}, compared '+\n",
    "        f'to {pr3t} one year prior. The spread between 10-year and '+\n",
    "        f'2-year treasuries {c_line(col102)} is {lt2t} on {ldate}, and '+\n",
    "        f'{pr2t} one year prior.')\n",
    "write_txt(text_dir / 'spread_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:40.465129Z",
     "start_time": "2022-03-25T04:25:40.458157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since 1989, the US has entered into four recessions and the 10-year to 2-year segment of the yield curve has newly inverted six times. The most recent such inversion started on March 22, 2019.\n"
     ]
    }
   ],
   "source": [
    "sp = spread.loc[(spread['Ten-3M'] < 0) & \n",
    "                (spread['Ten-3M'].shift().rolling(252).min() >= 0), \n",
    "                'Ten-3M']\n",
    "num_ic = len(sp) + 1 # Add one for 1989\n",
    "tnum_ic = numbers[f'{num_ic:.1f}']\n",
    "icdt = dtxt(sp.index[-1])['day1']\n",
    "\n",
    "#rec = fred_df('USREC')\n",
    "#num_rec = len(rec[(rec.VALUE==1) & (rec.VALUE.shift(1) == 0)])\n",
    "#tnum_rec = numbers[f'{num_rec:.1f}']\n",
    "tnum_rec = 'four'\n",
    "text = (f'Since 1989, the US has entered into {tnum_rec} '+\n",
    "        'recessions and the 10-year to 2-year segment of '+\n",
    "        f'the yield curve has newly inverted {tnum_ic} times. '+\n",
    "        f'The most recent such inversion started on {icdt}.')\n",
    "write_txt(text_dir / 'yc_inversion.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:45.715178Z",
     "start_time": "2022-03-25T04:25:40.466647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Data: March 24, 2022\n"
     ]
    }
   ],
   "source": [
    "date = dtxt(pd.to_datetime('today'))['datetime']\n",
    "url = ('https://prices.lbma.org.uk/export/xls/?c={\"metals\":[\"gold\"],'+\n",
    "       '\"type\":\"daily\",\"currency\":[\"usd\"],\"published\":[\"am\"],'+\n",
    "       f'\"dates\":{{\"start\":\"1989-01-01\",\"end\":\"{date}\"}}}}')\n",
    "data = pd.read_excel(url, header=1, index_col=0, \n",
    "                     parse_dates=True).sort_index()\n",
    "print('Latest Data:', dtxt(data.index[-1])['day1'])\n",
    "data.to_csv(data_dir / 'gold_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:45.753705Z",
     "start_time": "2022-03-25T04:25:45.716520Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of March 24, 2022, one troy ounce of \\textbf{gold} \\href{https://www.lbma.org.uk/prices-and-data/precious-metal-prices#/table}{sells} for \\$1,945.90 (see {\\color{orange!40!yellow}\\textbf{---}}), compared to an average of \\$1,721.56 per ounce one year prior, during March 2021. Following the great recession, the monthly average price of gold reached \\$1,780.65 per ounce, in September 2011. In August 2020, the average monthly price reached \\$1,971.17 per ounce.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90747/1549099801.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(lt)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir / 'gold_raw.csv', index_col='date', \n",
    "                   parse_dates=True)\n",
    "df = data.resample('MS').mean().iloc[:-1]\n",
    "df.index = df.index + pd.DateOffset(days=14)\n",
    "lt = data.iloc[-1]\n",
    "df = df.append(lt)\n",
    "df.to_csv(data_dir / 'gold.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['day1']\n",
    "ltval = df.AM.iloc[-1]\n",
    "prdate = dtxt(df.index[-13])['mon1']\n",
    "prval = df.AM.iloc[-13]\n",
    "grdate = dtxt(df.loc['2006':'2011', 'AM'].idxmax())['mon1']\n",
    "grval = df.loc['2006':'2011', 'AM'].max()\n",
    "\n",
    "color = 'orange!40!yellow'\n",
    "node = end_node(df.AM, color, dollar=True, digits='comma', date='d', \n",
    "                offset=-0.35, full_year=True)\n",
    "write_txt(text_dir / 'gold_node.txt', node)\n",
    "\n",
    "url = 'https://www.lbma.org.uk/prices-and-data/precious-metal-prices#/table'\n",
    "maxdt = df.AM.idxmax()\n",
    "maxdtt = dtxt(maxdt)['mon1']\n",
    "maxval = df.AM.max()\n",
    "text = (f'As of {ltdate}, one troy ounce of \\\\textbf{{gold}} '+\n",
    "        f'\\href{{{url}}}{{sells}} for \\${ltval:,.2f} {c_line(color)}, '\n",
    "        f'compared to an average of \\${prval:,.2f} per ounce one '+\n",
    "        f'year prior, during {prdate}. Following the great recession, '+\n",
    "        f'the monthly average price of gold reached \\${grval:,.2f} '+\n",
    "        f'per ounce, in {grdate}. In {maxdtt}, the average monthly '+\n",
    "        f'price reached \\${maxval:,.2f} per ounce.')\n",
    "print(text)\n",
    "write_txt(text_dir / 'gold.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fed Balance Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:51.064240Z",
     "start_time": "2022-03-25T04:25:45.754811Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H41&series=38d757c01cb3b550176f371352643679&lastobs=&'\n",
    "dt = 'from=01/01/2002&to=12/31/2022&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split(';')[0]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "clean_data = clean_data / 1_000_000\n",
    "\n",
    "clean_data.to_csv(data_dir / 'fed_assets.csv', index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:51.071527Z",
     "start_time": "2022-03-25T04:25:51.065427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the COVID-19 pandemic, the Fed offered lending to businesses and currency swaps to major US trading partners, began to purchase commercial bonds, and expanded purchases of treasuries and mortgage-backed securities.\n",
      "\n",
      " The Fed balance sheet increased from \\$4.2 trillion in February 2020 to \\$9.0 trillion, as of the latest data, covering March 23, 2022. \n"
     ]
    }
   ],
   "source": [
    "ltval = clean_data['RESPPMA_N.WW'].iloc[-1].round(1)\n",
    "ltdate = dtxt(clean_data.index[-1])['day1']\n",
    "n = (clean_data.iloc[-1] - clean_data.iloc[-2])['RESPPMA_N.WW'] * 1000\n",
    "chval = (f'increased by \\${abs(n):.0f} billion' if n >= 10 \n",
    "         else f'decreased by \\${abs(n):.0f} billion' \n",
    "         if n <= -10 else 'was largely unchanged')\n",
    "\n",
    "text = ('In response to the collapse of the housing bubble, the Fed purchased '+\n",
    "        'U.S. Treasury bonds and mortgage-backed securities. Total assets held by '+\n",
    "        'the Federal Reserve (see {\\color{blue!80!black}\\\\textbf{---}}) '+\n",
    "        'increased from \\$0.9 trillion in August 2008 to '+\n",
    "        '\\$2.2 trillion in November 2008. Additional rounds of asset purchases, '+\n",
    "        'referred to as quantitative easing, increased the balance sheet to '+\n",
    "        '\\$4.5 trillion by January 2014. As bonds mature they were replaced '+\n",
    "        'until October 2017, when the Fed allowed the size of its balance '+\n",
    "        'sheet to normalize. Total assets fell below \\$3.8 trillion in August 2019.')\n",
    "write_txt(text_dir / 'fed_assets1.txt', text)\n",
    "        \n",
    "txt2 = ('Balance sheet normalization ended in September 2019 when the Fed increased '+\n",
    "        'operations in overnight and term repurchase agreement (repo) markets, following '+\n",
    "        'a sharp increase in rates in these markets. The Fed balance sheet '+\n",
    "        'increased to \\$4.1 trillion by December 2019.')\n",
    "write_txt(text_dir / 'fed_assets2.txt', txt2)\n",
    "        \n",
    "txt3 = ('During the COVID-19 pandemic, the Fed offered lending to businesses and '+\n",
    "        'currency swaps to major US trading partners, began to purchase commercial bonds, '+\n",
    "        'and expanded purchases of treasuries and mortgage-backed securities.\\n\\n '+\n",
    "        'The Fed balance sheet increased from \\$4.2 trillion in February 2020 to '+\n",
    "        f'\\${ltval} trillion, as of the latest data, covering {ltdate}. ')\n",
    "write_txt(text_dir / 'fed_assets3.txt', txt3)\n",
    "print(txt3)\n",
    "        \n",
    "### Add something about recent pace (e.g. \"The total value of Fed assets {chval} from the value one week prior.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fed Balance Sheet Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:56.430995Z",
     "start_time": "2022-03-25T04:25:51.072879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fed currently holds \\$5.8 trillion in Treasuries and \\$2.7 trillion in mortgage-backed securities. \n"
     ]
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H41&series=bbb7b50f663fe933c8cce7e3707e3998&lastobs=&'\n",
    "dt = 'from=01/01/2002&to=12/31/2022&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, clean_data = clean_fed_data(url)\n",
    "\n",
    "d2 = {'RESPPA_N.WW': '\\\\textbf{Total} (see {\\color{blue!80!black}\\\\textbf{---}})',\n",
    "      'RESPPALGUO_N.WW': '\\hspace{2mm}U.S. Treasury securities',\n",
    "      'RESPPALGASMO_N.WW': '\\hspace{2mm}Mortgage-backed securities',\n",
    "      'RESH4SCS_N.WW': '\\hspace{2mm}Central bank liquidity swaps',\n",
    "      'RESPPALGTR_N.WW': '\\hspace{2mm}Repurchase agreements',\n",
    "      'RESPPALD_N.WW': '\\hspace{2mm}Loans',\n",
    "      'RESPPALDJ_N.WW': '\\hspace{4mm}Payroll Protection Program',\n",
    "      'NetPremDisc': '\\hspace{2mm}Net unamortized premium',\n",
    "      'Other': '\\hspace{2mm}Other'}\n",
    "\n",
    "pr_di = ['RESPPALSD_N.WW', 'RESPPALSP_N.WW']\n",
    "\n",
    "data = clean_data.copy()\n",
    "data['Other'] = (data['RESPPA_N.WW'] - \n",
    "                             data.drop('RESPPA_N.WW', axis=1).sum(axis=1))\n",
    "data['NetPremDisc'] = data[pr_di].sum(axis=1)\n",
    "ltval_treas = data['RESPPALGUO_N.WW'].iloc[-1] / 1_000_000\n",
    "ltval_mbs = data['RESPPALGASMO_N.WW'].iloc[-1] / 1_000_000\n",
    "\n",
    "data = data.rename(d2, axis=1).drop(pr_di, axis=1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in [-1, -2, -5, -53, -105]:\n",
    "    df[dtxt(data.index[i])['day2']] = data.iloc[i]\n",
    "    \n",
    "(df.loc[list(d2.values()), :].div(1000)\n",
    "   .applymap('{:,.1f}'.format)\n",
    "   .to_csv(data_dir / 'fed_bal_sheet.tex', sep='&', \n",
    "           line_terminator='\\\\\\ ', quotechar=' '))\n",
    "\n",
    "text = (f'The Fed currently holds \\${ltval_treas:,.1f} trillion in Treasuries '+\n",
    "        f'and \\${ltval_mbs:,.1f} trillion in mortgage-backed securities. ')\n",
    "write_txt(text_dir / 'fed_assets4.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:58.265313Z",
     "start_time": "2022-03-25T04:25:56.432037Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.federalreserve.gov/datadownload/Output.aspx?'+\n",
    "       'rel=H10&series=8dea680ff61ef97f0aefa5b17d760d87&lastobs=&'+\n",
    "       'from=01/01/2015&to=12/31/2022&filetype=csv&label=include&'+\n",
    "       'layout=seriescolumn')\n",
    "d, clean_data = clean_fed_data(url)\n",
    "clean_data.to_csv(data_dir / 'fx_raw_st.csv', index_label='date')\n",
    "\n",
    "url2 = ('https://www.federalreserve.gov/datadownload/Output.aspx?'+\n",
    "        'rel=H10&series=3b4f0209725fa1526861cfa9eeea0473&lastobs=&'+\n",
    "        'from=01/01/1989&to=12/31/2022&filetype=csv&label=include&'+\n",
    "        'layout=seriescolumn')\n",
    "d, clean_data = clean_fed_data(url2)\n",
    "clean_data.to_csv(data_dir / 'fx_raw_lt.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:58.328019Z",
     "start_time": "2022-03-25T04:25:58.266470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fed separately calculates the trade-weighted exchange rate with \\textbf{advanced economies}, and with \\textbf{emerging markets}. Since 2006, the dollar has increased 24.6 percent against emerging market currencies (see {\\color{green!75!yellow!90!black}\\textbf{---}}), and increased 9.6 percent against advanced economy currencies (see {\\color{violet!90!blue}\\textbf{---}}).  \n",
      "\n",
      "As of March 18, 2022, the broad dollar index is 16.3 percent above its value at inception in 2006. Over the past three years, the index value has averaged 115.6, compared to an average of 112.6 over the previous three-years. \n",
      "\n",
      "As of March 18, 2022, one US dollar buys approximately: 1.26 Canadian dollars (see {\\color{green!85!blue}\\textbf{---}}), 119 Japanese yen (see {\\color{red}\\textbf{---}}), 0.91 euros (see {\\color{cyan!90!white}\\textbf{---}}), and 0.76 British pounds (see {\\color{blue!90!cyan}\\textbf{---}}). Over the past three years, the nominal exchange rate between the US dollar and the Canadian dollar increased 1.3 percent, the USD-JPY rate increased 9.1 percent, the USD-EUR rate increased 7.8 percent, and the USD-GBP rate increased 5.5 percent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90747/4022257957.py:11: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  twidx = (clean_data.resample('MS').mean()\n",
      "/tmp/ipykernel_90747/4022257957.py:45: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  (clean_data.resample('MS').mean().append(latest)[major]\n"
     ]
    }
   ],
   "source": [
    "clean_data = pd.read_csv(data_dir / 'fx_raw_lt.csv', index_col='date', \n",
    "                         parse_dates=True)\n",
    "\n",
    "for cc in ['EU', 'UK']:\n",
    "    clean_data[f'RXI_N.B.{cc}'] = 1 / clean_data[f'RXI$US_N.B.{cc}'] \n",
    "clean_data['RXI_N.B.JA'] = clean_data['RXI_N.B.JA'] / 100.0\n",
    "\n",
    "latest = clean_data.dropna(how='all').iloc[-1]\n",
    "major = ['RXI_N.B.EU', 'RXI_N.B.UK', 'RXI_N.B.CA', 'RXI_N.B.JA']\n",
    "indx = ['JRXWTFB_N.B', 'JRXWTFN_N.B', 'JRXWTFO_N.B']\n",
    "twidx = (clean_data.resample('MS').mean()\n",
    "                   .append(latest)[indx].dropna())\n",
    "node = end_node(twidx['JRXWTFB_N.B'], 'blue!60!black', date='day', \n",
    "                full_year=True)\n",
    "write_txt(text_dir / 'twd_node.txt', node)\n",
    "adj = node_adj(twidx)\n",
    "smax = twidx.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "cols = {'JRXWTFN_N.B': 'violet!90!blue', \n",
    "        'JRXWTFO_N.B': 'green!75!yellow!90!black'}\n",
    "date = {series: 'd' if series == smax else None \n",
    "        for series in cols.keys()}\n",
    "nodes  ='\\n'.join([end_node(twidx[series], color, \n",
    "                            date=date[series], \n",
    "                            full_year=True, digits=2,\n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in cols.items()])\n",
    "write_txt(text_dir / 'twd_nodes.txt', nodes) \n",
    "twidx.to_csv(data_dir / 'fx_idx.csv', index_label='date', \n",
    "             float_format='%g', header=True)\n",
    "\n",
    "# Advanced and emerging markets index txt\n",
    "ltadv = value_text(latest['JRXWTFN_N.B'] - 100)\n",
    "ltem = value_text(latest['JRXWTFO_N.B'] - 100)\n",
    "text = ('The Fed separately calculates the trade-weighted exchange '+\n",
    "        'rate with \\\\textbf{advanced economies}, and with '+\n",
    "        '\\\\textbf{emerging markets}. Since 2006, the dollar has '+\n",
    "        f'{ltem} against emerging market currencies '+\n",
    "        f'{c_line(cols[\"JRXWTFO_N.B\"])}, and {ltadv} against advanced '+\n",
    "        f'economy currencies {c_line(cols[\"JRXWTFN_N.B\"])}. ')\n",
    "write_txt(text_dir / 'twd_adv_em.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "(clean_data.resample('MS').mean().append(latest)[major]\n",
    "           .to_csv(data_dir / 'fx1.csv', index_label='date', \n",
    "                   float_format='%g'))\n",
    "df = clean_data[major]\n",
    "df.columns = [i[-2:] for i in df.columns]\n",
    "adj = node_adj(df)\n",
    "smax = df.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "cols = {'CA': 'green!85!blue', 'JA': 'red', 'EU': \n",
    "        'cyan!90!white', 'UK': 'blue!90!cyan'}\n",
    "date = {series: 'd' if series == smax else None \n",
    "        for series in cols.keys()}\n",
    "nodes  ='\\n'.join([end_node(df[series], color, \n",
    "                            date=date[series], \n",
    "                            full_year=True, digits=2,\n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in cols.items()])\n",
    "write_txt(text_dir / 'fx_nodes.txt', nodes) \n",
    "\n",
    "# Broad dollar index text\n",
    "ldate = dtxt(twidx.index[-1])['day1']\n",
    "lval = twidx['JRXWTFB_N.B'].iloc[-1]\n",
    "totch = ((lval / 100) - 1) * 100\n",
    "threeyr = twidx['JRXWTFB_N.B'].iloc[-38:].mean()\n",
    "prev3yr = twidx['JRXWTFB_N.B'].iloc[-74:-38].mean()\n",
    "text = (f'As of {ldate}, the broad dollar index is {totch:.1f} '+\n",
    "        'percent above its value at inception in '+\n",
    "        f'2006. Over the past three years, the index value has '+\n",
    "        f'averaged {threeyr:.1f}, compared to an average of '+\n",
    "        f'{prev3yr:.1f} over the previous three-years.')\n",
    "write_txt(text_dir / 'twdbasic.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "cl = {name: c_line(col) for name, col in cols.items()}\n",
    "lt = clean_data.loc[ldate]\n",
    "ltd = {name: lt[f'RXI_N.B.{name}'] for name in cols.keys()}\n",
    "pc = clean_data.pct_change(262).iloc[-1] * 100\n",
    "pcd = {name: value_text(pc[f'RXI_N.B.{name}'], threshold=0.1) for name in cols.keys()}\n",
    "text = (f'As of {ldate}, one US dollar buys approximately: '+\n",
    "        f'{ltd[\"CA\"]:.2f} Canadian dollars {cl[\"CA\"]}, '+\n",
    "        f'{ltd[\"JA\"] * 100:.0f} Japanese yen {cl[\"JA\"]}, '+\n",
    "        f'{ltd[\"EU\"]:.2f} euros {cl[\"EU\"]}, and {ltd[\"UK\"]:.2f} '+\n",
    "        f'British pounds {cl[\"UK\"]}. Over the past three years, '+\n",
    "        f'the nominal exchange rate between the US dollar and '+\n",
    "        f'the Canadian dollar {pcd[\"CA\"]}, the USD-JPY rate '+\n",
    "        f'{pcd[\"JA\"]}, the USD-EUR rate {pcd[\"EU\"]}, and the '+\n",
    "        f'USD-GBP rate {pcd[\"UK\"]}.')\n",
    "write_txt(text_dir / 'selcurr_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange Rates Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:25:58.359615Z",
     "start_time": "2022-03-25T04:25:58.329268Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(data_dir / 'fx_raw_st.csv', index_col='date', \n",
    "                         parse_dates=True)\n",
    "for cc in ['EU', 'UK', 'AL', 'NZ']:\n",
    "    clean_data[f'RXI_N.B.{cc}'] = 1 / clean_data[f'RXI$US_N.B.{cc}'] \n",
    "\n",
    "fx = {'RXI_N.B.EU': 'EUR',\n",
    "      'RXI_N.B.UK': 'GBP',\n",
    "      'RXI_N.B.JA': 'JPY',\n",
    "      'RXI_N.B.CA': 'CAD',\n",
    "      'RXI_N.B.MX': 'MXN',\n",
    "      'RXI_N.B.CH': 'CNY',\n",
    "      'RXI_N.B.SZ': 'CHF',\n",
    "      'RXI_N.B.HK': 'HKD',\n",
    "      'RXI_N.B.IN': 'INR',\n",
    "      'RXI_N.B.AL': 'AUD',\n",
    "      'RXI_N.B.NZ': 'NZD',\n",
    "      'RXI_N.B.BZ': 'BRL',\n",
    "      'RXI_N.B.KO': 'KRW',\n",
    "      'RXI_N.B.MA': 'MYR',\n",
    "      'RXI_N.B.DN': 'DKK',\n",
    "      'RXI_N.B.NO': 'NOK',\n",
    "      'RXI_N.B.SD': 'SEK',\n",
    "      'RXI_N.B.SF': 'ZAR',\n",
    "      'RXI_N.B.SI': 'SGD',\n",
    "      'RXI_N.B.TA': 'TWD'}\n",
    "\n",
    "tbl_data = clean_data[fx.keys()].dropna(how='all')\n",
    "tbl_data.columns = fx.values()\n",
    "#tbl_data.loc[:,'JPY'] *= 100\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table[dtxt(tbl_data.index[-1])['day2']] = tbl_data.iloc[-1]\n",
    "table['1-month moving average'] = tbl_data.iloc[-22:].mean()\n",
    "table['1-year moving average'] = tbl_data.iloc[-262:].mean()\n",
    "table['2019 average'] = tbl_data.loc['2019'].mean()\n",
    "dec1 = ['JPY', 'KRW']\n",
    "table.loc[['JPY', 'KRW'],:] = table.loc[['JPY', 'KRW'],:].applymap(\"{0:.1f}\".format)\n",
    "dec3 = ['GBP', 'EUR', 'CHF', 'AUD', 'NZD', 'CAD', 'SGD']\n",
    "table.loc[dec3,:] = table.loc[dec3,:].applymap(\"{0:.3f}\".format)\n",
    "table.loc[~table.index.isin(dec3+dec1)] = (table.loc[~table.index.isin(dec3+dec1)]\n",
    "                                           .applymap(\"{0:.2f}\".format))\n",
    "table['1-month percent change'] = (tbl_data.pct_change(22)\n",
    "                                   * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "table['1-year percent change'] = (tbl_data.pct_change(262)\n",
    "                                  * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "table['5-year percent change'] = (tbl_data.pct_change(262*5)\n",
    "                                  * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "\n",
    "table.index = [f'\\includegraphics[width=.03\\\\textwidth]{{data/flags/{cc}}} \\ {cc}' \n",
    "               for cc in table.index]\n",
    "\n",
    "(table.to_csv(data_dir / 'fx_table.tex', sep='&', \n",
    "              line_terminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobless claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:00.199390Z",
     "start_time": "2022-03-25T04:25:58.360795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Department of Labor \\href{https://www.dol.gov/ui/data.pdf}{report} 181,087 actual \\textbf{new claims for unemployment insurance} (UI) under state programs (see {\\color{cyan!80!blue}\\textbf{---}}) during the week ending March 19, 2022, a one-week decrease of 22,800. Over the past four weeks, new claims have averaged 200,200 per week. During the same four-week period last year, there were an average of 721,800 new claims per week.\n",
      "For the week ending March 12, 2022, the Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{reports}} 1,730,622 continued claims for unemployment insurance (insured unemployed) under state programs (see {\\color{green!90!blue}\\textbf{---}}), a one-week decrease of 73,700. One year prior, during the week of March 13, 2021, there were an average of 4,233,700 insured unemployed.\n"
     ]
    }
   ],
   "source": [
    "data = fred_df('ICNSA', start='2017') / 1000 \n",
    "data['1M'] = data['VALUE'].rolling(4).mean()\n",
    "data.div(1000).to_csv(data_dir / 'icsa.csv', index_label='date', \n",
    "                      float_format='%g')\n",
    "\n",
    "totval = data['VALUE'].iloc[-1]*1000\n",
    "datelt = dtxt(data.index[-1])['day1']\n",
    "latest1m = data[\"1M\"].iloc[-1]*1000\n",
    "prev1m = data[\"1M\"].iloc[-53]*1000\n",
    "\n",
    "chval = totval - data['VALUE'].iloc[-2]*1000\n",
    "chtxt = f'{round(abs(chval),-2):,.0f}'\n",
    "if chval > 1000:\n",
    "    change = f'a one-week increase of {chtxt}'\n",
    "elif chval < -1000:\n",
    "    change = f'a one-week decrease of {chtxt}'\n",
    "else:\n",
    "    change = 'virtually unchanged from the previous week'\n",
    "url = 'https://www.dol.gov/ui/data.pdf'\n",
    "col = 'cyan!80!blue'\n",
    "text = (f'The Department of Labor \\href{{{url}}}{{report}} '+\n",
    "        f'{totval:,.0f} actual \\\\textbf{{new claims for unemployment '+\n",
    "        f'insurance}} (UI) under state programs {c_line(col)} '+\n",
    "        f'during the week ending {datelt}, {change}. Over '+\n",
    "        f'the past four weeks, new claims have averaged '+\n",
    "        f'{round(latest1m,-2):,.0f} per week. During the same '+\n",
    "        f'four-week period last year, there were an average of '+\n",
    "        f'{round(prev1m,-2):,.0f} new claims per week.')\n",
    "write_txt(text_dir / 'icsa.txt', text)\n",
    "print(text)\n",
    "data = fred_df('CCNSA', start='2017') / 1000 \n",
    "data.div(1000).to_csv(data_dir / 'ccsa.csv', index_label='date', \n",
    "                      float_format='%g')\n",
    "\n",
    "totval = data['VALUE'].iloc[-1]*1000\n",
    "prval = data['VALUE'].iloc[-2]*1000\n",
    "datelt = dtxt(data.index[-1])['day1']\n",
    "prevyrval = data['VALUE'].iloc[-53]*1000\n",
    "prmoval = data['VALUE'].iloc[-4]*1000\n",
    "datepr = dtxt(data.index[-53])['day1']\n",
    "\n",
    "chval = totval - prval\n",
    "chtxt = f'{round(abs(chval),-2):,.0f}'\n",
    "if chval > 1000:\n",
    "    change = f'a one-week increase of {chtxt}'\n",
    "elif chval < -1000:\n",
    "    change = f'a one-week decrease of {chtxt}'\n",
    "else:\n",
    "    change = 'virtually unchanged from the previous week'\n",
    "color = 'green!90!blue'\n",
    "text = (f'For the week ending {datelt}, the Department of Labor '+\n",
    "        '\\href{{https://www.dol.gov/ui/data.pdf}}{{reports}} '+\n",
    "        f'{totval:,.0f} continued claims for unemployment '+\n",
    "        'insurance (insured unemployed) under state programs '+\n",
    "        f'{c_line(color)}, {change}. One year prior, during '+\n",
    "        f'the week of {datepr}, there were an average of '+\n",
    "        f'{round(prevyrval,-2):,.0f} insured unemployed.')\n",
    "write_txt(text_dir / 'ccsa.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:01.033020Z",
     "start_time": "2022-03-25T04:26:00.200482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the week ending March 5, 2022, there were 600 initial UI \\href{https://oui.doleta.gov/unemploy/DataDashboard.asp}{claims} under the Pandemic Unemployment Assistance (PUA) program (see {\\color{blue!50!purple!80!black}\\textbf{---}}), compared to 500 during the prior week, and an average of 600 initial claims per week over the past four weeks. \n",
      "\n",
      "Federal program continuing claims total 101,041 in March 5, 2022 (see {\\color{green!50!blue}\\textbf{---}}). These include both claims under the PUA program and claims under the Pandemic Emergency Unemployment Compensation (PEUC) program. Combining federal program claims with state program claims indicates there are a total of 1.8 million insured unemployed persons during the week ending March 5, 2022, compared to 2.0 million one month prior, during the week ending February 12, 2022. \n"
     ]
    }
   ],
   "source": [
    "file = 'https://oui.doleta.gov/unemploy/docs/weekly_pandemic_claims.xlsx'\n",
    "fed_raw = pd.read_excel(file, usecols='A:F', parse_dates=True).dropna()\n",
    "fed_raw['pua_ic'] = (fed_raw['PUA IC'].astype(str).str.strip()\n",
    "                     .replace('', '0').astype('int'))\n",
    "pua_ic = fed_raw.groupby('Rptdate')['pua_ic'].sum()\n",
    "pua_ic.index = pd.to_datetime(pua_ic.index)\n",
    "pua_ic.index.name = 'date'\n",
    "cc_raw = fed_raw.dropna(subset=['PUA CC'])\n",
    "pua_cc = cc_raw.groupby('Rptdate')['PUA CC'].sum()\n",
    "peuc_cc = cc_raw.groupby('Rptdate')['PEUC CC'].sum()\n",
    "fed_cc = pua_cc + peuc_cc\n",
    "fed_cc.index = pd.to_datetime(fed_cc.index)\n",
    "fed_cc.index.name = 'date'\n",
    "fed_cc.name = 'fed_cc'\n",
    "\n",
    "d1 = pd.DataFrame([pua_ic, fed_cc]).T / 1000\n",
    "d1.div(1000).to_csv(data_dir / 'fed_uic.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ltdate = dtxt(d1.index[-1])['day1']\n",
    "prdatecc = dtxt(d1.dropna().index[-4])['day1']\n",
    "ltdatecc = dtxt(d1.dropna().index[-1])['day1']\n",
    "pua_ic_lt = f\"{round(d1['pua_ic'].iloc[-1] * 1000, -2):,.0f}\"\n",
    "pua_ic_pr = f\"{round(d1['pua_ic'].iloc[-2] * 1000, -2):,.0f}\"\n",
    "pua_ic_1m = f\"{round(d1['pua_ic'].iloc[-4:].mean() * 1000, -2):,.0f}\"\n",
    "fed_cc_lt = d1.dropna()['fed_cc'].iloc[-1] * 1_000\n",
    "fed_cc_mo = d1.dropna()['fed_cc'].iloc[-4] * 1_000\n",
    "fed_cc_ltt = f\"{fed_cc_lt:,.0f}\"\n",
    "tot_cc = fed_cc_lt + totval\n",
    "tot_lt = f\"{tot_cc / 1_000_000:,.1f} million\"\n",
    "tot_cc_pr = fed_cc_mo + prmoval\n",
    "tot_pr = f\"{tot_cc_pr / 1_000_000:,.1f} million\"\n",
    "\n",
    "text = (f'Over the week ending {ltdate}, there were {pua_ic_lt} '+\n",
    "        'initial UI \\href{https://oui.doleta.gov/unemploy/DataDashboard.asp}{claims} '+\n",
    "        'under the Pandemic Unemployment Assistance '+\n",
    "        '(PUA) program (see {\\color{blue!50!purple!80!black}\\\\textbf{---}}), '+\n",
    "        f'compared to {pua_ic_pr} during the prior week, '+\n",
    "        f'and an average of {pua_ic_1m} initial claims per week over the '+\n",
    "        'past four weeks. \\n\\n'+\n",
    "        f'Federal program continuing claims total {fed_cc_ltt} '+\n",
    "        f'in {ltdatecc} '+\n",
    "        '(see {\\color{green!50!blue}\\\\textbf{---}}). These include both ' +\n",
    "        'claims under the PUA program and claims under the Pandemic Emergency '+\n",
    "        'Unemployment Compensation (PEUC) program. Combining federal program '+\n",
    "        f'claims with state program claims indicates there are a total '+\n",
    "        f'of {tot_lt} insured unemployed persons during the week ending {ltdatecc}, '+\n",
    "        f'compared to {tot_pr} one month prior, during the week ending {prdatecc}. ')\n",
    "write_txt(text_dir / 'fed_uic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIX (SP500 volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:01.287613Z",
     "start_time": "2022-03-25T04:26:01.034107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This volatility measure, the VIX index (see {\\color{magenta}\\textbf{---}}), was 23.6 on March 23, 2022, in line with the average index value of 22.2 over the past three years. The VIX decreased by 3.1 points over the past week.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90747/3621382974.py:4: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = (curr['CLOSE'].resample('MS').mean()\n"
     ]
    }
   ],
   "source": [
    "VIX = ('https://cdn.cboe.com/api/global/us_indices/daily_prices/'+\n",
    "       'VIX_History.csv')\n",
    "curr = pd.read_csv(VIX, index_col='DATE', parse_dates=True)\n",
    "df = (curr['CLOSE'].resample('MS').mean()\n",
    "      .append(curr['CLOSE'].iloc[-1:]).rename('value'))\n",
    "df.to_csv(data_dir / 'vix.csv', index_label='date', header='True')\n",
    "color = 'magenta'\n",
    "node = end_node(df, color, date='d', offset=0.35, full_year=True)\n",
    "write_txt(text_dir / 'vix_node.txt', node)\n",
    "\n",
    "ldate = dtxt(df.index[-1])['day1']\n",
    "vallt = df.iloc[-1]\n",
    "val3y = df.iloc[-37:].mean()\n",
    "\n",
    "compare = compare_text(vallt, val3y, [3, 12, 30])\n",
    "\n",
    "one_wk = (value_text(curr.CLOSE.diff(5).iloc[-1], \n",
    "                     style='increase_by', ptype='pp')\n",
    "          .replace('percentage ', ''))\n",
    "\n",
    "text = (f'This volatility measure, the VIX index {c_line(color)}, '+\n",
    "        f'was {vallt:.1f} on {ldate}, {compare} the average index '+\n",
    "        f'value of {val3y:.1f} over the past three years. The VIX '+\n",
    "        f'{one_wk} over the past week.')\n",
    "write_txt(text_dir / 'vixbasic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil prices (WTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:02.153555Z",
     "start_time": "2022-03-25T04:26:01.289665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Data: March 22, 2022\n"
     ]
    }
   ],
   "source": [
    "url = (f'https://api.eia.gov/series/?api_key={eia_key}'+\n",
    "       '&series_id=PET.RCLC1.D&start=19890101')\n",
    "\n",
    "r = requests.get(url).json()\n",
    "data = (pd.Series({pd.to_datetime(f'{i[0]}'): i[1] \n",
    "                   for i in r['series'][0]['data']})\n",
    "          .sort_index().to_frame(name='VALUE'))\n",
    "print('Latest Data:', dtxt(data.index[-1])['day1'])\n",
    "data.to_csv(data_dir / 'wti_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:02.182927Z",
     "start_time": "2022-03-25T04:26:02.154706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of March 22, 2022, the benchmark \\href{https://www.eia.gov/dnav/pet/hist/RCLC1D.htm}{futures price} for a barrel of west Texas intermediate (WTI) \\textbf{crude oil} is \\$111.76 (see {\\color{red!80!purple}\\textbf{---}}). Over the past year, this measure of oil prices increased 79.2 percent. Over the past two years, the price increased 267.1 percent. The WTI price is currently \\$22 per barrel below its peak monthly average price of \\$134 per barrel in June 2008.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90747/2215678221.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(lt)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir / 'wti_raw.csv', index_col='date', \n",
    "                   parse_dates=True)\n",
    "df = data.resample('MS').mean().iloc[:-1]\n",
    "df.index = df.index + pd.DateOffset(days=14)\n",
    "lt = data.iloc[-1]\n",
    "df = df.append(lt)\n",
    "df.to_csv(data_dir / 'wti.csv', index_label='date')\n",
    "\n",
    "oneyr = value_text(df.VALUE.pct_change(12).iloc[-1] * 100)\n",
    "twoyr = value_text(df.VALUE.pct_change(24).iloc[-1] * 100)\n",
    "\n",
    "color = 'red!80!purple'\n",
    "node = end_node(df.VALUE, color, dollar=True, digits=2, date='d', \n",
    "                offset=True, full_year=True)\n",
    "write_txt(text_dir / 'oil_node.txt', node)\n",
    "\n",
    "maxdt = df.VALUE.idxmax()\n",
    "maxdtt = dtxt(maxdt)['mon1']\n",
    "maxval = df.VALUE.max()\n",
    "ltch = df.loc[maxdt, 'VALUE'] - df.VALUE.iloc[-1]\n",
    "ldate = dtxt(df.index[-1])['day1']\n",
    "url = 'https://www.eia.gov/dnav/pet/hist/RCLC1D.htm'\n",
    "text = (f'As of {ldate}, the benchmark \\href{{{url}}}{{futures price}} '+\n",
    "        f'for a barrel of west Texas intermediate (WTI) '+\n",
    "        f'\\\\textbf{{crude oil}} is \\${lt.VALUE:.2f} {c_line(color)}. '+\n",
    "        f'Over the past year, this measure of oil prices {oneyr}. Over '+\n",
    "        f'the past two years, the price {twoyr}. The WTI price is '+\n",
    "        f'currently \\${ltch:.0f} per barrel below its peak monthly '+\n",
    "        f'average price of \\${maxval:.0f} per barrel in {maxdtt}.')\n",
    "write_txt(text_dir / 'wti.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflation Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:03.368063Z",
     "start_time": "2022-03-25T04:26:02.184053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of March 24, 2022, markets expect an average inflation rate of 3.6 percent over the next five years (see {\\color{blue!70!black}\\textbf{---}}), compared to an expected rate of 2.5 percent on March 25, 2021. Markets had expected inflation to average 1.9 percent per year over the past five years, five years ago.\n",
      "Over this five-year period, markets suggest 2.3 percent inflation per year. Inflation rates in the near-term are therefore expected to exceed inflation rates in the longer-term\n"
     ]
    }
   ],
   "source": [
    "data1 = fred_df('T5YIE').loc['2015':,'VALUE']\n",
    "data1.to_csv(data_dir / 'infbreak.csv', index_label='date', \n",
    "             header=True)\n",
    "data2 = fred_df('T5YIFR').loc['2015':,'VALUE']\n",
    "df = pd.DataFrame({'5_year_breakeven': data1, \n",
    "                   '5_year_5_year_forward': data2})\n",
    "df.to_csv(data_dir / 'infbreak_comb.csv', index_label='date')\n",
    "\n",
    "color = 'blue!70!black'\n",
    "\n",
    "node = end_node(data1, color, percent=True)\n",
    "write_txt(text_dir / 'infbreak_node.txt', node)\n",
    "\n",
    "ldatem = dtxt(data1.index[-1])['day1']\n",
    "lvalm = data1.iloc[-1]\n",
    "pdatem = dtxt(data1.dropna().index[-252])['day1']\n",
    "pvalm = data1.dropna().iloc[-252]\n",
    "p5valm = data1.dropna().iloc[-(252*5)]\n",
    "\n",
    "text = (f'As of {ldatem}, markets expect an average inflation '+\n",
    "        f'rate of {lvalm:.1f} percent over the next five ' + \n",
    "        f'years {c_line(color)}, compared to an expected rate '+\n",
    "        f'of {pvalm:.1f} percent on {pdatem}. Markets had expected '+\n",
    "        f'inflation to average {p5valm:.1f} percent per year over '+\n",
    "        f'the past five years, five years ago.')\n",
    "write_txt(text_dir / 'inf_exp_mkts.txt', text)\n",
    "print(text)\n",
    "\n",
    "p55val = data2.iloc[-1]\n",
    "if data2.iloc[-1] + 0.1 > data1.iloc[-1]:\n",
    "    compare = 'fall below '\n",
    "elif data2.iloc[-1] - 0.1 < data1.iloc[-1]:\n",
    "    compare = 'exceed '\n",
    "else:\n",
    "    compare = 'maintain the same rate as '\n",
    "text = (f'Over this five-year period, markets suggest {p55val:.1f} '+\n",
    "        f'percent inflation per year. Inflation rates in the near-term '+\n",
    "        f'are therefore expected to {compare}inflation rates in the '+\n",
    "        'longer-term')\n",
    "write_txt(text_dir / 'inf_exp_mkts_55.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T21:23:52.854402Z",
     "start_time": "2022-03-12T21:23:52.849021Z"
    }
   },
   "source": [
    "### High Yield Corporate Bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:03.884444Z",
     "start_time": "2022-03-25T04:26:03.369246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of March 23, 2022, the effective yield for \\textbf{high yield corporate bonds} in the index is 6.0 percent (see {\\color{red!50!purple}\\textbf{---}}). In February 2022, the average effective yield was 5.4 percent. Prior to the COVID-19 pandemic, in 2019, the average effective yield was 6.1 percent. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90747/2554936523.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = df.dropna().resample('MS').mean().append(df.iloc[-1])\n"
     ]
    }
   ],
   "source": [
    "df = fred_df('BAMLH0A0HYM2EY')\n",
    "data = df.dropna().resample('MS').mean().append(df.iloc[-1])\n",
    "data = data[~data.index.duplicated(keep='last')]\n",
    "data.to_csv(data_dir / 'highyield.csv', index_label='date')\n",
    "color = 'red!50!purple'\n",
    "\n",
    "node = end_node(data['VALUE'], color, percent=True, date='d', full_year=True)\n",
    "write_txt(text_dir / 'highyield_node.txt', node)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['day1']\n",
    "ltval = data.VALUE.iloc[-1]\n",
    "mm = -2 if df.index[-1].is_month_start == True else -3\n",
    "prmoval = data.VALUE.iloc[mm]\n",
    "prmo = dtxt(data.index[mm])['mon1']\n",
    "val19 = data.loc['2019', 'VALUE'].mean()\n",
    "\n",
    "text = (f'As of {ltdt}, the effective yield for \\\\textbf{{high yield '+\n",
    "        f'corporate bonds}} in the index is {ltval:.1f} percent '+\n",
    "        f'{c_line(color)}. In {prmo}, the average effective yield was '+\n",
    "        f'{prmoval:.1f} percent. Prior to the COVID-19 pandemic, '+\n",
    "        f'in 2019, the average effective yield was {val19:.1f} '+\n",
    "        'percent. ')\n",
    "write_txt(text_dir / 'highyield.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporate Bonds Total Returns Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:03.887826Z",
     "start_time": "2022-03-25T04:26:03.885457Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = fred_df('BAMLCC0A0CMTRIV')\n",
    "#data = df.dropna().resample('MS').mean().append(df.iloc[-1])\n",
    "#data = data[~data.index.duplicated(keep='last')]\n",
    "#data.to_csv(data_dir / 'corpbond_tri.csv', index_label='date')\n",
    "#color = 'violet!80!blue'\n",
    "\n",
    "#node = end_node(data['VALUE'], color, percent=True, date='d', full_year=True)\n",
    "#write_txt(text_dir / 'cbtri_node.txt', node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rates Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:26:05.022028Z",
     "start_time": "2022-03-25T04:26:03.888916Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.clevelandfed.org/en/our-research/indicators-and-data/'+\n",
    "       '~/media/content/our%20research/indicators%20and%20data/'+\n",
    "       'inflation%20expectations/ie%20latest/ie%20xls.xls?la=en')\n",
    "df = pd.read_excel(url, sheet_name='Expected Inflation', index_col=0, \n",
    "                   parse_dates=True)\n",
    "df.columns = df.columns.str.replace('Expected Inflation', '').str.strip()\n",
    "df.to_csv(data_dir / 'exp_infl_raw.csv', index_label='date')\n",
    "\n",
    "df = pd.read_excel(url, sheet_name='Real Interest Rate', index_col=0, \n",
    "                   parse_dates=True)\n",
    "df.columns = df.columns.str.strip()\n",
    "df.to_csv(data_dir / 'frbcle_real_yield.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:29:53.180517Z",
     "start_time": "2022-03-25T04:29:53.115025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the three months ending March 2022, nominal two-year treasury yields increased 1.10 percentage points, real yields increased 0.81 percentage point, and inflation expectations increased 0.28 percentage point. Ten-year treasury nominal yields increased 0.57 percentage point, real yields increased 0.40 percentage point, and inflation expectations increased 0.17 percentage point.\n",
      "\n",
      "Over the three years ending March 2022, the nominal yield on two-year treasuries decreased 0.63 percentage point, the real yield decreased 1.47 percentage points, and inflation expectations increased 0.83 percentage point. For ten-year treasuries, the nominal yield decreased 0.54 percentage point, the real yield increased 0.40 percentage point, and expected inflation increased 0.24 percentage point.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'exp_infl_raw.csv', index_col='date', \n",
    "                  parse_dates=True) * 100\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "write_txt(text_dir / 'frbcle_ry_date.txt', ltdt)\n",
    "df2 = pd.read_csv(data_dir / 'treas_raw.csv', index_col='date', \n",
    "                  parse_dates=True).resample('MS').mean()\n",
    "\n",
    "data, data2 = pd.DataFrame(), pd.DataFrame()\n",
    "for dv in [3, 36]:\n",
    "    for yr in [2, 5, 10]:\n",
    "        ty = df2[f'{numbers2[yr].capitalize()}-year'].diff(dv).rename('Total')\n",
    "        ie = df[f'{yr} year'].diff(dv).rename('IE')\n",
    "        ry = (ty - ie).rename('RY')\n",
    "        res = pd.DataFrame([ty, ie, ry]).T.iloc[-1]\n",
    "        if dv == 3:\n",
    "            data[f'{yr}-year'] = res\n",
    "        else:\n",
    "            data2[f'{yr}-year'] = res\n",
    "tbl, tbl2 = data.T, data2.T\n",
    "tbl.to_csv(data_dir / 'inf_exp_ch.csv', index_label='name')\n",
    "tbl2.to_csv(data_dir / 'inf_exp_ch2.csv', index_label='name')\n",
    "offset = 0.08\n",
    "cols = ['IE', 'RY']\n",
    "nodes = []\n",
    "for col, row in itertools.product(cols, [0, 1, 2]):\n",
    "    sdf = tbl[cols].iloc[row]\n",
    "    i = tbl[col].iloc[row]\n",
    "    if tbl[col].iloc[row] >= 0: \n",
    "        h = ((sdf.cumsum() - (sdf / 2) + offset))\n",
    "    else:\n",
    "        h = (sdf / 2) + offset\n",
    "    v = h.to_dict()\n",
    "    node = (f'\\\\absnode{{{row}.22}}{{{v[col]}}}'+\n",
    "            f'{{\\scriptsize {i:.2f}}}')\n",
    "    nodes.append(node)\n",
    "nodetext = '\\n'.join(nodes)\n",
    "write_txt(text_dir / 'inf_exp_ch_nodes.txt', nodetext)\n",
    "offset = 0.12\n",
    "nodes = []\n",
    "for col, row in itertools.product(cols, [0, 1, 2]):\n",
    "    sdf = tbl2[cols].iloc[row]\n",
    "    i = tbl2[col].iloc[row]\n",
    "    if tbl2[col].iloc[row] >= 0: \n",
    "        h = ((sdf.cumsum() - (sdf / 2) + offset))\n",
    "    else:\n",
    "        h = (sdf / 2) + offset\n",
    "    v = h.to_dict()\n",
    "    node = (f'\\\\absnode{{{row}.22}}{{{v[col]}}}'+\n",
    "            f'{{\\scriptsize {i:.2f}}}')\n",
    "    nodes.append(node)\n",
    "nodetext = '\\n'.join(nodes)\n",
    "write_txt(text_dir / 'inf_exp_ch_nodes2.txt', nodetext)\n",
    "\n",
    "tx = pd.DataFrame({col: tbl[col].apply(lambda x: value_text(x, ptype='pp', digits=2)) \n",
    "                   for col in tbl.columns})\n",
    "tx2 = tx.loc['2-year']\n",
    "tx10 = tx.loc['10-year']\n",
    "tx_ = pd.DataFrame({col: tbl2[col].apply(lambda x: value_text(x, ptype='pp', digits=2)) \n",
    "                   for col in tbl2.columns})\n",
    "tx_2 = tx_.loc['2-year']\n",
    "tx_10 = tx_.loc['10-year']\n",
    "\n",
    "\n",
    "text = (f'Over the three months ending {ltdt}, nominal two-year '+\n",
    "        f'treasury yields {tx2.Total}, real yields {tx2.RY}, and '+\n",
    "        f'inflation expectations {tx2.IE}. Ten-year treasury nominal '+\n",
    "        f'yields {tx10.Total}, real yields {tx10.RY}, and inflation '+\n",
    "        f'expectations {tx10.IE}.\\n\\nOver the three years ending {ltdt}, '+\n",
    "        f'the nominal yield on two-year treasuries {tx_2.Total}, '+\n",
    "        f'the real yield {tx_2.RY}, and inflation expectations {tx_2.IE}. '+\n",
    "        f'For ten-year treasuries, the nominal yield {tx_10.Total}, '+\n",
    "        f'the real yield {tx10.RY}, and expected inflation {tx_10.IE}.')\n",
    "write_txt(text_dir / 'real_yield_model_ch.txt', text) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Interest Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:29:58.323477Z",
     "start_time": "2022-03-25T04:29:58.287825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model-based real yield on ten-year treasuries is 0.31 percent, as of March 2022 (see {\\color{blue}\\textbf{---}}). Ten-year treasury real yields averaged 3.30 percent during the 1990s. The model-based real yield for one-year treasuries is -3.51 percent in March 2022, compared to an average of 2.21 percent during the 1990s (see {\\color{green!68!black}\\textbf{---}}). \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'frbcle_real_yield.csv', index_col='date', \n",
    "                  parse_dates=True) * 100\n",
    "clean_data = pd.read_csv(data_dir / 'fed_rates_raw.csv', \n",
    "                         index_col='date', parse_dates=True)\n",
    "\n",
    "n = {'RIFLGFCY10_XII_N.B': 'Ten-year',\n",
    "     'RIFLGFCY05_XII_N.B': 'Five-year'}\n",
    "\n",
    "df3 = (clean_data[n.keys()].rename(n, axis=1)\n",
    "       .dropna(subset=['Ten-year']))\n",
    "\n",
    "data = pd.concat([df3.resample('MS').mean().iloc[:-1], \n",
    "                  df3.iloc[-1].to_frame().T], axis=0)\n",
    "\n",
    "#res = (pd.concat([data['Ten-year'], df], axis=1)\n",
    "#         .loc['1989':])\n",
    "res = df.loc['1989':]\n",
    "res.to_csv(data_dir / 'real_rates2.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "adj = node_adj(res)\n",
    "smax = res.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'Real Rate 10-year': 'blue', \n",
    "          'Real Rate 1-year': 'green!68!black'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(res[series], color, \n",
    "                            date=date[series], full_year=True, \n",
    "                            percent=True,\n",
    "                            digits=2, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'real_yield_nodes2.txt', nodes) \n",
    "\n",
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "ltval = res[\"Real Rate 10-year\"].iloc[-1]\n",
    "val90 = res.loc['1990':'1999', 'Real Rate 10-year'].mean()\n",
    "lt1 = res[\"Real Rate 1-year\"].iloc[-1]\n",
    "lt190 = res.loc['1990':'1999', 'Real Rate 1-year'].mean()\n",
    "cl = c_line(colors[\"Real Rate 10-year\"])\n",
    "cl2 = c_line(colors[\"Real Rate 1-year\"])\n",
    "text = ('The model-based real yield on ten-year treasuries is '+\n",
    "        f'{ltval:.2f} percent, as of {ltdt} {cl}. Ten-year '+\n",
    "        f'treasury real yields averaged {val90:.2f} percent during '+\n",
    "        'the 1990s. The model-based real yield for one-year '+\n",
    "        f'treasuries is {lt1:.2f} percent in {ltdt}, compared '+\n",
    "        f'to an average of {lt190:.2f} percent during the 1990s '+\n",
    "        f'{cl2}. ')\n",
    "write_txt(text_dir / 'real_yield_model.txt', text) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-25T04:30:02.479777Z",
     "start_time": "2022-03-25T04:30:02.441841Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One measure of real interest rates is treasury inflation-indexed securities. The yield on these securities can be a proxy for the interest rate investors would charge for treasuries, without inflation. \n",
      "\n",
      "On March 23, 2022, the real yield on ten year treasuries was -0.62 percent (see {\\color{green!85!blue}\\textbf{---}}), compared to -0.97 percent three months prior, on December 17, 2021. Five-year treasuries yield -1.23 percent in the latest data, and -1.47 percent three months prior, after adjusting for expected inflation (see {\\color{violet!50!blue!60!white}\\textbf{---}}). \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90747/141321519.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = (df.resample('MS').mean().iloc[:-1].append(df.iloc[-1]))\n"
     ]
    }
   ],
   "source": [
    "clean_data = pd.read_csv(data_dir / 'fed_rates_raw.csv', \n",
    "                         index_col='date', parse_dates=True)\n",
    "\n",
    "n = {'RIFLGFCY10_XII_N.B': 'Ten-year',\n",
    "     'RIFLGFCY05_XII_N.B': 'Five-year'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Ten-year'])\n",
    "\n",
    "data = (df.resample('MS').mean().iloc[:-1].append(df.iloc[-1]))\n",
    "data.to_csv(data_dir / 'real_rates.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "adj = node_adj(df)\n",
    "smax = df.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'Five-year': 'violet!50!blue!60!white', 'Ten-year': 'green!85!blue'}\n",
    "date = {series: 'd' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(df[series], color, \n",
    "                            date=date[series], full_year=True, \n",
    "                            digits=2, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'real_yield_nodes.txt', nodes)  \n",
    "\n",
    "ltdt = dtxt(df.index[-1])['day1']\n",
    "prdt = (dtxt(df.index[-66])['day4'] if df.index[-66].year == df.index[-1].year \n",
    "          else dtxt(df.index[-66])['day1'])\n",
    "ltval = df['Ten-year'].iloc[-1]\n",
    "ltval5 = df['Five-year'].iloc[-1]\n",
    "prval = df['Ten-year'].iloc[-66]\n",
    "prval5 = df['Five-year'].iloc[-66]\n",
    "cl = c_line(colors['Ten-year'])\n",
    "cl2 = c_line(colors['Five-year'])\n",
    "ch10 = value_text(df['Ten-year'].diff(252).iloc[-1], 'increase_by', \n",
    "                  ptype='pp', digits=2)\n",
    "ch5 = value_text(df['Five-year'].diff(252).iloc[-1], 'increase_by', \n",
    "                  ptype='pp', digits=2)\n",
    "text = ('One measure of real interest rates is treasury '+\n",
    "        'inflation-indexed securities. The yield on these securities '+\n",
    "        'can be a proxy for the interest rate investors would charge '+\n",
    "        'for treasuries, without inflation. \\n\\n'+\n",
    "        f'On {ltdt}, the real yield on ten year treasuries was {ltval:.2f} '+\n",
    "        f'percent {cl}, compared to {prval:.2f} percent three months prior, '+\n",
    "        f'on {prdt}. Five-year treasuries yield {ltval5:.2f} percent in the '+\n",
    "        f'latest data, and {prval5:.2f} percent three months prior, after '+\n",
    "        f'adjusting for expected inflation {cl2}. ')\n",
    "write_txt(text_dir / 'real_rates_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
