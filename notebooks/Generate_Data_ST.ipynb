{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('../src')\n",
    "\n",
    "import requests\n",
    "from io import StringIO\n",
    "import time\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'Date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a1533ae63e59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcsv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     d[t[1:]] = pd.read_table(csv, sep=',',\n\u001b[0m\u001b[1;32m     23\u001b[0m                              parse_dates=['Date']).set_index('Date')['Adj Close']\n\u001b[1;32m     24\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1947\u001b[0m                 \u001b[0m_validate_usecols_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1949\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_noconvert_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_set_noconvert_columns\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2013\u001b[0m                         \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2014\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2015\u001b[0;31m                     \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2017\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_set\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_noconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'Date' is not in list"
     ]
    }
   ],
   "source": [
    "tickers = ['^GSPC']\n",
    "start = '852076800'\n",
    "base = 'https://finance.yahoo.com/quote/'\n",
    "base2 = 'https://query1.finance.yahoo.com/v7/finance/download/'\n",
    "end = int(time.time())\n",
    "dates = '?period1={}&period2={}'.format(start, end)\n",
    "param = '&interval=1d&filter=history&frequency=1d'\n",
    "\n",
    "d = {}\n",
    "for t in tickers:\n",
    "    url = '{}{}/history{}{}'.format(base, t, dates, param)\n",
    "    s = requests.Session()\n",
    "    r = s.get(url)\n",
    "    regex = '\"CrumbStore\":{\"crumb\":\"(.+?)\"},'\n",
    "    pattern = re.compile(regex)\n",
    "    crumb = re.findall(pattern, r.text)[0]\n",
    "    param2 = '{}{}&interval=1d&events=history&crumb={}/Q'.format(\n",
    "        t, dates, crumb)\n",
    "    url2 = '{}{}'.format(base2, param2)\n",
    "    data = s.post(url2)\n",
    "    csv = StringIO(data.text)\n",
    "    d[t[1:]] = pd.read_table(csv, sep=',',\n",
    "                             parse_dates=['Date']).set_index('Date')['Adj Close']\n",
    "df = pd.DataFrame(d)\n",
    "final = df.resample('MS').mean().append(df.iloc[-1])\n",
    "\n",
    "final.to_csv(data_dir / 'sp500.csv', index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of March 2, 2020, the constant maturity yield for a ten-year Treasury bond (see {\\color{red!70!purple!90!black}\\textbf{---}}) is 1.10 percent, compared to 2.57 percent one-year prior. The yield for a two-year Treasury (see {\\color{orange!80!yellow}\\textbf{---}}) is 0.84 percent, compared to 2.41 percent a year prior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The effective fed funds (see {\\\\color{blue!60!black}\\\\textbf{---}}) rate is 1.59 percent, as of March 2, 2020.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H15&series=398c5ba6279c57e57055c6a65c95e9d3&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d = {\n",
    "    'RIFLGFCY10_N.B': 'Ten-year',\n",
    "    'RIFSPFF_N.B': 'Fed Funds',\n",
    "    'RIFLGFCM03_N.B': 'Three-month',\n",
    "    'RIFLGFCY02_N.B': 'Two-year'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "data = (df[df['Ten-year'] != 'ND'].astype('float')\n",
    "        .resample('M').mean().iloc[:-1]\n",
    "        .append(df.iloc[-1]))\n",
    "\n",
    "data.to_csv(data_dir / 'rates.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ldate = dtxt(data.index[-1])['day1']\n",
    "tenlt = data['Ten-year'].iloc[-1]\n",
    "tenpr = data['Ten-year'].iloc[-13]\n",
    "twolt = data['Two-year'].iloc[-1]\n",
    "twopr = data['Two-year'].iloc[-13]\n",
    "\n",
    "text = (f'As of {ldate}, the constant maturity yield for a ten-year '+\n",
    "        'Treasury bond (see {\\color{red!70!purple!90!black}\\\\textbf{---}}) '+\n",
    "        f'is {tenlt} percent, compared to {tenpr:.2f} percent one-year prior. '+\n",
    "        'The yield for a two-year Treasury (see {\\color{orange!80!yellow}\\\\textbf{---}}) '\n",
    "        +f'is {twolt} percent, compared to {twopr:.2f} '+\n",
    "        f'percent a year prior.')\n",
    "\n",
    "write_txt(text_dir / 'rates_basic.txt', text)\n",
    "\n",
    "print(text)\n",
    "\n",
    "text = ('The effective fed funds (see {\\color{blue!60!black}\\\\textbf{---}}) '+\n",
    "        f'rate is {data[\"Fed Funds\"].iloc[-1]} percent, as of {ldate}.')\n",
    "\n",
    "write_txt(text_dir / 'rates_ff.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The latest index value, as of February 28, 2020, is 117.8, thus an increase of 17.8 percent since inception in 2006. Over the past three years, the index value has averaged 113.6, compared to an average of 106.3 over the previous three year period.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H10&series=ad1712193ad5bad7b424e3ae5eb101a5&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split(';')[0]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "clean_data['RXI_N.B.EU'] = 1 / clean_data['RXI$US_N.B.EU'] \n",
    "clean_data['RXI_N.B.UK'] = 1 / clean_data['RXI$US_N.B.UK'] \n",
    "clean_data['RXI_N.B.JA'] = clean_data['RXI_N.B.JA'] / 100.0\n",
    "\n",
    "latest = clean_data.iloc[-1]\n",
    "major = ['RXI_N.B.EU', 'RXI_N.B.UK', 'RXI_N.B.CA', 'RXI_N.B.JA']\n",
    "oth = ['RXI_N.B.MX', 'RXI_N.B.BZ', 'RXI_N.B.CH', 'RXI_N.B.SD']\n",
    "twidx = clean_data.resample('MS').mean().append(latest)['JRXWTFB_N.B'].dropna()\n",
    "clean_data.resample('MS').mean().append(latest)[major].to_csv(data_dir / 'fx1.csv', index_label='date', float_format='%g')\n",
    "clean_data.resample('MS').mean().append(latest)[oth].to_csv(data_dir / 'fx2.csv', index_label='date', float_format='%g')\n",
    "twidx.to_csv(data_dir / 'fx_idx.csv', index_label='date', float_format='%g', header=True)\n",
    "\n",
    "ldate = dtxt(twidx.index[-1])['day1']\n",
    "lval = twidx.iloc[-1]\n",
    "totch = ((lval / 100) - 1) * 100\n",
    "threeyr = twidx.iloc[-38:].mean()\n",
    "prev3yr = twidx.iloc[-74:-38].mean()\n",
    "\n",
    "text = (f'The latest index value, as of {ldate}, is {lval:.1f}, thus an increase '+\n",
    "        f'of {totch:.1f} percent since inception in 2006. Over the past three years, '+\n",
    "        f'the index value has averaged {threeyr:.1f}, compared to an average '+\n",
    "        f'of {prev3yr:.1f} over the previous three year period.')\n",
    "\n",
    "write_txt(text_dir / 'twdbasic.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of February 28, 2020, one US dollar buys approximately: 1.34 Canadian dollars (see {\\\\color{green!85!blue}\\\\textbf{---}}), 108 Japanese Yen (see {\\\\color{red}\\\\textbf{---}}), 0.91 Euros (see {\\\\color{cyan!90!white}\\\\textbf{---}}), and 0.78 British Pounds (see {\\\\color{blue!90!cyan}\\\\textbf{---}}). Over the past three years, the nominal exchange rate between the US dollar and the Canadian dollar increased by 2.0 percent, the USD-JPY rate decreased by 2.5 percent, the USD-EUR rate increased by 3.4 percent, and the USD-GBP rate increased by 4.2 percent.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cad = clean_data.loc[ldate, 'RXI_N.B.CA']\n",
    "jpy = clean_data.loc[ldate, 'RXI_N.B.JA'] * 100\n",
    "eur = clean_data.loc[ldate, 'RXI_N.B.EU']\n",
    "gbp = clean_data.loc[ldate, 'RXI_N.B.UK']\n",
    "cadpc = inc_dec_percent(clean_data['RXI_N.B.CA'].pct_change(262).iloc[-1] * 100)\n",
    "jpypc = inc_dec_percent(clean_data['RXI_N.B.JA'].pct_change(262).iloc[-1] * 100)\n",
    "gbppc = inc_dec_percent(clean_data['RXI_N.B.UK'].pct_change(262).iloc[-1] * 100)\n",
    "eurpc = inc_dec_percent(clean_data['RXI_N.B.EU'].pct_change(262).iloc[-1] * 100)\n",
    "\n",
    "\n",
    "text = (f'As of {ldate}, one US dollar buys approximately: {cad:.2f} Canadian dollars '+\n",
    "        f'(see {{\\color{{green!85!blue}}\\\\textbf{{---}}}}), {jpy:.0f} Japanese Yen '+\n",
    "        f'(see {{\\color{{red}}\\\\textbf{{---}}}}), {eur:.2f} Euros '+\n",
    "        f'(see {{\\color{{cyan!90!white}}\\\\textbf{{---}}}}), and {gbp:.2f} British Pounds '+\n",
    "         '(see {\\color{blue!90!cyan}\\\\textbf{---}}). Over the past three years, the nominal '+\n",
    "        f'exchange rate between the US dollar and the Canadian dollar {cadpc}, the USD-JPY rate '+\n",
    "        f'{jpypc}, the USD-EUR rate {eurpc}, and the USD-GBP rate {gbppc}.')\n",
    "\n",
    "write_txt(text_dir / 'selcurr_basic.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial jobless claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = 'ICSA'\n",
    "start = '1988-01-01'\n",
    "base = 'https://api.stlouisfed.org/fred/series/observations?'\n",
    "param = f'series_id={series}&observation_start={start}&api_key={fred_key}'\n",
    "ftype = '&file_type=json'\n",
    "\n",
    "url = f'{base}{param}{ftype}'\n",
    "r = requests.get(url).json()['observations']\n",
    "data = pd.DataFrame(pd.Series({i['date']: int(i['value']) / 1000 \n",
    "                               for i in r}).rename('weekly'))\n",
    "\n",
    "data['3M'] = data['weekly'].rolling(12).mean()\n",
    "\n",
    "data.to_csv(data_dir / 'icsa.csv', index_label='date', float_format='%g')\n",
    "\n",
    "totval = data['weekly'].iloc[-1]*1000\n",
    "datelt = dtxt(data.index[-1])['day1']\n",
    "latest3m = data[\"3M\"].iloc[-1]*1000\n",
    "prev3m = data[\"3M\"].iloc[-157]*1000\n",
    "\n",
    "text = ('The Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{reported}} '+\n",
    "        f'{totval:,.0f} initial claims for unemployment '+\n",
    "        f'insurance during the week ending {datelt}. Over the past three months, '+\n",
    "        f'initial claims averaged {latest3m:,.0f} per week. During the same three month period '+\n",
    "        f'three years ago, initial claims averaged {prev3m:,.0f} per week.')\n",
    "\n",
    "write_txt(text_dir / 'icsa.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIX (SP500 volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This volatility measure, VIX, was 36.8 on March 3, 2020, compared to an average of 15.9 over the past three years.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev = pd.read_excel(data_dir/ 'vixarchive.xls', skiprows=1, index_col='Date')\n",
    "VIX = 'http://www.cboe.com/publish/scheduledtask/mktdata/datahouse/vixcurrent.csv'\n",
    "curr = pd.read_csv(VIX, skiprows=1, index_col='Date', parse_dates=True)\n",
    "df = (prev.append(curr)['VIX Close'].resample('MS').mean()\n",
    "      .append(curr['VIX Close'].iloc[-1:]).rename('value'))\n",
    "df.to_csv(data_dir / 'vix.csv', index_label='date', header='True')\n",
    "\n",
    "ldate = dtxt(df.index[-1])['day1']\n",
    "\n",
    "text = (f'This volatility measure, VIX, was {df.iloc[-1]:.1f} on {ldate}, '+\n",
    "        f'compared to an average of {df.iloc[-37:].mean():.1f} over the '+\n",
    "        'past three years.')\n",
    "\n",
    "write_txt(text_dir / 'vixbasic.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil prices (WTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of February 24, 2020, a barrel of west Texas intermediate (WTI) \\textbf{crude oil} sells for \\\\$51.36. Over the past year, this measure of oil prices has decreased by 6.5 percent. Over the past three years, the price decreased by 3.9 percent. Currently, the WTI price is \\\\$82.52 per barrel below its June 2008 average.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fred_df('DCOILWTICO')\n",
    "\n",
    "latest = df.iloc[-1]\n",
    "\n",
    "ma = df.resample('MS').mean()\n",
    "\n",
    "p = ma.append(latest)['VALUE']\n",
    "\n",
    "(p.to_csv(data_dir / 'wti.csv', index_label='date', header=True))\n",
    "\n",
    "oneyr = p.pct_change(13).iloc[-1] * 100\n",
    "\n",
    "threeyr = p.pct_change(37).iloc[-1] * 100\n",
    "\n",
    "oyt = inc_dec_percent(oneyr)\n",
    "tyt = inc_dec_percent(threeyr)\n",
    "    \n",
    "ltch = p.loc['2008-06-01'] - p.iloc[-1]\n",
    "\n",
    "ldate = dtxt(p.index[-1])['day1']\n",
    "\n",
    "text = (f'As of {ldate}, a barrel of west Texas '+\n",
    "        f'intermediate (WTI) \\textbf{{crude oil}} sells for \\${p.iloc[-1]}. Over the '+\n",
    "        f'past year, this measure of oil prices has {oyt}. Over the past three '+\n",
    "        f'years, the price {tyt}. Currently, the WTI price is \\${ltch:.2f} per barrel '+\n",
    "        'below its June 2008 average.')\n",
    "\n",
    "write_txt(text_dir / 'wti.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflation Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.sca.isr.umich.edu/files/tbmpx1px5.csv'\n",
    "df = pd.read_csv(url)\n",
    "df.index = pd.to_datetime(df['Month'] + ' ' + df['YYYY'].astype('str'))\n",
    "data = df['PX5_MD'].loc['2015':]\n",
    "\n",
    "data.to_csv(data_dir / 'infumich.csv', index_label='date', header='VALUE')\n",
    "\n",
    "node = end_node(data, 'violet')\n",
    "write_txt(text_dir / 'infumich_node.txt', node)\n",
    "\n",
    "data1 = fred_df('T5YIE').loc['2015':,'VALUE']\n",
    "data1.to_csv(data_dir / 'infbreak.csv', index_label='date', header=True)\n",
    "\n",
    "node = end_node(data1, 'blue!70!black')\n",
    "write_txt(text_dir / 'infbreak_node.txt', node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of February 2020, consumers expect an average inflation rate of 2.3 percent over the next five years, (see {\\\\color{violet!60!magenta}\\\\textbf{---}}), compared to an expected rate of 2.3 percent on February 2019. Consumers had expected inflation to average 2.7 percent over the past five years, while actual inflation over the period was 1.6 percent.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "pdate = dtxt(data.index[-13])['mon1']\n",
    "p5val = data.iloc[-61]\n",
    "lval = data.iloc[-1]\n",
    "pval = data.iloc[-13]\n",
    "\n",
    "ldatem = dtxt(data1.index[-1])['day1']\n",
    "lvalm = data1.iloc[-1]\n",
    "pdatem = dtxt(data1.index[-262])['day1']\n",
    "pvalm = data1.iloc[-262]\n",
    "p5valm = data1.iloc[-(262*5)]\n",
    "\n",
    "inf_act = pd.read_csv(data_dir / 'cpi.csv')['ALL'].iloc[-60:].mean()\n",
    "\n",
    "text = (f'As of {ldate}, consumers expect an average inflation rate of {lval} '+\n",
    "        'percent over the next five years, (see {\\color{violet!60!magenta}\\\\textbf{---}}), '+\n",
    "        f'compared to an expected rate of {pval} percent '+\n",
    "        f'on {pdate}. Consumers had expected inflation to average {p5val} percent over the past '+\n",
    "        f'five years, while actual inflation over the period was {inf_act:.1f} percent.')\n",
    "\n",
    "write_txt(text_dir / 'inf_exp_cons.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of March 3, 2020, markets expect an average inflation rate of 2.3 percent over the next five years (see {\\\\color{blue!70!black}\\\\textbf{---}}), compared to an expected rate of 1.84 percent on March 4, 2019. Markets had expected inflation to average 1.36 over the past five years, five years ago.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = (f'As of {ldatem}, markets expect an average inflation rate of {lval} percent ' + \n",
    "         'over the next five years (see {\\color{blue!70!black}\\\\textbf{---}}), '\n",
    "         +f'compared to an expected rate of {pvalm} percent on '+\n",
    "         f'{pdatem}. Markets had expected inflation to average {p5valm} over the past five '+\n",
    "         f'years, five years ago.')\n",
    "\n",
    "write_txt(text_dir / 'inf_exp_mkts.txt', text2)\n",
    "\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
