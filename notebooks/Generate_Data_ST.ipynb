{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:16.841741Z",
     "start_time": "2022-02-05T02:45:16.132871Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import time\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:17.211363Z",
     "start_time": "2022-02-05T02:45:16.842828Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The S\\&P 500 closed at 4,501 on February 4, 2022. The index is currently 6.6 percent below its one-year high of 4,819 on January 4, 2022, and 20.9 percent above its one-year low of 3,723 on March 4, 2021. The average over the past year is 4,344; the index is 3.6 percent above its one-year moving average (see {\\color{black!18!white}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "ltdate = int(time.time())\n",
    "\n",
    "url = ('https://query1.finance.yahoo.com/v7/finance/download/%5EGSPC?'+\n",
    "       f'period1=599616000&period2={ltdate}&interval=1d&events=history')\n",
    "\n",
    "df = pd.read_csv(url).set_index('Date')\n",
    "\n",
    "close = df['Adj Close']\n",
    "close.index = pd.to_datetime(close.index)\n",
    "lt = pd.Series({close.index[-1]: close[-1]})\n",
    "final = close.resample('MS').mean().append(lt)\n",
    "final.name = 'GSPC'\n",
    "final.to_csv(data_dir / 'sp500.csv', index_label='date') \n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['GSPC'] = close.loc['2017':]\n",
    "data['MA'] = close.rolling(253).mean().loc['2017':]\n",
    "data.to_csv(data_dir / 'sp500_recent.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(close.index[-1])['day1']\n",
    "ltval = close.iloc[-1]\n",
    "hival = df.High.iloc[-253:].max()\n",
    "chhi = (1 - ltval/hival) * 100\n",
    "hidt = dtxt(df.High.iloc[-253:].idxmax())['day1']\n",
    "loval = df.Low.iloc[-253:].min()\n",
    "chlo = abs((1 - ltval/loval) * 100)\n",
    "lodt = dtxt(df.Low.iloc[-253:].idxmin())['day1']\n",
    "avval = df['Adj Close'].iloc[-253:].mean()\n",
    "chav = (1 - ltval/avval) * 100\n",
    "chtxt = value_text(-chav, style='above_below', threshold=0.1)\n",
    "cline = '(see {\\color{black!18!white}\\\\textbf{---}}'\n",
    "text = (f'The S\\&P 500 closed at {ltval:,.0f} on {ltdate}. The '+\n",
    "        f'index is currently {chhi:.1f} percent below its one-year '+\n",
    "        f'high of {hival:,.0f} on {hidt}, and {chlo:.1f} percent '+\n",
    "        f'above its one-year low of {loval:,.0f} on {lodt}. The '+\n",
    "        f'average over the past year is {avval:,.0f}; the index is '+\n",
    "        f'{chtxt} its one-year moving average {cline}).')\n",
    "write_txt(text_dir / 'sp500.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Interest Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:22.670112Z",
     "start_time": "2022-02-05T02:45:17.212761Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H15&series=df361c47287a0589560a46dad7d610cb&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2022&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, clean_data = clean_fed_data(url)\n",
    "\n",
    "n = {'RIFLGFCY10_XII_N.B': 'Ten-year',\n",
    "     'RIFLGFCY05_XII_N.B': 'Five-year'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Ten-year'])\n",
    "\n",
    "data = (df.resample('MS').mean().iloc[:-1].append(df.iloc[-1]))\n",
    "data.to_csv(data_dir / 'real_rates.csv', index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:22.676306Z",
     "start_time": "2022-02-05T02:45:22.671316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US Treasury inflation-indexed securities are used to measure real interest rates. Treasury yields in general are a good proxy for low-risk rates, and the treasury offers specific securities that have interest payments indexed to the consumer price index (CPI) rate of inflation. \n",
      "\n",
      " The real yield for such treasuries with ten years to maturity is -0.56 percent, as of February 3, 2022 (see {\\color{red}\\textbf{---}}), compared to -0.91 percent on January 4, 2022. For a five-year maturity, the real yield is -1.10 percent in the latest data (see {\\color{violet}\\textbf{---}}), compared to -1.56 percent a month prior. \n"
     ]
    }
   ],
   "source": [
    "write_txt(text_dir / 'real_10y_node.txt', \n",
    "          end_node(data['Ten-year'], 'red', digits=2))\n",
    "write_txt(text_dir / 'real_5y_node.txt', \n",
    "          end_node(data['Five-year'], 'violet', digits=2))\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['day1']\n",
    "prdate = dtxt(df.index[-22])['day1']\n",
    "ltval = df['Ten-year'].iloc[-1]\n",
    "ltval5 = df['Five-year'].iloc[-1]\n",
    "prval = df['Ten-year'].iloc[-22]\n",
    "prval5 = df['Five-year'].iloc[-22]\n",
    "cline = '(see {\\color{red}\\\\textbf{---}})'\n",
    "cline2 = '(see {\\color{violet}\\\\textbf{---}})'\n",
    "text = ('US Treasury inflation-indexed securities are used to measure '+\n",
    "        'real interest rates. Treasury yields in general are a good '+\n",
    "        'proxy for low-risk rates, and the treasury offers specific '+\n",
    "        'securities that have interest payments indexed to the consumer '+\n",
    "        'price index (CPI) rate of inflation. \\n\\n The real yield for '+\n",
    "        f'such treasuries with ten years to maturity is {ltval:.2f} percent, '+\n",
    "        f'as of {ltdate} {cline}, compared to {prval:.2f} percent on '+\n",
    "        f'{prdate}. For a five-year maturity, the real yield is {ltval5:.2f} '+\n",
    "        f'percent in the latest data {cline2}, compared to {prval5:.2f} '+\n",
    "        'percent a month prior. ')\n",
    "write_txt(text_dir / 'real_rates_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:23.647151Z",
     "start_time": "2022-02-05T02:45:22.677163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taylor Rule suggested Fed Funds rate\n",
    "p = (pd.read_csv(data_dir / 'pce_pi.csv', parse_dates=['date'])\n",
    "       .set_index('date')['CORE']).resample('QS').mean() * 0.5\n",
    "\n",
    "y = ((nipa_df(retrieve_table('T10106')['Data'], ['A191RX']))\n",
    "      .loc['1989':, 'A191RX'])\n",
    "\n",
    "y_p = fred_df('GDPPOT')['VALUE'] * 1_000\n",
    "\n",
    "o = (y - (y_p)).divide(y_p).dropna()\n",
    "\n",
    "taylor_ff = (p + 3 + (0.5*(p - 2)) + (1*(o*100)))\n",
    "\n",
    "taylor_ff.name = 'Value'\n",
    "\n",
    "taylor_ff.dropna().to_csv(data_dir / 'taylor.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:25.558815Z",
     "start_time": "2022-02-05T02:45:23.650832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States Treasury securities, or treasuries, are the asset created by federal government borrowing. The treasuries market is traditionally considered both very low risk and fairly liquid. The yield on these securities has fallen over time, from an average 10-year treasury bond annual yield of 8.5 percent in 1989 to an average of 0.62 percent in July 2020. As of February 3, 2022, the constant maturity yield for 10-year treasury bonds is 1.82 percent (see {\\color{red!90}\\textbf{---}}), compared to 1.15 percent one year prior. \n",
      "\n",
      "Yields have also fallen since 1989 for shorter-duration treasuries, though shorter-duration treasuries are more acutely affected by changes in the key interest rate set by the Federal Reserve. Over the past year, yields on two-year treasuries have increased by 1.1 percentage points, as the Federal Reserve is expected to raise interest rates. As of February 3, 2022, the annual yield on two-year treasuries is 1.19 percent (see {\\color{red}\\textbf{---}}).  \n",
      "\n",
      "The effective fed funds rate is 0.1 percent, as of February 3, 2022 (see {\\color{blue!60!black}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H15&series=a2738d013c65f34c46f905d1d7913f78&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2022&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, clean_data = clean_fed_data(url)\n",
    "\n",
    "n = {'RIFLGFCY10_N.B': 'Ten-year',\n",
    "    'RIFLGFCY30_N.B': 'Thirty-year',\n",
    "    'RIFSPFF_N.B': 'Fed Funds',\n",
    "    'RIFLGFCM03_N.B': 'Three-month',\n",
    "    'RIFLGFCY05_N.B': 'Five-year',\n",
    "    'RIFLGFCY02_N.B': 'Two-year',\n",
    "    'RIFLGFCM01_N.B': 'One-month',\n",
    "    'RIFLGFCY01_N.B': 'One-year',\n",
    "    'RIFLGFCY20_N.B': 'Twenty-year'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Ten-year'])\n",
    "\n",
    "data = (df.resample('MS').mean().iloc[:-1].append(df.iloc[-1]))\n",
    "data.to_csv(data_dir / 'rates.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ldate = dtxt(data.index[-1])['day1']\n",
    "tenlt = df['Ten-year'].iloc[-1]\n",
    "tenpr = df['Ten-year'].iloc[-252]\n",
    "twolt = df['Two-year'].iloc[-1]\n",
    "twopr = df['Two-year'].iloc[-252]\n",
    "val89 = df['Ten-year'].loc['1989'].mean()\n",
    "lowval = data['Ten-year'].min()\n",
    "lowmon = dtxt(data['Ten-year'].idxmin())['mon1']\n",
    "cline10 = '(see {\\color{red!90}\\\\textbf{---}})'\n",
    "cline2 = '(see {\\color{blue}\\\\textbf{---}})'\n",
    "ch2yr = value_text(df['Two-year'].diff(252).iloc[-1], \n",
    "                   'increase_by', ptype='pp')\n",
    "ff = fred_df('FEDTARMD')['VALUE']\n",
    "ffd = ff.diff(2).iloc[-1]\n",
    "fv = 'raise' if ffd > 0.3 else 'lower' if ffd <0.3 else 'maintain'\n",
    "text = ('United States Treasury securities, or treasuries, are the '+\n",
    "        'asset created by federal government borrowing. The treasuries '+\n",
    "        'market is traditionally considered both very low risk and fairly '+\n",
    "        'liquid. The yield on these securities has fallen over time, '+\n",
    "        'from an average 10-year treasury bond annual yield of '+\n",
    "        f'{val89:.1f} percent in 1989 to an average of {lowval:.2f} '+\n",
    "        f'percent in {lowmon}. As of {ldate}, the constant maturity yield '+\n",
    "        f'for 10-year treasury bonds is {tenlt} percent {cline10}, '+\n",
    "        f'compared to {tenpr:.2f} percent one year prior. \\n\\nYields '+\n",
    "        'have also fallen since 1989 for shorter-duration treasuries, '+\n",
    "        f'though shorter-duration treasuries are more acutely affected '+\n",
    "        'by changes in the key interest rate set by the Federal Reserve. '+\n",
    "        f'Over the past year, yields on two-year treasuries have {ch2yr}, '+\n",
    "        f'as the Federal Reserve is expected to {fv} interest rates. '+\n",
    "        f'As of {ldate}, the annual yield on two-year treasuries is '+\n",
    "        f'{twolt} percent {cline}. ')\n",
    "write_txt(text_dir / 'rates_basic.txt', text)\n",
    "print(text, '\\n')\n",
    "cline = '(see {\\color{blue!60!black}\\\\textbf{---}})'\n",
    "val = f'{data[\"Fed Funds\"].iloc[-1]:.1f} percent'\n",
    "text = (f'The effective fed funds rate is {val}, as of {ldate} {cline}.')\n",
    "write_txt(text_dir / 'rates_ff.txt', text)\n",
    "print(text)\n",
    "\n",
    "rows = ['Three-month', 'Two-year', 'Five-year', 'Ten-year', 'Thirty-year']\n",
    "columns = [-1, -2, -5, -22, -64, -127, -252, -1251]\n",
    "data2 = df[rows].iloc[columns].T\n",
    "data2.columns = [dtxt(i)['day2'] for i in pd.to_datetime(data2.keys())]\n",
    "\n",
    "(data2.applymap('{:,.2f}'.format)\n",
    "      .to_csv(data_dir / 'treasury_rates.tex', sep='&', \n",
    "           line_terminator='\\\\\\ ', quotechar=' '))\n",
    "\n",
    "#data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:37:54.210618Z",
     "start_time": "2020-09-18T17:37:54.206641Z"
    }
   },
   "source": [
    "### Yield Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:25.568747Z",
     "start_time": "2022-02-05T02:45:25.559895Z"
    }
   },
   "outputs": [],
   "source": [
    "i = {'One-month': 1, 'Three-month': 2, 'One-year': 3, 'Two-year': 4, \n",
    "     'Five-year': 5, 'Ten-year': 6, 'Twenty-year': 7, 'Thirty-year': 8}\n",
    "tbl = pd.DataFrame()\n",
    "for v, c in [(-1, 'value'), (-252, 'oneyear'), (-252*5, 'fiveyear')]:\n",
    "    col = df[i.keys()].iloc[v]\n",
    "    col.index = col.index.map(i)\n",
    "    tbl[c] = col\n",
    "tbl.index.name = 'number'\n",
    "tbl['alignment'] = 270\n",
    "\n",
    "tbl.to_csv(data_dir / 'yc.csv', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:25.612441Z",
     "start_time": "2022-02-05T02:45:25.570474Z"
    }
   },
   "outputs": [],
   "source": [
    "data = df[df['Ten-year'] != 'ND'].astype('float')\n",
    "spread = pd.DataFrame()\n",
    "spread['Ten-3M'] = data['Ten-year'] - data['Three-month']\n",
    "spread['Ten-2Y'] = data['Ten-year'] - data['Two-year']\n",
    "spread.loc['2012':].to_csv(data_dir / 'spread.csv', index_label='date', \n",
    "                           float_format='%g', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:25.655479Z",
     "start_time": "2022-02-05T02:45:25.613616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of February 3, 2022, the spread between a 10-year treasury bond and a three-month treasury bill is 1.62 percentage points (see {\\color{blue}\\textbf{---}}), compared to 1.11 percentage points one year prior. The spread between 10-year and 2-year treasuries (see {\\color{red!90!black}\\textbf{---}}) is 0.63 percentage point on February 3, 2022, and 1.04 percentage points one year prior.\n"
     ]
    }
   ],
   "source": [
    "data = df[df['Ten-year'] != 'ND'].astype('float')\n",
    "spread = pd.DataFrame()\n",
    "spread['Ten-3M'] = data['Ten-year'] - data['Three-month']\n",
    "spread['Ten-2Y'] = data['Ten-year'] - data['Two-year']\n",
    "spread.loc['2012':].to_csv(data_dir / 'spread.csv', index_label='date', \n",
    "                           float_format='%g', header=True)\n",
    "\n",
    "node = end_node(spread['Ten-3M'], 'blue', digits=2)\n",
    "write_txt(text_dir / 'spread_node.txt', node)\n",
    "\n",
    "node = end_node(spread['Ten-2Y'], 'red!90!black', digits=2)\n",
    "write_txt(text_dir / 'spread_node2.txt', node)\n",
    "\n",
    "def pp(value):\n",
    "    return 'percentage points' if value > 1.01 else 'percentage point'\n",
    "\n",
    "lt3 = spread['Ten-3M'].iloc[-1]\n",
    "lt3t = f'{lt3:.2f} {pp(lt3)}'\n",
    "pr3 = spread['Ten-3M'].iloc[-252]\n",
    "pr3t = f'{pr3:.2f} {pp(pr3)}'\n",
    "lt2 = spread['Ten-2Y'].iloc[-1]\n",
    "lt2t = f'{lt2:.2f} {pp(lt2)}'\n",
    "pr2 = spread['Ten-2Y'].iloc[-252]\n",
    "pr2t = f'{pr2:.2f} {pp(pr2)}'\n",
    "\n",
    "text = (f'As of {ldate}, the spread between a 10-year treasury bond and '+\n",
    "        f'a three-month treasury bill is {lt3t} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}), compared to '+\n",
    "        f'{pr3t} one year prior. The spread between 10-year '+\n",
    "        'and 2-year treasuries (see {\\color{red!90!black}\\\\textbf{---}}) '+\n",
    "        f'is {lt2t} on {ldate}, and '+\n",
    "        f'{pr2t} one year prior.')\n",
    "\n",
    "write_txt(text_dir / 'spread_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:25.658204Z",
     "start_time": "2022-02-05T02:45:25.656546Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = fred_df('GOLDAMGBD228NLBM').dropna()\n",
    "# data = (df.resample('M').mean().iloc[:-1].append(df.iloc[-1]))\n",
    "# data.to_csv(data_dir / 'gold.csv', index_label='date')\n",
    "\n",
    "# ltdate = dtxt(data.index[-1])['day1']\n",
    "# ltval = data.VALUE.iloc[-1]\n",
    "# prdate = dtxt(data.index[-13])['mon1']\n",
    "# prval = data.VALUE.iloc[-13]\n",
    "# grdate = dtxt(data.loc['2006':'2011', 'VALUE'].idxmax())['mon1']\n",
    "# grval = data.loc['2006':'2011', 'VALUE'].max()\n",
    "\n",
    "# text = (f'As of {ltdate}, one troy ounce of gold sells for \\${ltval:,.2f} '+\n",
    "#         '(see {\\color{orange!40!yellow}\\\\textbf{---}}), '\n",
    "#         f'compared to an average of \\${prval:,.2f} per ounce during {prdate}. '+\n",
    "#         'Following the great recession, the monthly average price '+\n",
    "#         f'of gold reached \\${grval:,.2f} per ounce, in {grdate}.')\n",
    "# print(text)\n",
    "# write_txt(text_dir / 'gold.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fed Balance Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:25.860812Z",
     "start_time": "2022-02-05T02:45:25.659178Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H41&series=38d757c01cb3b550176f371352643679&lastobs=&'\n",
    "dt = 'from=01/01/2002&to=12/31/2022&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split(';')[0]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "clean_data = clean_data / 1_000_000\n",
    "\n",
    "clean_data.to_csv(data_dir / 'fed_assets.csv', index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:25.866789Z",
     "start_time": "2022-02-05T02:45:25.861782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the COVID-19 pandemic, the Fed offered lending to businesses and currency swaps to major US trading partners, began to purchase commercial bonds, and expanded purchases of treasuries and mortgage-backed securities.\n",
      "\n",
      " The Fed balance sheet increased from \\$4.2 trillion in February 2020 to \\$8.9 trillion, as of the latest data, covering February 2, 2022. \n"
     ]
    }
   ],
   "source": [
    "ltval = clean_data['RESPPMA_N.WW'].iloc[-1].round(1)\n",
    "ltdate = dtxt(clean_data.index[-1])['day1']\n",
    "n = (clean_data.iloc[-1] - clean_data.iloc[-2])['RESPPMA_N.WW'] * 1000\n",
    "chval = (f'increased by \\${abs(n):.0f} billion' if n >= 10 \n",
    "         else f'decreased by \\${abs(n):.0f} billion' \n",
    "         if n <= -10 else 'was largely unchanged')\n",
    "\n",
    "text = ('In response to the collapse of the housing bubble, the Fed purchased '+\n",
    "        'U.S. Treasury bonds and mortgage-backed securities. Total assets held by '+\n",
    "        'the Federal Reserve (see {\\color{blue!80!black}\\\\textbf{---}}) '+\n",
    "        'increased from \\$0.9 trillion in August 2008 to '+\n",
    "        '\\$2.2 trillion in November 2008. Additional rounds of asset purchases, '+\n",
    "        'referred to as quantitative easing, increased the balance sheet to '+\n",
    "        '\\$4.5 trillion by January 2014. As bonds mature they were replaced '+\n",
    "        'until October 2017, when the Fed allowed the size of its balance '+\n",
    "        'sheet to normalize. Total assets fell below \\$3.8 trillion in August 2019.')\n",
    "write_txt(text_dir / 'fed_assets1.txt', text)\n",
    "        \n",
    "txt2 = ('Balance sheet normalization ended in September 2019 when the Fed increased '+\n",
    "        'operations in overnight and term repurchase agreement (repo) markets, following '+\n",
    "        'a sharp increase in rates in these markets. The Fed balance sheet '+\n",
    "        'increased to \\$4.1 trillion by December 2019.')\n",
    "write_txt(text_dir / 'fed_assets2.txt', txt2)\n",
    "        \n",
    "txt3 = ('During the COVID-19 pandemic, the Fed offered lending to businesses and '+\n",
    "        'currency swaps to major US trading partners, began to purchase commercial bonds, '+\n",
    "        'and expanded purchases of treasuries and mortgage-backed securities.\\n\\n '+\n",
    "        'The Fed balance sheet increased from \\$4.2 trillion in February 2020 to '+\n",
    "        f'\\${ltval} trillion, as of the latest data, covering {ltdate}. ')\n",
    "write_txt(text_dir / 'fed_assets3.txt', txt3)\n",
    "print(txt3)\n",
    "        \n",
    "### Add something about recent pace (e.g. \"The total value of Fed assets {chval} from the value one week prior.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fed Balance Sheet Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:26.134950Z",
     "start_time": "2022-02-05T02:45:25.867705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fed currently holds \\$5.7 trillion in Treasuries and \\$2.7 trillion in mortgage-backed securities. \n"
     ]
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H41&series=bbb7b50f663fe933c8cce7e3707e3998&lastobs=&'\n",
    "dt = 'from=01/01/2002&to=12/31/2022&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, clean_data = clean_fed_data(url)\n",
    "\n",
    "d2 = {'RESPPA_N.WW': '\\\\textbf{Total} (see {\\color{blue!80!black}\\\\textbf{---}})',\n",
    "      'RESPPALGUO_N.WW': '\\hspace{2mm}U.S. Treasury securities',\n",
    "      'RESPPALGASMO_N.WW': '\\hspace{2mm}Mortgage-backed securities',\n",
    "      'RESH4SCS_N.WW': '\\hspace{2mm}Central bank liquidity swaps',\n",
    "      'RESPPALGTR_N.WW': '\\hspace{2mm}Repurchase agreements',\n",
    "      'RESPPALD_N.WW': '\\hspace{2mm}Loans',\n",
    "      'RESPPALDJ_N.WW': '\\hspace{4mm}Payroll Protection Program',\n",
    "      'NetPremDisc': '\\hspace{2mm}Net unamortized premium',\n",
    "      'Other': '\\hspace{2mm}Other'}\n",
    "\n",
    "pr_di = ['RESPPALSD_N.WW', 'RESPPALSP_N.WW']\n",
    "\n",
    "data = clean_data.copy()\n",
    "data['Other'] = (data['RESPPA_N.WW'] - \n",
    "                             data.drop('RESPPA_N.WW', axis=1).sum(axis=1))\n",
    "data['NetPremDisc'] = data[pr_di].sum(axis=1)\n",
    "ltval_treas = data['RESPPALGUO_N.WW'].iloc[-1] / 1_000_000\n",
    "ltval_mbs = data['RESPPALGASMO_N.WW'].iloc[-1] / 1_000_000\n",
    "\n",
    "data = data.rename(d2, axis=1).drop(pr_di, axis=1)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in [-1, -2, -5, -53, -105]:\n",
    "    df[dtxt(data.index[i])['day2']] = data.iloc[i]\n",
    "    \n",
    "(df.loc[list(d2.values()), :].div(1000)\n",
    "   .applymap('{:,.1f}'.format)\n",
    "   .to_csv(data_dir / 'fed_bal_sheet.tex', sep='&', \n",
    "           line_terminator='\\\\\\ ', quotechar=' '))\n",
    "\n",
    "text = (f'The Fed currently holds \\${ltval_treas:,.1f} trillion in Treasuries '+\n",
    "        f'and \\${ltval_mbs:,.1f} trillion in mortgage-backed securities. ')\n",
    "write_txt(text_dir / 'fed_assets4.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:27.673513Z",
     "start_time": "2022-02-05T02:45:26.136115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest index value, as of January 28, 2022, is 116.1, an increase of 16.1 percent since inception in 2006. Over the past three years, the index value has averaged 115.5, compared to an average of 112.7 over the previous three-year period.\n"
     ]
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H10&series=ad1712193ad5bad7b424e3ae5eb101a5&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2022&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split(';')[0]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "for cc in ['EU', 'UK', 'AL', 'NZ']:\n",
    "    clean_data[f'RXI_N.B.{cc}'] = 1 / clean_data[f'RXI$US_N.B.{cc}'] \n",
    "clean_data['RXI_N.B.JA'] = clean_data['RXI_N.B.JA'] / 100.0\n",
    "\n",
    "latest = clean_data.dropna(how='all').iloc[-1]\n",
    "major = ['RXI_N.B.EU', 'RXI_N.B.UK', 'RXI_N.B.CA', 'RXI_N.B.JA']\n",
    "twidx = clean_data.resample('MS').mean().append(latest)['JRXWTFB_N.B'].dropna()\n",
    "(clean_data.resample('MS').mean().append(latest)[major]\n",
    "           .to_csv(data_dir / 'fx1.csv', index_label='date', float_format='%g'))\n",
    "twidx.to_csv(data_dir / 'fx_idx.csv', index_label='date', float_format='%g', header=True)\n",
    "\n",
    "ldate = dtxt(twidx.index[-1])['day1']\n",
    "lval = twidx.iloc[-1]\n",
    "totch = ((lval / 100) - 1) * 100\n",
    "threeyr = twidx.iloc[-38:].mean()\n",
    "prev3yr = twidx.iloc[-74:-38].mean()\n",
    "\n",
    "text = (f'The latest index value, as of {ldate}, is {lval:.1f}, an increase '+\n",
    "        f'of {totch:.1f} percent since inception in 2006. Over the past three years, '+\n",
    "        f'the index value has averaged {threeyr:.1f}, compared to an average '+\n",
    "        f'of {prev3yr:.1f} over the previous three-year period.')\n",
    "write_txt(text_dir / 'twdbasic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:27.682951Z",
     "start_time": "2022-02-05T02:45:27.674618Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of January 28, 2022, one US dollar buys approximately: 1.28 Canadian dollars (see {\\color{green!85!blue}\\textbf{---}}), 115 Japanese yen (see {\\color{red}\\textbf{---}}), 0.90 euros (see {\\color{cyan!90!white}\\textbf{---}}), and 0.75 British pounds (see {\\color{blue!90!cyan}\\textbf{---}}). Over the past three years, the nominal exchange rate between the US dollar and the Canadian dollar decreased by 0.2 percent, the USD-JPY rate increased by 10.7 percent, the USD-EUR rate increased by 8.4 percent, and the USD-GBP rate increased by 2.0 percent.\n"
     ]
    }
   ],
   "source": [
    "cad = clean_data.loc[ldate, 'RXI_N.B.CA']\n",
    "jpy = clean_data.loc[ldate, 'RXI_N.B.JA'] * 100\n",
    "eur = clean_data.loc[ldate, 'RXI_N.B.EU']\n",
    "gbp = clean_data.loc[ldate, 'RXI_N.B.UK']\n",
    "cadpc = inc_dec_percent(clean_data['RXI_N.B.CA'].pct_change(262).iloc[-1] * 100)\n",
    "jpypc = inc_dec_percent(clean_data['RXI_N.B.JA'].pct_change(262).iloc[-1] * 100)\n",
    "gbppc = inc_dec_percent(clean_data['RXI_N.B.UK'].pct_change(262).iloc[-1] * 100)\n",
    "eurpc = inc_dec_percent(clean_data['RXI_N.B.EU'].pct_change(262).iloc[-1] * 100)\n",
    "\n",
    "text = (f'As of {ldate}, one US dollar buys approximately: {cad:.2f} Canadian dollars '+\n",
    "        f'(see {{\\color{{green!85!blue}}\\\\textbf{{---}}}}), {jpy:.0f} Japanese yen '+\n",
    "        f'(see {{\\color{{red}}\\\\textbf{{---}}}}), {eur:.2f} euros '+\n",
    "        f'(see {{\\color{{cyan!90!white}}\\\\textbf{{---}}}}), and {gbp:.2f} British pounds '+\n",
    "         '(see {\\color{blue!90!cyan}\\\\textbf{---}}). Over the past three years, the nominal '+\n",
    "        f'exchange rate between the US dollar and the Canadian dollar {cadpc}, the USD-JPY rate '+\n",
    "        f'{jpypc}, the USD-EUR rate {eurpc}, and the USD-GBP rate {gbppc}.')\n",
    "write_txt(text_dir / 'selcurr_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange Rates Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:27.710629Z",
     "start_time": "2022-02-05T02:45:27.683904Z"
    }
   },
   "outputs": [],
   "source": [
    "fx = {'RXI_N.B.EU': 'EUR',\n",
    "      'RXI_N.B.UK': 'GBP',\n",
    "      'RXI_N.B.JA': 'JPY',\n",
    "      'RXI_N.B.CA': 'CAD',\n",
    "      'RXI_N.B.MX': 'MXN',\n",
    "      'RXI_N.B.CH': 'CNY',\n",
    "      'RXI_N.B.SZ': 'CHF',\n",
    "      'RXI_N.B.HK': 'HKD',\n",
    "      'RXI_N.B.IN': 'INR',\n",
    "      'RXI_N.B.AL': 'AUD',\n",
    "      'RXI_N.B.NZ': 'NZD',\n",
    "      'RXI_N.B.BZ': 'BRL',\n",
    "      'RXI_N.B.KO': 'KRW',\n",
    "      'RXI_N.B.MA': 'MYR',\n",
    "      'RXI_N.B.DN': 'DKK',\n",
    "      'RXI_N.B.NO': 'NOK',\n",
    "      'RXI_N.B.SD': 'SEK',\n",
    "      'RXI_N.B.SF': 'ZAR',\n",
    "      'RXI_N.B.SI': 'SGD',\n",
    "      'RXI_N.B.TA': 'TWD'}\n",
    "\n",
    "tbl_data = clean_data[fx.keys()].dropna(how='all')\n",
    "tbl_data.columns = fx.values()\n",
    "tbl_data.loc[:,'JPY'] *= 100\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table[dtxt(tbl_data.index[-1])['day2']] = tbl_data.iloc[-1]\n",
    "table['1-month moving average'] = tbl_data.iloc[-22:].mean()\n",
    "table['1-year moving average'] = tbl_data.iloc[-262:].mean()\n",
    "dec1 = ['JPY', 'KRW']\n",
    "table.loc[['JPY', 'KRW'],:] = table.loc[['JPY', 'KRW'],:].applymap(\"{0:.1f}\".format)\n",
    "dec3 = ['GBP', 'EUR', 'CHF', 'AUD', 'NZD', 'CAD', 'SGD']\n",
    "table.loc[dec3,:] = table.loc[dec3,:].applymap(\"{0:.3f}\".format)\n",
    "table.loc[~table.index.isin(dec3+dec1)] = table.loc[~table.index.isin(dec3+dec1)].applymap(\"{0:.2f}\".format)\n",
    "table['1-month percent change'] = (tbl_data.pct_change(22) * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "table['1-year percent change'] = (tbl_data.pct_change(262) * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "table['5-year percent change'] = (tbl_data.pct_change(262*5) * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "\n",
    "table.index = [f'\\includegraphics[width=.03\\\\textwidth]{{data/flags/{cc}}} \\ {cc}' for cc in table.index]\n",
    "\n",
    "(table.to_csv(data_dir / 'fx_table.tex', sep='&', \n",
    "              line_terminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobless claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:29.588239Z",
     "start_time": "2022-02-05T02:45:27.711589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{report}} 257,002 actual new claims for unemployment insurance (UI) under state programs (see {\\color{cyan!80!blue}\\textbf{---}}) during the week ending January 29, 2022, a one-week decrease of 11,700. Over the past four weeks, new claims have averaged 321,900 per week. During the same four-week period last year, there were an average of 927,600 new claims per week.\n",
      "For the week ending January 22, 2022, the Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{reports}} 2,040,548 continued claims for unemployment insurance (insured unemployed) under state programs (see {\\color{green!90!blue}\\textbf{---}}), a one-week increase of 39,300. One year prior, during the week of January 23, 2021, there were an average of 5,193,800 insured unemployed.\n"
     ]
    }
   ],
   "source": [
    "data = fred_df('ICNSA', start='2017') / 1000 \n",
    "data['1M'] = data['VALUE'].rolling(4).mean()\n",
    "data.div(1000).to_csv(data_dir / 'icsa.csv', index_label='date', float_format='%g')\n",
    "\n",
    "totval = data['VALUE'].iloc[-1]*1000\n",
    "datelt = dtxt(data.index[-1])['day1']\n",
    "latest1m = data[\"1M\"].iloc[-1]*1000\n",
    "prev1m = data[\"1M\"].iloc[-53]*1000\n",
    "\n",
    "chval = totval - data['VALUE'].iloc[-2]*1000\n",
    "chtxt = f'{round(abs(chval),-2):,.0f}'\n",
    "if chval > 1000:\n",
    "    change = f'a one-week increase of {chtxt}'\n",
    "elif chval < -1000:\n",
    "    change = f'a one-week decrease of {chtxt}'\n",
    "else:\n",
    "    change = 'virtually unchanged from the previous week'\n",
    "\n",
    "text = ('The Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{report}} '+\n",
    "        f'{totval:,.0f} actual new claims for unemployment '+\n",
    "        'insurance (UI) under state programs (see {\\color{cyan!80!blue}\\\\textbf{---}}) '+\n",
    "        f'during the week ending {datelt}, {change}. Over the past four weeks, '+\n",
    "        f'new claims have averaged {round(latest1m,-2):,.0f} per week. During the same '+\n",
    "        f'four-week period last year, there were an average of {round(prev1m,-2):,.0f} '+\n",
    "        'new claims per week.')\n",
    "write_txt(text_dir / 'icsa.txt', text)\n",
    "print(text)\n",
    "data = fred_df('CCNSA', start='2017') / 1000 \n",
    "data.div(1000).to_csv(data_dir / 'ccsa.csv', index_label='date', float_format='%g')\n",
    "\n",
    "totval = data['VALUE'].iloc[-1]*1000\n",
    "prval = data['VALUE'].iloc[-2]*1000\n",
    "datelt = dtxt(data.index[-1])['day1']\n",
    "prevyrval = data['VALUE'].iloc[-53]*1000\n",
    "prmoval = data['VALUE'].iloc[-4]*1000\n",
    "datepr = dtxt(data.index[-53])['day1']\n",
    "\n",
    "chval = totval - prval\n",
    "chtxt = f'{round(abs(chval),-2):,.0f}'\n",
    "if chval > 1000:\n",
    "    change = f'a one-week increase of {chtxt}'\n",
    "elif chval < -1000:\n",
    "    change = f'a one-week decrease of {chtxt}'\n",
    "else:\n",
    "    change = 'virtually unchanged from the previous week'\n",
    "\n",
    "text = (f'For the week ending {datelt}, the Department of Labor '+\n",
    "        '\\href{{https://www.dol.gov/ui/data.pdf}}{{reports}} '+\n",
    "        f'{totval:,.0f} continued claims for unemployment '+\n",
    "        'insurance (insured unemployed) under state programs '+\n",
    "        '(see {\\color{green!90!blue}\\\\textbf{---}})'+\n",
    "        f', {change}. One year prior, during the week of {datepr}, '+\n",
    "        f'there were an average of {round(prevyrval,-2):,.0f} '+\n",
    "        'insured unemployed.')\n",
    "write_txt(text_dir / 'ccsa.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:30.668334Z",
     "start_time": "2022-02-05T02:45:29.590975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the week ending January 29, 2022, there were 600 initial UI \\href{https://oui.doleta.gov/unemploy/DataDashboard.asp}{claims} under the Pandemic Unemployment Assistance (PUA) program (see {\\color{blue!50!purple!80!black}\\textbf{---}}), compared to 500 during the prior week, and an average of 700 initial claims per week over the past four weeks. \n",
      "\n",
      "Federal program continuing claims total 128,179 in January 22, 2022 (see {\\color{green!50!blue}\\textbf{---}}). These include both claims under the PUA program and claims under the Pandemic Emergency Unemployment Compensation (PEUC) program. Combining federal program claims with state program claims indicates there are a total of 2.2 million insured unemployed persons during the week ending January 22, 2022, compared to 2.2 million one month prior, during the week ending January 1, 2022. \n"
     ]
    }
   ],
   "source": [
    "file = 'https://oui.doleta.gov/unemploy/docs/weekly_pandemic_claims.xlsx'\n",
    "fed_raw = pd.read_excel(file).iloc[1:]\n",
    "pua_ic = fed_raw.groupby('Rptdate')['PUA IC'].sum()\n",
    "pua_ic.index = pd.to_datetime(pua_ic.index)\n",
    "pua_ic.index.name = 'date'\n",
    "pua_ic.name = 'pua_ic'\n",
    "cc_raw = fed_raw.dropna(subset=['PUA CC'])\n",
    "pua_cc = cc_raw.groupby('Rptdate')['PUA CC'].sum()\n",
    "peuc_cc = cc_raw.groupby('Rptdate')['PEUC CC'].sum()\n",
    "fed_cc = pua_cc + peuc_cc\n",
    "fed_cc.index = pd.to_datetime(fed_cc.index)\n",
    "fed_cc.index.name = 'date'\n",
    "fed_cc.name = 'fed_cc'\n",
    "\n",
    "d1 = pd.DataFrame([pua_ic, fed_cc]).T / 1000\n",
    "d1.div(1000).to_csv(data_dir / 'fed_uic.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ltdate = dtxt(d1.index[-1])['day1']\n",
    "prdatecc = dtxt(d1.dropna().index[-4])['day1']\n",
    "ltdatecc = dtxt(d1.dropna().index[-1])['day1']\n",
    "pua_ic_lt = f\"{round(d1['pua_ic'].iloc[-1] * 1000, -2):,.0f}\"\n",
    "pua_ic_pr = f\"{round(d1['pua_ic'].iloc[-2] * 1000, -2):,.0f}\"\n",
    "pua_ic_1m = f\"{round(d1['pua_ic'].iloc[-4:].mean() * 1000, -2):,.0f}\"\n",
    "fed_cc_lt = d1.dropna()['fed_cc'].iloc[-1] * 1_000\n",
    "fed_cc_mo = d1.dropna()['fed_cc'].iloc[-4] * 1_000\n",
    "fed_cc_ltt = f\"{fed_cc_lt:,.0f}\"\n",
    "tot_cc = fed_cc_lt + totval\n",
    "tot_lt = f\"{tot_cc / 1_000_000:,.1f} million\"\n",
    "tot_cc_pr = fed_cc_mo + prmoval\n",
    "tot_pr = f\"{tot_cc_pr / 1_000_000:,.1f} million\"\n",
    "\n",
    "text = (f'Over the week ending {ltdate}, there were {pua_ic_lt} '+\n",
    "        'initial UI \\href{https://oui.doleta.gov/unemploy/DataDashboard.asp}{claims} '+\n",
    "        'under the Pandemic Unemployment Assistance '+\n",
    "        '(PUA) program (see {\\color{blue!50!purple!80!black}\\\\textbf{---}}), '+\n",
    "        f'compared to {pua_ic_pr} during the prior week, '+\n",
    "        f'and an average of {pua_ic_1m} initial claims per week over the '+\n",
    "        'past four weeks. \\n\\n'+\n",
    "        f'Federal program continuing claims total {fed_cc_ltt} '+\n",
    "        f'in {ltdatecc} '+\n",
    "        '(see {\\color{green!50!blue}\\\\textbf{---}}). These include both ' +\n",
    "        'claims under the PUA program and claims under the Pandemic Emergency '+\n",
    "        'Unemployment Compensation (PEUC) program. Combining federal program '+\n",
    "        f'claims with state program claims indicates there are a total '+\n",
    "        f'of {tot_lt} insured unemployed persons during the week ending {ltdatecc}, '+\n",
    "        f'compared to {tot_pr} one month prior, during the week ending {prdatecc}. ')\n",
    "write_txt(text_dir / 'fed_uic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIX (SP500 volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:31.281155Z",
     "start_time": "2022-02-05T02:45:30.669421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This volatility measure, the VIX index (see {\\color{magenta}\\textbf{---}}), was 24.4 on February 3, 2022, in line with the average index value of 21.8 over the past three years. The VIX decreased by 6.1 points over the past week.\n"
     ]
    }
   ],
   "source": [
    "#prev = pd.read_excel(data_dir/ 'vixarchive.xls', skiprows=1, index_col='Date')\n",
    "VIX = 'https://cdn.cboe.com/api/global/us_indices/daily_prices/VIX_History.csv'\n",
    "curr = pd.read_csv(VIX, index_col='DATE', parse_dates=True)\n",
    "df = (curr['CLOSE'].resample('MS').mean()\n",
    "      .append(curr['CLOSE'].iloc[-1:]).rename('value'))\n",
    "df.to_csv(data_dir / 'vix.csv', index_label='date', header='True')\n",
    "\n",
    "node = end_node(df, 'magenta', date='d', offset=0.35, full_year=True)\n",
    "write_txt(text_dir / 'vix_node.txt', node)\n",
    "\n",
    "ldate = dtxt(df.index[-1])['day1']\n",
    "vallt = df.iloc[-1]\n",
    "val3y = df.iloc[-37:].mean()\n",
    "\n",
    "compare = compare_text(vallt, val3y, [3, 12, 30])\n",
    "\n",
    "one_wk = (value_text(curr.CLOSE.diff(5).iloc[-1], style='increase_by', ptype='pp')\n",
    "          .replace('percentage ', ''))\n",
    "\n",
    "text = ('This volatility measure, the VIX index (see {\\color{magenta}\\\\textbf{---}}), '+\n",
    "        f'was {vallt:.1f} on {ldate}, '+\n",
    "        f'{compare} the average index value of {val3y:.1f} over the '+\n",
    "        f'past three years. The VIX {one_wk} over the past week.')\n",
    "write_txt(text_dir / 'vixbasic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil prices (WTI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:32.537150Z",
     "start_time": "2022-02-05T02:45:31.282146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of January 31, 2022, a barrel of west Texas intermediate (WTI) \\textbf{crude oil} sells for \\$89.16 (see {\\color{red!80!purple}\\textbf{---}}). Over the past year, this measure of oil prices grew 71.4 percent. Over the past two years, the price increased 55.0 percent. Notably, the WTI price is currently \\$45 per barrel below its peak price of \\$134 per barrel in June 2008 (monthly average).\n"
     ]
    }
   ],
   "source": [
    "df = fred_df('DCOILWTICO')\n",
    "latest = df.iloc[-1]\n",
    "ma = df.resample('MS').mean()\n",
    "p = ma.append(latest)['VALUE']\n",
    "(p.to_csv(data_dir / 'wti.csv', index_label='date', header=True))\n",
    "\n",
    "oneyr = p.pct_change(13).iloc[-1] * 100\n",
    "twoyr = p.pct_change(25).iloc[-1] * 100\n",
    "\n",
    "oyt = value_text(oneyr, casual=True)\n",
    "tyt = value_text(twoyr)\n",
    "\n",
    "node = end_node(p, 'red!80!purple', dollar=True, digits=2, date='d', \n",
    "                offset=0.35, full_year=True)\n",
    "write_txt(text_dir / 'oil_node.txt', node)\n",
    "    \n",
    "ltch = p.loc['2008-06-01'] - p.iloc[-1]\n",
    "ldate = dtxt(p.index[-1])['day1']\n",
    "text = (f'As of {ldate}, a barrel of west Texas '+\n",
    "        f'intermediate (WTI) \\\\textbf{{crude oil}} sells for \\${p.iloc[-1]:.2f} '+\n",
    "        '(see {\\color{red!80!purple}\\\\textbf{---}}). Over the past year, '+\n",
    "        f'this measure of oil prices {oyt}. Over the past two years, the '+\n",
    "        f'price {tyt}. Notably, the WTI price is currently \\${ltch:.0f} per barrel '+\n",
    "        'below its peak price of \\$134 per barrel in June 2008 (monthly average).')\n",
    "write_txt(text_dir / 'wti.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflation Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-05T02:45:34.236665Z",
     "start_time": "2022-02-05T02:45:32.538201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of February 4, 2022, markets expect an average inflation rate of 2.8 percent over the next five years (see {\\color{blue!70!black}\\textbf{---}}), compared to an expected rate of 2.3 percent on February 5, 2021. Markets had expected inflation to average 2.0 percent per year over the past five years, five years ago.\n"
     ]
    }
   ],
   "source": [
    "data1 = fred_df('T5YIE').loc['2015':,'VALUE']\n",
    "data1.to_csv(data_dir / 'infbreak.csv', index_label='date', header=True)\n",
    "data2 = fred_df('T5YIFR').loc['2015':,'VALUE']\n",
    "df = pd.DataFrame({'5_year_breakeven': data1, '5_year_5_year_forward': data2})\n",
    "df.to_csv(data_dir / 'infbreak_comb.csv', index_label='date')\n",
    "\n",
    "node = end_node(data1, 'blue!70!black', percent=True)\n",
    "write_txt(text_dir / 'infbreak_node.txt', node)\n",
    "\n",
    "ldatem = dtxt(data1.index[-1])['day1']\n",
    "lvalm = data1.iloc[-1]\n",
    "pdatem = dtxt(data1.dropna().index[-252])['day1']\n",
    "pvalm = data1.dropna().iloc[-252]\n",
    "p5valm = data1.dropna().iloc[-(252*5)]\n",
    "\n",
    "text = (f'As of {ldatem}, markets expect an average inflation rate of {lvalm:.1f} ' + \n",
    "         'percent over the next five years (see {\\color{blue!70!black}\\\\textbf{---}}), '\n",
    "         +f'compared to an expected rate of {pvalm:.1f} percent on '+\n",
    "         f'{pdatem}. Markets had expected inflation to average {p5valm:.1f} percent '+\n",
    "         f'per year over the past five years, five years ago.')\n",
    "write_txt(text_dir / 'inf_exp_mkts.txt', text)\n",
    "print(text)\n",
    "\n",
    "p55val = data2.iloc[-1]\n",
    "if data2.iloc[-1] + 0.1 > data1.iloc[-1]:\n",
    "    compare = 'fall below '\n",
    "elif data2.iloc[-1] - 0.1 < data1.iloc[-1]:\n",
    "    compare = 'exceed '\n",
    "else:\n",
    "    compare = 'maintain the same rate as '\n",
    "text = (f'Over this five-year period, markets suggest {p55val:.1f} percent inflation '+\n",
    "        f'per year. Inflation rates in the near-term are therefore expected to {compare}'+\n",
    "        'inflation rates in the longer-term')\n",
    "write_txt(text_dir / 'inf_exp_mkts_55.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
