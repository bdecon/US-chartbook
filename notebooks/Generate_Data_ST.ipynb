{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:22.802688Z",
     "start_time": "2023-11-20T22:26:21.823786Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import time\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equities Index Data from Yahoo! Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:24.267250Z",
     "start_time": "2023-11-20T22:26:22.804243Z"
    }
   },
   "outputs": [],
   "source": [
    "ltdate = int(time.time())\n",
    "colors = {'GSPC': ['S\\&P 500', 'green!80!blue!90!black'], \n",
    "          'IXIC': ['Nasdaq', 'blue'], \n",
    "          'DJI': ['Dow 30', 'red'], \n",
    "          'RUT': ['Russell 3000', 'violet']}\n",
    "raw = pd.DataFrame()\n",
    "for s in colors.keys():\n",
    "    url = ('https://query1.finance.yahoo.com/v7/finance/download/'+\n",
    "           f'%5E{s}?period1=599616000&period2={ltdate}&'+\n",
    "           'interval=1d&events=history')\n",
    "    df = pd.read_csv(url, index_col='Date', parse_dates=True)\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    raw[f'{s}_close'] = df['Adj Close']\n",
    "    raw[f'{s}_volume'] = df['Volume']\n",
    "raw.to_csv(data_dir / 'equity_indices_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:24.336151Z",
     "start_time": "2023-11-20T22:26:24.268494Z"
    }
   },
   "outputs": [],
   "source": [
    "closecol = [f'{s}_close' for s in colors.keys()]\n",
    "raw = pd.read_csv(data_dir / 'equity_indices_raw.csv', \n",
    "                  index_col='date', parse_dates=True)[closecol] / 1_000\n",
    "\n",
    "rename = {f'{s}_close': f'{s}_MA' for s in colors.keys()}\n",
    "(raw.join(raw.loc['2017':]\n",
    "          .rolling(252).mean()\n",
    "          .rename(rename, axis=1))\n",
    "    .loc['2018':]\n",
    "    .to_csv(data_dir / 'equity_indices_lt.csv', \n",
    "            index_label='date', float_format='%g'))\n",
    "prmo = raw.resample('MS').mean().iloc[:-1]\n",
    "prmo.index = prmo.index + pd.DateOffset(days=14)\n",
    "data = pd.concat([prmo, raw.iloc[-1].to_frame().T])\n",
    "res = data.rename({f'{s}_close': s for s in colors.keys()}, axis=1)\n",
    "res.to_csv(data_dir / 'equity_indices.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "rename = {f'{s}_close': f'{s}_MA' for s in colors.keys()}\n",
    "(raw.join(raw.loc['2017':]\n",
    "          .rolling(252).mean()\n",
    "          .rename(rename, axis=1))\n",
    "    .loc['2018':]\n",
    "    .to_csv(data_dir / 'equity_indices_lt.csv', \n",
    "            index_label='date', float_format='%g'))\n",
    "\n",
    "# Percent change each year\n",
    "ch = (raw.resample('Y').last().pct_change().iloc[-6:].multiply(100)\n",
    "         .applymap('{:.1f}'.format))\n",
    "ch.index = ch.index.year.astype('str').rename('')\n",
    "\n",
    "yrago = ((raw.iloc[-252:].mean() * 1000)\n",
    "             .rename('1-year moving average')\n",
    "             .apply('{:,.0f}'.format))\n",
    "ltval = ((raw.iloc[-1] * 1000)\n",
    "             .rename(dtxt(raw.index[-1])['day2'])\n",
    "             .apply('{:,.0f}'.format))\n",
    "ch = pd.concat([ch, yrago.to_frame().T, ltval.to_frame().T])\n",
    "cl = {i: c_line(c) for i, [n, c] in colors.items()}\n",
    "cl2 = {i: c_line(c, see=False, paren=False) for i, [n, c] in colors.items()}\n",
    "names = {f'{i}_close': f'\\hspace{{0.1mm}} {cl2[i]} \\ {n}' \n",
    "         for i, [n, c] in colors.items()}\n",
    "ch = (ch.rename({'2023': '2023 YTD'}).iloc[::-1].T)\n",
    "ch = (ch.reindex(list(names.keys())).rename(names))\n",
    "ch.to_csv(data_dir / 'equities.tex', sep='&', lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:24.351507Z",
     "start_time": "2023-11-20T22:26:24.338079Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \\href{https://us.spindices.com/indices/equity/sp-500}{S\\&P 500} (see {\\color{green!80!blue!90!black}\\textbf{---}}) is a market-cap-weighted stock market index based on 500 large companies listed on US exchanges. As of November 20, 2023, the S\\&P 500 has increased at an annual rate of 7.8 percent since 1992, and 9.3 percent since 2018. The \\href{https://www.nasdaq.com/market-activity/index/comp}{Nasdaq} composite index (see {\\color{blue}\\textbf{---}}) includes nearly all companies listed on the Nasdaq stock exchange, and is heavily-weighted towards large tech companies. The Nasdaq index increased at an annual rate of 10.5 percent since 1992, and 12.9 percent since 2018.\n",
      "\n",
      "The \\href{https://finance.yahoo.com/quote/\\%5EDJI/}{Dow 30} industrial average (see {\\color{red}\\textbf{---}}) is an index based on 30 large and prominent companies listed on US exchanges. The measure is used as a proxy for the performance of the largest companies, and increased at an annual rate of 7.8 percent since 1992 and 6.1 percent since 2018. Lastly, the \\href{https://www.ftserussell.com/products/indices/russell-us}{Russell 3000} (see {\\color{violet}\\textbf{---}}) is a broad measure of the US stock market that seeks to be a benchmark of the performance of the overall market. Since 1992, the Russell 3000 has increased at an annual rate of 7.3 percent. Since 2018, the measure increased at an annual rate of 2.6 percent. \n"
     ]
    }
   ],
   "source": [
    "# Nodes with summary of changes\n",
    "ltdt = dtxt(raw.index[-1])['day1']\n",
    "dwnar = '\\color{red} \\\\raisebox{1pt}{\\\\blacktriangledown} \\\\normalcolor'\n",
    "upar = '\\color{green!80!black}  \\\\raisebox{1pt}{\\\\blacktriangle} \\\\normalcolor'\n",
    "years = ['1992', '2018']\n",
    "vt, vt2, vt3 = {}, {}, {}\n",
    "for i in ['GSPC', 'IXIC', 'DJI', 'RUT']:\n",
    "    t = {}\n",
    "    for y in years:\n",
    "        iy = f'{i}{y[2:]}'\n",
    "        data = raw.loc[y:, f'{i}_close'].dropna()\n",
    "        p = (data.index[-1] - data.index[0]).days / 365\n",
    "        v = ((data.iloc[-1] / data.iloc[0])**(1/p) - 1) * 100\n",
    "        arr = upar if v > 0 else dwnar\n",
    "        t[y] = f'{y}: {arr} {v:.1f}\\%'\n",
    "        vt[iy], vt2[iy], vt3[iy] = (value_text(v), value_text(v, 'plain'), \n",
    "                                    value_text(v, adj='annual'))\n",
    "    node = ('\\\\node[below right, align=left, shift=({rel axis cs:0.02,0.98}), '+\n",
    "            'draw=black!30!white, fill=white, inner sep=3.0] {\\\\normalsize '+\n",
    "            f'\\color{{black!80!white}} \\\\textbf{{{colors[i][0]}}}}};\\n'+\n",
    "            '\\\\node[below, align=left, shift=({rel axis cs:0.55,0.97}), '+\n",
    "            'draw=black!30!white, fill=white, inner sep=3.0] '+\n",
    "            '{\\scriptsize ann. growth since:\\\\\\\\ \\\\footnotesize \\\\ \\\\ '+\n",
    "            f'{t[\"1992\"]} \\\\\\\\ \\\\footnotesize \\\\ \\\\ {t[\"2018\"]}}};')\n",
    "    write_txt(text_dir / f'{i}_ch_node.txt', node)\n",
    "    \n",
    "# urls to references\n",
    "links = {'GSPC': 'https://us.spindices.com/indices/equity/sp-500',\n",
    "         'IXIC': 'https://www.nasdaq.com/market-activity/index/comp',\n",
    "         'DJI': 'https://finance.yahoo.com/quote/\\%5EDJI/',\n",
    "         'RUT': 'https://www.ftserussell.com/products/indices/russell-us'}\n",
    "url = {i: f'\\href{{{links[i]}}}{{{colors[i][0]}}}' for i in colors.keys()}\n",
    "\n",
    "# Summary text\n",
    "text = (f'The {url[\"GSPC\"]} {cl[\"GSPC\"]} is a market-cap-weighted '+\n",
    "        'stock market index based on 500 large companies listed on '+\n",
    "        'US exchanges. '+\n",
    "        f'As of {ltdt}, the S\\&P 500 has {vt3[\"GSPC92\"]} since {years[0]}, '+\n",
    "        f'and {vt2[\"GSPC18\"]} since {years[1]}. '+\n",
    "        f'The {url[\"IXIC\"]} composite index {cl[\"IXIC\"]} includes nearly '+\n",
    "        f'all companies listed on the Nasdaq stock exchange, and is '+\n",
    "        'heavily-weighted towards large tech companies. '+\n",
    "        f'The Nasdaq index {vt3[\"IXIC92\"]} since {years[0]}, and '+\n",
    "        f'{vt2[\"IXIC18\"]} since {years[1]}.\\n\\n'+\n",
    "        f'The {url[\"DJI\"]} industrial average {cl[\"DJI\"]} is an index based '+\n",
    "        'on 30 large and prominent companies listed on US exchanges. The measure '+\n",
    "        'is used as a proxy for the performance of the largest companies, and '+\n",
    "        f'{vt3[\"DJI92\"]} since {years[0]} and {vt2[\"DJI18\"]} since {years[1]}. '+\n",
    "        f'Lastly, the {url[\"RUT\"]} {cl[\"RUT\"]} is a broad measure of the US stock '+\n",
    "        'market that seeks to be a benchmark of the performance of the overall '+\n",
    "        f'market. Since {years[0]}, the Russell 3000 has {vt3[\"RUT92\"]}. '+\n",
    "        f'Since {years[1]}, the measure {vt3[\"RUT18\"]}. ')\n",
    "write_txt(text_dir / 'equities_ch_summary.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500 Sector performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:28.548439Z",
     "start_time": "2023-11-20T22:26:24.353079Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'SP500-15': 'Materials', 'SP500-20': 'Industrials', \n",
    "     'SP500-25': 'Consumer \\\\\\\\[-1ex] Discretionary', \n",
    "     'SP500-30': 'Consumer \\\\\\\\[-1ex] Staples', \n",
    "     'SP500-35': 'Health Care', 'SP500-40': 'Financials', \n",
    "     'SP500-45': 'Information \\\\\\\\[-1ex] Technology', \n",
    "     'SP500-50': 'Communication \\\\\\\\[-1ex] Services',\n",
    "     'SP500-55': 'Utilities', 'SP500-60': 'Real Estate',\n",
    "     'GSPE': 'Energy', 'GSPC': '\\\\textbf{S\\&P 500}'}\n",
    "\n",
    "ltdate = int(time.time())\n",
    "raw = pd.DataFrame()\n",
    "for s, n in d.items():\n",
    "    url = ('https://query1.finance.yahoo.com/v7/finance/download/'+\n",
    "           f'%5E{s}?period1=599616000&period2={ltdate}&'+\n",
    "           'interval=1d&events=history')\n",
    "    df = pd.read_csv(url, index_col='Date', parse_dates=True)\n",
    "    df = df[~df.index.duplicated(keep='last')]\n",
    "    raw[n] = df['Adj Close']\n",
    "raw.to_csv(data_dir / 'sp500_sector_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:28.572838Z",
     "start_time": "2023-11-20T22:26:28.549724Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'sp500_sector_raw.csv', index_col='date',\n",
    "                 parse_dates=True)\n",
    "ch = df.resample('Y').last().pct_change().iloc[-6:].multiply(100)\n",
    "s = ch.iloc[-1].sort_values()\n",
    "\n",
    "# Empty bars to set spacing\n",
    "cmin, cmax = s.min(), s.max()\n",
    "crng = cmax - cmin\n",
    "cbuf = max([(cmax - 0), (0 - cmin)]) * 0.68 #Buffer for text labels\n",
    "thresh = crng * 0.21 #Bigger bars labeled inside\n",
    "empty_neg = f'\\\\addplot[white!0] coordinates {{(-{cbuf:.2f}, 0)}};'\n",
    "empty_pos = f'\\\\addplot[white!0] coordinates {{({cbuf:.2f}, 0)}};'\n",
    "txt = [empty_neg, empty_pos]\n",
    "\n",
    "for i, (val, name) in enumerate(list(zip(s, s.index))):\n",
    "    color = 'green!78!black' if name != '\\\\textbf{S\\&P 500}' else 'green!60!black'\n",
    "    # Add bar\n",
    "    bar = f'\\\\addplot[{color}] coordinates {{({val}, {i})}};'\n",
    "    txt.append(bar)\n",
    "    pos = ('left', 'right') if val >= 0 else ('right', 'left')\n",
    "    # Add y label with sector name\n",
    "    ylab = (f'\\\\node[{pos[0]}, align={pos[1]}, text width=2.0cm] '+\n",
    "            f'at (axis cs:0,{i}) {{\\scriptsize{{{name}}}}};')\n",
    "    txt.append(ylab)\n",
    "    # Add value label\n",
    "    vtx = f'\\scriptsize {val:.1f}'\n",
    "    if abs(val) > thresh:  # Some value labels inside of bars\n",
    "        vt = f'\\scriptsize \\color{{white}} \\\\textbf{{{vtx}}}'\n",
    "        inside = True\n",
    "    else:\n",
    "        vt = f'\\scriptsize {vtx}'\n",
    "        inside = False\n",
    "    if val >= 0:\n",
    "        vtlab = 'left, align=right' if inside == True else 'right, align=right'\n",
    "    else:\n",
    "        vtlab = 'right, align=left' if inside == True else 'left, align=left'        \n",
    "    vlab = f'\\\\node[{vtlab}] at (axis cs:{val},{i}) {{{vt}}};'\n",
    "    txt.append(vlab)\n",
    "    \n",
    "nodes = '\\n'.join(txt)\n",
    "write_txt(text_dir / 'sp500sector.txt', nodes)\n",
    "\n",
    "ltdate_txt = dtxt(df.index[-1])['day2']\n",
    "write_txt(text_dir / 'sp500sector_date.txt', ltdate_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:30.726882Z",
     "start_time": "2023-11-20T22:26:28.574008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest sector is information technology, which makes up 28.1 percent of the index, by market cap, as of October 31, 2023. The health care sector makes up 13.1 percent, the financials sector makes up 12.8 percent, and the consumer discretionary sector makes up 10.6 percent.\n"
     ]
    }
   ],
   "source": [
    "# Sector Representation\n",
    "url = ('https://www.spglobal.com/spdji/en/documents/additional-material/'+\n",
    "       'sp-500-market-attributes-web-file.xlsx')\n",
    "data = pd.read_excel(url, sheet_name='SECTOR REPRESENTATION', \n",
    "                     index_col=0, header=3).dropna(how='all')\n",
    "ltval = data.T.iloc[0] * 100\n",
    "ltdt = dtxt(pd.to_datetime(ltval.name))['day1']\n",
    "\n",
    "vals = ltval.drop('S&P 500').sort_values()\n",
    "vals.index = vals.index.str.strip().str.replace('*', '', regex=True).str.lower()\n",
    "v1 = value_text(vals.iloc[-1], 'plain')\n",
    "n1 = vals.index[-1]\n",
    "v2 = value_text(vals.iloc[-2], 'plain')\n",
    "n2 = vals.index[-2]\n",
    "v3 = value_text(vals.iloc[-3], 'plain')\n",
    "n3 = vals.index[-3]\n",
    "v4 = value_text(vals.iloc[-4], 'plain')\n",
    "n4 = vals.index[-4]\n",
    "text = (f'The largest sector is {n1}, which makes up '+\n",
    "        f'{v1} of the index, by market cap, as of {ltdt}. '+\n",
    "        f'The {n2} sector makes up {v2}, the '+\n",
    "        f'{n3} sector makes up {v3}, and the {n4} '+\n",
    "        f'sector makes up {v4}.')\n",
    "write_txt(text_dir / 'sp500sector_comp.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:30.738884Z",
     "start_time": "2023-11-20T22:26:30.728404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the latest full year of data, 2022, the S\\&P 500 adjusted loss was 19.4 percent. The communication services sector lost 40.4 percent, the consumer discretionary sector lost 37.6 percent, and the information technology sector lost 28.9 percent. The largest gain in 2022 was in the energy sector, with a total increase of 59.0 percent.\n"
     ]
    }
   ],
   "source": [
    "# Text for sector performance\n",
    "cht = ch.rename({'\\\\textbf{S\\&P 500}': 'sp500'}, axis=1)\n",
    "cht.columns = [c.lower().replace('\\\\\\\\[-1ex] ', '') \n",
    "               for c in cht.columns]\n",
    "ltdt = dtxt(df.index[-1])['day1']\n",
    "# Previous year\n",
    "dft = cht.iloc[-2]\n",
    "pr_tot = dft['sp500']\n",
    "pryr = f'{dft.name.year}'\n",
    "gl_tot = 'gain' if pr_tot >= 0 else 'loss'\n",
    "prtott = f'adjusted {gl_tot} was {abs(pr_tot):.1f} percent'\n",
    "\n",
    "# Top four sectors\n",
    "srs = abs(dft).sort_values(ascending=False).index[:4].to_list()\n",
    "# Retrieve values the same sign as the total\n",
    "res = abs(dft[(dft * pr_tot) > 0])\n",
    "sel_col = res[res > abs(pr_tot)].sort_values(ascending=False).index.to_list()\n",
    "overlap = [i for i in sel_col if i in srs]\n",
    "# Values with the opposite sign\n",
    "opp_col = abs(dft[(dft * pr_tot) < 0]).sort_values(ascending=False).index.to_list()\n",
    "\n",
    "# Text for top values\n",
    "maxn = sel_col[0]\n",
    "maxv = value_text(dft[maxn], 'return')\n",
    "\n",
    "# Adjust text for number of relevant sectors\n",
    "ov2 = ''\n",
    "if len(overlap) == 1:\n",
    "    wh = ', while '\n",
    "    wh2 = ', and the '\n",
    "if len(overlap) > 1:\n",
    "    wh = ', and '\n",
    "    wh2 = '. The '\n",
    "    n2 = sel_col[1]\n",
    "    v2 = value_text(dft[n2], 'return')\n",
    "if len(overlap) > 2:\n",
    "    wh = ', '\n",
    "    wh2 = ', and the '\n",
    "    n3 = sel_col[2]\n",
    "    v3 = value_text(dft[n3], 'gain')\n",
    "    \n",
    "# Opposing data\n",
    "if len(opp_col) > 0:\n",
    "    gl_tot2 = 'loss' if gl_tot == 'gain' else 'gain'\n",
    "    o1 = opp_col[0]\n",
    "    ov1 = value_text(dft[o1], 'increase_of', adj='total')\n",
    "    endtxt = (f'The largest {gl_tot2} in {pryr} was in the '+\n",
    "             f'{o1} sector, with {ov1}{ov2}.')\n",
    "else: # Text for smallest value \n",
    "    small = res.sort_values().index[0]\n",
    "    smval = value_text(dft[small], 'plain')\n",
    "    endtxt = (f'The smallest {gl_tot} was the {small} sector ({smval}).')\n",
    "\n",
    "txt = (f'In the latest full year of data, {pryr}, the '+\n",
    "       f'S\\&P 500 {prtott}. The {maxn} sector {maxv}{wh}'+\n",
    "       f'the {n2} sector {v2}{wh2}{n3} '+\n",
    "       f'sector {v3}. {endtxt}')\n",
    "write_txt(text_dir / 'sp500sector_ch.txt', txt)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:30.751890Z",
     "start_time": "2023-11-20T22:26:30.740324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 20, 2023, the \\textbf{year-to-date total return} for the S\\&P 500 is 18.4 percent. The information technology sector returned 51.8 percent, the communication services sector returned 50.4 percent, and the consumer discretionary sector gained 32.4 percent. The largest loss is in the utilities sector, with a total decrease of 12.5 percent.\n"
     ]
    }
   ],
   "source": [
    "# Year to date\n",
    "dft = cht.iloc[-1]\n",
    "pr_tot = dft['sp500']\n",
    "pryr = f'{dft.name.year}'\n",
    "gl_tot = 'gain' if pr_tot >= 0 else 'loss'\n",
    "prtott = value_text(pr_tot, 'plain')\n",
    "\n",
    "# Top four sectors\n",
    "srs = abs(dft).sort_values(ascending=False).index[:4].to_list()\n",
    "# Retrieve values the same sign as the total\n",
    "res = abs(dft[(dft * pr_tot) > 0])\n",
    "sel_col = res[res > abs(pr_tot)].sort_values(ascending=False).index.to_list()\n",
    "overlap = [i for i in sel_col if i in srs]\n",
    "# Values with the opposite sign\n",
    "opp_col = abs(dft[(dft * pr_tot) < 0]).sort_values(ascending=False).index.to_list()\n",
    "\n",
    "# Text for top values\n",
    "maxn = sel_col[0]\n",
    "maxv = value_text(dft[maxn], 'return')\n",
    "\n",
    "# Adjust text for number of relevant sectors\n",
    "ov2 = ''\n",
    "if len(overlap) == 1:\n",
    "    wh = ', while '\n",
    "    wh2 = ', and the '\n",
    "if len(overlap) > 1:\n",
    "    wh = ', and '\n",
    "    wh2 = '. The '\n",
    "    n2 = sel_col[1]\n",
    "    v2 = value_text(dft[n2], 'return')\n",
    "    #ov2 = ', followed by {} in the {} sector'\n",
    "if len(overlap) > 2:\n",
    "    wh = ', '\n",
    "    wh2 = ', and the '\n",
    "    n3 = sel_col[2]\n",
    "    v3 = value_text(dft[n3], 'gain')\n",
    "    \n",
    "# Opposing data\n",
    "if len(opp_col) > 0:\n",
    "    gl_tot2 = 'loss' if gl_tot == 'gain' else 'gain'\n",
    "    o1 = opp_col[0]\n",
    "    ov1 = value_text(dft[o1], 'increase_of', adj='total')\n",
    "    endtxt = (f'The largest {gl_tot2} is in the '+\n",
    "             f'{o1} sector, with {ov1}{ov2}.')\n",
    "else: # Text for smallest value \n",
    "    small = res.sort_values().index[0]\n",
    "    smval = value_text(dft[small], 'plain')\n",
    "    endtxt = (f'The smallest {gl_tot} was the {small} sector ({smval}).')\n",
    "\n",
    "txt = (f'As of {ltdt}, the \\\\textbf{{year-to-date total return}} '+\n",
    "       f'for the S\\&P 500 is {prtott}. The {maxn} sector {maxv}{wh}'+\n",
    "       f'the {n2} sector {v2}{wh2}{n3} '+\n",
    "       f'sector {v3}. {endtxt}')\n",
    "write_txt(text_dir / 'sp500sector_ch2.txt', txt)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:30.762708Z",
     "start_time": "2023-11-20T22:26:30.754748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the past month, the S\\&P 500 has returned 4.9 percent. The information technology sector returned 9.7 percent, the utilities sector gained 6.9 percent, and the real estate sector returned 6.8 percent.\n"
     ]
    }
   ],
   "source": [
    "# Latest month\n",
    "dft = (df.rename({'\\\\textbf{S\\&P 500}': 'sp500'}, axis=1).pct_change(30).iloc[-1] * 100)\n",
    "dft.index = [c.lower().replace('\\\\\\\\[-1ex] ', '') \n",
    "               for c in dft.index]\n",
    "pr_tot = dft['sp500']\n",
    "pryr = f'{dft.name.year}'\n",
    "gl_tot = 'gain' if pr_tot >= 0 else 'loss'\n",
    "prtott = value_text(pr_tot, 'return')\n",
    "\n",
    "# Top three sectors\n",
    "srs = abs(dft.drop('sp500')).sort_values(ascending=False).index[:3].to_list()\n",
    "\n",
    "n1 = srs[0]\n",
    "v1 = value_text(dft[n1], 'return')\n",
    "n2 = srs[1]\n",
    "v2 = value_text(dft[n2], 'gain')\n",
    "n3 = srs[2]\n",
    "v3 = value_text(dft[n3], 'return')\n",
    "\n",
    "txt = (f'Over the past month, the S\\&P 500 has {prtott}. '+\n",
    "       f'The {n1} sector {v1}, '+\n",
    "       f'the {n2} sector {v2}, and the {n3} '+\n",
    "       f'sector {v3}.')\n",
    "write_txt(text_dir / 'sp500sector_ch3.txt', txt)\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rates Data From Fed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:34.630306Z",
     "start_time": "2023-11-20T22:26:30.763917Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.federalreserve.gov/datadownload/Output.aspx?'+\n",
    "       'rel=H15&series=4216503bb3a25c994952047659b79297&lastobs=&'+\n",
    "       'from=01/01/1988&to=12/31/2023&filetype=csv&label=include&'+\n",
    "       'layout=seriescolumn')\n",
    "d, df = clean_fed_data(url)\n",
    "df.to_csv(data_dir / 'fed_rates_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:34.708781Z",
     "start_time": "2023-11-20T22:26:34.631497Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(data_dir / 'fed_rates_raw.csv', \n",
    "                         index_col='date', parse_dates=True)\n",
    "\n",
    "n = {'RIFLGFCY10_N.B': 'Ten-year',\n",
    "    'RIFLGFCY30_N.B': 'Thirty-year',\n",
    "    'RIFLGFCM03_N.B': 'Three-month',\n",
    "    'RIFLGFCY05_N.B': 'Five-year',\n",
    "    'RIFLGFCY02_N.B': 'Two-year',\n",
    "    'RIFLGFCM01_N.B': 'One-month',\n",
    "    'RIFLGFCY01_N.B': 'One-year',\n",
    "    'RIFLGFCY20_N.B': 'Twenty-year',\n",
    "    'RIFLGFCM06_N.B': 'Six-month',\n",
    "    'RIFLGFCY03_N.B': 'Three-year',\n",
    "    'RIFLGFCY07_N.B': 'Seven-year'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Ten-year'])\n",
    "df.to_csv(data_dir / 'treas_raw.csv', index_label='date')\n",
    "\n",
    "# Fed funds rate \n",
    "n = {'RIFSPFF_N.B': 'Fed Funds'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Fed Funds'])\n",
    "df.to_csv(data_dir / 'ff_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:36.012190Z",
     "start_time": "2023-11-20T22:26:34.710101Z"
    }
   },
   "outputs": [],
   "source": [
    "# Taylor Rule suggested Fed Funds rate\n",
    "p = (pd.read_csv(data_dir / 'pce_pi.csv', parse_dates=['date'])\n",
    "       .set_index('date')['CORE']).resample('QS').mean() * 0.5\n",
    "\n",
    "y = ((nipa_df(retrieve_table('T10106')['Data'], ['A191RX']))\n",
    "      .loc['1989':, 'A191RX'])\n",
    "\n",
    "# Special case to handle revision to GDP\n",
    "url = ('https://api.stlouisfed.org/fred/series?series_id=GDPPOT&'+\n",
    "       f'api_key={fred_key}&file_type=json')\n",
    "r = requests.get(url).json()\n",
    "update = r['seriess'][0]['last_updated']\n",
    "gdppot_adj = 1\n",
    "if update < '2023-08-02':\n",
    "    gdppot_adj = pd.read_csv(data_dir / 'gdppot_adj.csv', \n",
    "                             index_col='date', parse_dates=True)['A191RX']\n",
    "y_p = fred_df('GDPPOT')['VALUE'] * 1_000 * gdppot_adj\n",
    "\n",
    "o = (y - (y_p)).divide(y_p).dropna()\n",
    "\n",
    "taylor_ff = (p + 3 + (0.5*(p - 2)) + (1*(o*100))).dropna()\n",
    "\n",
    "taylor_ff.name = 'Value'\n",
    "\n",
    "taylor_ff.to_csv(data_dir / 'taylor.csv', index_label='date')\n",
    "\n",
    "# Median projection for Fed Funds Rate\n",
    "ff = fred_df('FEDTARMD')['VALUE']\n",
    "ff.index = ff.index + pd.DateOffset(days = 360)\n",
    "ff.to_csv(data_dir / 'ffproj.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:36.095859Z",
     "start_time": "2023-11-20T22:26:36.018414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the 1980s to 2021, treasury yields fell considerably. The annual yield on ten-year treasuries (see {\\color{blue!70!black}\\textbf{---}}) fell from 8.49 percent in 1989 to 0.62 percent in July 2020. As of November 17, 2023, ten-year treasury bonds yield 4.44 percent, an increase of 0.77 percentage point from the year prior. \n",
      "\n",
      "Short-term treasury yields more-closely track the base interest rate set by the Federal Reserve. Three-month treasury bills (see {\\color{green!60!black}\\textbf{---}}) return an annual rate of 8.39 percent in 1989 but pay virtually no interest from 2009 to 2016. As of November 17, 2023, three-month treasuries yield 5.50 percent, an increase of 1.18 percentage points from the year prior. \n"
     ]
    }
   ],
   "source": [
    "# Nominal Treasury Yields \n",
    "df = pd.read_csv(data_dir / 'treas_raw.csv', index_col='date', \n",
    "                 parse_dates=True).loc['1989':]\n",
    "\n",
    "# Colors for chart\n",
    "color = {'Ten-year': 'blue!70!black', 'Two-year': 'cyan!75!white', \n",
    "          'Three-month': 'green!60!black'}\n",
    "\n",
    "# Monthly data for long-term chart\n",
    "mon = df.resample('MS').mean().iloc[:-1]\n",
    "lt = df.iloc[-1].to_frame().T\n",
    "data = pd.concat([mon, lt])\n",
    "data.to_csv(data_dir / 'rates.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "# Text \n",
    "ldate = dtxt(data.index[-1])['day1']\n",
    "ltv = df.iloc[-1].apply(\"{0:.2f} percent\".format)\n",
    "v89 = df.loc['1989'].mean().apply(\"{0:.2f} percent\".format)\n",
    "lowmon10 = dtxt(data['Ten-year'].idxmin())['mon1']\n",
    "low10y = f\"{data['Ten-year'].min():.2f} percent\"\n",
    "cht, cl = {}, {}\n",
    "for s in ['Ten-year', 'Three-month']:\n",
    "    cht[s] = value_text(df[s].diff(252).iloc[-1], 'increase_of', \n",
    "                        ptype='pp', digits=2)\n",
    "    cl[s] = c_line(color[s])\n",
    "    \n",
    "text = ('From the 1980s to 2021, treasury yields fell considerably. '+\n",
    "        f'The annual yield on ten-year treasuries {cl[\"Ten-year\"]} fell '\n",
    "        f'from {v89[\"Ten-year\"]} in 1989 to {low10y} in {lowmon10}. '+\n",
    "        f'As of {ldate}, ten-year treasury bonds yield {ltv[\"Ten-year\"]}, '+\n",
    "        f'{cht[\"Ten-year\"]} from the year prior. \\n\\n'+\n",
    "        'Short-term treasury yields more-closely track the base interest '+\n",
    "        'rate set by the Federal Reserve. Three-month treasury bills '+\n",
    "        f'{cl[\"Three-month\"]} return an annual rate of {v89[\"Three-month\"]} '+\n",
    "        'in 1989 but pay virtually no interest from 2009 to 2016. As of '+\n",
    "        f'{ldate}, three-month treasuries yield {ltv[\"Three-month\"]}, '+\n",
    "        f'{cht[\"Three-month\"]} from the year prior. ')\n",
    "write_txt(text_dir / 'rates_basic.txt', text)\n",
    "print(text)\n",
    "\n",
    "    \n",
    "# Treasury recent data for smaller chart 2\n",
    "tst = df[['Three-month', 'Ten-year']].iloc[-420:]\n",
    "tst.to_csv(data_dir / 'treas_recent2.csv', index_label='date')\n",
    "adj = node_adj(tst)\n",
    "nodes = []\n",
    "for s in tst.columns:\n",
    "    date = None\n",
    "    adjm = 0\n",
    "    xoff = 0\n",
    "    if tst.iloc[-1].idxmax() == s:\n",
    "        date = 'ds'\n",
    "        adjm = 0.15\n",
    "        xoff = -0.35 if len(str(tst.index[-1].day)) == 2 else -0.175\n",
    "    node = end_node(tst[s], color[s], digits=2, date=date, align='right',\n",
    "                    offset=adjm + adj[s], size=1.1, xoffset=xoff)\n",
    "    nodes.append(node)\n",
    "node_txt = '\\n'.join(n for n in nodes)\n",
    "write_txt(text_dir / 'treas_recent_nodes2.txt', node_txt)    \n",
    "\n",
    "# blank dataframe to generate x axis labels\n",
    "dm = tst.resample('MS').mean().iloc[1:]\n",
    "dm['label'] = [dt.strftime('%b\\\\\\%Y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') if dt.month in [4, 7, 10]\n",
    "                 else '' for dt in dm.index]\n",
    "# Add year to first mark\n",
    "fmark = dm[dm.label.str.len() > 0].index[0]\n",
    "dm.loc[fmark, 'label'] = fmark.strftime('%b\\\\\\%Y')\n",
    "# Extra monthly series used to create ticks in latex\n",
    "dm[['Ten-year', 'label']].to_csv(data_dir / 'treas_recent_mon2.csv', index_label='date', \n",
    "                      float_format='%g')    \n",
    "    \n",
    "# Treasury recent data for smaller chart\n",
    "tst = df[['Three-month', 'Two-year', 'Ten-year']].iloc[-250:]\n",
    "tst.to_csv(data_dir / 'treas_recent.csv', index_label='date')\n",
    "adj = node_adj(tst)\n",
    "nodes = []\n",
    "for s in tst.columns:\n",
    "    date = None\n",
    "    adjm = 0\n",
    "    if tst.iloc[-1].idxmax() == s:\n",
    "        date = 'ds'\n",
    "        adjm = 0.15\n",
    "    node = end_node(tst[s], color[s], digits=2, date=date, \n",
    "                    offset=adjm + adj[s], size=1.1)\n",
    "    nodes.append(node)\n",
    "node_txt = '\\n'.join(n for n in nodes)\n",
    "write_txt(text_dir / 'treas_recent_nodes.txt', node_txt)\n",
    "\n",
    "# blank dataframe to generate x axis labels\n",
    "dm = tst.resample('MS').mean()\n",
    "dm['label'] = [dt.strftime('%b\\\\\\%Y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') if dt.month in [4, 7, 10]\n",
    "                 else '' for dt in dm.index]\n",
    "# Add year to first mark\n",
    "fmark = dm[dm.label.str.len() > 0].index[0]\n",
    "dm.loc[fmark, 'label'] = fmark.strftime('%b\\\\\\%Y')\n",
    "\n",
    "# LaTeX box showing inset area\n",
    "vmax = tst.max().max() * 1.06\n",
    "vmin = tst.min().min() * 0.94\n",
    "dmax = dtxt(tst.index[-1] - pd.DateOffset(months=1))['datetime']\n",
    "dmin = dtxt(tst.index[0] + pd.DateOffset(months=1))['datetime']\n",
    "linecol = 'black!75'\n",
    "text = (f'\\coordinate (c1) at (axis cs: {{{dmin}}},{vmin});\\n'+\n",
    "        f'\\coordinate (c2) at (axis cs: {{{dmax}}},{vmin});\\n'+\n",
    "        f'\\coordinate (c3) at (axis cs: {{{dmin}}},{vmax});\\n'+\n",
    "        f'\\coordinate (c4) at (axis cs: {{{dmax}}},{vmax});\\n'+\n",
    "        f'\\draw [{linecol}, densely dotted] (c1) -- (c2);\\n'+\n",
    "        f'\\draw [{linecol}, densely dotted] (c1) -- (c3);\\n'+\n",
    "        f'\\draw [{linecol}, densely dotted] (c3) -- (c4);\\n')\n",
    "write_txt(text_dir / 'treas_inset_box.txt', text)\n",
    "\n",
    "# Extra monthly series used to create ticks in latex\n",
    "dm[['Two-year', 'label']].to_csv(data_dir / 'treas_recent_mon.csv', index_label='date', \n",
    "                      float_format='%g')    \n",
    "\n",
    "# Table showing treasury yields\n",
    "rows = ['One-month', 'Three-month', 'Six-month', 'One-year', \n",
    "        'Two-year', 'Three-year', 'Five-year', 'Seven-year', \n",
    "        'Ten-year', 'Twenty-year', 'Thirty-year']\n",
    "columns = [-1, -2, -5]\n",
    "data2 = df[rows].iloc[columns].T\n",
    "data2.columns = [dtxt(i)['day2'] for i in data2.keys()]\n",
    "curmo = pd.to_datetime(f\"{dtxt(df.index[-1])['mon5']}-01\")\n",
    "prmo = (curmo - pd.DateOffset(months=1))\n",
    "prmov = dtxt(prmo)['mon5']\n",
    "prmot = dtxt(prmo)['mon2']\n",
    "data2[prmot] = df.loc[prmov].mean()\n",
    "pryr = (curmo - pd.DateOffset(years=1))\n",
    "pryrv = dtxt(pryr)['mon5']\n",
    "pryrt = dtxt(pryr)['mon2']\n",
    "data2[pryrt] = df.loc[pryrv].mean()\n",
    "data2['2019'] = df.loc['2019'].mean()\n",
    "data2['2010 --`13'] = df.loc['2010': '2013'].mean()\n",
    "data2['1998 --`00'] = df.loc['1998': '2000'].mean()\n",
    "data2['1989'] = df.loc['1989'].mean()\n",
    "(data2.applymap('{:,.2f}'.format).replace('nan', '--')\n",
    "      .to_csv(data_dir / 'treasury_rates.tex', sep='&', \n",
    "           lineterminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:36.375346Z",
     "start_time": "2023-11-20T22:26:36.097246Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The effective Fed funds rate is 5.33 percent, as of November 17, 2023 (see {\\color{blue!60!black}\\textbf{---}}).\n",
      "As of the second quarter of 2023, the modified Taylor rule suggests a federal funds rate of 4.8 percent, 0.51 percentage point below the current rate.\n",
      "\n",
      "FOMC meeting participants provide \\href{https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm}{projections} which can be used to summarize policymaker views on the future path of the federal funds rate, as seen by the people who set it. As of September 20, 2023, the median projected federal funds rate rate is 5.6 percent for 2023, 5.1 percent for 2024, and 3.9 percent for 2025 (see\\cbox{purple}).\n"
     ]
    }
   ],
   "source": [
    "# Descripion/discussion of Fed Funds Rate\n",
    "df = pd.read_csv(data_dir / 'ff_raw.csv', index_col='date', \n",
    "                 parse_dates=True).loc['1989':]\n",
    "\n",
    "mon = df.resample('MS').mean().iloc[:-1]\n",
    "lt = df.iloc[-1].to_frame().T\n",
    "data = pd.concat([mon, lt])\n",
    "data.to_csv(data_dir / 'ffrate.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "dfff = df['Fed Funds'].dropna()\n",
    "ltdt = dtxt(dfff.index[-1])['day1']\n",
    "cline = c_line('blue!60!black')\n",
    "val = f'{dfff.iloc[-1]:.2f} percent'\n",
    "text = (f'The effective Fed funds rate is {val}, as of {ltdt} {cline}.')\n",
    "write_txt(text_dir / 'rates_ff.txt', text)\n",
    "print(text)\n",
    "\n",
    "ff = pd.read_csv(data_dir / 'ffproj.csv', index_col='date', \n",
    "                 parse_dates=True).VALUE\n",
    "\n",
    "sep = ff#.loc[str(pd.to_datetime('today').year):]\n",
    "sep.to_csv(data_dir / 'sep.csv', index_label='date', header=True)\n",
    "dt = dtxt(data.index[-1])['datetime']\n",
    "text = (f'\\draw [dashed, black!16] (axis cs:{{{dt}}},'+\n",
    "        '\\pgfkeysvalueof{/pgfplots/ymin}) -- '+\n",
    "        f'(axis cs:{{{dt}}}, \\pgfkeysvalueof{{'+\n",
    "        '/pgfplots/ymax});')\n",
    "write_txt(text_dir / 'ff_proj_bar.txt', text)\n",
    "\n",
    "url = ('https://api.stlouisfed.org/fred/series?'+\n",
    "       f'series_id=FEDTARMD&api_key={fred_key}&file_type=json')\n",
    "r = requests.get(url)\n",
    "mdt = dtxt(pd.to_datetime(r.json()['seriess'][0]['last_updated']))['day1']\n",
    "taylor_ff = pd.read_csv(data_dir / 'taylor.csv', index_col='date', \n",
    "                        parse_dates=True)\n",
    "tffdt = dtxt(taylor_ff.index[-1])['qtr2']\n",
    "tfflt = taylor_ff.Value.iloc[-1]\n",
    "fflt = dfff.iloc[-1]\n",
    "tffdiff = tfflt - fflt\n",
    "difftxt = value_text(tffdiff, 'above_below', ptype='pp', digits=2)\n",
    "url = 'https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm'\n",
    "sepcol = 'purple'\n",
    "cb = c_box(sepcol).replace('see ', 'see')\n",
    "text = (f'As of {tffdt}, the modified Taylor rule suggests a federal '+\n",
    "        f'funds rate of {tfflt:.1f} percent, {difftxt} the current '+\n",
    "        f'rate.\\n\\nFOMC meeting participants provide \\href{{{url}}}'+\n",
    "        '{projections} which can be used to summarize policymaker '+\n",
    "        'views on the future path of the federal funds rate, as seen '+\n",
    "        f'by the people who set it. As of {mdt}, the median projected '+\n",
    "        f'federal funds rate rate is {sep.iloc[0]} percent for '+\n",
    "        f'{sep.index[0].year}, {sep.iloc[1]} percent for '+\n",
    "        f'{sep.index[1].year}, and {sep.iloc[2]} percent for '+\n",
    "        f'{sep.index[2].year} {cb}.')\n",
    "write_txt(text_dir / 'rates_ff_proj.txt', text)\n",
    "print(text)\n",
    "\n",
    "text = ('\\\\node[text width=7.8cm, anchor=west, fill=white] at (axis '+\n",
    "        'description cs: 0.01, 0.08){\\scriptsize Summary of Economic '+\n",
    "        f'Projections (\\color{{{sepcol}}}\\\\textbf{{SEP}}\\\\normalcolor) '+\n",
    "        f'as of {mdt}}};')\n",
    "write_txt(text_dir / 'rates_ff_proj_date.txt', text)\n",
    "\n",
    "node = (end_node(sep, sepcol, date='y', full_year=True, anchor='south', \n",
    "               align='center', colon=False, offset=0.15))\n",
    "write_txt(text_dir / 'rates_ff_proj_node.txt', node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-18T17:37:54.210618Z",
     "start_time": "2020-09-18T17:37:54.206641Z"
    }
   },
   "source": [
    "### Yield Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:36.401491Z",
     "start_time": "2023-11-20T22:26:36.380718Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\node[text width=3.8cm, anchor=west] at (axis description cs: 0, 0.95) {\\small As of {November 17, 2023}:};\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'treas_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "\n",
    "i = {'One-month': 1, 'Three-month': 2, 'Six-month': 3, 'One-year': 4, \n",
    "     'Two-year': 5, 'Five-year': 6, 'Ten-year': 7, 'Twenty-year': 8, \n",
    "     'Thirty-year': 9}\n",
    "tbl = pd.DataFrame()\n",
    "for v, c in [(-1, 'value'), (-252, 'oneyear'), (-252*5, 'fiveyear')]:\n",
    "    col = df[i.keys()].iloc[v]\n",
    "    col.index = col.index.map(i)\n",
    "    tbl[c] = col\n",
    "tbl.index.name = 'number'\n",
    "tbl['alignment'] = 270\n",
    "\n",
    "tbl.to_csv(data_dir / 'yc.csv', float_format='%g')\n",
    "dt = dtxt(df.index[-1])['day1']\n",
    "date = ('\\\\node[text width=3.8cm, anchor=west] at (axis description cs: '+\n",
    "        f'0, 0.95) {{\\small As of {{{dt}}}:}};')\n",
    "write_txt(text_dir / 'yc_date.txt', date)\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:36.433213Z",
     "start_time": "2023-11-20T22:26:36.402720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 17, 2023, the spread between a 10-year treasury bond and a three-month treasury bill is negative 1.06 percentage points (see {\\color{blue!70!cyan!80!white}\\textbf{---}}), compared to negative 0.55 percentage point one year prior. The spread between 10-year and 2-year treasuries (see {\\color{red!60!violet!90!white}\\textbf{---}}) is negative 0.44 percentage point on November 17, 2023, and negative 0.66 percentage point one year prior.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'treas_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "\n",
    "data = df[df['Ten-year'] != 'ND'].astype('float')\n",
    "ldate = dtxt(data.index[-1])['day1']\n",
    "spread = pd.DataFrame()\n",
    "spread['Ten-3M'] = data['Ten-year'] - data['Three-month']\n",
    "spread['Ten-2Y'] = data['Ten-year'] - data['Two-year']\n",
    "spread.loc['2017':].to_csv(data_dir / 'spread.csv', index_label='date', \n",
    "                           float_format='%g', header=True)\n",
    "\n",
    "col103 = 'blue!70!cyan!80!white'\n",
    "col102 = 'red!60!violet!90!white'\n",
    "\n",
    "node = end_node(spread['Ten-3M'], col103, digits=2, date='d', full_year=True)\n",
    "write_txt(text_dir / 'spread_node.txt', node)\n",
    "\n",
    "node = end_node(spread['Ten-2Y'], col102, digits=2, date='d', full_year=True)\n",
    "write_txt(text_dir / 'spread_node2.txt', node)\n",
    "\n",
    "lt = spread.iloc[-1]\n",
    "pr = spread.iloc[-252]\n",
    "d = {}\n",
    "for s in ['Ten-3M', 'Ten-2Y']:\n",
    "    d[f'lt_{s[4]}'] = value_text(lt[s], 'plain', 'pp', digits=2)\n",
    "    d[f'pr_{s[4]}'] = value_text(pr[s], 'plain', 'pp', digits=2)    \n",
    "    \n",
    "text = (f'As of {ldate}, the spread between a 10-year treasury bond and '+\n",
    "        f'a three-month treasury bill is {d[\"lt_3\"]} {c_line(col103)}, compared '+\n",
    "        f'to {d[\"pr_3\"]} one year prior. The spread between 10-year and '+\n",
    "        f'2-year treasuries {c_line(col102)} is {d[\"lt_2\"]} on {ldate}, and '+\n",
    "        f'{d[\"pr_2\"]} one year prior.')\n",
    "write_txt(text_dir / 'spread_basic.txt', text)\n",
    "print(text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:36.439912Z",
     "start_time": "2023-11-20T22:26:36.434502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since 1989, the US has entered into four recessions and the 10-year to 2-year segment of the yield curve has newly inverted six times. The most recent such inversion started on April 1, 2022.\n"
     ]
    }
   ],
   "source": [
    "sp = spread.loc[(spread['Ten-2Y'] < 0) & \n",
    "                (spread['Ten-2Y'].shift().rolling(252).min() >= 0), \n",
    "                'Ten-2Y']\n",
    "num_ic = len(sp) + 1 # Add one for 1989\n",
    "tnum_ic = numbers[f'{num_ic:.1f}']\n",
    "icdt = dtxt(sp.index[-1])['day1']\n",
    "\n",
    "#rec = fred_df('USREC')\n",
    "#num_rec = len(rec[(rec.VALUE==1) & (rec.VALUE.shift(1) == 0)])\n",
    "#tnum_rec = numbers[f'{num_rec:.1f}']\n",
    "tnum_rec = 'four'\n",
    "text = (f'Since 1989, the US has entered into {tnum_rec} '+\n",
    "        'recessions and the 10-year to 2-year segment of '+\n",
    "        f'the yield curve has newly inverted {tnum_ic} times. '+\n",
    "        f'The most recent such inversion started on {icdt}.')\n",
    "write_txt(text_dir / 'yc_inversion.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gold Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:43.089921Z",
     "start_time": "2023-11-20T22:26:36.441247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest Data: November 17, 2023\n"
     ]
    }
   ],
   "source": [
    "date = dtxt(pd.to_datetime('today'))['datetime']\n",
    "url = ('https://prices.lbma.org.uk/export/xls/?c={\"metals\":[\"gold\"],'+\n",
    "       '\"type\":\"daily\",\"currency\":[\"usd\"],\"published\":[\"am\"],'+\n",
    "       f'\"dates\":{{\"start\":\"1989-01-01\",\"end\":\"{date}\"}}}}')\n",
    "data = pd.read_excel(url, header=1, index_col=0, \n",
    "                     parse_dates=True).sort_index()\n",
    "print('Latest Data:', dtxt(data.index[-1])['day1'])\n",
    "data.to_csv(data_dir / 'gold_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:43.112564Z",
     "start_time": "2023-11-20T22:26:43.091600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 17, 2023, one troy ounce of \\textbf{gold} \\href{https://www.lbma.org.uk/prices-and-data/precious-metal-prices#/table}{sells} for \\$1,992.15 (see {\\color{orange!40!yellow}\\textbf{---}}), compared to an average of \\$1,725.40 one year prior. Following the great recession, the monthly average price of gold reached \\$1,780.65 per ounce, in September 2011. In April 2023, the average monthly price reached \\$1,998.84 per ounce.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir / 'gold_raw.csv', index_col='date', \n",
    "                   parse_dates=True)\n",
    "df = data.resample('MS').mean().iloc[:-1]\n",
    "df.index = df.index + pd.DateOffset(days=14)\n",
    "lt = data.iloc[-1]\n",
    "df = pd.concat([df, lt.to_frame().T])\n",
    "df.to_csv(data_dir / 'gold.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['day1']\n",
    "ltval = df.AM.iloc[-1]\n",
    "prdate = dtxt(df.index[-13])['mon1']\n",
    "prval = df.AM.iloc[-13]\n",
    "grdate = dtxt(df.loc['2006':'2011', 'AM'].idxmax())['mon1']\n",
    "grval = df.loc['2006':'2011', 'AM'].max()\n",
    "\n",
    "color = 'orange!40!yellow'\n",
    "node = end_node(df.AM, color, dollar=True, digits='comma', date='d', \n",
    "                offset=-0.35, full_year=True)\n",
    "write_txt(text_dir / 'gold_node.txt', node)\n",
    "\n",
    "url = 'https://www.lbma.org.uk/prices-and-data/precious-metal-prices#/table'\n",
    "maxdt = df.AM.idxmax()\n",
    "maxdtt = dtxt(maxdt)['mon1']\n",
    "maxval = df.AM.max()\n",
    "text = (f'As of {ltdate}, one troy ounce of \\\\textbf{{gold}} '+\n",
    "        f'\\href{{{url}}}{{sells}} for \\${ltval:,.2f} {c_line(color)}, '\n",
    "        f'compared to an average of \\${prval:,.2f} one '+\n",
    "        f'year prior. Following the great recession, '+\n",
    "        f'the monthly average price of gold reached \\${grval:,.2f} '+\n",
    "        f'per ounce, in {grdate}. In {maxdtt}, the average monthly '+\n",
    "        f'price reached \\${maxval:,.2f} per ounce.')\n",
    "print(text)\n",
    "write_txt(text_dir / 'gold.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:50.103764Z",
     "start_time": "2023-11-20T22:26:43.113940Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.federalreserve.gov/datadownload/Output.aspx?'+\n",
    "       'rel=H10&series=8dea680ff61ef97f0aefa5b17d760d87&lastobs=&'+\n",
    "       'from=01/01/2015&to=12/31/2023&filetype=csv&label=include&'+\n",
    "       'layout=seriescolumn')\n",
    "d, clean_data = clean_fed_data(url)\n",
    "clean_data.to_csv(data_dir / 'fx_raw_st.csv', index_label='date')\n",
    "\n",
    "url2 = ('https://www.federalreserve.gov/datadownload/Output.aspx?'+\n",
    "        'rel=H10&series=3b4f0209725fa1526861cfa9eeea0473&lastobs=&'+\n",
    "        'from=01/01/1989&to=12/31/2023&filetype=csv&label=include&'+\n",
    "        'layout=seriescolumn')\n",
    "d, clean_data = clean_fed_data(url2)\n",
    "clean_data.to_csv(data_dir / 'fx_raw_lt.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:50.153269Z",
     "start_time": "2023-11-20T22:26:50.105364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fed separately calculates the trade-weighted exchange rate with \\textbf{advanced economies}, and with \\textbf{emerging markets}. Since 2006, the dollar has increased 27.8 percent against emerging market currencies (see {\\color{green!75!yellow!90!black}\\textbf{---}}), and increased 16.6 percent against advanced economy currencies (see {\\color{violet!90!blue}\\textbf{---}}).  \n",
      "\n",
      "As of November 17, 2023, the broad dollar index is 21.3 percent above its value at inception in 2006. Over the past three years, the index value has averaged 117.7, compared to an average of 114.9 over the previous three-years. \n",
      "\n",
      "As of November 17, 2023, one US dollar buys approximately: 1.37 Canadian dollars (see {\\color{green!85!blue}\\textbf{---}}), 150 Japanese yen (see {\\color{red}\\textbf{---}}), 0.92 euros (see {\\color{cyan!90!white}\\textbf{---}}), and 0.80 British pounds (see {\\color{blue!90!cyan}\\textbf{---}}). Over the past three years, the nominal exchange rate between the US dollar and the Canadian dollar increased three percent, the USD-JPY rate increased 7.3 percent, the USD-EUR rate decreased 4.4 percent, and the USD-GBP rate decreased 4.4 percent.\n"
     ]
    }
   ],
   "source": [
    "clean_data = pd.read_csv(data_dir / 'fx_raw_lt.csv', index_col='date', \n",
    "                         parse_dates=True)\n",
    "for cc in ['EU', 'UK']:\n",
    "    clean_data[f'RXI_N.B.{cc}'] = 1 / clean_data[f'RXI$US_N.B.{cc}'] \n",
    "clean_data['RXI_N.B.JA'] = clean_data['RXI_N.B.JA'] / 100.0\n",
    "latest = clean_data.dropna(how='all').iloc[-1]\n",
    "major = ['RXI_N.B.EU', 'RXI_N.B.UK', 'RXI_N.B.CA', 'RXI_N.B.JA']\n",
    "indx = ['JRXWTFB_N.B', 'JRXWTFN_N.B', 'JRXWTFO_N.B']\n",
    "prmo = clean_data.resample('MS').mean().iloc[:-1]\n",
    "lt = latest.to_frame().T\n",
    "avglt = pd.concat([prmo, lt])\n",
    "twidx = avglt[indx].dropna()\n",
    "node = end_node(twidx['JRXWTFB_N.B'], 'blue!60!black', date='ds')\n",
    "write_txt(text_dir / 'twd_node.txt', node)\n",
    "adj = node_adj(twidx)\n",
    "smax = twidx.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.25\n",
    "\n",
    "cols = {'JRXWTFN_N.B': 'violet!90!blue', \n",
    "        'JRXWTFO_N.B': 'green!75!yellow!90!black'}\n",
    "date = {series: 'ds' if series == smax else None \n",
    "        for series in cols.keys()}\n",
    "nodes  ='\\n'.join([end_node(twidx[series], color, \n",
    "                            date=date[series], \n",
    "                            full_year=True, \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in cols.items()])\n",
    "write_txt(text_dir / 'twd_nodes.txt', nodes) \n",
    "twidx.to_csv(data_dir / 'fx_idx.csv', index_label='date', \n",
    "             float_format='%g', header=True)\n",
    "\n",
    "# Advanced and emerging markets index txt\n",
    "ltadv = value_text(latest['JRXWTFN_N.B'] - 100)\n",
    "ltem = value_text(latest['JRXWTFO_N.B'] - 100)\n",
    "text = ('The Fed separately calculates the trade-weighted exchange '+\n",
    "        'rate with \\\\textbf{advanced economies}, and with '+\n",
    "        '\\\\textbf{emerging markets}. Since 2006, the dollar has '+\n",
    "        f'{ltem} against emerging market currencies '+\n",
    "        f'{c_line(cols[\"JRXWTFO_N.B\"])}, and {ltadv} against advanced '+\n",
    "        f'economy currencies {c_line(cols[\"JRXWTFN_N.B\"])}. ')\n",
    "write_txt(text_dir / 'twd_adv_em.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "(avglt[major].to_csv(data_dir / 'fx1.csv', index_label='date', \n",
    "                   float_format='%g'))\n",
    "\n",
    "df = clean_data[major].dropna(how='all')\n",
    "df.columns = [i[-2:] for i in df.columns]\n",
    "adj = node_adj(df)\n",
    "smax = df.iloc[-1].idxmax()\n",
    "if pd.Series(node_adj(df)).idxmax() != df.iloc[-1].idxmax():\n",
    "    smax = pd.Series(node_adj(df)).idxmax()\n",
    "adj[smax] = adj[smax] + 0.15\n",
    "\n",
    "cols = {'CA': 'green!85!blue', 'JA': 'red', 'EU': \n",
    "        'cyan!90!white', 'UK': 'blue!90!cyan'}\n",
    "date = {series: 'ds' if series == smax else None \n",
    "        for series in cols.keys()}\n",
    "nodes  ='\\n'.join([end_node(df[series], color, date=date[series], \n",
    "                            full_year=True, digits=2,\n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in cols.items()])\n",
    "write_txt(text_dir / 'fx_nodes.txt', nodes) \n",
    "\n",
    "# Broad dollar index text\n",
    "ldate = dtxt(twidx.index[-1])['day1']\n",
    "lval = twidx['JRXWTFB_N.B'].iloc[-1]\n",
    "totch = ((lval / 100) - 1) * 100\n",
    "threeyr = twidx['JRXWTFB_N.B'].iloc[-38:].mean()\n",
    "prev3yr = twidx['JRXWTFB_N.B'].iloc[-74:-38].mean()\n",
    "text = (f'As of {ldate}, the broad dollar index is {totch:.1f} '+\n",
    "        'percent above its value at inception in '+\n",
    "        f'2006. Over the past three years, the index value has '+\n",
    "        f'averaged {threeyr:.1f}, compared to an average of '+\n",
    "        f'{prev3yr:.1f} over the previous three-years.')\n",
    "write_txt(text_dir / 'twdbasic.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "cl = {name: c_line(col) for name, col in cols.items()}\n",
    "lt = clean_data.loc[ldate]\n",
    "ltd = {name: lt[f'RXI_N.B.{name}'] for name in cols.keys()}\n",
    "pc = clean_data.pct_change(262).iloc[-1] * 100\n",
    "pcd = {name: value_text(pc[f'RXI_N.B.{name}'], threshold=0.1) \n",
    "       for name in cols.keys()}\n",
    "text = (f'As of {ldate}, one US dollar buys approximately: '+\n",
    "        f'{ltd[\"CA\"]:.2f} Canadian dollars {cl[\"CA\"]}, '+\n",
    "        f'{ltd[\"JA\"] * 100:.0f} Japanese yen {cl[\"JA\"]}, '+\n",
    "        f'{ltd[\"EU\"]:.2f} euros {cl[\"EU\"]}, and {ltd[\"UK\"]:.2f} '+\n",
    "        f'British pounds {cl[\"UK\"]}. Over the past three years, '+\n",
    "        f'the nominal exchange rate between the US dollar and '+\n",
    "        f'the Canadian dollar {pcd[\"CA\"]}, the USD-JPY rate '+\n",
    "        f'{pcd[\"JA\"]}, the USD-EUR rate {pcd[\"EU\"]}, and the '+\n",
    "        f'USD-GBP rate {pcd[\"UK\"]}.')\n",
    "write_txt(text_dir / 'selcurr_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange Rates Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:50.181631Z",
     "start_time": "2023-11-20T22:26:50.154771Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_data = pd.read_csv(data_dir / 'fx_raw_st.csv', index_col='date', \n",
    "                         parse_dates=True)\n",
    "for cc in ['EU', 'UK', 'AL', 'NZ']:\n",
    "    clean_data[f'RXI_N.B.{cc}'] = 1 / clean_data[f'RXI$US_N.B.{cc}'] \n",
    "\n",
    "fx = {'RXI_N.B.EU': 'EUR',\n",
    "      'RXI_N.B.UK': 'GBP',\n",
    "      'RXI_N.B.JA': 'JPY',\n",
    "      'RXI_N.B.CA': 'CAD',\n",
    "      'RXI_N.B.MX': 'MXN',\n",
    "      'RXI_N.B.CH': 'CNY',\n",
    "      'RXI_N.B.SZ': 'CHF',\n",
    "      'RXI_N.B.HK': 'HKD',\n",
    "      'RXI_N.B.IN': 'INR',\n",
    "      'RXI_N.B.AL': 'AUD',\n",
    "      'RXI_N.B.NZ': 'NZD',\n",
    "      'RXI_N.B.BZ': 'BRL',\n",
    "      'RXI_N.B.KO': 'KRW',\n",
    "      'RXI_N.B.MA': 'MYR',\n",
    "      'RXI_N.B.DN': 'DKK',\n",
    "      'RXI_N.B.NO': 'NOK',\n",
    "      'RXI_N.B.SD': 'SEK',\n",
    "      'RXI_N.B.SF': 'ZAR',\n",
    "      'RXI_N.B.SI': 'SGD',\n",
    "      'RXI_N.B.TA': 'TWD'}\n",
    "\n",
    "tbl_data = clean_data[fx.keys()].dropna(how='all')\n",
    "tbl_data.columns = fx.values()\n",
    "#tbl_data.loc[:,'JPY'] *= 100\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table[dtxt(tbl_data.index[-1])['day2']] = tbl_data.iloc[-1]\n",
    "table['1-month moving average'] = tbl_data.iloc[-22:].mean()\n",
    "table['1-year moving average'] = tbl_data.iloc[-262:].mean()\n",
    "table['2019 average'] = tbl_data.loc['2019'].mean()\n",
    "dec1 = ['JPY', 'KRW']\n",
    "table.loc[['JPY', 'KRW'],:] = table.loc[['JPY', 'KRW'],:].applymap(\"{0:.1f}\".format)\n",
    "dec3 = ['GBP', 'EUR', 'CHF', 'AUD', 'NZD', 'CAD', 'SGD']\n",
    "table.loc[dec3,:] = table.loc[dec3,:].applymap(\"{0:.3f}\".format)\n",
    "table.loc[~table.index.isin(dec3+dec1)] = (table.loc[~table.index.isin(dec3+dec1)]\n",
    "                                           .applymap(\"{0:.2f}\".format))\n",
    "table['1-month percent change'] = (tbl_data.pct_change(22)\n",
    "                                   * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "table['1-year percent change'] = (tbl_data.pct_change(262)\n",
    "                                  * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "table['5-year percent change'] = (tbl_data.pct_change(262*5)\n",
    "                                  * 100).iloc[-1].apply(\"{0:.1f}\".format)\n",
    "\n",
    "table.index = [f'\\includegraphics[width=.03\\\\textwidth]{{data/flags/{cc}}} \\ {cc}' \n",
    "               for cc in table.index]\n",
    "\n",
    "(table.to_csv(data_dir / 'fx_table.tex', sep='&', \n",
    "              lineterminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobless claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:52.534792Z",
     "start_time": "2023-11-20T22:26:50.183179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "November 11, 2023\n"
     ]
    }
   ],
   "source": [
    "# retrieve data from FRED and save\n",
    "df = pd.DataFrame()\n",
    "for s in ['icsa', 'icnsa', 'ccsa', 'ccnsa']:\n",
    "    df[s] = fred_df(s.upper(), start='1989')\n",
    "df.to_csv(data_dir / f'jobless_claims_raw.csv', index_label='date', \n",
    "          float_format='%g')\n",
    "print(dtxt(df.index[-1])['day1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonally adjusted jobless claims (recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:52.559395Z",
     "start_time": "2023-11-20T22:26:52.536734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the week ending November 11, 2023, seasonally-adjusted initial claims for UI total 231,000 (see {\\color{orange!80!yellow}\\textbf{---}}), an increase of 13,000 from the previous week. Initial claims average 220,200 per week over the past four weeks, 225,300 per week over the past year, and 217,500 per week during 2019.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir / 'jobless_claims_raw.csv', index_col='date', \n",
    "                         parse_dates=True)\n",
    "data['1M'] = data['icsa'].rolling(4).mean()\n",
    "data['V12M'] = data['icsa'].rolling(52).mean()\n",
    "# past two years\n",
    "cut = -118\n",
    "# Store subset of data for chart\n",
    "(data['icsa'].iloc[cut:].divide(1_000)\n",
    "             .to_csv(data_dir / 'icsa.csv', index_label='date', \n",
    "                     float_format='%g'))\n",
    "\n",
    "# blank dataframe to generate x axis labels\n",
    "dm = data.iloc[cut:].resample('MS').mean().divide(1000)\n",
    "dm['label'] = [dt.strftime('%b\\\\\\%Y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') if dt.month in [4, 7, 10]\n",
    "                 else '' for dt in dm.index]\n",
    "# Extra monthly series used to create ticks in latex\n",
    "dm[['icsa', 'label']].to_csv(data_dir / 'icsa_mon.csv', index_label='date', \n",
    "                      float_format='%g')\n",
    "\n",
    "# End node\n",
    "color = 'orange!80!yellow'\n",
    "node = end_node(data.icsa / 1000, color, date='ds', offset=0.25, \n",
    "                full_year=True)\n",
    "write_txt(text_dir / 'icsa_node.txt', node)\n",
    "\n",
    "# Text for recent seasonally adjusted initial claims\n",
    "ltdt = dtxt(data.index[-1])['day1']\n",
    "ltval = f'{data.icsa.iloc[-1]:,.0f}'\n",
    "chwk = value_text(data.icsa.diff().iloc[-1], style='increase_of', \n",
    "                  ptype=None, digits=0, threshold=10000)\n",
    "lt1m = f'{round(data[\"1M\"].iloc[-1], -2):,.0f}'\n",
    "lt12m = f'{round(data[\"V12M\"].iloc[-1], -2):,.0f}'\n",
    "prval = f'{round(data.loc[\"2019\", \"icsa\"].mean(), -2):,.0f}'\n",
    "\n",
    "text = (f'In the week ending {ltdt}, seasonally-adjusted '+\n",
    "        f'initial claims for UI total {ltval} {c_line(color)}, '+\n",
    "        f'{chwk} from the previous week. Initial claims average '+\n",
    "        f'{lt1m} per week over the past four weeks, '+\n",
    "        f'{lt12m} per week over the past year, and {prval} '+\n",
    "        'per week during 2019.')\n",
    "write_txt(text_dir / 'icsa.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:52.582729Z",
     "start_time": "2023-11-20T22:26:52.561071Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the week ending November 4, 2023, seasonally-adjusted insured unemployment totals 1,865,000 (see {\\color{green!75!black}\\textbf{---}}), an increase of 32,000 from the previous week. These continued claims average 1,823,200 over the past four weeks, 1,720,900  over the past year, and 1,698,500 during 2019.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir / 'jobless_claims_raw.csv', index_col='date', \n",
    "                         parse_dates=True)[['ccsa', 'ccnsa']].dropna()\n",
    "data['1M'] = data['ccsa'].rolling(4).mean()\n",
    "data['V12M'] = data['ccsa'].rolling(52).mean()\n",
    "# past two years\n",
    "cut = -117\n",
    "# Store subset of data for chart\n",
    "(data['ccsa'].iloc[cut:].divide(1_000)\n",
    "             .to_csv(data_dir / 'ccsa.csv', index_label='date', \n",
    "                     float_format='%g'))\n",
    "\n",
    "# blank dataframe to generate x axis labels\n",
    "dm = data.iloc[cut:].resample('MS').mean().divide(1000)\n",
    "dm['label'] = [dt.strftime('%b\\\\\\%Y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') if dt.month in [4, 7, 10]\n",
    "                 else '' for dt in dm.index]\n",
    "# Extra monthly series used to create ticks in latex\n",
    "dm[['ccsa', 'label']].to_csv(data_dir / 'ccsa_mon.csv', index_label='date', \n",
    "                      float_format='%g')\n",
    "\n",
    "# End node\n",
    "color = 'green!75!black'\n",
    "node = end_node(data.ccsa / 1000, color, date='ds', offset=0.1, \n",
    "                full_year=True, digits='comma')\n",
    "write_txt(text_dir / 'ccsa_node.txt', node)\n",
    "\n",
    "# Text for recent seasonally adjusted initial claims\n",
    "ltdt = dtxt(data.index[-1])['day1']\n",
    "ltval = f'{data.ccsa.iloc[-1]:,.0f}'\n",
    "chwk = value_text(data.ccsa.diff().iloc[-1], style='increase_of', \n",
    "                  ptype=None, digits=0, threshold=10000)\n",
    "lt1m = f'{round(data[\"1M\"].iloc[-1], -2):,.0f}'\n",
    "lt12m = f'{round(data[\"V12M\"].iloc[-1], -2):,.0f}'\n",
    "prval = f'{round(data.loc[\"2019\", \"ccsa\"].mean(), -2):,.0f}'\n",
    "\n",
    "text = (f'During the week ending {ltdt}, seasonally-adjusted '+\n",
    "        f'insured unemployment totals {ltval} {c_line(color)}, '+\n",
    "        f'{chwk} from the previous week. These continued claims '+\n",
    "        f'average {lt1m} over the past four weeks, '+\n",
    "        f'{lt12m}  over the past year, and {prval} '+\n",
    "        'during 2019.')\n",
    "write_txt(text_dir / 'ccsa.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:52.591825Z",
     "start_time": "2023-11-20T22:26:52.584014Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UI only covers some workers. In October 2023, the Bureau of Labor Statistics classify 6.5 million people as unemployed, and identify another 5.0 million who want a job but do not count as unemployed.\n"
     ]
    }
   ],
   "source": [
    "# Additional context on total UI numbers\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', index_col='date', \n",
    "                 parse_dates=True)[['Level', 'WantJob']] / 1000)\n",
    "un = df.Level.iloc[-1]\n",
    "wj = df.WantJob.iloc[-1]\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "\n",
    "text = (f'UI only covers some workers. In {ltdt}, the Bureau of '+\n",
    "        f'Labor Statistics classify {un:.1f} million people as '+\n",
    "        f'unemployed, and identify another {wj:.1f} million who want '+\n",
    "        \"a job but do not count as unemployed.\")\n",
    "write_txt(text_dir / 'ccsa_alt.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:52.622884Z",
     "start_time": "2023-11-20T22:26:52.595016Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir / 'jobless_claims_raw.csv', index_col='date', \n",
    "                         parse_dates=True) / 1000\n",
    "\n",
    "n = {'icsa': 'Initial Claims (SA)',\n",
    "     'icnsa': 'Initial Claims (NSA)',\n",
    "     'ccsa': 'Continued Claims (SA)',\n",
    "     'ccnsa': 'Continued Claims (NSA)'}\n",
    "\n",
    "table = pd.DataFrame()\n",
    "\n",
    "for i in [-1, -2, -3]:\n",
    "    table[dtxt(data.index[i])['day2']] = data.iloc[i]\n",
    "    \n",
    "# Monthly average columns\n",
    "currmo, curryr = data.index[-1].month, data.index[-1].year\n",
    "\n",
    "# Get prior month, two months prior, and prior year\n",
    "pmmon = currmo - 1 if currmo > 1 else 12\n",
    "pmyr = curryr if currmo > 1 else curryr - 1\n",
    "pm2mon = currmo - 2 if currmo > 2 else (12 - (2 - currmo))\n",
    "pm2yr = curryr if currmo > 2 else curryr - 1\n",
    "pyyr = curryr - 1\n",
    "py2yr = curryr - 2\n",
    "\n",
    "for mon, yr in [(pmmon, pmyr), (pm2mon, pm2yr), \n",
    "                (currmo, pyyr), (currmo, py2yr)]:\n",
    "    dt = f'{yr}-{mon:02}-01'\n",
    "    table[dtxt(dt)['mon2']] = data.resample('MS').mean().loc[dt]\n",
    "\n",
    "table = table.rename(n).applymap('{:,.0f}'.format).replace('nan', '--')\n",
    "(table.to_csv(data_dir / 'jobless_claims.tex', sep='&', \n",
    "           lineterminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIX (SP500 volatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:52.905958Z",
     "start_time": "2023-11-20T22:26:52.624410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When investors are uncertain about the future, they will pay a premium for the insurance-like qualities of options. The CBOE volatility index, popularly known as the VIX, captures overall changes in options prices to identify the market-implied volatility in the S\\&P 500 index over the following 30 days.\n",
      "\n",
      "The latest value for the VIX is 13.8 on November 17, 2023 (see {\\color{violet}\\textbf{---}}), slightly below the average index value of 21.1 over the past three years, and slightly below the typical index value of 17.8 since 1990. The VIX decreased by 0.4 point over the past week.\n"
     ]
    }
   ],
   "source": [
    "VIX = ('https://cdn.cboe.com/api/global/us_indices/daily_prices/'+\n",
    "       'VIX_History.csv')\n",
    "curr = pd.read_csv(VIX, index_col='DATE', parse_dates=True)\n",
    "prmo = curr.resample('MS').mean().iloc[:-1]\n",
    "prmo.index = prmo.index + pd.DateOffset(days=14)\n",
    "df = pd.concat([prmo, curr.iloc[-1].to_frame().T]).CLOSE\n",
    "df.to_csv(data_dir / 'vix.csv', index_label='date', header='True')\n",
    "color = 'violet'\n",
    "node = end_node(df, color, date='d', offset=0.35, full_year=True)\n",
    "write_txt(text_dir / 'vix_node.txt', node)\n",
    "\n",
    "ldate = dtxt(df.index[-1])['day1']\n",
    "vallt = df.iloc[-1]\n",
    "val3y = df.iloc[-37:].mean()\n",
    "valmed = curr.CLOSE.median()\n",
    "\n",
    "compare = compare_text(vallt, val3y, [3, 12, 30])\n",
    "comp2 = compare_text(vallt, valmed, [3, 12, 30])\n",
    "\n",
    "one_wk = (value_text(curr.CLOSE.diff(5).iloc[-1], \n",
    "                     style='increase_by', ptype='pp')\n",
    "          .replace('percentage ', ''))\n",
    "\n",
    "text = ('When investors are uncertain about the future, they will pay a '+\n",
    "        'premium for the insurance-like qualities of options. The CBOE '+\n",
    "        'volatility index, popularly known as the VIX, captures overall '+\n",
    "        'changes in options prices to identify the market-implied volatility '+\n",
    "        'in the S\\&P 500 index over the following 30 days.\\n\\n'+\n",
    "        f'The latest value for the VIX is {vallt:.1f} on {ldate} '+\n",
    "        f'{c_line(color)}, {compare} the average index value of {val3y:.1f} '+\n",
    "        f'over the past three years, and {comp2} the typical index value of '+\n",
    "        f'{valmed:.1f} since 1990. The VIX {one_wk} over the past week.')\n",
    "write_txt(text_dir / 'vixbasic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inflation Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:54.203293Z",
     "start_time": "2023-11-20T22:26:52.907348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 20, 2023, markets expect an average inflation rate of 2.3 percent over the next five years (see {\\color{blue!70!black}\\textbf{---}}), compared to an expected rate of 2.3 percent on November 18, 2022. Markets had expected inflation to average 1.9 percent per year over the past five years, five years ago.\n",
      "Over this five-year period, markets suggest 2.3 percent inflation per year, as of November 20, 2023. Inflation rates in the near-term are therefore expected to fall below inflation rates in the longer-term.\n"
     ]
    }
   ],
   "source": [
    "data1 = fred_df('T5YIE').loc['2017':,'VALUE']\n",
    "data1.to_csv(data_dir / 'infbreak.csv', index_label='date', \n",
    "             header=True)\n",
    "data2 = fred_df('T5YIFR').loc['2017':,'VALUE']\n",
    "df = pd.DataFrame({'5_year_breakeven': data1, \n",
    "                   '5_year_5_year_forward': data2})\n",
    "df.to_csv(data_dir / 'infbreak_comb.csv', index_label='date')\n",
    "\n",
    "color = 'blue!70!black'\n",
    "\n",
    "node = end_node(data1, color)\n",
    "write_txt(text_dir / 'infbreak_node.txt', node)\n",
    "\n",
    "ldatem = dtxt(data1.index[-1])['day1']\n",
    "lvalm = data1.iloc[-1]\n",
    "pdatem = dtxt(data1.dropna().index[-252])['day1']\n",
    "pvalm = data1.dropna().iloc[-252]\n",
    "p5valm = data1.dropna().iloc[-(252*5)]\n",
    "\n",
    "text = (f'As of {ldatem}, markets expect an average inflation '+\n",
    "        f'rate of {lvalm:.1f} percent over the next five ' + \n",
    "        f'years {c_line(color)}, compared to an expected rate '+\n",
    "        f'of {pvalm:.1f} percent on {pdatem}. Markets had expected '+\n",
    "        f'inflation to average {p5valm:.1f} percent per year over '+\n",
    "        f'the past five years, five years ago.')\n",
    "write_txt(text_dir / 'inf_exp_mkts.txt', text)\n",
    "print(text)\n",
    "\n",
    "p55val = data2.iloc[-1]\n",
    "if data2.iloc[-1] + 0.1 > data1.iloc[-1]:\n",
    "    compare = 'fall below '\n",
    "elif data2.iloc[-1] - 0.1 < data1.iloc[-1]:\n",
    "    compare = 'exceed '\n",
    "else:\n",
    "    compare = 'maintain the same rate as '\n",
    "text = (f'Over this five-year period, markets suggest {p55val:.1f} '+\n",
    "        f'percent inflation per year, as of {ldatem}. Inflation '+\n",
    "        'rates in the near-term are therefore expected to '+\n",
    "        f'{compare}inflation rates in the longer-term.')\n",
    "write_txt(text_dir / 'inf_exp_mkts_55.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleveland Fed Inflation nowcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:54.741940Z",
     "start_time": "2023-11-20T22:26:54.205170Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve latest nowcast\n",
    "url = 'https://www.clevelandfed.org/indicators-and-data/inflation-nowcasting'\n",
    "df = pd.read_html(url)[0].iloc[:-1] # Switch to two after new month starts\n",
    "df.index = pd.to_datetime(df.Month)\n",
    "df.index.name = 'date'\n",
    "df.to_csv(data_dir / 'FRBC_inflation_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:54.756591Z",
     "start_time": "2023-11-20T22:26:54.743373Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPI Nowcast added to cpi\n",
    "df = pd.read_csv(data_dir / 'FRBC_inflation_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "dfc = 1 + (df['CPI'].dropna().sort_index() / 100)\n",
    "\n",
    "# Find next month from CPI data\n",
    "cpi = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                  index_col='date', parse_dates=True)['All items (SA)']\n",
    "\n",
    "nextmo = cpi.index[-1] + pd.DateOffset(months=1)\n",
    "nextmo2 = cpi.index[-1] + pd.DateOffset(months=2)\n",
    "cpi.loc[nextmo] = cpi.iloc[-1] * dfc.loc[nextmo]\n",
    "if nextmo2 in dfc.index:\n",
    "    cpi.loc[nextmo2] = cpi.iloc[-1] * dfc.loc[nextmo2]\n",
    "cpi.to_csv(data_dir / 'cpinow.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:54.772478Z",
     "start_time": "2023-11-20T22:26:54.757827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 20, the November 2023 nowcast is 0.1 percent (see \\tikz \\draw[black, fill=blue!90!black] (2.5pt,2.5pt) circle (2.5pt);).\n"
     ]
    }
   ],
   "source": [
    "# CPI Missing Month\n",
    "df = pd.read_csv(data_dir / 'FRBC_inflation_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "\n",
    "# Find next month from CPI data\n",
    "cpilt = (pd.read_csv(data_dir / 'cpi.csv', \n",
    "                     index_col='date', parse_dates=True)\n",
    "           .index[-1] + pd.DateOffset(months=1))\n",
    "dft = df.loc[cpilt]\n",
    "nowmo = dtxt(cpilt)['mon1']\n",
    "nowcast = f'{df.loc[cpilt, \"CPI\"]:.1f}'\n",
    "\n",
    "# Node in CPI monthly chart\n",
    "mark = ' (see \\\\tikz \\draw[black, fill=blue!90!black] (2.5pt,2.5pt) circle (2.5pt);)'\n",
    "node = (f'\\\\node[label={{[align=left]90:{{\\scriptsize \\\\textit{{{nowcast}}}}}}}, '+\n",
    "            'circle, draw=black, fill=blue!90!black, inner sep=1.6pt] at '+\n",
    "            f'(axis cs:{cpilt}, {nowcast}) {{}};')\n",
    "write_txt(text_dir / 'cpinow_node.txt', node)\n",
    "# Version for summary chart\n",
    "node = (f'\\\\node[label={{[align=left]90:{{\\scriptsize \\ \\ \\\\textit{{{nowcast}}}}}}}, '+\n",
    "            'circle, draw=black, fill=blue!90!black, inner sep=1.6pt] at '+\n",
    "            f'(axis cs:{cpilt}, {nowcast}) {{}};')\n",
    "write_txt(text_dir / 'cpinow_node2.txt', node)\n",
    "\n",
    "update = dtxt(f'{dft.Updated}/{dft.Month[-4:]}')['day4']\n",
    "text = (f'As of {update}, the {nowmo} nowcast '+\n",
    "        f'is {nowcast} percent{mark}.')\n",
    "write_txt(text_dir / 'cpinow.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:55.032084Z",
     "start_time": "2023-11-20T22:26:54.773687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve latest quarterly PCE inflation nowcast\n",
    "url = 'https://www.clevelandfed.org/indicators-and-data/inflation-nowcasting'\n",
    "df = pd.read_html(url)[2]\n",
    "\n",
    "pce = df.set_index('Quarter')['PCE'].iloc[0]\n",
    "dt = pd.to_datetime(df.set_index('Quarter')['PCE'].index[0].replace(':', '-'))\n",
    "res = pd.Series({'date': dt, 'pce': float(pce)})\n",
    "res.to_frame().T.set_index('date').to_csv(data_dir / 'pce_now.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T21:23:52.854402Z",
     "start_time": "2022-03-12T21:23:52.849021Z"
    }
   },
   "source": [
    "### High Yield Corporate Bond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:55.657224Z",
     "start_time": "2023-11-20T22:26:55.034407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of November 17, 2023, the effective yield for \\textbf{high-yield corporate bonds} in the index is 8.6 percent (see {\\color{red!50!purple}\\textbf{---}}). In September 2023, the average effective yield was 8.5 percent. Prior to the COVID-19 pandemic, in 2019, the average effective yield was 6.1 percent. \n"
     ]
    }
   ],
   "source": [
    "df = fred_df('BAMLH0A0HYM2EY')\n",
    "prmo = df.resample('MS').mean().iloc[:-1]\n",
    "prmo.index = prmo.index + pd.DateOffset(days=14)\n",
    "lt = df.iloc[-1].to_frame().T\n",
    "data = pd.concat([prmo, lt])\n",
    "data = data[~data.index.duplicated(keep='last')]\n",
    "data.to_csv(data_dir / 'highyield.csv', index_label='date')\n",
    "color = 'red!50!purple'\n",
    "\n",
    "node = end_node(data['VALUE'], color, date='d', full_year=True)\n",
    "write_txt(text_dir / 'highyield_node.txt', node)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['day1']\n",
    "ltval = data.VALUE.iloc[-1]\n",
    "mm = -2 if df.index[-1].is_month_start == True else -3\n",
    "prmoval = data.VALUE.iloc[mm]\n",
    "prmo = dtxt(data.index[mm])['mon1']\n",
    "val19 = data.loc['2019', 'VALUE'].mean()\n",
    "\n",
    "text = (f'As of {ltdt}, the effective yield for \\\\textbf{{high-yield '+\n",
    "        f'corporate bonds}} in the index is {ltval:.1f} percent '+\n",
    "        f'{c_line(color)}. In {prmo}, the average effective yield was '+\n",
    "        f'{prmoval:.1f} percent. Prior to the COVID-19 pandemic, '+\n",
    "        f'in 2019, the average effective yield was {val19:.1f} '+\n",
    "        'percent. ')\n",
    "write_txt(text_dir / 'highyield.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporate Bonds Total Returns Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:55.661698Z",
     "start_time": "2023-11-20T22:26:55.659046Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = fred_df('BAMLCC0A0CMTRIV')\n",
    "#data = pd.concat([df.dropna().resample('MS').mean(), df.iloc[-1].to_frame().T])\n",
    "#data = data[~data.index.duplicated(keep='last')]\n",
    "#data.to_csv(data_dir / 'corpbond_tri.csv', index_label='date')\n",
    "#color = 'violet!80!blue'\n",
    "\n",
    "#node = end_node(data['VALUE'], color, percent=True, date='d', full_year=True)\n",
    "#write_txt(text_dir / 'cbtri_node.txt', node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest Rates Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:56.897118Z",
     "start_time": "2023-11-20T22:26:55.664558Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.clevelandfed.org/-/media/files/webcharts/inflationexpectations/'+\n",
    "       'inflation-expectations.xlsx?sc_lang=en')\n",
    "df = pd.read_excel(url, sheet_name='Expected Inflation', index_col=0, \n",
    "                   parse_dates=True)\n",
    "df.columns = df.columns.str.replace('Expected Inflation', '').str.strip()\n",
    "df.to_csv(data_dir / 'exp_infl_raw.csv', index_label='date')\n",
    "\n",
    "df = pd.read_excel(url, sheet_name='Real Interest Rate', index_col=0, \n",
    "                   parse_dates=True)\n",
    "df.columns = df.columns.str.strip()\n",
    "df.to_csv(data_dir / 'frbcle_real_yield.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:56.968926Z",
     "start_time": "2023-11-20T22:26:56.898739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the three months ending November 2023, nominal two-year treasury yields increased 0.02 percentage point, real yields decreased 0.20 percentage point, and inflation expectations increased 0.22 percentage point. Ten-year treasury nominal yields increased 0.41 percentage point, real yields increased 0.16 percentage point, and inflation expectations increased 0.24 percentage point.\n",
      "\n",
      "Over the four years ending November 2023, the nominal yield on two-year treasuries increased 3.31 percentage points, the real yield increased 2.30 percentage points, and inflation expectations increased 1.02 percentage point. For ten-year treasuries, the nominal yield increased 2.76 percentage points, the real yield increased 0.16 percentage point, and expected inflation increased 0.70 percentage point.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'exp_infl_raw.csv', index_col='date', \n",
    "                  parse_dates=True) * 100\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "write_txt(text_dir / 'frbcle_ry_date.txt', ltdt)\n",
    "df2 = pd.read_csv(data_dir / 'treas_raw.csv', index_col='date', \n",
    "                  parse_dates=True).resample('MS').mean()\n",
    "df2 = df2.loc[df.loc['1988':].index]\n",
    "data, data2 = pd.DataFrame(), pd.DataFrame()\n",
    "for dv in [3, 48]:\n",
    "    for yr in [2, 5, 10]:\n",
    "        ty = df2[f'{numbers2[yr].capitalize()}-year'].diff(dv).rename('Total')\n",
    "        ie = df[f'{yr} year'].diff(dv).rename('IE')\n",
    "        ry = (ty - ie).rename('RY')\n",
    "        res = pd.DataFrame([ty, ie, ry]).T.iloc[-1]\n",
    "        if dv == 3:\n",
    "            data[f'{yr}-year'] = res\n",
    "        else:\n",
    "            data2[f'{yr}-year'] = res\n",
    "tbl, tbl2 = data.T, data2.T\n",
    "tbl.to_csv(data_dir / 'inf_exp_ch.csv', index_label='name')\n",
    "tbl2.to_csv(data_dir / 'inf_exp_ch2.csv', index_label='name')\n",
    "offset = 0.1\n",
    "offset2 = 0.04\n",
    "cols = ['IE', 'RY']\n",
    "nodes = []\n",
    "for col, row in itertools.product(cols, [0, 1, 2]):\n",
    "    sdf = tbl[cols].iloc[row]\n",
    "    i = tbl[col].iloc[row]\n",
    "    j = (tbl['Total'] - tbl[col]).iloc[row]\n",
    "    if ((i >= 0) & (j >= 0)): \n",
    "        h = ((sdf.cumsum() - (sdf / 2) + offset))\n",
    "    elif ((i < 0) & (j < 0)):\n",
    "        h = ((sdf.cumsum() - (sdf / 2) + offset2))\n",
    "    else:\n",
    "        h = (sdf / 2) + offset2\n",
    "    v = h.to_dict()\n",
    "    node = (f'\\\\absnode{{{row}.19}}{{{v[col]}}}'+\n",
    "            f'{{\\scriptsize {i:.2f}}}')\n",
    "    nodes.append(node)\n",
    "nodetext = '\\n'.join(nodes)\n",
    "write_txt(text_dir / 'inf_exp_ch_nodes.txt', nodetext)\n",
    "nodes = []\n",
    "for col, row in itertools.product(cols, [0, 1, 2]):\n",
    "    sdf = tbl2[cols].iloc[row]\n",
    "    i = tbl2[col].iloc[row]\n",
    "    j = (tbl2['Total'] - tbl[col]).iloc[row]\n",
    "    if ((i >= 0) & (j >= 0)): \n",
    "        h = ((sdf.cumsum() - (sdf / 2) + offset))\n",
    "    elif ((i < 0) & (j < 0)):\n",
    "        h = ((sdf.cumsum() - (sdf / 2) + offset2))\n",
    "    else:\n",
    "        h = (sdf / 2) + offset2\n",
    "    v = h.to_dict()\n",
    "    node = (f'\\\\absnode{{{row}.19}}{{{v[col]}}}'+\n",
    "            f'{{\\scriptsize {i:.2f}}}')\n",
    "    nodes.append(node)\n",
    "nodetext = '\\n'.join(nodes)\n",
    "write_txt(text_dir / 'inf_exp_ch_nodes2.txt', nodetext)\n",
    "\n",
    "tx = pd.DataFrame({col: tbl[col].apply(lambda x: value_text(x, ptype='pp', \n",
    "                                                            digits=2, obj='plural',\n",
    "                                                            threshold=0.01)) \n",
    "                   for col in tbl.columns})\n",
    "tx2 = tx.loc['2-year']\n",
    "tx10 = tx.loc['10-year']\n",
    "tx_ = pd.DataFrame({col: tbl2[col].apply(lambda x: value_text(x, ptype='pp', \n",
    "                                                              digits=2, obj='plural', \n",
    "                                                              threshold=0.01)) \n",
    "                   for col in tbl2.columns})\n",
    "tx_2 = tx_.loc['2-year']\n",
    "tx_10 = tx_.loc['10-year']\n",
    "\n",
    "text = (f'Over the three months ending {ltdt}, nominal two-year '+\n",
    "        f'treasury yields {tx2.Total}, real yields {tx2.RY}, and '+\n",
    "        f'inflation expectations {tx2.IE}. Ten-year treasury nominal '+\n",
    "        f'yields {tx10.Total}, real yields {tx10.RY}, and inflation '+\n",
    "        f'expectations {tx10.IE}.\\n\\nOver the four years ending {ltdt}, '+\n",
    "        f'the nominal yield on two-year treasuries {tx_2.Total}, '+\n",
    "        f'the real yield {tx_2.RY}, and inflation expectations {tx_2.IE}. '+\n",
    "        f'For ten-year treasuries, the nominal yield {tx_10.Total}, '+\n",
    "        f'the real yield {tx10.RY}, and expected inflation {tx_10.IE}.')\n",
    "write_txt(text_dir / 'real_yield_model_ch.txt', text) \n",
    "print(text)\n",
    "\n",
    "# Store change dates for chart\n",
    "dt1 = dtxt(df.index[-4])['mon1']\n",
    "dt2 = dtxt(df.index[-49])['mon1']\n",
    "write_txt(text_dir / 'inf_exp_dt1.txt', dt1)\n",
    "write_txt(text_dir / 'inf_exp_dt2.txt', dt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Interest Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:57.004428Z",
     "start_time": "2023-11-20T22:26:56.970276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model-based real yield on ten-year treasuries is 2.10 percent, as of November 2023 (see {\\color{blue}\\textbf{---}}). Ten-year treasury real yields averaged 3.30 percent during the 1990s. The model-based real yield for one-year treasuries is 2.80 percent in November 2023, compared to an average of 2.21 percent during the 1990s (see {\\color{green!68!black}\\textbf{---}}). \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'frbcle_real_yield.csv', index_col='date', \n",
    "                  parse_dates=True) * 100\n",
    "clean_data = pd.read_csv(data_dir / 'fed_rates_raw.csv', \n",
    "                         index_col='date', parse_dates=True)\n",
    "\n",
    "n = {'RIFLGFCY10_XII_N.B': 'Ten-year',\n",
    "     'RIFLGFCY05_XII_N.B': 'Five-year'}\n",
    "\n",
    "df3 = (clean_data[n.keys()].rename(n, axis=1)\n",
    "       .dropna(subset=['Ten-year']))\n",
    "\n",
    "data = pd.concat([df3.resample('MS').mean().iloc[:-1], \n",
    "                  df3.iloc[-1].to_frame().T], axis=0)\n",
    "\n",
    "#res = (pd.concat([data['Ten-year'], df], axis=1)\n",
    "#         .loc['1989':])\n",
    "res = df.loc['1989':]\n",
    "res.to_csv(data_dir / 'real_rates2.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "colors = {'Real Rate 10-year': 'blue', \n",
    "          'Real Rate 1-year': 'green!68!black'}\n",
    "\n",
    "adj = node_adj(res[colors.keys()])\n",
    "smax = res[colors.keys()].iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(res[series], color, \n",
    "                            date=date[series], \n",
    "                            digits=2, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'real_yield_nodes2.txt', nodes) \n",
    "\n",
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "ltval = res[\"Real Rate 10-year\"].iloc[-1]\n",
    "val90 = res.loc['1990':'1999', 'Real Rate 10-year'].mean()\n",
    "lt1 = res[\"Real Rate 1-year\"].iloc[-1]\n",
    "lt190 = res.loc['1990':'1999', 'Real Rate 1-year'].mean()\n",
    "cl = c_line(colors[\"Real Rate 10-year\"])\n",
    "cl2 = c_line(colors[\"Real Rate 1-year\"])\n",
    "text = ('The model-based real yield on ten-year treasuries is '+\n",
    "        f'{ltval:.2f} percent, as of {ltdt} {cl}. Ten-year '+\n",
    "        f'treasury real yields averaged {val90:.2f} percent during '+\n",
    "        'the 1990s. The model-based real yield for one-year '+\n",
    "        f'treasuries is {lt1:.2f} percent in {ltdt}, compared '+\n",
    "        f'to an average of {lt190:.2f} percent during the 1990s '+\n",
    "        f'{cl2}. ')\n",
    "write_txt(text_dir / 'real_yield_model.txt', text) \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T22:26:57.035137Z",
     "start_time": "2023-11-20T22:26:57.005779Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One measure of real interest rates comes from Treasury inflation-indexed securities. The yield on these securities can be a proxy for the interest rate investors would charge for treasuries, without inflation. \n",
      "\n",
      "As of November 17, 2023, the real yield on ten-year treasuries is 2.16 percent (see {\\color{green!85!blue}\\textbf{---}}), compared to 1.96 percent three months prior, on August 16. Five-year treasuries yield 2.22 percent in the latest data, and 2.19 percent three months prior, after adjusting for expected inflation (see {\\color{violet!50!blue!60!white}\\textbf{---}}). \n"
     ]
    }
   ],
   "source": [
    "clean_data = pd.read_csv(data_dir / 'fed_rates_raw.csv', \n",
    "                         index_col='date', parse_dates=True)\n",
    "\n",
    "n = {'RIFLGFCY10_XII_N.B': 'Ten-year',\n",
    "     'RIFLGFCY05_XII_N.B': 'Five-year'}\n",
    "\n",
    "df = clean_data[n.keys()].rename(n, axis=1).dropna(subset=['Ten-year'])\n",
    "\n",
    "data = pd.concat([df.resample('MS').mean().iloc[:-1], df.iloc[-1].to_frame().T])\n",
    "data.to_csv(data_dir / 'real_rates.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "adj = node_adj(df)\n",
    "smax = df.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'Five-year': 'violet!50!blue!60!white', 'Ten-year': 'green!85!blue'}\n",
    "date = {series: 'd' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(df[series], color, \n",
    "                            date=date[series], full_year=True, \n",
    "                            digits=2, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'real_yield_nodes.txt', nodes)  \n",
    "\n",
    "ltdt = dtxt(df.index[-1])['day1']\n",
    "prdt = (dtxt(df.index[-66])['day4'] if df.index[-66].year == df.index[-1].year \n",
    "          else dtxt(df.index[-66])['day1'])\n",
    "ltval = df['Ten-year'].iloc[-1]\n",
    "ltval5 = df['Five-year'].iloc[-1]\n",
    "prval = df['Ten-year'].iloc[-66]\n",
    "prval5 = df['Five-year'].iloc[-66]\n",
    "cl = c_line(colors['Ten-year'])\n",
    "cl2 = c_line(colors['Five-year'])\n",
    "ch10 = value_text(df['Ten-year'].diff(252).iloc[-1], 'increase_by', \n",
    "                  ptype='pp', digits=2)\n",
    "ch5 = value_text(df['Five-year'].diff(252).iloc[-1], 'increase_by', \n",
    "                  ptype='pp', digits=2)\n",
    "text = ('One measure of real interest rates comes from Treasury '+\n",
    "        'inflation-indexed securities. The yield on these securities '+\n",
    "        'can be a proxy for the interest rate investors would charge '+\n",
    "        'for treasuries, without inflation. \\n\\n'+\n",
    "        f'As of {ltdt}, the real yield on ten-year treasuries is {ltval:.2f} '+\n",
    "        f'percent {cl}, compared to {prval:.2f} percent three months prior, '+\n",
    "        f'on {prdt}. Five-year treasuries yield {ltval5:.2f} percent in the '+\n",
    "        f'latest data, and {prval5:.2f} percent three months prior, after '+\n",
    "        f'adjusting for expected inflation {cl2}. ')\n",
    "write_txt(text_dir / 'real_rates_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
