{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceaee2be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-04T05:58:33.048544Z",
     "start_time": "2022-04-04T05:58:33.043077Z"
    }
   },
   "source": [
    "### BLS CES (Current Employment Statistics)\n",
    "\n",
    "Uses flat files from the establishment survey from the monthly jobs report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a83ea01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:48:11.852787Z",
     "start_time": "2024-01-05T14:48:10.481880Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01835a16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:48:27.116509Z",
     "start_time": "2024-01-05T14:48:26.627397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve flat files from BLS\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',\n",
    "           'Accept-Encoding': 'gzip, deflate, br',\n",
    "           'Accept-Language': 'en-US,en;q=0.5',\n",
    "           'Connection': 'keep-alive'}\n",
    "\n",
    "# Industry codes\n",
    "url = 'https://download.bls.gov/pub/time.series/ce/ce.industry'\n",
    "r = requests.get(url, headers=headers)\n",
    "ind = pd.read_csv(io.StringIO(r.content.decode('utf-8')), sep='\\t')\n",
    "ind_g1 = ind[(ind['naics_code'].str.len() == 3)]\n",
    "ind_g2 = ind[(ind['naics_code'].str.len() != 3) & \n",
    "             (ind['display_level'] == 4) & \n",
    "             (ind['publishing_status'] != 'C') &\n",
    "             (ind['naics_code'] != '621,2,3') &\n",
    "             (ind['naics_code'] != '-')]\n",
    "ind_g3 = ind[(ind['naics_code'].str.len() == 2) & \n",
    "             (~ind['naics_code'].isin(ind_g1.naics_code.str[:2].unique()))]\n",
    "\n",
    "indg = pd.concat([ind_g1, ind_g2, ind_g3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9bc1c4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:48:32.897595Z",
     "start_time": "2024-01-05T14:48:32.521249Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series IDs\n",
    "url2 = 'https://download.bls.gov/pub/time.series/ce/ce.series'\n",
    "r2 = requests.get(url2, headers=headers)\n",
    "converters = {'series_id        ': lambda x: x.strip()}\n",
    "srs = pd.read_csv(io.StringIO(r2.content.decode('utf-8')), sep='\\t', \n",
    "                  converters=converters)\n",
    "srs.columns = srs.columns.str.strip()\n",
    "\n",
    "# AHE and Payrolls for 3 digit industries, NSA\n",
    "ind_grps = indg.merge(srs).query('data_type_code in [1, 3] and seasonal == \"U\"')\n",
    "\n",
    "# Supersector\n",
    "ss = {'90000000': 'Government',\n",
    "      '06000000': 'Private Goods-Producing',\n",
    "      '08000000': 'Private Service-Producing'}\n",
    "ss = {f'CEU{k}01':v for k,v in ss.items()}\n",
    "\n",
    "# Government Jobs\n",
    "g = {'Government Total': '000000',\n",
    "     '\\hspace{1mm}Federal': '910000',\n",
    "     '\\hspace{3mm}Federal Hospitals': '916220',\n",
    "     '\\hspace{3mm}Department of Defense': '919110',\n",
    "     '\\hspace{3mm}US Postal Service': '919120',\n",
    "     '\\hspace{1mm}State Government': '920000',\n",
    "     '\\hspace{3mm}State Education': '921611',\n",
    "     '\\hspace{3mm}State Hospitals': '922622',\n",
    "     '\\hspace{3mm}General Admin.': '922920',\n",
    "     '\\hspace{1mm}Local Government': '930000',\n",
    "     '\\hspace{3mm}Local Education ': '931611',\n",
    "     '\\hspace{3mm}Utilities': '932221',\n",
    "     '\\hspace{3mm}Transportation': '932480',\n",
    "     '\\hspace{3mm}Local Hospitals ': '932622',\n",
    "     '\\hspace{3mm}General Admin. ': '932920'}\n",
    "govjobs = [f'CES90{v}01' for k,v in g.items()]\n",
    "\n",
    "# Hours worked series\n",
    "hrs = {'CES0500000002': 'ceshrstot',\n",
    "       'CES0600000002': 'ceshrsgoods',\n",
    "       'CES0800000002': 'ceshrsserv',\n",
    "       'CES0500000007': 'ceshrspns'}\n",
    "hrslist = [i for i, n in hrs.items()]\n",
    "\n",
    "# Seleted other series\n",
    "s_list = (['CEU0000000001', 'CES0000000001', 'CEU0500000006', \n",
    "          'CES0500000003', 'CES0500000008', 'CES9091000001',\n",
    "          'CES9092000001', 'CES9093000001', 'CES0600000002',\n",
    "          'CES9000000001', 'CES3000000008', 'CES1000000008', \n",
    "          'CES4422000008', 'CES4142000008', 'CES5000000008', \n",
    "          'CES5500000008', 'CES6000000008', 'CES6500000008', \n",
    "          'CES2000000008', 'CES7000000008', 'CES4300000008', \n",
    "          'CES4200000008', 'CEU0500000001', 'CES0500000006', \n",
    "          'CES0500000001', 'CES0000000001', 'CES3000000001', \n",
    "          'CES1000000001', 'CES4422000001', 'CES4142000001', \n",
    "          'CES5000000001', 'CES5500000001', 'CES6000000001', \n",
    "          'CES6500000001', 'CES0500000001', 'CES2000000001', \n",
    "          'CES7000000001', 'CES4300000001', 'CES4200000001',\n",
    "          'CES0600000008', 'CES0800000008', 'CES0500000016']\n",
    "          + list(ss.keys())\n",
    "          + govjobs + hrslist)\n",
    "others = srs[srs['series_id'].isin(s_list)]\n",
    "sel = pd.concat([ind_grps, others])\n",
    "sel.to_csv(data_dir / 'ces_meta_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fba31f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:48:42.525202Z",
     "start_time": "2024-01-05T14:48:36.122966Z"
    }
   },
   "outputs": [],
   "source": [
    "# Full CES dataset\n",
    "url3 = 'https://download.bls.gov/pub/time.series/ce/ce.data.0.AllCESSeries'\n",
    "r3 = requests.get(url3, headers=headers)\n",
    "converters = {'series_id        ': lambda x: x.strip()}\n",
    "raw = pd.read_csv(io.StringIO(r3.content.decode('utf-8')), sep='\\t', \n",
    "                  converters=converters)\n",
    "raw.columns = raw.columns.str.strip()\n",
    "\n",
    "# Annual data\n",
    "sd = raw.query('series_id in @sel.series_id and year > 1987')\n",
    "sdy = sd.query('period == \"M13\"').set_index(['year', 'series_id'])['value'].unstack()\n",
    "sdy.index = pd.to_datetime(dict(year=sdy.index, month=7, day=1))\n",
    "sdy.to_csv(data_dir / 'ces_ann_raw.csv', index_label='date')\n",
    "\n",
    "#Monthly data\n",
    "idx = ['year', 'period', 'series_id']\n",
    "sdm = sd.query('period != \"M13\"').set_index(idx)['value'].unstack()\n",
    "sdm.index = [pd.to_datetime(f'{year}-{period[1:]}-01') \n",
    "             for year, period in sdm.index]\n",
    "sdm.to_csv(data_dir / 'ces_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0bfef",
   "metadata": {},
   "source": [
    "### Job Growth by Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "880e45e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:53:54.378273Z",
     "start_time": "2024-01-05T14:53:54.358051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the four years ending December 2023, nonfarm payrolls increased by a total of 5,383,000. By sector, combined government payrolls grew by 241,000 (see\\cbox{green!85!yellow!75!black}), and private payrolls increased by a total of 5,142,000 over the four-year period. Private goods-producing industries added 681,000 jobs (see\\cbox{blue!80!black}), and private service-providing industries added 4.5 million jobs (see\\cbox{cyan!80!white}). \n"
     ]
    }
   ],
   "source": [
    "sdm = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "# Supersector\n",
    "ss = {'90000000': 'Gov.',\n",
    "      '06000000': 'Goods',\n",
    "      '08000000': 'Services'}\n",
    "ss = {f'CEU{k}01':v for k,v in ss.items()}\n",
    "df = sdm[ss.keys()]\n",
    "res = (df.iloc[-1] - \n",
    "       df.loc[pd.to_datetime(f'{2019}-{df.index[-1].month}-01')]).rename(ss)\n",
    "\n",
    "# Bar plot\n",
    "ssd = {'Gov.': 'green!85!yellow!75!black',\n",
    "       'Goods': 'blue!80!black',\n",
    "       'Services': 'cyan!80!white'}\n",
    "\n",
    "bars = '\\n'.join([f'\\\\addplot[{ssd[n]}]coordinates {{({i+1},{res[n]})}};' \n",
    "                  for i, n in enumerate(ssd.keys())])\n",
    "write_txt(text_dir / 'emp_ss_bars.txt', bars)\n",
    "\n",
    "ltdt = dtxt(sdm.index[-1])['mon1']\n",
    "tot = value_text(res.sum() * 1_000, ptype=None, adj='total', digits=0)\n",
    "gov = value_text(res['Gov.'] * 1_000, 'increase_by', ptype=None, \n",
    "                 digits=0, casual=True)\n",
    "priv = value_text((res.sum() - res['Gov.']) * 1_000, ptype=None, \n",
    "                  adj='total', digits=0)\n",
    "goods = value_text(res['Goods'] * 1_000, 'added_lost', ptype=None, \n",
    "                   digits=0)\n",
    "serv = (value_text(res['Services'] / 1_000, 'added_lost', \n",
    "                   ptype=None, digits=1) + ' million')\n",
    "if res.Services < 1_000:\n",
    "    serv = value_text(res['Services'] * 1_000, 'added_lost', \n",
    "                      ptype=None, digits=0)\n",
    "text = (f'Over the four years ending {ltdt}, nonfarm payrolls '+\n",
    "        f'{tot}. By sector, combined government payrolls {gov} {c_box(ssd[\"Gov.\"])}, '+\n",
    "        f'and private payrolls {priv} over the four-year period. Private '+\n",
    "        f'goods-producing industries {goods} jobs {c_box(ssd[\"Goods\"])}, and private service-'+\n",
    "        f'providing industries {serv} jobs {c_box(ssd[\"Services\"])}. ')\n",
    "write_txt(text_dir / 'nfp_ss.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434e54c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a3364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36d13c5a",
   "metadata": {},
   "source": [
    "### Job Growth By 2019 Wage Tercile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b2e5cb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:53:56.566237Z",
     "start_time": "2024-01-05T14:53:56.528543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dividing the private industries into three wage groups, the lowest-wage industries added 1,040,000 jobs since December 2019, the middle-wage industries gained 660,000 jobs, and the highest-wage industries added 3.20 million jobs (see\\cbox{violet!70!magenta}). \n"
     ]
    }
   ],
   "source": [
    "sel = pd.read_csv(data_dir / 'ces_meta_raw.csv')\n",
    "d = sel.set_index('series_id')['industry_name'].dropna().to_dict()\n",
    "\n",
    "v19 = pd.read_csv(data_dir / 'ces_ann_raw.csv', index_col='date', \n",
    "                 parse_dates=True).loc['2019-07-01', d.keys()]\n",
    "\n",
    "c = {'ahe': '3', 'emp': '1'}\n",
    "df = pd.DataFrame({n: v19[v19.index.str.endswith(i)].rename(d) \n",
    "                   for n, i in c.items()})\n",
    "\n",
    "# Latest data and four-year prior\n",
    "data = lt = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "lt = data.iloc[[-1, -49]].T.loc[d.keys()]\n",
    "df[['emplt', 'emppr']] = lt[lt.index.str.endswith('1')].rename(d)\n",
    "df['diff'] = df['emplt'] - df['emppr']\n",
    "\n",
    "\n",
    "# Split into three wage groups\n",
    "dft = df.dropna()\n",
    "df['cdf']  = dft.sort_values('ahe').emp.cumsum() / dft.emp.sum()\n",
    "grps = (lambda x: np.where(x.cdf < (1/3), 'Lowest Third', \n",
    "                  np.where((x.cdf >= (1/3)) & (x.cdf < (2/3)), 'Middle Third', \n",
    "                  np.where((x.cdf >= (2/3)) & (x.cdf <= 1), 'Highest Third', 'none'))))\n",
    "\n",
    "df = df.assign(grps = grps)\n",
    "\n",
    "res = df.groupby('grps')['diff'].sum().drop('none').round()\n",
    "\n",
    "(res.to_csv(data_dir / 'jobs_tercile.csv', index_label='grps', \n",
    "            header=True))\n",
    "\n",
    "# Footer for industries missing wage data\n",
    "nonech = value_text(df.groupby('grps')['diff'].sum()['none'] * 1_000, \n",
    "                    'added_lost', ptype=None, digits=0)\n",
    "text = (f'Private industries without wage information {nonech} '+\n",
    "        'jobs over the period.')\n",
    "write_txt(text_dir / 'jobs_nowage_ch.txt', text)\n",
    "emp3dt = f\"{dtxt(lt.columns[1])['mon1']} to {dtxt(lt.columns[0])['mon1']}\"\n",
    "write_txt(text_dir / 'emp_3_dates.txt', emp3dt)\n",
    "\n",
    "# Text\n",
    "low = value_text(res['Lowest Third'] * 1000, 'added_lost', ptype=None, digits=0)\n",
    "mid = value_text(res['Middle Third'] * 1000, 'added_lost', ptype=None, \n",
    "                 digits=0, casual=True)\n",
    "high = (value_text(res['Highest Third'] / 1000, 'added_lost', ptype=None, \n",
    "                   digits=2) + ' million')\n",
    "if res['Highest Third'] < 1000:\n",
    "    high = value_text(res['Highest Third'] * 1000, 'added_lost', \n",
    "                      ptype=None, digits=0)\n",
    "prdt = dtxt(lt.columns[1])['mon1']\n",
    "text = ('Dividing the private industries into three wage groups, the '+\n",
    "        f'lowest-wage industries {low} jobs since {prdt}, the middle-wage '+\n",
    "        f'industries {mid} jobs, and the highest-wage industries {high} '+\n",
    "        f'jobs {c_box(\"violet!70!magenta\")}. ')\n",
    "write_txt(text_dir / 'nfp_wg.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0108ee40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fdbf60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6b283f3",
   "metadata": {},
   "source": [
    "### Overview Jobs Growth and Monthly Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "556ba2b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:53:58.748292Z",
     "start_time": "2024-01-05T14:53:58.717246Z"
    }
   },
   "outputs": [],
   "source": [
    "sl = {'CEU0000000001': 'NFP', 'CES0000000001': 'NFPsa', \n",
    "      'CEU0500000006': 'PNS', 'CES0500000006': 'PNSsa',\n",
    "      'CEU0500000001': 'PNFP', 'CES0500000001': 'PNFPsa'}\n",
    "# CES series from flat/text files\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True).loc[:, sl.keys()].rename(sl, axis=1)\n",
    "# Add LFS series from jobs report\n",
    "df[['EMP', 'EMPsa']] = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                                   index_col='date', parse_dates=True)\n",
    "                          .loc[:, ['EMP', 'EMPsa']])\n",
    "# Save results for time series graph\n",
    "res = df.loc['1989':].divide(1000)\n",
    "res.to_csv(data_dir / 'emp_ts.csv', index_label='date')\n",
    "\n",
    "# End nodes for time series graph\n",
    "res2 = res[['NFP', 'EMP', 'PNS']]\n",
    "adj = node_adj(res2)\n",
    "smax = res2.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "cols = {'NFP': 'blue!70!white', 'EMP': 'magenta',\n",
    "        'PNS': 'orange!80!yellow'}\n",
    "date = {series: 'm' if series in ['EMP'] else None \n",
    "        for series in cols.keys()}\n",
    "nodes  ='\\n'.join([end_node(res2[series].dropna(), color, date=date[series], \n",
    "                            full_year=True, size=1.1, offset=adj[series]) \n",
    "                   for series, color in cols.items()])\n",
    "write_txt(text_dir / 'emp_ts_nodes.txt', nodes) \n",
    "\n",
    "# Latest values bar graph\n",
    "sa = df[['NFPsa', 'EMPsa']]\n",
    "final2 = sa.diff().loc['2019'].mean().to_frame().T\n",
    "final2['label'] = '2019 Average'\n",
    "final = sa.diff().iloc[-3:]\n",
    "final['label'] = [dtxt(i)['mon2'] for i in final.index]\n",
    "final = pd.concat([final2, final])\n",
    "final.to_csv(data_dir / 'emp_lt.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "109af2af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:00.703209Z",
     "start_time": "2024-01-05T14:54:00.691095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In December 2023, establishments report 158.2 million \\textbf{nonfarm payroll employees} (see {\\color{blue!70!white}\\textbf{---}}). The pre-COVID peak was 153.1 million in November 2019. Households report 160.8 million employed people, including the self-employed but not including armed forces, in the latest month, compared to a pre-COVID peak of 159.1 million (see {\\color{magenta}\\textbf{---}}). \n",
      "\n",
      "Private production and nonsupervisory workers are engaged in production, including working supervisors, or in other activities but not above the working supervisor level. In December 2023, this group totals 109.8 million, compared to a pre-COVID peak of 106.9 million (see {\\color{orange!80!yellow}\\textbf{---}}). Production and nonsupervisory workers comprise 81.4 percent of private nonfarm payrolls in December 2023. \n",
      "\n",
      " In December 2023, seasonally-adjusted civilian employment decreased by 683,000 (see\\cbox{magenta}), far below the 2019 average increase of 169,000 jobs per month. The US added a net total of 216,000 nonfarm payroll jobs in December 2023 (see\\cbox{blue!70!white}), compared to a monthly average of 163,250 in 2019. The average of both surveys over the past three months shows an increase of 21,200 employees per month.  \n"
     ]
    }
   ],
   "source": [
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "lt = res.iloc[-1]\n",
    "pc = res.loc[:'2020-03-01']\n",
    "pnssh = (lt.PNS / lt.PNFP) * 100\n",
    "\n",
    "cl = {n: c_line(col) for n, col in cols.items()}\n",
    "text = (f'In {ltdt}, establishments report {lt.NFP:.1f} million '+\n",
    "        f'\\\\textbf{{nonfarm payroll employees}} {cl[\"NFP\"]}. '+\n",
    "        f'The pre-COVID peak was {pc.NFP.max():.1f} million '+\n",
    "        f'in {dtxt(pc.NFP.idxmax())[\"mon1\"]}. '+\n",
    "        f'Households report {lt.EMP:.1f} million employed '+\n",
    "        'people, including the self-employed but not including '+\n",
    "        'armed forces, in the latest month, compared to a pre-COVID '+\n",
    "        f'peak of {pc.EMP.max():.1f} million {cl[\"EMP\"]}. \\n\\nPrivate '+\n",
    "        'production and nonsupervisory workers are engaged in '+\n",
    "        'production, including working supervisors, or in other '+\n",
    "        'activities but not above the working supervisor level. '+\n",
    "        f'In {ltdt}, this group totals {lt.PNS:.1f} million, compared '+\n",
    "        f'to a pre-COVID peak of {pc.PNS.max():.1f} million {cl[\"PNS\"]}. '+\n",
    "        f'Production and nonsupervisory workers comprise {pnssh:.1f} '+\n",
    "        f'percent of private nonfarm payrolls in {ltdt}. ')\n",
    "write_txt(text_dir / 'emp_overview1.txt', text)\n",
    "print(text)\n",
    "\n",
    "lc = res.diff().iloc[-1] * 1_000_000\n",
    "ltemp = value_text(lc.EMPsa, 'increase_by', ptype=None, digits=0)\n",
    "a19 = res.diff().loc['2019'].mean() * 1_000_000\n",
    "empc = compare_text(lc.EMPsa, a19.EMPsa, [30000, 50000, 150000])\n",
    "nfpal = 'added' if lc.NFPsa >= 0 else 'lost'\n",
    "a3m = value_text(round(res[['NFPsa', 'EMPsa']].diff().iloc[-3:].mean().mean()\n",
    "                       * 1_000_000, -2), \n",
    "                 'increase_of', ptype=None, digits=0)\n",
    "text = (f'In {ltdt}, seasonally-adjusted civilian employment {ltemp} '+\n",
    "        f'{c_box(cols[\"EMP\"])}, {empc} the 2019 average increase of '+\n",
    "        f'{a19.EMPsa:,.0f} jobs per month. The US {nfpal} a net total '+\n",
    "        f'of {lc.NFPsa:,.0f} nonfarm payroll jobs in {ltdt} '+\n",
    "        f'{c_box(cols[\"NFP\"])}, compared to a monthly average of '+\n",
    "        f'{a19.NFPsa:,.0f} in 2019. The average of both surveys over '+\n",
    "        f'the past three months shows {a3m} employees per month.  ')\n",
    "write_txt(text_dir / 'emp_overview2.txt', text)\n",
    "print('\\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6df8f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:02.937304Z",
     "start_time": "2024-01-05T14:54:02.907055Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'EMP': 'Employed', 'NFP': 'Nonfarm Payrolls',\n",
    "     'PNFP': '\\hspace{1mm} Private Nonfarm Payrolls',\n",
    "     'PNS': '\\hspace{2mm} Production \\& Nonsuperv.'}\n",
    "d = {**{f'{k}sa': v for k,v in d.items()}, **d}\n",
    "\n",
    "g1 = ['EMP', 'NFP', 'PNFP', 'PNS']\n",
    "g2 = [f'{i}sa' for i in g1]\n",
    "\n",
    "r2 = res.copy()\n",
    "r2.index = [dtxt(i)['mon2'] for i in r2.index]\n",
    "\n",
    "tbl = pd.concat([r2[g2].iloc[-2:].T.iloc[:, ::-1].rename(d), \n",
    "                 r2[g1].iloc[-2:].T.iloc[:, ::-1].rename(d)], axis=1)\n",
    "tbl['2019 Avg.'] = res.loc['2019', g1].mean().rename(d)\n",
    "tbl['2017 Avg.'] = res.loc['2017', g1].mean().rename(d)\n",
    "tbl['2000 Avg.'] = res.loc['2000', g1].mean().rename(d)\n",
    "\n",
    "tbl.applymap('{:.1f}'.format).to_csv(data_dir/'emp_overview.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd18d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db5f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abd7308a",
   "metadata": {},
   "source": [
    "### Payrolls by Industry Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73f67885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:04.956939Z",
     "start_time": "2024-01-05T14:54:04.953224Z"
    }
   },
   "outputs": [],
   "source": [
    "s = {'CEU0000000001': 'Total nonfarm',\n",
    "     'CEU0500000001': '\\hspace{1mm} Total Private',\n",
    "     'CEU0600000001': '\\hspace{2mm} Goods-Producing',\n",
    "     'CEU1000000001': '\\hspace{4mm} Mining \\& Logging',\n",
    "     'CEU2000000001': '\\hspace{4mm} Construction',\n",
    "     'CEU3000000001': '\\hspace{4mm} Manufacturing',\n",
    "     'CEU0800000001': '\\hspace{2mm} Private Service-Providing',\n",
    "     'CEU4142000001': '\\hspace{4mm} Wholesale Trade',\n",
    "     'CEU4200000001': '\\hspace{4mm} Retail Trade',\n",
    "     'CEU4300000001': '\\hspace{4mm} Transportation \\& Warehousing',\n",
    "     'CEU5000000001': '\\hspace{4mm} Information',\n",
    "     'CEU5500000001': '\\hspace{4mm} Financial Activities',\n",
    "     'CEU5553000001': '\\hspace{4mm} Real Estate \\& Rental \\& Leasing',\n",
    "     'CEU6054000001': '\\hspace{4mm} Professional \\& Technical Services',\n",
    "     'CEU6055000001': '\\hspace{4mm} Management',\n",
    "     'CEU6056100001': '\\hspace{4mm} Administrative \\& Support',\n",
    "     'CEU6561000001': '\\hspace{4mm} Educational Services',\n",
    "     'CEU6562000101': '\\hspace{4mm} Health Care',\n",
    "     'CEU6562400001': '\\hspace{4mm} Social Assistance',\n",
    "     'CEU7071000001': '\\hspace{4mm} Arts, Entertainment, \\& Recreation',\n",
    "     'CEU7072100001': '\\hspace{4mm} Accommodation',\n",
    "     'CEU7072200001': '\\hspace{4mm} Food Services \\& Drinking Places',\n",
    "     'CEU8000000001': '\\hspace{4mm} Other Services',\n",
    "     'FromData': '\\hspace{4mm} Utilities \\& waste management',\n",
    "     'CEU9000000001': '\\hspace{1mm} Government'}\n",
    "s_other = ['CEU4422000001', 'CEU6056200001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b71c77f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:07.388254Z",
     "start_time": "2024-01-05T14:54:05.732963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Not seasonally adjusted data\n",
    "res = raw.query('(series_id in @s.keys() or series_id in @s_other) '+\n",
    "                'and year > 1988 and period != \"M13\"')\n",
    "res = res.set_index(['year', 'period', 'series_id'])['value'].unstack()\n",
    "res.index = [pd.to_datetime(f'{year}-{period[1:]}-01') \n",
    "             for year, period in res.index]\n",
    "res[s['FromData']] = res[s_other].sum(axis=1)\n",
    "res = res.drop(s_other, axis=1)\n",
    "res = res.rename(s, axis=1)\n",
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "tbl = pd.DataFrame({ltdt: res.iloc[-1], \n",
    "                    '4-year change': res.diff(48).iloc[-1]}).loc[s.values()]\n",
    "# Seasonally adjusted data\n",
    "s2 = {k.replace('CEU', 'CES'): v for k,v in s.items()}\n",
    "s2_other = [i.replace('CEU', 'CES') for i in s_other]\n",
    "res2 = raw.query('(series_id in @s2.keys() or series_id in @s2_other) '+\n",
    "                'and year > 1988 and period != \"M13\"')\n",
    "res2 = res2.set_index(['year', 'period', 'series_id'])['value'].unstack()\n",
    "res2.index = [pd.to_datetime(f'{year}-{period[1:]}-01') \n",
    "             for year, period in res2.index]\n",
    "res2[s['FromData']] = res2[s2_other].sum(axis=1)\n",
    "res2 = res2.drop(s2_other, axis=1)\n",
    "res2 = res2.rename(s2, axis=1)\n",
    "ltdr = (f\"\\mbox{{{dtxt(res2.index[-3])['mon6']}--}} \"+\n",
    "        f\"\\mbox{{{dtxt(res2.index[-1])['mon6']}}} \\mbox{{average}}\")\n",
    "prdr = (f\"\\mbox{{{dtxt(res2.index[-6])['mon6']}--}} \"+\n",
    "        f\"\\mbox{{{dtxt(res2.index[-4])['mon6']}}} \\mbox{{average}}\")\n",
    "tbl2 = pd.DataFrame({f'{ltdt} ': res2.iloc[-1], \n",
    "                     '1-month change': res2.diff().iloc[-1],\n",
    "                     ltdr: res2.diff().iloc[-3:].mean(),\n",
    "                     prdr: res2.diff().iloc[-6:-3].mean()}).loc[s2.values()]\n",
    "table = tbl2.join(tbl).applymap('{:,.0f}'.format).replace('-0', '0')\n",
    "table.index.name = ''\n",
    "table.to_csv(data_dir/'nfp.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9343c6d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:08.924222Z",
     "start_time": "2024-01-05T14:54:08.917076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the four years ending December 2023, the industry groups with the largest increase in payrolls were professional and technical services (+1,337,900), transportation and warehousing (+971,400), health care (+839,500), and construction (+543,000). The private industry groups with the least least job growth were accommodation (-215,100), retail trade (-60,900), and mining and logging (-53,000).\n"
     ]
    }
   ],
   "source": [
    "st = res.diff(48).iloc[-1].sort_values()\n",
    "st.index = [i.split('} ')[-1].replace('\\&', 'and').lower() \n",
    "            for i in st.index]\n",
    "excats = ['government', 'other services', 'total nonfarm', \n",
    "          'total private', 'private service-providing', \n",
    "          'goods-producing']\n",
    "st = (st.multiply(1000).apply('{:+,.0f}'.format)\n",
    "        .drop(excats))\n",
    "\n",
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "high = [f'{st.index[i]} ({st.iloc[i]})' for i in [-1, -2, -3, -4]]\n",
    "htxt = ', and '.join([', '.join(high[:3]), high[3]])\n",
    "low = [f'{st.index[i]} ({st.iloc[i]})' for i in [0, 1, 2]]\n",
    "ltxt = ', and '.join([', '.join(low[:2]), low[2]])\n",
    "\n",
    "text = (f'Over the four years ending {ltdt}, the industry '+\n",
    "        'groups with the largest increase in payrolls were '+\n",
    "        f'{htxt}. The private industry groups with the least '+\n",
    "        f'least job growth were {ltxt}.')\n",
    "write_txt(text_dir / 'emp_ind.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96296acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6e0a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7128f8f9",
   "metadata": {},
   "source": [
    "### Gross Labor Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce4ce62b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:11.888877Z",
     "start_time": "2024-01-05T14:54:11.859009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the nonfarm payrolls approach (see {\\color{blue!55!purple!50!white}\\textbf{---}}), the one-year growth rate of gross labor income is 6.0 percent in December 2023, following 7.8 percent one-year prior, in December 2022.\n"
     ]
    }
   ],
   "source": [
    "# Calculate GLI\n",
    "start = '2017-01-01'\n",
    "emp = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)['CEU0000000001'].pct_change(12) * 100\n",
    "ahe = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date',  \n",
    "                  parse_dates=True)['CES0500000003'].pct_change(12) * 100\n",
    "nfp = (emp + ahe).rename('NFP').dropna()\n",
    "nfp.loc[start:].to_csv(data_dir / 'gli_nfp.csv', index_label='date')\n",
    "\n",
    "# Horizontal bar at 5\n",
    "end = dtxt(nfp.index[-1] + pd.DateOffset(months=1))['datetime']\n",
    "hbar = (f'\\draw [dotted, thick] (axis cs:{{{start}}}, 5) -- '+\n",
    "        f'(axis cs:{{{end}}}, 5);')\n",
    "write_txt(text_dir / 'gli_hbar.txt', hbar) \n",
    "\n",
    "# Text\n",
    "cline = c_line('blue!55!purple!50!white')\n",
    "ltdt = dtxt(nfp.index[-1])['mon1']\n",
    "prdt = dtxt(nfp.index[-13])['mon1']\n",
    "text = (f'Using the nonfarm payrolls approach {cline}, the one-year '+\n",
    "        f'growth rate of gross labor income is {nfp.iloc[-1]:.1f} '+\n",
    "        f'percent in {ltdt}, following {nfp.iloc[-13]:.1f} percent '+\n",
    "        f'one-year prior, in {prdt}.')\n",
    "write_txt(text_dir / 'gli_nfp.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c95b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0960bcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6344cea2",
   "metadata": {},
   "source": [
    "### Government Jobs\n",
    "The jobs report doesn't include the full population, which is provided by Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4a641aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:15.181701Z",
     "start_time": "2024-01-05T14:54:15.062028Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Timestamp('2023-12-01 00:00:00')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:516\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:545\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:203\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:211\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/_libs/index.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.index._unpack_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1701388800000000000",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py:736\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2023-12-01 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fill missing population date from Census\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m pop\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 17\u001b[0m     pop[df\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[43mpopest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Share of population    \u001b[39;00m\n\u001b[1;32m     20\u001b[0m sh \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdivide(pop, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m   1066\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[0;32m-> 1067\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1069\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1247\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   1246\u001b[0m     tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> 1247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m tup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tup):\n\u001b[1;32m    964\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;66;03m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m    966\u001b[0m         \u001b[38;5;66;03m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m--> 967\u001b[0m         section \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    969\u001b[0m         \u001b[38;5;66;03m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m    970\u001b[0m         \u001b[38;5;66;03m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m    971\u001b[0m         \u001b[38;5;66;03m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m    972\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m section\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m    973\u001b[0m             \u001b[38;5;66;03m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m    974\u001b[0m             \u001b[38;5;66;03m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1312\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> 1312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1260\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/generic.py:4056\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   4054\u001b[0m             new_index \u001b[38;5;241m=\u001b[39m index[loc]\n\u001b[1;32m   4055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4056\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4058\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m   4059\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m loc\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mbool_:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/core/indexes/datetimes.py:738\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39mget_loc(\u001b[38;5;28mself\u001b[39m, key, method, tolerance)\n\u001b[1;32m    737\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 738\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: Timestamp('2023-12-01 00:00:00')"
     ]
    }
   ],
   "source": [
    "pop = (pd.read_csv(data_dir/'nipa20600.csv', index_col='date', \n",
    "                  parse_dates=True)['B230RC'])\n",
    "popest = pd.read_csv(data_dir/'pop_est_bea.csv', index_col='date', \n",
    "                     parse_dates=True) / 1000\n",
    "\n",
    "data = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "\n",
    "jobcats = {'CES9000000001': 'govjobs',\n",
    "           'CES9091000001': 'fedjobs',\n",
    "           'CES9092000001': 'stjobs',\n",
    "           'CES9093000001': 'locjobs'}\n",
    "df = data.rename(jobcats, axis=1)[jobcats.values()]\n",
    "\n",
    "# Fill missing population date from Census\n",
    "if df.index[-1] > pop.index[-1]:\n",
    "    pop[df.index[-1]] = popest.loc[df.index[-1], 'POP']\n",
    "    \n",
    "# Share of population    \n",
    "sh = df.divide(pop, axis=0) * 100\n",
    "sh.loc['1989':].to_csv(data_dir / 'govjobs.csv', index_label='date')\n",
    "grps = {'govjobs': 'blue!50!cyan', 'fedjobs': 'green!80!blue',\n",
    "        'stjobs': 'orange', 'locjobs': 'red'}\n",
    "for cat, col in grps.items():\n",
    "    node = (end_node(sh[cat], col, date='m') \n",
    "            if cat == 'govjobs' \n",
    "            else end_node(sh[cat], col))\n",
    "    write_txt(text_dir / f'{cat}_node.txt', node)\n",
    "    \n",
    "ltdate = dtxt(sh.index[-1])['mon1']\n",
    "pryrdate = dtxt(sh.index[-13])['mon1']\n",
    "ltval = df.govjobs.iloc[-1] / 1000 \n",
    "pryrval = df.govjobs.iloc[-13] / 1000 \n",
    "ltsh = sh.govjobs.iloc[-1]\n",
    "pryrsh = sh.govjobs.iloc[-13]\n",
    "ltfed = df.fedjobs.iloc[-1] / 1000 \n",
    "ltst = df.stjobs.iloc[-1] / 1000 \n",
    "ltloc = df.locjobs.iloc[-1] / 1000 \n",
    "ltfedsh = sh.fedjobs.iloc[-1] \n",
    "ltstsh = sh.stjobs.iloc[-1]\n",
    "ltlocsh = sh.locjobs.iloc[-1]\n",
    "diff = df.govjobs.iloc[-1] - df.govjobs.loc['2019-12-01']#.mean()\n",
    "gl = 'gained' if diff > 0 else 'lost'\n",
    "difftxt = (f'{gl} {abs(diff):.0f},000' if abs(diff) < 1000 \n",
    "           else f'{gl} {abs(diff) / 1000:.1f} million')\n",
    "txt3 = f'Since 2019, the US has {difftxt} total government jobs. '\n",
    "sh90 = sh.loc['1990':'1999', 'govjobs'].mean()\n",
    "diff90 = ((sh90 / 100)\n",
    "          * pop.iloc[-1]) - df.govjobs.iloc[-1]\n",
    "\n",
    "txt1 = (f'In {ltdate}, there were {ltval:.1f} million government jobs, '+\n",
    "        f'equivalent to {ltsh:.1f} for every 100 people '+\n",
    "        f'(see {{\\color{{{grps[\"govjobs\"]}}}\\\\textbf{{---}}}}). The previous year, '+\n",
    "        f'in {pryrdate}, there were {pryrval:.1f} million government jobs, '+\n",
    "        f'equivalent to {pryrsh:.1f} per 100 people. '+\n",
    "        f'During the 1990s, there were {sh90:.1f} government jobs per 100 people. '+\n",
    "        'If the rate was the same today, there would be '+\n",
    "        f'{diff90 / 1_000:.1f} million additional government jobs.'+\n",
    "        f'\\n\\nBy level of government, there were {ltloc:.1f} million '+\n",
    "        f'local government jobs in {ltdate}, equivalent to '+\n",
    "        f'{ltlocsh:.1f} per 100 people '+\n",
    "        f'(see {{\\color{{{grps[\"locjobs\"]}}}\\\\textbf{{---}}}}). '+\n",
    "        f'In the same period, there were {ltst:.1f} million state '+\n",
    "        f'government job ({ltstsh:.1f} per 100 people, '+\n",
    "        f'see {{\\color{{{grps[\"stjobs\"]}}}\\\\textbf{{---}}}}), and '+\n",
    "        f'{ltfed:.1f} million federal government job ({ltfedsh:.1f} '+\n",
    "        f'per 100 people, see {{\\color{{{grps[\"fedjobs\"]}}}\\\\textbf{{---}}}}).')\n",
    "\n",
    "ch19 = df.iloc[-1] - df.loc['2019-12-01']#.mean()\n",
    "locchsh = (ch19.locjobs / ch19.govjobs) * 100\n",
    "stchtxt = value_text(ch19.stjobs, style='added_lost', ptype=None, digits=0)\n",
    "fedchtxt = value_text(ch19.fedjobs, style='added_lost', ptype=None, digits=0)\n",
    "locchtxt = value_text(ch19.locjobs, style='added_lost', ptype=None, digits=0)\n",
    "aw = 'and' if ch19.fedjobs < 0 else 'while'\n",
    "if (ch19.govjobs < 0) and (ch19.locjobs < 0):\n",
    "    txt = (f'Of these, {abs(ch19.locjobs):,.0f},000, or {locchsh:.1f} '+\n",
    "           'percent of the shortfall, are local government jobs. '+\n",
    "           'During the same period, ')\n",
    "else:\n",
    "    txt = f'During the same period, local governments {locchtxt},000 jobs, '\n",
    "    \n",
    "txt2 = (f'state governments {stchtxt},000 jobs, {aw} '+\n",
    "        f'the federal government {fedchtxt},000 jobs.')\n",
    "text = txt1 + '\\n\\n' + txt3 + txt + txt2\n",
    "write_txt(text_dir / 'govjobs.txt', text)\n",
    "print(text)\n",
    "\n",
    "# Government jobs table\n",
    "gj = {f'CES90{v}01': n for n, v in g.items()}\n",
    "j = data[govjobs].rename(gj, axis=1)\n",
    "res = pd.concat([j.iloc[i] for i in [-1, -2, -13, -25]], axis=1)\n",
    "res.columns = [dtxt(i)['mon6'] for i in res.columns]\n",
    "for year in ['2019', '2005']:\n",
    "    res[year] = j.loc[year].mean()\n",
    "res = res.applymap('{:,.0f}'.format).replace('nan', '--')\n",
    "res.to_csv(data_dir / 'gov_jobs.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b82bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d568f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f6fdba17",
   "metadata": {},
   "source": [
    "### Nonfarm Payrolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e1e8db9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:17.620692Z",
     "start_time": "2024-01-05T14:54:17.589140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonfarm payrolls increased by 216,000 in December 2023, following 173,000 jobs added in November, and 105,000 added in October (see\\cbox{blue!60!purple}). Average payroll growth was 164,700 over these three months, slightly below the average of 221,000 during the previous three months. \n",
      "\n",
      " During March and April 2020, the US lost a combined 22 million jobs. Since May 2020, a total of 26.8 million jobs have been added, equivalent to 122.2 percent of those lost.\n",
      "\n",
      "To maintain a steady payroll employment rate with population growth, the US needed to add 153,000 jobs in December 2023. Pre-pandemic, in 2019, the US was adding an average of 163,200 jobs per month.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                   parse_dates=True).loc['2015':, 'CES0000000001']\n",
    "\n",
    "pop = pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True).loc['2015':, 'POP']\n",
    "\n",
    "data = df.diff().loc['2019':] * 1_000\n",
    "data.name = 'ALL'\n",
    "data.div(1_000_000).to_csv(data_dir / 'nfp.csv', index_label='date')\n",
    "\n",
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "prdt = dtxt(data.index[-2])['mon1']\n",
    "if prdt[-4:] == ltdt[-4:]:\n",
    "    prdt = prdt[:-5]\n",
    "pr2dt = dtxt(data.index[-3])['mon1']\n",
    "if pr2dt[-4:] == ltdt[-4:]:\n",
    "    pr2dt = pr2dt[:-5]\n",
    "lt = value_text(data.iloc[-1], 'increase_by', ptype=None, digits=0)\n",
    "al = 'added' if data.iloc[-2] >= 0 else 'lost'\n",
    "pr = f'{data.iloc[-2]:,.0f} jobs {al}'\n",
    "pr2 = value_text(data.iloc[-3], 'added_lost_rev', ptype=None, \n",
    "                 digits=0)\n",
    "cb = c_box('blue!60!purple')\n",
    "val3m = data.iloc[-3:].mean()\n",
    "valpr3m = data.iloc[-6:-3].mean()\n",
    "ct = compare_text(val3m, valpr3m, [50000, 150000, 500000])\n",
    "cov = data.loc['2020-03-01':'2020-04-01'].sum() / 1_000_000\n",
    "pcadd = data.loc['2020-05-01':].sum() / 1_000_000\n",
    "pcsh = (pcadd / abs(cov)) * 100\n",
    "lpop = (pop.diff().rolling(12).mean().iloc[-1] * \n",
    "        (df / pop).rolling(12).mean().iloc[-1]) * 1_000\n",
    "pr19v = data.loc['2019'].mean().round(-2)\n",
    "pr3yr = value_text(data.iloc[-48:].mean().round(-2), 'added_lost', \n",
    "                   ptype=None, digits=0, adj='average')\n",
    "\n",
    "text = (f'Nonfarm payrolls {lt} in {ltdt}, following {pr} in {prdt}, '+\n",
    "        f'and {pr2} in {pr2dt} {cb}. Average payroll growth was '+\n",
    "        f'{round(val3m,-2):,.0f} over these three months, '+\n",
    "        f'{ct} the average of {round(valpr3m,-2):,.0f} '+\n",
    "        'during the previous three months. \\n\\n During March and '+\n",
    "        f'April 2020, the US lost a combined {abs(cov):.0f} million '+\n",
    "        f'jobs. Since May 2020, a total of {pcadd:.1f} million jobs '+\n",
    "        f'have been added, equivalent to {pcsh:.1f} percent of those lost.\\n\\n'+\n",
    "        'To maintain a steady payroll employment rate with population growth, '+\n",
    "        f'the US needed to add {round(lpop, -3):,.0f} '+\n",
    "        f'jobs in {ltdt}. Pre-pandemic, in 2019, the US was adding an average '+\n",
    "        f'of {pr19v:,.0f} jobs per month.')\n",
    "write_txt(text_dir / 'nfp_basic_text.txt', text)\n",
    "print(text)\n",
    "\n",
    "# Node for latest value\n",
    "tloc = dtxt(data.index[-1] - pd.DateOffset(weeks=26))['datetime']\n",
    "tdt = dtxt(data.index[-1])['mon6']\n",
    "pm = '+' if data.iloc[-1] >= 0 else '-'\n",
    "tv = f'{pm}{abs(data.iloc[-1] / 1_000):.0f}k'\n",
    "if abs(data.iloc[-1]) > 994_000:\n",
    "    tv = f'{pm}{abs(data.iloc[-1] / 1_000_000):.1f} million'\n",
    "text = ('\\\\node[below, align=right, pin=45:{}] at (axis cs: '+\n",
    "        f'{{{tloc}}}, -1.2) {{\\scriptsize {tdt}\\\\\\\\ \\scriptsize {tv}}};')\n",
    "write_txt(text_dir / 'nfp_lt_val.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b01071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75e034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e659232",
   "metadata": {},
   "source": [
    "### Recent values in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48916f04",
   "metadata": {},
   "source": [
    "### Nonfarm Payrolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20e67c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-05T14:54:19.482542Z",
     "start_time": "2024-01-05T14:54:19.458959Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nonfarm payrolls\n",
    "s = {'CES0000000001': 'NFP'}\n",
    "# CES series from flat/text files\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)[s.keys()].rename(s, axis=1)\n",
    "res = df.diff()\n",
    "res['label'] = [dt.strftime('%b\\\\\\%Y') if dt.month == 1 \n",
    "                else dt.strftime('%b') if dt.month in [4, 7, 10]\n",
    "                else '' for dt in res.index]\n",
    "\n",
    "# Axis from CPI chart\n",
    "cpi = pd.read_csv(data_dir / 'cpi_monthly.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "\n",
    "d = (pd.concat([cpi[['ALL_S', 'FILL']], res.iloc[-19:]], axis=1)\n",
    "       .dropna(subset=['NFP']))\n",
    "\n",
    "d.to_csv(data_dir / 'nfp_monthly.csv', index_label='date', \n",
    "         float_format='%g')\n",
    "\n",
    "# End node\n",
    "ltdt = d.index[-1]\n",
    "ltdtime = dtxt(ltdt)['datetime'].replace('-08-', '-8-').replace('-09-', '-9-')\n",
    "mo = dtxt(ltdt)['mon6']\n",
    "v = d.NFP.iloc[-1]\n",
    "pos = '+' if v >= 0 else '-'\n",
    "pos2 = '' if v >= 0 else '-'\n",
    "pin = 270 if v >= 0 else 90\n",
    "above = 'above' if v >= 0 else 'below'\n",
    "vt = f'{pos}{abs(v):.0f}k'\n",
    "node = (f'\\\\node[{above}, yshift={pos2}0.5cm, align=center, pin={pin}:] at '+\n",
    "        f'({{{ltdtime}}}, {v:.0f}) {{\\scriptsize {mo}: \\\\\\\\ \\scriptsize {vt}}};')\n",
    "write_txt(text_dir / 'nfp_summary_node.txt', node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996a41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804fdf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
