{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Jobs Report Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:29.248841Z",
     "start_time": "2023-07-25T15:18:28.229321Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T14:51:40.934243Z",
     "start_time": "2023-07-07T14:51:29.997128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "June 2023\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS14000003': 'White', \n",
    "          'LNS14000006': 'Black',\n",
    "          'LNS14000009': 'Hispanic',\n",
    "          'LNS14032183': 'Asian',\n",
    "          'LNS14000000': 'Total',\n",
    "          'LNS13327709': 'U6',\n",
    "          'LNS13000000': 'Level',\n",
    "          'LNU05026639': 'WantJob',\n",
    "          'LNU03008636': 'LT',\n",
    "          'LNU03008516': 'MT',\n",
    "          'LNU00000000': 'POP',\n",
    "          'LNS12300060': 'PA_EPOP',\n",
    "          'LNS13023621': 'Job Loser',\n",
    "          'LNS13023653': 'Temporary Layoff',\n",
    "          'LNS13026638': 'Permanent Separation',\n",
    "          'LNS13023705': 'Job Leaver', \n",
    "          'LNS13023557': 'Re-entrant',\n",
    "          'LNS13023569': 'New entrant',\n",
    "          'LNS13008276': 'Median',\n",
    "          'LNS13008275': 'Mean',\n",
    "          'LNS17200000': 'NILF',\n",
    "          'LNS17100000': 'UNEMP',\n",
    "          'LNS11000000': 'LF',\n",
    "          'LNS12032194': 'PTECON',\n",
    "          'LNS12005977': 'PTNONECON'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1988, 2023)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main.csv', index_label='date')\n",
    "print(dtxt(df.index[-1])['mon1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T14:51:50.799638Z",
     "start_time": "2023-07-07T14:51:40.935416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'CES0500000003': 'ALL', \n",
    "          'CES0500000008': 'PNS',\n",
    "          'LNS12005054': 'avghrstot',\n",
    "          'LNU02033699': 'avghrsserv',\n",
    "          'CES0500000002': 'ceshrstot',\n",
    "          'CES0600000002': 'ceshrsgoods',\n",
    "          'CES0800000002': 'ceshrsserv',\n",
    "          'CES0500000007': 'ceshrspns',\n",
    "          'LNU02033232': 'avghrsptecon',\n",
    "          'LNU01000000': 'LFnsa',\n",
    "          'LNS12026619': 'MJHsa',\n",
    "          'LNU02000000': 'EMP',\n",
    "          'LNS12000000': 'EMPsa',\n",
    "          'LNU00000001': 'MenPop',\n",
    "          'LNU00000002': 'WomenPop',\n",
    "          'LNU01000001': 'MenLF',\n",
    "          'LNU01000002': 'WomenLF',\n",
    "          'LNS11300001': 'MenLFPR',\n",
    "          'LNS11300002': 'WomenLFPR',\n",
    "          'LNU02048984': 'seinc',\n",
    "          'LNS12027714': 'seuninc',\n",
    "          'LNU02374597': 'empdis',\n",
    "          'LNS12300000': 'EPOP'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1988, 2023)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T14:51:52.383899Z",
     "start_time": "2023-07-07T14:51:50.801724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS17100001': 'MenUE',\n",
    "          'LNS17100002': 'WomenUE',\n",
    "          'LNS17200001': 'MenNE',\n",
    "          'LNS17200002': 'WomenNE',\n",
    "          'LNS17400001': 'MenEU',\n",
    "          'LNS17400002': 'WomenEU',\n",
    "          'LNS17600001': 'MenNU',\n",
    "          'LNS17600002': 'WomenNU',\n",
    "          'LNS17800001': 'MenEN',\n",
    "          'LNS17800002': 'WomenEN',\n",
    "          'LNS17900001': 'MenUN',\n",
    "          'LNS17900002': 'WomenUN',\n",
    "          'LNS12000001': 'MenE',\n",
    "          'LNS12000002': 'WomenE',\n",
    "          'LNS13000001': 'MenU',\n",
    "          'LNS13000002': 'WomenU',\n",
    "          'LNS15000001': 'MenN',\n",
    "          'LNS15000002': 'WomenN'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (2018, 2023)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main3.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Gross Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-12T19:55:03.076976Z",
     "start_time": "2023-07-12T19:55:03.044090Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main3.csv', parse_dates=['date'])\n",
    "        .set_index('date')) / 1000\n",
    "\n",
    "cols = ['MenEU', 'WomenEU', 'MenEN', 'WomenEN', 'MenUE', 'WomenUE',\n",
    "        'MenUN', 'WomenUN', 'MenNE', 'WomenNE', 'MenNU', 'WomenNU']\n",
    "\n",
    "cols2 = []\n",
    "for col in cols:\n",
    "    name = f'{col}{col[-2]}'\n",
    "    cols2.append(name)\n",
    "    df[name] = (df[col] / df[f'{col[:-2]}{col[-2]}'].shift()) * 100\n",
    "\n",
    "df.loc['2013-01-01':, cols2].to_csv(data_dir / 'grosslf.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:34.663901Z",
     "start_time": "2023-07-25T15:18:34.631557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLS \\href{https://www.bls.gov/news.release/empsit.nr0.htm}{reports} 6.0 million unemployed people in June 2023, and an unemployment rate of 3.6 percent (see {\\color{blue!50!cyan}\\textbf{---}}), in line with the May 2023 rate of 3.7 percent. \n",
      "\n",
      "In June 2023, the labor under-utilization rate is 6.9 percent (see {\\color{blue}\\textbf{---}}). \n",
      "\n",
      "Periods of unemployment are more common for disadvantaged groups. The black or African American unemployment rate is typically double the white unemployment rate. Employment opportunities for disadvantaged groups are more-dependent on current labor market conditions. A very tight labor market reduces racial discrimination in hiring, while disadvantaged groups are more likely to lose jobs in a downturn. Since February 2020, the black unemployment rate has increased by 0.0 percentage point to 6.0 percent (see {\\color{green!50!teal!60!black}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'jobs_report_main.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "srs = ['Total', 'U6']\n",
    "df.loc['1989':, srs].to_csv(data_dir / 'unemp2.csv', index_label='date')\n",
    "\n",
    "srs = ['White', 'Black', 'Hispanic']\n",
    "df.loc['1989':, srs].to_csv(data_dir / 'unemp.csv', index_label='date')\n",
    "\n",
    "s = series_info(df['Level'])\n",
    "s2 = series_info(df['Total'])\n",
    "s3 = series_info(df['Black'])\n",
    "s4 = series_info(df['U6'])\n",
    "compare = compare_text(df['Total'].iloc[-1], df['Total'].iloc[-2], [0.15, 1.5, 3.0])\n",
    "compare2 = compare_text(df['Total'].iloc[-1], df['Total'].iloc[-13], [0.15, 1.5, 3.0])\n",
    "pryrdt = dtxt(df.index[-13])['mon1']\n",
    "\n",
    "if compare[-5:] != compare2[-5:]:\n",
    "    conj = f', but {compare2} the {pryrdt} rate of {df[\"Total\"].iloc[-13]:.1f} percent'\n",
    "elif compare != compare2:\n",
    "    conj = f', and {compare2} the {pryrdt} rate of {df[\"Total\"].iloc[-13]:.1f} percent'\n",
    "else:\n",
    "    conj = ''\n",
    "    \n",
    "text = ('BLS \\href{https://www.bls.gov/news.release/empsit.nr0.htm}{reports} '+\n",
    "        f'{s[\"val_latest\"]/1000:.1f} million '+\n",
    "        f'unemployed people in {s[\"date_latest_ft\"]}, '+\n",
    "        f'and an unemployment rate of {s2[\"val_latest\"]} percent '+\n",
    "        '(see {\\color{blue!50!cyan}\\\\textbf{---}}), '+\n",
    "        f'{compare} the {s[\"date_prev_ft\"]} rate of {s2[\"val_prev\"]} percent'+\n",
    "        f'{conj}.')\n",
    "write_txt(text_dir / 'unemp1.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "mval = f', {s4[\"last_matched\"]}.' if s4['days_since_match'] > 1000 else '.'\n",
    "text = (f'In {s[\"date_latest_ft\"]}, the labor under-utilization rate is '+\n",
    "        f'{s4[\"val_latest\"]} percent '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}})'+\n",
    "        f'{mval}')\n",
    "write_txt(text_dir / 'unemp2.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "write_txt(text_dir / 'u6_node.txt', \n",
    "          end_node(df['U6'], 'blue', date='m', percent=True, offset=0.4))\n",
    "write_txt(text_dir / 'u3_node.txt', end_node(df['Total'], 'blue!50!cyan', percent=True))\n",
    "\n",
    "black_ch = df['Black'].iloc[-1] - df.loc['2020-02-01', 'Black']\n",
    "bch = value_text(black_ch, style='increase_by', ptype='pp')\n",
    "text = ('Periods of unemployment are more common for disadvantaged groups. '+\n",
    "        'The black or African American unemployment rate is typically '+\n",
    "        'double the white unemployment rate. Employment opportunities for '+\n",
    "        'disadvantaged groups are more-dependent on current labor market '+\n",
    "        'conditions. A very tight labor market reduces racial '+\n",
    "        'discrimination in hiring, while disadvantaged groups are more '+\n",
    "        'likely to lose jobs in a downturn. '+\n",
    "        'Since February 2020, the black unemployment rate '+\n",
    "        f'has {bch} to {s3[\"val_latest\"]:.1f} percent '+\n",
    "        '(see {\\color{green!50!teal!60!black}\\\\textbf{---}}).')\n",
    "write_txt(text_dir / 'unemp3.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:35.574409Z",
     "start_time": "2023-07-25T15:18:35.535793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Jun `23</th>\n",
       "      <th>May `23</th>\n",
       "      <th>Apr `23</th>\n",
       "      <th>Mar `23</th>\n",
       "      <th>Feb `23</th>\n",
       "      <th>Jan `23</th>\n",
       "      <th>GFC peak</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under-utilization Rate (U6)</th>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Dec `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployment Rate (U3)</th>\n",
       "      <td>3.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Oct `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\textit{by race/ethnicity:}</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} White</th>\n",
       "      <td>3.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Oct `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Black</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>Mar `10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Hispanic</th>\n",
       "      <td>4.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Aug `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Asian</th>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Dec `09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Jun `23 May `23 Apr `23 Mar `23 Feb `23 Jan `23  \\\n",
       "Under-utilization Rate (U6)     6.9     6.7     6.6     6.7     6.8     6.6   \n",
       "Unemployment Rate (U3)          3.6     3.7     3.4     3.5     3.6     3.4   \n",
       "\\textit{by race/ethnicity:}                                                   \n",
       "\\hspace{2mm} White              3.1     3.3     3.1     3.2     3.2     3.1   \n",
       "\\hspace{2mm} Black              6.0     5.6     4.7     5.0     5.7     5.4   \n",
       "\\hspace{2mm} Hispanic           4.3     4.0     4.4     4.6     5.3     4.5   \n",
       "\\hspace{2mm} Asian              3.2     2.9     2.8     2.8     3.4     2.8   \n",
       "\n",
       "                            GFC peak     Date  \n",
       "Under-utilization Rate (U6)     17.2  Dec `09  \n",
       "Unemployment Rate (U3)          10.0  Oct `09  \n",
       "\\textit{by race/ethnicity:}                    \n",
       "\\hspace{2mm} White               9.2  Oct `09  \n",
       "\\hspace{2mm} Black              16.8  Mar `10  \n",
       "\\hspace{2mm} Hispanic           13.0  Aug `09  \n",
       "\\hspace{2mm} Asian               8.4  Dec `09  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs = ['U6', 'Total', 'White', 'Black', 'Hispanic', 'Asian']\n",
    "untab = df[srs].iloc[-6:].iloc[::-1].T\n",
    "untab.columns = untab.columns.strftime('%b `%y')\n",
    "untab['GFC peak'] = df.loc['2005':'2013', srs].max()\n",
    "untab['Date'] = df.loc['2005':'2013', srs].idxmax().dt.strftime('%b `%y')\n",
    "d = {'Total': 'Unemployment Rate (U3)',\n",
    "     'U6': 'Under-utilization Rate (U6)',\n",
    "     'White': '\\hspace{2mm} White',\n",
    "     'Black': '\\hspace{2mm} Black',\n",
    "     'Hispanic': '\\hspace{2mm} Hispanic',\n",
    "     'Asian': '\\hspace{2mm} Asian'}\n",
    "untab.index = untab.index.map(d)\n",
    "\n",
    "untab.loc['\\\\textit{by race/ethnicity:}', untab.columns] = [''] * 8\n",
    "untab = pd.concat([untab.iloc[0:2], untab.iloc[-1].to_frame().T, untab.iloc[2:6]])\n",
    "untab.columns.name = None\n",
    "untab.to_csv(data_dir / 'unemp1.tex', sep='&', lineterminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "untab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Participation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:39.230250Z",
     "start_time": "2023-07-25T15:18:39.205010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the latest data, covering June 2023, 62.6 percent of people age 16 and older are in the labor force (see {\\color{green!70!blue}\\textbf{---}}), compared to 62.6 percent in May and 62.6 percent in April. In February 2020, when US confirmed cases of COVID-19 were still low, the labor force participation rate was 63.3 percent.\n",
      "\n",
      "In June 2023, 68.1 percent of men age 16 and older are in the labor force (see {\\color{blue!90!cyan}\\textbf{---}}), compared to 57.3 percent of women (see {\\color{orange!90!red}\\textbf{---}}). Since February 2020, labor force participation has decreased 1.1 percentage points among men, and decreased 0.5 percentage point among women.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))[['MenLFPR', 'WomenLFPR']]\n",
    "df['TotLFPR'] = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                             parse_dates=['date'])\n",
    "                   .assign(TotLFPR = lambda x: (x.LF / x.POP)*100)\n",
    "                   .set_index('date'))['TotLFPR']\n",
    "df.loc['1989':].to_csv(data_dir / 'lfpr.csv', index_label='date')\n",
    "\n",
    "col = {'MenLFPR': 'blue!90!cyan',\n",
    "       'WomenLFPR': 'orange!90!red',\n",
    "       'TotLFPR': 'green!70!blue'}\n",
    "nodes = (end_node(df['MenLFPR'], col['MenLFPR'], \n",
    "                  percent=True, date='m', full_year=True, \n",
    "                  offset=0.35) + '\\n' + \n",
    "         '\\n'.join(end_node(df[name], color, percent=True) \n",
    "                   for name, color in col.items() if name != 'MenLFPR'))\n",
    "write_txt(text_dir / 'lfpr_nodes.txt', nodes)\n",
    "\n",
    "tot = df['TotLFPR']\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "write_txt(text_dir / 'lfpr_blsdate.txt', ltdt)\n",
    "prdt, prdt2 = (dtxt(df.index[i])['mon3'] \n",
    "               if df.index[-1].year == df.index[i].year \n",
    "               else dtxt(df.index[i])['mon1'] \n",
    "               for i in [-2, -3])\n",
    "cpdt = '2020-02-01'\n",
    "compdt = dtxt(cpdt)['mon1']\n",
    "feb20val = tot.loc[cpdt]\n",
    "mltval = df['MenLFPR'].iloc[-1]\n",
    "wltval = df['WomenLFPR'].iloc[-1]\n",
    "mchval = mltval - df['MenLFPR'].loc['2020-01-01']\n",
    "wchval = wltval - df['WomenLFPR'].loc['2020-01-01']\n",
    "mch = value_text(mchval, style='increase', ptype='pp')\n",
    "wch = value_text(wchval, style='increase', ptype='pp')\n",
    "cl = {k: c_line(v) for k, v in col.items()}\n",
    "text = (f'In the latest data, covering {ltdt}, {tot.iloc[-1]:.1f} '+\n",
    "        'percent of people age 16 and older are in the labor force '+\n",
    "        f'{cl[\"TotLFPR\"]}, compared to {tot.iloc[-2]:.1f} percent in '+\n",
    "        f'{prdt} and {tot.iloc[-3]:.1f} percent in {prdt2}. In '+\n",
    "        f'{compdt}, when US confirmed cases of COVID-19 were still '+\n",
    "        f'low, the labor force participation rate was {feb20val:.1f} '+\n",
    "        f'percent.\\n\\nIn {ltdt}, {mltval:.1f} percent of men age '+\n",
    "        f'16 and older are in the labor force {cl[\"MenLFPR\"]}, compared to '+\n",
    "        f'{wltval:.1f} percent of women {cl[\"WomenLFPR\"]}. Since '+\n",
    "        f'{compdt}, labor force participation has {mch} among men, '+\n",
    "        f'and {wch} among women.')\n",
    "write_txt(text_dir / 'lfpr_text.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:41.329723Z",
     "start_time": "2023-07-25T15:18:41.239035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of June 2023, the Bureau of Labor Statistics \\href{https://data.bls.gov/timeseries/LNS12300000}{report} an overall (age 16 and older) employment rate of 60.3 percent (see {\\color{green!60!black}\\textbf{---}}), a one-year increase of 0.4 percentage point, but a 0.5 percentage point decrease since 2019.\n",
      "In June 2023, 80.9 percent of 25 to 54 years olds were employed (see {\\color{blue!90!cyan}\\textbf{---}}), the highest level since April 2001. Over the past year, the age 25 to 54 employment rate increased 1.1 percentage points. The June 2023 rate is 0.5 percentage point (equivalent to 690,000 workers) below the average rate of 81.4 during the tight labor market of 1999--2000.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://data.bls.gov/timeseries/LNS12300000'\n",
    "pa_url = 'https://data.bls.gov/timeseries/LNS12300060'\n",
    "df1 = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, 'PA_EPOP'])\n",
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, 'EPOP'])\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df.to_csv(data_dir / 'epop.csv', index_label='date')\n",
    "\n",
    "color = 'green!60!black'\n",
    "node = end_node(df['EPOP'], color, date='m', percent=True, \n",
    "                full_year=True)\n",
    "write_txt(text_dir / 'epop_node2.txt', node)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "ltval = df['EPOP'].iloc[-1]\n",
    "chval = df['EPOP'].diff(12).iloc[-1]\n",
    "chtxt = value_text(chval, 'increase_of', ptype='pp', time_str='one-year ')\n",
    "chval2 = df['EPOP'].iloc[-1] - df.loc['2019', 'EPOP'].mean()\n",
    "chtxt2 = value_text(chval2, style='increase_end', ptype='pp')\n",
    "ab = 'but'\n",
    "if ((chval<0) == (chval2<0)) == True:\n",
    "    ab = 'and'\n",
    "text = (f'As of {ltdt}, the Bureau of Labor Statistics '+\n",
    "        f'\\href{{{url}}}{{report}} '+\n",
    "        f'an overall (age 16 and older) employment rate of {ltval} '+\n",
    "        f'percent {c_line(color)}, {chtxt}, {ab} {chtxt2} since 2019.')\n",
    "write_txt(text_dir / 'epop_text2.txt', text)\n",
    "print(text)\n",
    "\n",
    "color = 'blue!90!cyan'\n",
    "adj = 0\n",
    "if (df['PA_EPOP'].iloc[-1] / df['PA_EPOP'].max()) > 0.95:\n",
    "    adj = -0.25\n",
    "elif (df['PA_EPOP'].iloc[-1] / df['PA_EPOP'].max()) > 1:\n",
    "    adj = -0.4\n",
    "node = end_node(df['PA_EPOP'], color, date='m', percent=True, \n",
    "                full_year=True, offset=adj)\n",
    "write_txt(text_dir / 'epop_node.txt', node)\n",
    "\n",
    "ltval = df['PA_EPOP'].iloc[-1]\n",
    "prval = df['PA_EPOP'].iloc[-2]\n",
    "prdt = dtxt(df['PA_EPOP'].index[-2])['mon1']\n",
    "prtxt = f'compared to {prval} percent in {prdt}'\n",
    "compval = df['PA_EPOP'].loc['2019-06-01': '2020-03-01'].max()\n",
    "last = series_info(df['PA_EPOP'])['last_matched']\n",
    "text2 = prtxt if ltval < compval else last\n",
    "chtxt = value_text(df['PA_EPOP'].diff(12).iloc[-1], ptype='pp', threshold=0.1)\n",
    "\n",
    "pop = (cps_1mo(cps_dir, cps_date(), ['BASICWGT', 'AGE'])\n",
    "       .query('25 <= AGE <=54').BASICWGT.sum()) / 1_000\n",
    "rt99 = df['PA_EPOP'].loc['1999': '2000'].mean()\n",
    "ch99 =  ltval - rt99\n",
    "ch99w = (-ch99 / 100) * pop\n",
    "ch99t = (f'{round(abs(ch99w) / 1000, 1)} million' \n",
    "         if ch99w > 999 else f'{round(abs(ch99w), -1):.0f},000')\n",
    "ch99t2 = f'(equivalent to {ch99t} workers)'\n",
    "threshold = 0.1\n",
    "txt = value_text(ch99, style='above_below', \n",
    "                 ptype='pp', threshold=threshold)\n",
    "if abs(ch99) > threshold:\n",
    "    ch99txt = f'{txt[:-6]} {ch99t2} {txt[-5:]}'\n",
    "else:\n",
    "    ch99txt = txt\n",
    "text = (f'In {ltdt}, {ltval} percent of 25 to 54 years olds were '+\n",
    "        f'employed {c_line(color)}, {text2}. Over the past year, '+\n",
    "        f'the age 25 to 54 employment rate {chtxt}. The {ltdt} rate '+\n",
    "        f'is {ch99txt} the average rate of {rt99:.1f} during the '+\n",
    "        'tight labor market of 1999--2000.')\n",
    "write_txt(text_dir / 'epop_text.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment by reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:46.174017Z",
     "start_time": "2023-07-25T15:18:44.550037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several \\textbf{reasons for unemployment}. In June 2023, 2.9 million people, or 1.7 percent of the labor force, were unemployed from losing their job (see \\cbox{red!75!orange!70!white}). An additional 0.5 percent voluntarily left a job (see \\cbox{blue!72!black}). Re-entrants, people who left the labor force but are looking for a new job, comprised 1.0 percent (see \\cbox{blue!70!teal!70!gray!62!white}). Lastly, 0.3 percent of the labor force were new entrants to the labor market, looking for their first job (see \\cbox{purple!80!red!85!black}).\n",
      "\n",
      " In June 2023, temporary layoffs were 0.5 percent of the labor force. Permanent job losses were 0.9 percent of labor force. \n"
     ]
    }
   ],
   "source": [
    "srs = ['Job Loser', 'Job Leaver', 'Re-entrant', 'New entrant', \n",
    "       'Temporary Layoff', 'Permanent Separation', 'Level']\n",
    "d1 = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':]\n",
    "\n",
    "df = d1[srs].div(d1['LF'], axis='index') * 100\n",
    "dfa = df.resample('AS').mean()\n",
    "dfa.index = dfa.index + pd.DateOffset(months=6)\n",
    "dfa.to_csv(data_dir / 'unemp_reason.csv', index_label='date', \n",
    "          float_format='%g')\n",
    "\n",
    "lt = df.iloc[-3:]\n",
    "lt.index = [dtxt(i)['mon7'] for i in lt.index]\n",
    "lt = pd.concat([df.rolling(12).mean().iloc[-1].rename('12m avg'), lt.T], axis=1).T\n",
    "lt.to_csv(data_dir / 'unemp_reason_mon.csv', index_label='date', \n",
    "          float_format='%g')\n",
    "\n",
    "x_val = dtxt(dfa.index[-1])['datetime']\n",
    "x_valpr = dtxt(dfa.index[-2])['datetime']\n",
    "y_val = dfa.Level.iloc[-1]\n",
    "prelim = '(p)' if df.index[-1].month != 12 else ''\n",
    "yrp = f'{dtxt(dfa.index[-1])[\"year\"][2:]}{prelim}'\n",
    "barh = ('\\\\addplot[ybar, bar width=5.4pt, draw=black, fill=white!0] '+\n",
    "        f'plot coordinates{{({x_val},{y_val})}};\\n'+\n",
    "        f'\\\\absnode{{{x_valpr}}}{{-0.25}}{{\\scriptsize \\color{{black!70}} {yrp}}};')\n",
    "write_txt(text_dir / 'unemp_rsn_ltbar.txt', barh)\n",
    "\n",
    "cols = ['Job Loser', 'New entrant', 'Re-entrant', 'Job Leaver']\n",
    "sdf = lt[cols].iloc[-1]\n",
    "height = ((sdf.cumsum() - (sdf / 2) + 0.25)).to_dict()\n",
    "val = sdf.to_dict()\n",
    "nodes = [f'\\\\absnode{{3.3}}{{{height[i]}}}{{\\scriptsize {val[i]:.1f}}}' for i in cols]\n",
    "nodetext = '\\n'.join(nodes)\n",
    "write_txt(text_dir / 'unemp_rsn_ltval.txt', nodetext)\n",
    "\n",
    "colors = {'Job Loser': 'red!75!orange!70!white', 'New entrant': 'purple!80!red!85!black', \n",
    "          'Re-entrant': 'blue!70!teal!70!gray!62!white', 'Job Leaver': 'blue!72!black'}\n",
    "cl = {k: c_box(v) for k, v in colors.items()}\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "lt = df.iloc[-1]\n",
    "jlsh = lt['Job Loser']\n",
    "jl = (d1['Job Loser'].iloc[-1] / 1_000)\n",
    "jle = lt['Job Leaver']\n",
    "re = lt['Re-entrant']\n",
    "ne = lt['New entrant']\n",
    "text = ('There are several \\\\textbf{reasons for unemployment}. In '+\n",
    "        f'{ltdt}, {jl:.1f} million people, or {jlsh:.1f} percent of '+\n",
    "        'the labor force, were unemployed from losing their job '+\n",
    "        f'{cl[\"Job Loser\"]}. An additional {jle:.1f} percent '+\n",
    "        f'voluntarily left a job {cl[\"Job Leaver\"]}. Re-entrants, '+\n",
    "        'people who left the labor force but are looking for a new '+\n",
    "        f'job, comprised {re:.1f} percent {cl[\"Re-entrant\"]}. Lastly, '+\n",
    "        f'{ne:.1f} percent of the labor force were new entrants to '+\n",
    "        f'the labor market, looking for their first job '+\n",
    "        f'{cl[\"New entrant\"]}.')\n",
    "write_txt(text_dir / 'unemp_rsn.txt', text)\n",
    "print(text)\n",
    "\n",
    "lf = ['Employed', 'Unemployed']\n",
    "naw_rate = lambda x: np.average(x['NOTATWORK'], weights=x['BASICWGT'])\n",
    "\n",
    "columns = ['LFS', 'MONTH', 'YEAR', 'BASICWGT', 'NOTATWORK']\n",
    "\n",
    "naw = (pd.concat([(pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "              .query('LFS in @lf'))\n",
    "           for year in range(2009, 2024)])\n",
    "        .groupby(['YEAR', 'MONTH'])\n",
    "        .apply(naw_rate) * 100)\n",
    "naw.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in naw.index]\n",
    "df['Employed, Not at Work'] = naw\n",
    "\n",
    "tbl = df.iloc[-3:].T.iloc[:, ::-1]\n",
    "tbl.columns = [dtxt(i)['mon2'] for i in tbl.columns]\n",
    "tbl['12m Avg.'] = df.rolling(12).mean().iloc[-1]\n",
    "tbl['Apr 2020'] = df.loc['2020-04-01']\n",
    "tbl['2020'] = df.loc['2020'].mean()\n",
    "tbl['2019'] = df.loc['2019'].mean()\n",
    "tbl['2009 --`11'] = df.loc['2009': '2011'].mean()\n",
    "tbl = tbl.round(1)\n",
    "d = {'Level': '\\ Unemployed, Any Reason',\n",
    "     'Job Loser': f'\\hspace{{2mm}}\\cbox{{{colors[\"Job Loser\"]}}} Job Loser',\n",
    "     'Temporary Layoff': '\\hspace{9mm}Temporary Layoff',\n",
    "     'Permanent Separation': '\\hspace{9mm}Permanent Separation',\n",
    "     'Re-entrant': f'\\hspace{{2mm}}\\cbox{{{colors[\"Re-entrant\"]}}} Re-entrant',\n",
    "     'New entrant': f'\\hspace{{2mm}}\\cbox{{{colors[\"New entrant\"]}}} New entrant',\n",
    "     'Job Leaver': f'\\hspace{{2mm}}\\cbox{{{colors[\"Job Leaver\"]}}} Job Leaver'}\n",
    "\n",
    "final = tbl.loc[d.keys()].rename(d)\n",
    "\n",
    "final.loc['\\\\textit{See also:}', final.columns] = [''] * 8\n",
    "final.loc['\\ \\ Employed, Not at Work*'] = tbl.loc['Employed, Not at Work']\n",
    "final.to_csv(data_dir / 'unempreason_table.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "tl = lt['Temporary Layoff']\n",
    "pjl = lt['Permanent Separation']\n",
    "\n",
    "text = (f'In {ltdt}, temporary layoffs were {tl:.1f} percent of '+\n",
    "        f'the labor force. Permanent job losses were {pjl:.1f} '+\n",
    "        'percent of labor force. ')\n",
    "write_txt(text_dir / 'unemp_rsn2.txt', text)\n",
    "print('\\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployed long-term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:49.088111Z",
     "start_time": "2023-07-25T15:18:49.071288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of June 2023, BLS \\href{https://www.bls.gov/webapps/legacy/cpsatab12.htm}{reports} that 0.39 percent of the age 16 and older population have been unemployed for 27 weeks or longer, compared to 0.49 percent in June 2022 (see {\\color{blue}\\textbf{---}}). This measure of \\textbf{long-term unemployment} peaked at 2.96 percent of the population in April 2010, but had fallen to 0.42 percent in December 2019. \n",
      " \n",
      "In June 2023, 0.71 percent of those age 16 and older have been unemployed for at least 15 weeks (see {\\color{violet!90!black}\\textbf{---}}), following 0.80 percent in May 2023, and 0.77 percent in April 2023.\n"
     ]
    }
   ],
   "source": [
    "srs = ['LT', 'MT', 'POP']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, srs]\n",
    "\n",
    "data = (df.divide(df['POP'], axis=0) * 100).drop(['POP'], axis=1)\n",
    "data.to_csv(data_dir / 'ltu.csv', index_label='date', float_format='%g')\n",
    "\n",
    "node = end_node(data['LT'], 'blue', percent=True, \n",
    "                date='m', full_year=True, offset=0.35)\n",
    "write_txt(text_dir / 'ltu_node.txt', node)\n",
    "\n",
    "node = end_node(data['MT'], 'violet!90!black', percent=True, \n",
    "                date='m', full_year=True, offset=0.35)\n",
    "write_txt(text_dir / 'ltu_node2.txt', node)\n",
    "\n",
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "pdate = dtxt(data.index[-13])['mon1']\n",
    "hdate = dtxt(data['LT'].idxmax())['mon1']\n",
    "prdt = dtxt(data.index[-2])['mon1']\n",
    "prdt2 = dtxt(data.index[-3])['mon1']\n",
    "\n",
    "recent_min = data.loc['2015':'2020-02-01', 'LT'].min()\n",
    "recent_min_dt = dtxt(data.loc['2015':'2020-02-01', 'LT'].idxmin())['mon1']\n",
    "\n",
    "text = (f'As of {ldate}, BLS '+\n",
    "        '\\href{https://www.bls.gov/webapps/legacy/cpsatab12.htm}{reports} '+\n",
    "        f'that {data[\"LT\"].iloc[-1]:.2f} percent of the age 16 and older '+\n",
    "         'population have been unemployed for 27 weeks or longer, '+\n",
    "        f'compared to {data[\"LT\"].iloc[-13]:.2f} percent in {pdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}). This measure of \\\\textbf{long-term '+\n",
    "        f'unemployment}} peaked at {data[\"LT\"].max():.2f} percent of the '+\n",
    "        f'population in {hdate}, but had fallen to {recent_min:.2f} percent '+\n",
    "        f'in {recent_min_dt}. \\n \\nIn {ldate}, {data[\"MT\"].iloc[-1]:.2f} '+\n",
    "        'percent of those age 16 and older have been unemployed for at '+\n",
    "        'least 15 weeks (see {\\color{violet!90!black}\\\\textbf{---}}), following '+\n",
    "        f'{data[\"MT\"].iloc[-2]:.2f} percent in {prdt}, '+\n",
    "        f'and {data[\"MT\"].iloc[-3]:.2f} percent in {prdt2}.')\n",
    "write_txt(text_dir / 'ltu.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:51.192519Z",
     "start_time": "2023-07-25T15:18:51.157476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among those who are unemployed in June 2023, the average (mean) \\textbf{duration of unemployment} is 20.7 weeks (see {\\color{blue!60!cyan}\\textbf{---}}), and the typical (median) duration of unemployment is 8.7 weeks (see {\\color{green!75!blue}\\textbf{---}}). Over the year prior to COVID-19, ending February 2020, the average duration of unemployment was 21.7 weeks and the typical duration was 9.3 weeks.\n"
     ]
    }
   ],
   "source": [
    "s = {'Median': 'green!75!blue', 'Mean': 'blue!60!cyan'}\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, s.keys()]\n",
    "df.to_csv(data_dir / 'unempdur.csv', index_label='date', \n",
    "          float_format='%g')\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "lt = df.iloc[-1]\n",
    "\n",
    "adj = node_adj(df)\n",
    "smax = df.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in s.keys()}\n",
    "nodes  ='\\n'.join([end_node(df[series], color, \n",
    "                            date=date[series], full_year=True, \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in s.items()])\n",
    "write_txt(text_dir / 'unempdur_nodes.txt', nodes) \n",
    "\n",
    "pc_yr = df.loc['2019-03-01':'2020-02-01'].mean()\n",
    "text = (f'Among those who are unemployed in {ltdt}, the average '+\n",
    "        f'(mean) \\\\textbf{{duration of unemployment}} is {lt.Mean:.1f} '+\n",
    "        f'weeks {c_line(s[\"Mean\"])}, and the typical (median) '+\n",
    "        f'duration of unemployment is {lt.Median:.1f} weeks '+\n",
    "        f'{c_line(s[\"Median\"])}. Over the year '+\n",
    "        'prior to COVID-19, ending February 2020, the '+\n",
    "        'average duration of unemployment was '+\n",
    "        f'{pc_yr.Mean:.1f} weeks and the typical '+\n",
    "        f'duration was {pc_yr.Median:.1f} weeks.')\n",
    "write_txt(text_dir / 'unempdur.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-Time Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:53.472618Z",
     "start_time": "2023-07-25T15:18:53.438967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 25 million people work part-time, defined as fewer than 35 hours per week, and the reasons for doing so vary. \n",
      "\n",
      "In June 2023, 4.2 million people worked part-time for economic reasons, equivalent to 2.5 percent of the labor force (see {\\color{red}\\textbf{---}}). In 2019, an average of 2.7 percent of the labor force worked part-time for economic reasons; in 2010, following the great recession, the rate was 5.8 percent.\n",
      "\n",
      "Voluntary part-time workers total 21.3 million in June 2023, or 12.7 percent of the labor force (see {\\color{orange!80!yellow}\\textbf{---}}). The category made up 13.1 percent of the labor force in 2019, on average.\n"
     ]
    }
   ],
   "source": [
    "srs = ['PTECON', 'PTNONECON', 'LF']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, srs])\n",
    "df['TOTAL'] = df['PTECON'] + df['PTNONECON']\n",
    "# Total part-time for summary text\n",
    "text = (f'Around {df.TOTAL.iloc[-1] / 1000:.0f} million people '+\n",
    "        'work part-time, defined as fewer than 35 hours per week, '+\n",
    "        'and the reasons for doing so vary.')\n",
    "\n",
    "write_txt(text_dir / 'pt_tot.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "# Share of labor force\n",
    "data = (df.divide(df.LF, axis=0) * 100)\n",
    "data = data.loc['1994':, ['PTECON', 'PTNONECON', 'TOTAL']]\n",
    "data.to_csv(data_dir / 'parttime.csv', index_label='date')\n",
    "\n",
    "color = 'red'\n",
    "col2 = 'orange!80!yellow'\n",
    "node = end_node(data.PTECON, color, date='m', percent=True, \n",
    "                offset=True)\n",
    "node2 = end_node(data.PTNONECON, col2, percent=True)\n",
    "nodes = node + '\\n' + node2\n",
    "write_txt(text_dir / 'pt_nodes.txt', nodes)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "lttot = df.PTECON.iloc[-1] / 1_000\n",
    "ltvpt = df.PTNONECON.iloc[-1] / 1_000\n",
    "ltsh = data.PTECON.iloc[-1]\n",
    "val19 = data.loc['2019', 'PTECON'].mean()\n",
    "val10 = data.loc['2010', 'PTECON'].mean()\n",
    "ltvsh = data.PTNONECON.iloc[-1]\n",
    "vsh19 = data.loc['2019', 'PTNONECON'].mean()\n",
    "\n",
    "text = (f'In {ltdt}, {lttot:.1f} million people worked part-time '+\n",
    "        f'for economic reasons, equivalent to {ltsh:.1f} percent '+\n",
    "        f'of the labor force {c_line(color)}. In 2019, an average '+\n",
    "        f'of {val19:.1f} percent of the labor force worked part-time '+\n",
    "        'for economic reasons; in 2010, following the great '+\n",
    "        f'recession, the rate was {val10:.1f} percent.\\n\\nVoluntary '+\n",
    "        f'part-time workers total {ltvpt:.1f} million in {ltdt}, or '+\n",
    "        f'{ltvsh:.1f} percent of the labor force {c_line(col2)}. The '+\n",
    "        f'category made up {vsh19:.1f} percent of the labor force in '+\n",
    "        '2019, on average.')\n",
    "write_txt(text_dir / 'parttime.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Jobholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:55.298664Z",
     "start_time": "2023-07-25T15:18:55.286289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In June 2023, a seasonally-adjusted total of 8.0 million people \\textbf{worked more than one job} during the survey reference week, equivalent to 5.0 percent of workers. Over the three months ending June 2023, an average of 4.9 percent of workers were multiple jobholders (see {\\color{cyan!50!blue}\\textbf{---}}). In 2019, 5.1 percent of workers had more than one job during the survey reference week. \n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, ['MJHsa', 'EMPsa']])\n",
    "data = ((df.MJHsa / df.EMPsa) * 100).dropna().rename('MJH')\n",
    "d3m = data.rolling(3).mean()\n",
    "d3m.to_csv(data_dir / 'mjh.csv', index_label='date')\n",
    "color = 'cyan!50!blue'\n",
    "node = end_node(d3m, color, percent=True, size=1.2)\n",
    "write_txt(text_dir / 'mjh_node.txt', node)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "totval = df.MJHsa.iloc[-1] / 1_000\n",
    "ltval = f'{data.iloc[-1]:.1f}'\n",
    "l3val = f'{d3m.iloc[-1]:.1f}'\n",
    "l19val = data.loc['2019'].mean()\n",
    "comp_date = '2020-02-01'\n",
    "same = 'Over' # Less awkward text when latest and 3ma match\n",
    "if ltval == l3val:\n",
    "    same = 'Likewise, over'\n",
    "\n",
    "text = (f'In {ltdt}, a seasonally-adjusted total of {totval:.1f} '+\n",
    "        'million people \\\\textbf{worked '+\n",
    "        'more than one job} during the survey reference week, '+\n",
    "        f'equivalent to {ltval} percent of workers. '+\n",
    "        f'{same} the three months ending {ltdt}, an average of '+\n",
    "        f'{l3val} percent of workers were multiple '\n",
    "        f'jobholders {c_line(color)}. In 2019, {l19val:.1f} '+\n",
    "        'percent of workers had more than one job during '+\n",
    "        'the survey reference week. ')\n",
    "write_txt(text_dir / 'mjh.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:57.064295Z",
     "start_time": "2023-07-25T15:18:57.037878Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1988':, ['seinc', 'seuninc', 'LFnsa']])\n",
    "\n",
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1988':, ['LF']])\n",
    "\n",
    "df3 = pd.read_csv(data_dir / 'se_inc_hist.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "\n",
    "uninc = (df['seuninc'].divide(df2['LF'], axis=0) * 100).rename('uninc')\n",
    "inc = (df['seinc'].divide(df['LFnsa'], axis=0) * 100).rename('inc')\n",
    "INC = (df3.INC.divide(df['LFnsa'], axis=0) / 10).rename('INC')\n",
    "res = uninc.to_frame().join(inc).join(INC).loc['1989':]\n",
    "res.to_csv(data_dir / 'selfemp.csv', index_label='date')\n",
    "dft = res[['inc', 'uninc']]\n",
    "\n",
    "adj = node_adj(dft)\n",
    "smax = dft.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'inc': 'green!80!black', \n",
    "          'uninc': 'purple'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(dft[series], color, \n",
    "                            date=date[series], \n",
    "                            percent=True, full_year=True, \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'selfemp_nodes.txt', nodes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:18:57.830007Z",
     "start_time": "2023-07-25T15:18:57.804196Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of June 2023, there are 9.6 million \\textbf{unincorporated self-employed}, equivalent to 5.7 percent of the labor force (see {\\color{purple}\\textbf{---}}). Over the past year, the unincorporated self-employed made up an average of 5.9 percent of the labor force, compared to an average of 5.8 percent in 2019. From 1989 to 1994, the category made up an average of 8.0 percent of the labor force.  \n",
      "\n",
      "The \\textbf{incorporated self-employed} total 6.8 million in June 2023, equivalent to 4.1 percent of the labor force (see {\\color{green!80!black}\\textbf{---}}). In 2019, the category made up 3.8 percent of the labor force. Incorporated self-employed are not reported by BLS prior to 2000, but can be calculated from the CPS, and make up a average of 2.8 percent of the labor force from 1989 to 1994. \n"
     ]
    }
   ],
   "source": [
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "seutot = df['seuninc'].iloc[-1] / 1_000\n",
    "seush = res['uninc'].iloc[-1]\n",
    "seu1yr = res['uninc'].iloc[-12:].mean()\n",
    "seu19 = res.loc['2019', 'uninc'].mean()\n",
    "seu89 = res.loc['1989':'1994', 'uninc'].mean()\n",
    "\n",
    "text = (f'As of {ltdt}, there are {seutot:.1f} million \\\\textbf{{unincorporated '+\n",
    "        f'self-employed}}, equivalent to {seush:.1f} percent of the labor '+\n",
    "        f'force {c_line(colors[\"uninc\"])}. Over the past year, the '+\n",
    "        f'unincorporated self-employed made up an average of {seu1yr:.1f} '+\n",
    "        f'percent of the labor force, compared to an average of {seu19:.1f} '+\n",
    "        'percent in 2019. From 1989 to 1994, the category made up an '+\n",
    "        f'average of {seu89:.1f} percent of the labor force. ')\n",
    "write_txt(text_dir / 'selfemp1.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "seitot = df['seinc'].iloc[-1] / 1_000\n",
    "seish = res['inc'].iloc[-1]\n",
    "sei19 = res.loc['2019', 'inc'].mean()\n",
    "sei89 = res.loc['1989':'1994', 'INC'].mean()\n",
    "\n",
    "text = (f'The \\\\textbf{{incorporated self-employed}} total {seitot:.1f} million '+\n",
    "        f'in {ltdt}, equivalent to {seish:.1f} percent of the labor force '+\n",
    "        f'{c_line(colors[\"inc\"])}. In 2019, the category made up {sei19:.1f} percent '+\n",
    "        'of the labor force. Incorporated self-employed are not reported by '+\n",
    "        'BLS prior to 2000, but can be calculated from the CPS, and make up a '+\n",
    "        f'average of {sei89:.1f} percent of the labor force from 1989 to 1994. ')\n",
    "print(text)\n",
    "write_txt(text_dir / 'selfemp2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Weekly Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:19:00.282092Z",
     "start_time": "2023-07-25T15:18:59.742742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:203: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in one or more of the estimated spectra.\n",
      "  warn(errors, X13Warning)\n",
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:203: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in the estimated spectrum of the regARIMA residuals.\n",
      "  warn(errors, X13Warning)\n"
     ]
    }
   ],
   "source": [
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['TOTCES'] = df2['ceshrstot']\n",
    "data['TOTLFS'] = df2['avghrstot']\n",
    "data['SERVNSA'] = df2['avghrsserv']\n",
    "data['SERVSA'] = x13_arima_analysis(df2['avghrsserv'].dropna()).seasadj\n",
    "data['PNS'] = df2['ceshrspns']\n",
    "data['PTECONNSA'] = df2['avghrsptecon']\n",
    "data['PTECONSA'] = x13_arima_analysis(df2['avghrsptecon'].dropna()).seasadj\n",
    "\n",
    "data.loc['1989':].to_csv(data_dir / 'hours.csv', index_label='date')\n",
    "\n",
    "ltval = data['TOTLFS'].iloc[-1]\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "feb20val = data.loc['2020-02-01', 'TOTLFS']\n",
    "compare = compare_text(ltval, feb20val, [0.2, 1.5, 3.0])\n",
    "avg90 = data.loc['1998':'2000', 'TOTLFS'].mean()\n",
    "gfclow = data.loc['2005': '2012', 'TOTLFS'].min()\n",
    "gfclowdt = dtxt(data.loc['2005': '2012', 'TOTLFS'].idxmin())['mon1']\n",
    "#data.plot(color=['blue', 'lime', 'darkgreen', 'orange', 'lightpink', 'red'], figsize=(3, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:19:01.652563Z",
     "start_time": "2023-07-25T15:19:01.634864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual hours worked by people at work in all industries during the survey reference week average 38.5 in June 2023 (see {\\color{blue}\\textbf{---}}), slightly below the 38.8 average actual hours worked in February 2020. Average actual hours for this group average 39.6 from 1998 through 2000, and fell to a great recession low of 37.4 in February 2010.\n",
      "Those in service occupations (see {\\color{green!90!blue!70!black}\\textbf{---}}) work fewer hours on average, with 35.0 average weekly hours in June 2023, slightly below the 35.2 average in February 2020. Those part-time for economic reasons (see {\\color{red!90!black}\\textbf{---}}) work an average of 23.0 hours per week in June 2023. \n",
      "In June 2023, production and non-supervisory workers (see {\\color{orange}\\textbf{---}}), about four of every five employees, worked 33.8 hours per week on average, in line with the 33.6 average weekly hours in February 2020 and slightly below the 1998--2000 average of 34.4 hours.\n"
     ]
    }
   ],
   "source": [
    "text = ('Actual hours worked by people at work in all industries '+\n",
    "        f'during the survey reference week average {ltval:.1f} in {ltdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}), '+\n",
    "        f'{compare} the {feb20val:.1f} average actual hours worked in February 2020. '+\n",
    "        f'Average actual hours for this group average {avg90:.1f} from '+\n",
    "        '1998 through 2000, and fell to a great recession low of '+\n",
    "        f'{gfclow:.1f} in {gfclowdt}.')\n",
    "\n",
    "write_txt(text_dir / 'hours_tot.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval2 = data.SERVSA.iloc[-1]\n",
    "feb20val2 = data.loc['2020-02-01', 'SERVSA']\n",
    "compare2 = compare_text(ltval2, feb20val2, [0.2, 0.6, 2.5])\n",
    "pteval = data.PTECONSA.iloc[-1]\n",
    "\n",
    "text = ('Those in service occupations (see '+\n",
    "        '{\\color{green!90!blue!70!black}\\\\textbf{---}}) '+\n",
    "        f'work fewer hours on average, with {ltval2:.1f} average '+\n",
    "        f'weekly hours in {ltdate}, {compare2} the {feb20val2:.1f} '+\n",
    "        'average in February 2020. Those part-time '+\n",
    "        'for economic reasons (see {\\color{red!90!black}\\\\textbf{---}}) '+\n",
    "        f'work an average of {pteval:.1f} hours per week in {ltdate}. ')\n",
    "\n",
    "write_txt(text_dir / 'hours_lfs2.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval3 = data.PNS.iloc[-1]\n",
    "feb20val3 = data.loc['2020-02-01', 'PNS']\n",
    "compare3 = compare_text(ltval3, feb20val3, [0.2, 0.6, 2.5])\n",
    "val98 = data.loc['1998':'2000', 'PNS'].mean()\n",
    "compare4 = compare_text(ltval3, val98, [0.2, 0.6, 2.5])\n",
    "\n",
    "text = (f'In {ltdate}, '+\n",
    "        'production and non-supervisory workers (see {\\color{orange}\\\\textbf{---}})'+\n",
    "        ', about four of every five employees, '+\n",
    "        f'worked {ltval3:.1f} hours per week on average, '+\n",
    "        f'{compare3} the {feb20val3:.1f} average weekly hours in February 2020 and '+\n",
    "        f'{compare4} the 1998--2000 average of {val98:.1f} hours.')\n",
    "\n",
    "write_txt(text_dir / 'hours_ces.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:19:03.186246Z",
     "start_time": "2023-07-25T15:19:03.163185Z"
    }
   },
   "outputs": [],
   "source": [
    "data['TOTCPS'] = pd.read_csv(data_dir / 'uslhrs.csv', index_col='name', parse_dates=True)\n",
    "\n",
    "d = {'TOTCES': 'Total Actual, CES',\n",
    "     'TOTLFS': 'Total Actual, LFS ({\\color{blue}\\\\textbf{---}})',\n",
    "     'TOTCPS': 'Total Usual, CPS',\n",
    "     'PNS': 'Production \\& Non-Supervisory, CES ({\\color{orange}\\\\textbf{---}} )',\n",
    "     'SERVSA': 'Services Occupations, LFS ({\\color{green!90!blue!70!black}\\\\textbf{---}} )',\n",
    "     'PTECONSA': 'Part-Time for Economic Reasons, LFS ({\\color{red!90!black}\\\\textbf{---}})'}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "loc_list = [-1, -2, -3, -13, -14, -15, -25]\n",
    "\n",
    "for key, value in d.items():\n",
    "    for i in loc_list:\n",
    "        final.loc[value, dtxt(data.index[i])['mon6']] = data[key].iloc[i].round(1)\n",
    "\n",
    "final.to_csv(data_dir / 'hoursworked_table.tex', sep='&', lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flows, Newly Employed, Not looking for work previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:19:05.170865Z",
     "start_time": "2023-07-25T15:19:05.124313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In June 2023, 6.4 million people were newly employed (on a gross basis). Of these, 74.6 percent were not looking for work in the prior month (see {\\color{lime!80!green}\\textbf{---}}). Over the past three months, an average of 74.8 percent of the newly employed were not looking for work the month prior (see {\\color{green!60!teal!80!black}\\textbf{---}}). When unemployment is low, the newly employed are more likely to come from outside of the labor force. Four years ago, in June 2019, 73.7 percent of the newly employed had not looked for work the previous month.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date')).loc['1990':, ['NILF', 'UNEMP']]\n",
    "df['TOTAL'] = df.astype('float').sum(axis=1)\n",
    "sh = (df['NILF'] / df['TOTAL']).rename('total') * 100\n",
    "\n",
    "sh.to_csv(data_dir / 'lf_flow.csv', index_label='date', \n",
    "          header=True, float_format='%g')\n",
    "ma = sh.resample('QS').mean().rename('quarterly')\n",
    "ma.to_csv(data_dir / 'lf_flow_q.csv', index_label='date', \n",
    "          header=True, float_format='%g')\n",
    "\n",
    "col = 'green!60!teal!80!black'\n",
    "col2 = 'lime!80!green'\n",
    "node = end_node(ma, col, percent=True, size=1.2)\n",
    "write_txt(text_dir / 'lf_flow_node.txt', node)\n",
    "\n",
    "totval = df['TOTAL'].iloc[-1] / 1000\n",
    "shval = sh.iloc[-1]\n",
    "maval = ma.iloc[-1] \n",
    "sh4y = sh.iloc[-49]\n",
    "\n",
    "ltdt = dtxt(sh.index[-1])['mon1']\n",
    "prdt = dtxt(sh.index[-49])['mon1']\n",
    "\n",
    "text = (f'In {ltdt}, {totval:.1f} million people were newly '+\n",
    "        f'employed (on a gross basis). Of these, {shval:.1f} '+\n",
    "        f'percent were not looking for work in the prior month '+\n",
    "        f'{c_line(col2)}. Over the past three months, an average '+\n",
    "        f'of {maval:.1f} percent of the newly employed were not '+\n",
    "        f'looking for work the month prior {c_line(col)}. When '+\n",
    "        'unemployment is low, the newly employed are more '+\n",
    "        'likely to come from outside of the labor force. Four '+\n",
    "        f'years ago, in {prdt}, {sh4y:.1f} percent of the newly '+\n",
    "        'employed had not looked for work the previous month.')\n",
    "write_txt(text_dir / 'lf_flow.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Hourly Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:19:06.733846Z",
     "start_time": "2023-07-25T15:19:06.701652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the year ending June 2023, \\textbf{average hourly earnings} increased by 4.4 percent for all employees (see {\\color{magenta}\\textbf{---}}) and increased by 4.7 percent for production and non-supervisory workers (see {\\color{blue!80!black}\\textbf{---}}), according to the Bureau of Labor Statistics. Comparing the latest three months to the previous three months, average earnings increased at an annual rate of 4.3 percent for all employees and increased at an annual rate of 4.5 percent for production and non-supervisory employees.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date'))[['ALL', 'PNS']]\n",
    "data = (df.pct_change(12) * 100)\n",
    "d3 = m3rate(df).rename({'ALL': 'ALL_3M', 'PNS': 'PNS_3M'}, axis=1)\n",
    "data = data.join(d3).loc['1989':]\n",
    "data.to_csv(data_dir / 'ahe.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "lt = data.iloc[-1]\n",
    "all_lt = value_text(lt.ALL, style='increase_by')\n",
    "pns_lt = value_text(lt.PNS, style='increase_by')\n",
    "all_3m = value_text(lt.ALL_3M, style='increase_by', adj='annual')\n",
    "pns_3m = value_text(lt.PNS_3M, style='increase_by', adj='annual')\n",
    "cla = c_line('magenta')\n",
    "clp = c_line('blue!80!black')\n",
    "text = (f'Over the year ending {ltdt}, \\\\textbf{{average hourly earnings}} '+\n",
    "        f'{all_lt} for all employees {cla} and {pns_lt} for production '+\n",
    "        f'and non-supervisory workers {clp}, according to the '+\n",
    "        'Bureau of Labor Statistics. Comparing the latest '+\n",
    "        f'three months to the previous three months, average earnings '+\n",
    "        f'{all_3m} for all employees and {pns_3m} for production '+\n",
    "        'and non-supervisory employees.')\n",
    "write_txt(text_dir / 'ahe_summary.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AHE by Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T14:51:56.498013Z",
     "start_time": "2023-07-07T14:51:55.393532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "series = {'CES3000000008': 'Manufacturing',\n",
    "          'CES1000000008': 'Mining \\& Logging',\n",
    "          'CES4422000008': 'Utilities',\n",
    "          'CES4142000008': 'Wholesale Trade',\n",
    "          'CES5000000008': 'Information',\n",
    "          'CES5500000008': 'Financial Activities',\n",
    "          'CES6000000008': 'Professional \\& Business Services',\n",
    "          'CES6500000008': 'Education \\& Health Services',\n",
    "          'CES0500000008': 'Total Private',\n",
    "          'CES2000000008': 'Construction',\n",
    "          'CES7000000008': 'Leisure \\& Hospitality',\n",
    "          'CES4300000008': 'Transportation \\& Warehousing',\n",
    "          'CES4200000008': 'Retail Trade'}\n",
    "\n",
    "years = (2017, 2023)\n",
    "df = bls_api(series, years, bls_key)\n",
    "df.to_csv(data_dir / 'ahe_industry_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:19:12.862444Z",
     "start_time": "2023-07-25T15:19:12.848113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By industry, 12 of the 12 groups experienced real wage growth (wage growth above the increase in prices indicated by the consumer price index). The transportation \\& warehousing industry had the fastest nominal growth rate, at 6.0 percent, followed by 5.7 percent in construction and 5.6 percent in manufacturing. \n"
     ]
    }
   ],
   "source": [
    "s = pd.read_csv(data_dir / 'cpi.csv')\n",
    "df = (pd.read_csv(data_dir / 'ahe_industry_raw.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "allitems = s['ALL'].iloc[-1]\n",
    "data = (df.pct_change(12).iloc[-1] * 100.0).sort_values(ascending=False)\n",
    "\n",
    "(data.to_csv(data_dir / 'ahe_ind.csv', index_label='name', header=True))\n",
    "\n",
    "write_txt(text_dir / 'ahe_bar_date.txt', df.index[-1].strftime('%B %Y'))\n",
    "\n",
    "real = (data - allitems).drop('Total Private')\n",
    "ltd = {i: (data.index[i].lower(), data.iloc[i]) for i in [0, 1, 2]}\n",
    "rwn = len(real.loc[real > 0])\n",
    "rwg = numbers2[rwn] if rwn < 10 else rwn\n",
    "if rwn == 0:\n",
    "    rwg = 'none'\n",
    "\n",
    "txt1 = (f'By industry, {rwg} of the {len(real)} groups '+\n",
    "         'experienced real wage growth (wage growth above the increase in '+\n",
    "        f'prices indicated by the consumer price index). The {ltd[0][0]} '+\n",
    "        f'industry had the fastest nominal growth rate, at {ltd[0][1]:.1f} percent, followed '+\n",
    "        f'by {ltd[1][1]:.1f} percent in {ltd[1][0]} and {ltd[2][1]:.1f} percent in {ltd[2][0]}. ')\n",
    "write_txt(text_dir / 'ahe_comp.txt', txt1)\n",
    "print(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CES data - Payrolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-07T14:51:58.147828Z",
     "start_time": "2023-07-07T14:51:56.512961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "series = {'CES0000000001': 'ALL',\n",
    "          'CES3000000001': 'Manufacturing',\n",
    "          'CES1000000001': 'Mining \\& Logging',\n",
    "          'CES4422000001': 'Utilities',\n",
    "          'CES4142000001': 'Wholesale Trade',\n",
    "          'CES5000000001': 'Information',\n",
    "          'CES5500000001': 'Financial Activities',\n",
    "          'CES6000000001': 'Professional \\& Business Serv.',\n",
    "          'CES6500000001': 'Education \\& Health Services',\n",
    "          'CES0500000001': 'Total Private',\n",
    "          'CES2000000001': 'Construction',\n",
    "          'CES7000000001': 'Leisure \\& Hospitality',\n",
    "          'CES4300000001': 'Transportation \\& Warehousing',\n",
    "          'CES4200000001': 'Retail Trade'}\n",
    "df = bls_api(series, (2015, 2023), bls_key)\n",
    "df.to_csv(data_dir / 'ces_data.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:19:17.810101Z",
     "start_time": "2023-07-25T15:19:17.786909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonfarm payrolls increased by 209,000 in June 2023, following 306,000 jobs added in May, and 217,000 added in April (see \\cbox{blue!60!purple}). Average payroll growth was 244,000 over these three months, slightly below the average of 312,300 during the previous three months. \n",
      "\n",
      " During March and April 2020, the US lost a combined 22 million jobs. Since May 2020, a total of 25.8 million jobs have been added, equivalent to 117.5 percent of those lost.\n",
      "\n",
      "To maintain a steady payroll employment rate with population growth, the US needed to add 144,000 jobs in June 2023. Pre-pandemic, in 2019, the US was adding an average of 163,200 jobs per month.\n"
     ]
    }
   ],
   "source": [
    "pop = pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True).loc['2015':, 'POP']\n",
    "\n",
    "df = pd.read_csv(data_dir / 'ces_data.csv', index_col='date', \n",
    "                 parse_dates=True)['ALL']\n",
    "\n",
    "data = df.diff().loc['2019':] * 1_000\n",
    "data.div(1_000_000).to_csv(data_dir / 'nfp.csv', index_label='date')\n",
    "\n",
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "prdt = dtxt(data.index[-2])['mon1']\n",
    "if prdt[-4:] == ltdt[-4:]:\n",
    "    prdt = prdt[:-5]\n",
    "pr2dt = dtxt(data.index[-3])['mon1']\n",
    "if pr2dt[-4:] == ltdt[-4:]:\n",
    "    pr2dt = pr2dt[:-5]\n",
    "lt = value_text(data.iloc[-1], 'increase_by', ptype=None, digits=0)\n",
    "al = 'added' if data.iloc[-2] >= 0 else 'lost'\n",
    "pr = f'{data.iloc[-2]:,.0f} jobs {al}'\n",
    "pr2 = value_text(data.iloc[-3], 'added_lost_rev', ptype=None, \n",
    "                 digits=0)\n",
    "cb = c_box('blue!60!purple')\n",
    "val3m = data.iloc[-3:].mean()\n",
    "valpr3m = data.iloc[-6:-3].mean()\n",
    "ct = compare_text(val3m, valpr3m, [50000, 150000, 500000])\n",
    "cov = data.loc['2020-03-01':'2020-04-01'].sum() / 1_000_000\n",
    "pcadd = data.loc['2020-05-01':].sum() / 1_000_000\n",
    "pcsh = (pcadd / abs(cov)) * 100\n",
    "lpop = (pop.diff().rolling(12).mean().iloc[-1] * \n",
    "        (df / pop).rolling(12).mean().iloc[-1]) * 1_000\n",
    "pr19v = data.loc['2019'].mean().round(-2)\n",
    "pr3yr = value_text(data.iloc[-48:].mean().round(-2), 'added_lost', \n",
    "                   ptype=None, digits=0, adj='average')\n",
    "\n",
    "text = (f'Nonfarm payrolls {lt} in {ltdt}, following {pr} in {prdt}, '+\n",
    "        f'and {pr2} in {pr2dt} {cb}. Average payroll growth was '+\n",
    "        f'{round(val3m,-2):,.0f} over these three months, '+\n",
    "        f'{ct} the average of {round(valpr3m,-2):,.0f} '+\n",
    "        'during the previous three months. \\n\\n During March and '+\n",
    "        f'April 2020, the US lost a combined {abs(cov):.0f} million '+\n",
    "        f'jobs. Since May 2020, a total of {pcadd:.1f} million jobs '+\n",
    "        f'have been added, equivalent to {pcsh:.1f} percent of those lost.\\n\\n'+\n",
    "        'To maintain a steady payroll employment rate with population growth, '+\n",
    "        f'the US needed to add {round(lpop, -3):,.0f} '+\n",
    "        f'jobs in {ltdt}. Pre-pandemic, in 2019, the US was adding an average '+\n",
    "        f'of {pr19v:,.0f} jobs per month.')\n",
    "write_txt(text_dir / 'nfp_basic_text.txt', text)\n",
    "print(text)\n",
    "\n",
    "# Node for latest value\n",
    "tloc = dtxt(data.index[-1] - pd.DateOffset(weeks=26))['datetime']\n",
    "tdt = dtxt(data.index[-1])['mon6']\n",
    "pm = '+' if data.iloc[-1] >= 0 else '-'\n",
    "tv = f'{pm}{abs(data.iloc[-1] / 1_000):.0f}k'\n",
    "if abs(data.iloc[-1]) > 994_000:\n",
    "    tv = f'{pm}{abs(data.iloc[-1] / 1_000_000):.1f} million'\n",
    "text = ('\\\\node[below, align=right, pin=45:{}] at (axis cs: '+\n",
    "        f'{{{tloc}}}, -1.2) {{\\scriptsize {tdt}\\\\\\\\ \\scriptsize {tv}}};')\n",
    "write_txt(text_dir / 'nfp_lt_val.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T15:19:20.953774Z",
     "start_time": "2023-07-25T15:19:20.900610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In June 2023, there were 22.7 million government jobs, equivalent to 8.5 for every 100 people in the age 16 and older population (see {\\color{blue!50!cyan}\\textbf{---}}). The previous year, in June 2022, there were 22.1 million government jobs, equivalent to 8.4 percent of the age 16 and older population. During the 1990s, there were 9.7 government jobs per person age 16 or older. If the rate was the same today, there would be 3.3 million additional government workers.\n",
      "\n",
      "By level of government, there were 14.6 million local government workers in June 2023, equivalent to 5.5 percent of those age 16 or older (see {\\color{red}\\textbf{---}}). In the same period, there were 5.2 million state government workers (2.0 percent of 16+ year olds, see {\\color{orange}\\textbf{---}}), and 2.9 million federal government workers (1.1 percent, see {\\color{green!80!blue}\\textbf{---}}).\n",
      "\n",
      "Since 2019, the US has lost 13,000 total government jobs. Of these, 85,000, or 653.8 percent of the shortfall, are local government jobs. During the same period, state governments lost 6,000 jobs, while the federal government added 78,000 jobs.\n"
     ]
    }
   ],
   "source": [
    "pop = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date'))['POP']\n",
    "\n",
    "data = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "\n",
    "jobcats = {'CES9000000001': 'govjobs',\n",
    "           'CES9091000001': 'fedjobs',\n",
    "           'CES9092000001': 'stjobs',\n",
    "           'CES9093000001': 'locjobs'}\n",
    "df = data.rename(jobcats, axis=1)[jobcats.values()]\n",
    "sh = df.divide(pop, axis=0) * 100\n",
    "sh.loc['1989':].to_csv(data_dir / 'govjobs.csv', index_label='date')\n",
    "grps = {'govjobs': 'blue!50!cyan', 'fedjobs': 'green!80!blue',\n",
    "        'stjobs': 'orange', 'locjobs': 'red'}\n",
    "for cat, col in grps.items():\n",
    "    node = (end_node(sh[cat], col, date='m', percent=True) \n",
    "            if cat == 'govjobs' \n",
    "            else end_node(sh[cat], col, percent=True))\n",
    "    write_txt(text_dir / f'{cat}_node.txt', node)\n",
    "    \n",
    "ltdate = dtxt(sh.index[-1])['mon1']\n",
    "pryrdate = dtxt(sh.index[-13])['mon1']\n",
    "ltval = df.govjobs.iloc[-1] / 1000 \n",
    "pryrval = df.govjobs.iloc[-13] / 1000 \n",
    "ltsh = sh.govjobs.iloc[-1]\n",
    "pryrsh = sh.govjobs.iloc[-13]\n",
    "ltfed = df.fedjobs.iloc[-1] / 1000 \n",
    "ltst = df.stjobs.iloc[-1] / 1000 \n",
    "ltloc = df.locjobs.iloc[-1] / 1000 \n",
    "ltfedsh = sh.fedjobs.iloc[-1] \n",
    "ltstsh = sh.stjobs.iloc[-1]\n",
    "ltlocsh = sh.locjobs.iloc[-1]\n",
    "diff = df.govjobs.iloc[-1] - df.govjobs.loc['2019-12-01']#.mean()\n",
    "gl = 'gained' if diff > 0 else 'lost'\n",
    "difftxt = (f'{gl} {abs(diff):.0f},000' if abs(diff) < 1000 \n",
    "           else f'{gl} {abs(diff) / 1000:.1f} million')\n",
    "txt3 = f'Since 2019, the US has {difftxt} total government jobs. '\n",
    "sh90 = sh.loc['1990':'1999', 'govjobs'].mean()\n",
    "diff90 = ((sh90 / 100)\n",
    "          * pop.iloc[-1]) - df.govjobs.iloc[-1]\n",
    "\n",
    "txt1 = (f'In {ltdate}, there were {ltval:.1f} million government jobs, '+\n",
    "        f'equivalent to {ltsh:.1f} for every 100 people in the age 16 and older population '+\n",
    "        f'(see {{\\color{{{grps[\"govjobs\"]}}}\\\\textbf{{---}}}}). The previous year, '+\n",
    "        f'in {pryrdate}, there were {pryrval:.1f} million government jobs, '+\n",
    "        f'equivalent to {pryrsh:.1f} percent of the age 16 and older population. '+\n",
    "        f'During the 1990s, there were {sh90:.1f} government jobs per person '+\n",
    "        'age 16 or older. If the rate was the same today, there would be '+\n",
    "        f'{diff90 / 1_000:.1f} million additional government workers.'+\n",
    "        f'\\n\\nBy level of government, there were {ltloc:.1f} million '+\n",
    "        f'local government workers in {ltdate}, equivalent to '+\n",
    "        f'{ltlocsh:.1f} percent of those age 16 or older '+\n",
    "        f'(see {{\\color{{{grps[\"locjobs\"]}}}\\\\textbf{{---}}}}). '+\n",
    "        f'In the same period, there were {ltst:.1f} million state '+\n",
    "        f'government workers ({ltstsh:.1f} percent of 16+ year olds, '+\n",
    "        f'see {{\\color{{{grps[\"stjobs\"]}}}\\\\textbf{{---}}}}), and '+\n",
    "        f'{ltfed:.1f} million federal government workers ({ltfedsh:.1f} '+\n",
    "        f'percent, see {{\\color{{{grps[\"fedjobs\"]}}}\\\\textbf{{---}}}}).')\n",
    "\n",
    "ch19 = df.iloc[-1] - df.loc['2019-12-01']#.mean()\n",
    "locchsh = (ch19.locjobs / ch19.govjobs) * 100\n",
    "stchtxt = value_text(ch19.stjobs, style='added_lost', ptype=None, digits=0)\n",
    "fedchtxt = value_text(ch19.fedjobs, style='added_lost', ptype=None, digits=0)\n",
    "locchtxt = value_text(ch19.locjobs, style='added_lost', ptype=None, digits=0)\n",
    "aw = 'and' if ch19.fedjobs < 0 else 'while'\n",
    "if (ch19.govjobs < 0) and (ch19.locjobs < 0):\n",
    "    txt = (f'Of these, {abs(ch19.locjobs):,.0f},000, or {locchsh:.1f} '+\n",
    "           'percent of the shortfall, are local government jobs. '+\n",
    "           'During the same period, ')\n",
    "else:\n",
    "    txt = f'During the same period, local governments {locchtxt},000 jobs, '\n",
    "    \n",
    "txt2 = (f'state governments {stchtxt},000 jobs, {aw} '+\n",
    "        f'the federal government {fedchtxt},000 jobs.')\n",
    "text = txt1 + '\\n\\n' + txt3 + txt + txt2\n",
    "write_txt(text_dir / 'govjobs.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
