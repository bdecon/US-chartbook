{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Jobs Report Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:36:55.030855Z",
     "start_time": "2023-10-06T12:36:54.004874Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:09.791446Z",
     "start_time": "2023-10-06T12:36:55.032541Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "September 2023\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS14000003': 'White', \n",
    "          'LNS14000006': 'Black',\n",
    "          'LNS14000009': 'Hispanic',\n",
    "          'LNS14032183': 'Asian',\n",
    "          'LNS14000000': 'Total',\n",
    "          'LNS13327709': 'U6',\n",
    "          'LNS13000000': 'Level',\n",
    "          'LNU05026639': 'WantJob',\n",
    "          'LNU03008636': 'LT',\n",
    "          'LNU03008516': 'MT',\n",
    "          'LNU00000000': 'POP',\n",
    "          'LNS12300060': 'PA_EPOP',\n",
    "          'LNS13023621': 'Job Loser',\n",
    "          'LNS13023653': 'Temporary Layoff',\n",
    "          'LNS13026638': 'Permanent Separation',\n",
    "          'LNS13023705': 'Job Leaver', \n",
    "          'LNS13023557': 'Re-entrant',\n",
    "          'LNS13023569': 'New entrant',\n",
    "          'LNS13008276': 'Median',\n",
    "          'LNS13008275': 'Mean',\n",
    "          'LNS17200000': 'NILF',\n",
    "          'LNS17100000': 'UNEMP',\n",
    "          'LNS11000000': 'LF',\n",
    "          'LNS12032194': 'PTECON',\n",
    "          'LNS12005977': 'PTNONECON'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1988, 2023)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main.csv', index_label='date')\n",
    "print(dtxt(df.index[-1])['mon1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:28.632374Z",
     "start_time": "2023-10-06T12:37:09.792700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS12300061': 'PA_EPOP_M', \n",
    "          'LNS12300062': 'PA_EPOP_W',\n",
    "          'LNS12005054': 'avghrstot',\n",
    "          'LNU02033699': 'avghrsserv',\n",
    "          'CES0500000002': 'ceshrstot',\n",
    "          'CES0600000002': 'ceshrsgoods',\n",
    "          'CES0800000002': 'ceshrsserv',\n",
    "          'CES0500000007': 'ceshrspns',\n",
    "          'LNU02033232': 'avghrsptecon',\n",
    "          'LNU01000000': 'LFnsa',\n",
    "          'LNS12026619': 'MJHsa',\n",
    "          'LNU02000000': 'EMP',\n",
    "          'LNS12000000': 'EMPsa',\n",
    "          'LNU00000001': 'MenPop',\n",
    "          'LNU00000002': 'WomenPop',\n",
    "          'LNU01000001': 'MenLF',\n",
    "          'LNU01000002': 'WomenLF',\n",
    "          'LNS11300001': 'MenLFPR',\n",
    "          'LNS11300002': 'WomenLFPR',\n",
    "          'LNU02048984': 'seinc',\n",
    "          'LNS12027714': 'seuninc',\n",
    "          'LNU02374597': 'empdis',\n",
    "          'LNS12300000': 'EPOP'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1988, 2023)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:30.204580Z",
     "start_time": "2023-10-06T12:37:28.634659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS17100001': 'MenUE',\n",
    "          'LNS17100002': 'WomenUE',\n",
    "          'LNS17200001': 'MenNE',\n",
    "          'LNS17200002': 'WomenNE',\n",
    "          'LNS17400001': 'MenEU',\n",
    "          'LNS17400002': 'WomenEU',\n",
    "          'LNS17600001': 'MenNU',\n",
    "          'LNS17600002': 'WomenNU',\n",
    "          'LNS17800001': 'MenEN',\n",
    "          'LNS17800002': 'WomenEN',\n",
    "          'LNS17900001': 'MenUN',\n",
    "          'LNS17900002': 'WomenUN',\n",
    "          'LNS12000001': 'MenE',\n",
    "          'LNS12000002': 'WomenE',\n",
    "          'LNS13000001': 'MenU',\n",
    "          'LNS13000002': 'WomenU',\n",
    "          'LNS15000001': 'MenN',\n",
    "          'LNS15000002': 'WomenN'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (2018, 2023)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main3.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Gross Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:30.225466Z",
     "start_time": "2023-10-06T12:37:30.209285Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main3.csv', parse_dates=['date'])\n",
    "        .set_index('date')) / 1000\n",
    "\n",
    "cols = ['MenEU', 'WomenEU', 'MenEN', 'WomenEN', 'MenUE', 'WomenUE',\n",
    "        'MenUN', 'WomenUN', 'MenNE', 'WomenNE', 'MenNU', 'WomenNU']\n",
    "\n",
    "cols2 = []\n",
    "for col in cols:\n",
    "    name = f'{col}{col[-2]}'\n",
    "    cols2.append(name)\n",
    "    df[name] = (df[col] / df[f'{col[:-2]}{col[-2]}'].shift()) * 100\n",
    "\n",
    "df.loc['2013-01-01':, cols2].to_csv(data_dir / 'grosslf.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:30.255171Z",
     "start_time": "2023-10-06T12:37:30.227263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLS \\href{https://www.bls.gov/news.release/empsit.nr0.htm}{reports} 6.4 million unemployed people in September 2023, and an unemployment rate of 3.8 percent (see {\\color{blue!50!cyan}\\textbf{---}}), in line with the August 2023 rate of 3.8 percent, but slightly above the September 2022 rate of 3.5 percent. \n",
      "\n",
      "In September 2023, the labor under-utilization rate is 7.0 percent (see {\\color{blue}\\textbf{---}}). \n",
      "\n",
      "Periods of unemployment are more common for disadvantaged groups. The black or African American unemployment rate is typically double the white unemployment rate. Employment opportunities for disadvantaged groups are more-dependent on current labor market conditions. A very tight labor market reduces racial discrimination in hiring, while disadvantaged groups are more likely to lose jobs in a downturn. Since February 2020, the black unemployment rate has decreased by 0.3 percentage point to 5.7 percent (see {\\color{green!50!teal!60!black}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'jobs_report_main.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "srs = ['Total', 'U6']\n",
    "df.loc['1989':, srs].to_csv(data_dir / 'unemp2.csv', index_label='date')\n",
    "\n",
    "srs = ['White', 'Black', 'Hispanic']\n",
    "df.loc['1989':, srs].to_csv(data_dir / 'unemp.csv', index_label='date')\n",
    "\n",
    "s = series_info(df['Level'])\n",
    "s2 = series_info(df['Total'])\n",
    "s3 = series_info(df['Black'])\n",
    "s4 = series_info(df['U6'])\n",
    "compare = compare_text(df['Total'].iloc[-1], df['Total'].iloc[-2], [0.15, 1.5, 3.0])\n",
    "compare2 = compare_text(df['Total'].iloc[-1], df['Total'].iloc[-13], [0.15, 1.5, 3.0])\n",
    "pryrdt = dtxt(df.index[-13])['mon1']\n",
    "\n",
    "if compare[-5:] != compare2[-5:]:\n",
    "    conj = f', but {compare2} the {pryrdt} rate of {df[\"Total\"].iloc[-13]:.1f} percent'\n",
    "elif compare != compare2:\n",
    "    conj = f', and {compare2} the {pryrdt} rate of {df[\"Total\"].iloc[-13]:.1f} percent'\n",
    "else:\n",
    "    conj = ''\n",
    "    \n",
    "text = ('BLS \\href{https://www.bls.gov/news.release/empsit.nr0.htm}{reports} '+\n",
    "        f'{s[\"val_latest\"]/1000:.1f} million '+\n",
    "        f'unemployed people in {s[\"date_latest_ft\"]}, '+\n",
    "        f'and an unemployment rate of {s2[\"val_latest\"]} percent '+\n",
    "        '(see {\\color{blue!50!cyan}\\\\textbf{---}}), '+\n",
    "        f'{compare} the {s[\"date_prev_ft\"]} rate of {s2[\"val_prev\"]} percent'+\n",
    "        f'{conj}.')\n",
    "write_txt(text_dir / 'unemp1.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "mval = f', {s4[\"last_matched\"]}.' if s4['days_since_match'] > 1000 else '.'\n",
    "text = (f'In {s[\"date_latest_ft\"]}, the labor under-utilization rate is '+\n",
    "        f'{s4[\"val_latest\"]} percent '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}})'+\n",
    "        f'{mval}')\n",
    "write_txt(text_dir / 'unemp2.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "write_txt(text_dir / 'u6_node.txt', \n",
    "          end_node(df['U6'], 'blue', date='m', percent=True, offset=0.4))\n",
    "write_txt(text_dir / 'u3_node.txt', end_node(df['Total'], 'blue!50!cyan', percent=True))\n",
    "\n",
    "black_ch = df['Black'].iloc[-1] - df.loc['2020-02-01', 'Black']\n",
    "bch = value_text(black_ch, style='increase_by', ptype='pp')\n",
    "text = ('Periods of unemployment are more common for disadvantaged groups. '+\n",
    "        'The black or African American unemployment rate is typically '+\n",
    "        'double the white unemployment rate. Employment opportunities for '+\n",
    "        'disadvantaged groups are more-dependent on current labor market '+\n",
    "        'conditions. A very tight labor market reduces racial '+\n",
    "        'discrimination in hiring, while disadvantaged groups are more '+\n",
    "        'likely to lose jobs in a downturn. '+\n",
    "        'Since February 2020, the black unemployment rate '+\n",
    "        f'has {bch} to {s3[\"val_latest\"]:.1f} percent '+\n",
    "        '(see {\\color{green!50!teal!60!black}\\\\textbf{---}}).')\n",
    "write_txt(text_dir / 'unemp3.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:30.279596Z",
     "start_time": "2023-10-06T12:37:30.256468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sep `23</th>\n",
       "      <th>Aug `23</th>\n",
       "      <th>Jul `23</th>\n",
       "      <th>Jun `23</th>\n",
       "      <th>Sep `22</th>\n",
       "      <th>Sep `21</th>\n",
       "      <th>GFC peak</th>\n",
       "      <th>Date of peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under-utilization Rate (U6)</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Dec `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployment Rate (U3)</th>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Oct `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\textit{by race/ethnicity:}</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} White</th>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Oct `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Black</th>\n",
       "      <td>5.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>16.8</td>\n",
       "      <td>Mar `10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Hispanic</th>\n",
       "      <td>4.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Aug `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Asian</th>\n",
       "      <td>2.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Dec `09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Sep `23 Aug `23 Jul `23 Jun `23 Sep `22 Sep `21  \\\n",
       "Under-utilization Rate (U6)     7.0     7.1     6.7     6.9     6.7     8.5   \n",
       "Unemployment Rate (U3)          3.8     3.8     3.5     3.6     3.5     4.8   \n",
       "\\textit{by race/ethnicity:}                                                   \n",
       "\\hspace{2mm} White              3.4     3.4     3.1     3.1     3.1     4.2   \n",
       "\\hspace{2mm} Black              5.7     5.3     5.8     6.0     5.9     7.8   \n",
       "\\hspace{2mm} Hispanic           4.6     4.9     4.4     4.3     3.9     6.2   \n",
       "\\hspace{2mm} Asian              2.8     3.1     2.3     3.2     2.5     4.2   \n",
       "\n",
       "                            GFC peak Date of peak  \n",
       "Under-utilization Rate (U6)     17.2      Dec `09  \n",
       "Unemployment Rate (U3)          10.0      Oct `09  \n",
       "\\textit{by race/ethnicity:}                        \n",
       "\\hspace{2mm} White               9.2      Oct `09  \n",
       "\\hspace{2mm} Black              16.8      Mar `10  \n",
       "\\hspace{2mm} Hispanic           13.0      Aug `09  \n",
       "\\hspace{2mm} Asian               8.4      Dec `09  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs = ['U6', 'Total', 'White', 'Black', 'Hispanic', 'Asian']\n",
    "untab = df[srs].iloc[[-1, -2, -3, -4, -13, -25]].T\n",
    "untab.columns = untab.columns.strftime('%b `%y')\n",
    "untab['GFC peak'] = df.loc['2005':'2013', srs].max()\n",
    "untab['Date of peak'] = df.loc['2005':'2013', srs].idxmax().dt.strftime('%b `%y')\n",
    "d = {'Total': 'Unemployment Rate (U3)',\n",
    "     'U6': 'Under-utilization Rate (U6)',\n",
    "     'White': '\\hspace{2mm} White',\n",
    "     'Black': '\\hspace{2mm} Black',\n",
    "     'Hispanic': '\\hspace{2mm} Hispanic',\n",
    "     'Asian': '\\hspace{2mm} Asian'}\n",
    "untab.index = untab.index.map(d)\n",
    "\n",
    "untab.loc['\\\\textit{by race/ethnicity:}', untab.columns] = [''] * 8\n",
    "untab = pd.concat([untab.iloc[0:2], untab.iloc[-1].to_frame().T, untab.iloc[2:6]])\n",
    "untab.columns.name = None\n",
    "untab.to_csv(data_dir / 'unemp1.tex', sep='&', lineterminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "untab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Participation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:30.299814Z",
     "start_time": "2023-10-06T12:37:30.280859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the latest data, covering September 2023, 62.8 percent of people age 16 and older are in the labor force (see {\\color{green!80!blue!60!black}\\textbf{---}}), compared to 62.8 percent in August and 62.6 percent in July. In February 2020, when US confirmed cases of COVID-19 were still low, the labor force participation rate was 63.3 percent.\n",
      "\n",
      "In September 2023, 68.3 percent of men age 16 and older are in the labor force (see {\\color{blue!70!black}\\textbf{---}}), compared to 57.5 percent of women (see {\\color{red!80!black}\\textbf{---}}). Since February 2020, labor force participation has decreased 0.9 percentage point among men, and decreased 0.3 percentage point among women.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))[['MenLFPR', 'WomenLFPR']]\n",
    "df['TotLFPR'] = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                             parse_dates=['date'])\n",
    "                   .assign(TotLFPR = lambda x: (x.LF / x.POP)*100)\n",
    "                   .set_index('date'))['TotLFPR']\n",
    "df.loc['1989':].to_csv(data_dir / 'lfpr.csv', index_label='date')\n",
    "\n",
    "col = {'MenLFPR': 'blue!70!black',\n",
    "       'WomenLFPR': 'red!80!black',\n",
    "       'TotLFPR': 'green!80!blue!60!black'}\n",
    "nodes = (end_node(df['MenLFPR'], col['MenLFPR'], date='m', \n",
    "                  offset=0.35) + '\\n' + \n",
    "         '\\n'.join(end_node(df[name], color) \n",
    "                   for name, color in col.items() if name != 'MenLFPR'))\n",
    "write_txt(text_dir / 'lfpr_nodes.txt', nodes)\n",
    "\n",
    "tot = df['TotLFPR']\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "write_txt(text_dir / 'lfpr_blsdate.txt', ltdt)\n",
    "prdt, prdt2 = (dtxt(df.index[i])['mon3'] \n",
    "               if df.index[-1].year == df.index[i].year \n",
    "               else dtxt(df.index[i])['mon1'] \n",
    "               for i in [-2, -3])\n",
    "cpdt = '2020-02-01'\n",
    "compdt = dtxt(cpdt)['mon1']\n",
    "feb20val = tot.loc[cpdt]\n",
    "mltval = df['MenLFPR'].iloc[-1]\n",
    "wltval = df['WomenLFPR'].iloc[-1]\n",
    "mchval = mltval - df['MenLFPR'].loc['2020-01-01']\n",
    "wchval = wltval - df['WomenLFPR'].loc['2020-01-01']\n",
    "mch = value_text(mchval, style='increase', ptype='pp')\n",
    "wch = value_text(wchval, style='increase', ptype='pp')\n",
    "cl = {k: c_line(v) for k, v in col.items()}\n",
    "text = (f'In the latest data, covering {ltdt}, {tot.iloc[-1]:.1f} '+\n",
    "        'percent of people age 16 and older are in the labor force '+\n",
    "        f'{cl[\"TotLFPR\"]}, compared to {tot.iloc[-2]:.1f} percent in '+\n",
    "        f'{prdt} and {tot.iloc[-3]:.1f} percent in {prdt2}. In '+\n",
    "        f'{compdt}, when US confirmed cases of COVID-19 were still '+\n",
    "        f'low, the labor force participation rate was {feb20val:.1f} '+\n",
    "        f'percent.\\n\\nIn {ltdt}, {mltval:.1f} percent of men age '+\n",
    "        f'16 and older are in the labor force {cl[\"MenLFPR\"]}, compared to '+\n",
    "        f'{wltval:.1f} percent of women {cl[\"WomenLFPR\"]}. Since '+\n",
    "        f'{compdt}, labor force participation has {mch} among men, '+\n",
    "        f'and {wch} among women.')\n",
    "write_txt(text_dir / 'lfpr_text.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:30.387476Z",
     "start_time": "2023-10-06T12:37:30.301088Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of September 2023, the Bureau of Labor Statistics \\href{https://data.bls.gov/timeseries/LNS12300000}{report} an overall (age 16 and older) employment rate of 60.4 percent (see {\\color{green!60!black}\\textbf{---}}), a one-year increase of 0.3 percentage point, but a 0.4 percentage point decrease since 2019.\n",
      "In September 2023, 80.8 percent of 25 to 54 years olds were employed (see {\\color{blue!90!cyan}\\textbf{---}}), the lowest level since May 2023. Over the past year, the age 25 to 54 employment rate increased 0.6 percentage point. The September 2023 rate is 0.6 percentage point (equivalent to 820,000 workers) below the average rate of 81.4 during the tight labor market of 1999--2000.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://data.bls.gov/timeseries/LNS12300000'\n",
    "pa_url = 'https://data.bls.gov/timeseries/LNS12300060'\n",
    "df1 = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, 'PA_EPOP'])\n",
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, 'EPOP'])\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df.to_csv(data_dir / 'epop.csv', index_label='date')\n",
    "\n",
    "color = 'green!60!black'\n",
    "node = end_node(df['EPOP'], color, date='m')\n",
    "write_txt(text_dir / 'epop_node2.txt', node)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "ltval = df['EPOP'].iloc[-1]\n",
    "chval = df['EPOP'].diff(12).iloc[-1]\n",
    "chtxt = value_text(chval, 'increase_of', ptype='pp', time_str='one-year ')\n",
    "chval2 = df['EPOP'].iloc[-1] - df.loc['2019', 'EPOP'].mean()\n",
    "chtxt2 = value_text(chval2, style='increase_end', ptype='pp')\n",
    "ab = 'but'\n",
    "if ((chval<0) == (chval2<0)) == True:\n",
    "    ab = 'and'\n",
    "text = (f'As of {ltdt}, the Bureau of Labor Statistics '+\n",
    "        f'\\href{{{url}}}{{report}} '+\n",
    "        f'an overall (age 16 and older) employment rate of {ltval} '+\n",
    "        f'percent {c_line(color)}, {chtxt}, {ab} {chtxt2} since 2019.')\n",
    "write_txt(text_dir / 'epop_text2.txt', text)\n",
    "print(text)\n",
    "\n",
    "color = 'blue!90!cyan'\n",
    "adj = 0\n",
    "if (df['PA_EPOP'].iloc[-1] / df['PA_EPOP'].max()) > 0.95:\n",
    "    adj = -0.25\n",
    "elif (df['PA_EPOP'].iloc[-1] / df['PA_EPOP'].max()) > 1:\n",
    "    adj = -0.4\n",
    "node = end_node(df['PA_EPOP'], color, date='m', offset=adj)\n",
    "write_txt(text_dir / 'epop_node.txt', node)\n",
    "\n",
    "ltval = df['PA_EPOP'].iloc[-1]\n",
    "prval = df['PA_EPOP'].iloc[-2]\n",
    "prdt = dtxt(df['PA_EPOP'].index[-2])['mon1']\n",
    "prtxt = f'compared to {prval} percent in {prdt}'\n",
    "compval = df['PA_EPOP'].loc['2019-06-01': '2020-03-01'].max()\n",
    "last = series_info(df['PA_EPOP'])['last_matched']\n",
    "text2 = prtxt if ltval < compval else last\n",
    "chtxt = value_text(df['PA_EPOP'].diff(12).iloc[-1], ptype='pp', threshold=0.1)\n",
    "\n",
    "pop = (cps_1mo(cps_dir, cps_date(), ['BASICWGT', 'AGE'])\n",
    "       .query('25 <= AGE <=54').BASICWGT.sum()) / 1_000\n",
    "rt99 = df['PA_EPOP'].loc['1999': '2000'].mean()\n",
    "ch99 =  ltval - rt99\n",
    "ch99w = (-ch99 / 100) * pop\n",
    "ch99t = (f'{round(abs(ch99w) / 1000, 1)} million' \n",
    "         if ch99w > 999 else f'{round(abs(ch99w), -1):.0f},000')\n",
    "ch99t2 = f'(equivalent to {ch99t} workers)'\n",
    "threshold = 0.1\n",
    "txt = value_text(ch99, style='above_below', \n",
    "                 ptype='pp', threshold=threshold)\n",
    "if abs(ch99) > threshold:\n",
    "    ch99txt = f'{txt[:-6]} {ch99t2} {txt[-5:]}'\n",
    "else:\n",
    "    ch99txt = txt\n",
    "text = (f'In {ltdt}, {ltval} percent of 25 to 54 years olds were '+\n",
    "        f'employed {c_line(color)}, {text2}. Over the past year, '+\n",
    "        f'the age 25 to 54 employment rate {chtxt}. The {ltdt} rate '+\n",
    "        f'is {ch99txt} the average rate of {rt99:.1f} during the '+\n",
    "        'tight labor market of 1999--2000.')\n",
    "write_txt(text_dir / 'epop_text.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recent Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:30.402449Z",
     "start_time": "2023-10-06T12:37:30.390001Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, 'PA_EPOP'])\n",
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, ['PA_EPOP_M', 'PA_EPOP_W']])\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df['label'] = [dt.strftime('%b\\\\\\%Y') if dt.month == 1 \n",
    "                  else dt.strftime('%b') if dt.month == 7\n",
    "                  else '' for dt in df.index]\n",
    "res = df.iloc[-25:]\n",
    "\n",
    "res.to_csv(data_dir / 'pa_epop_rec.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:30.409480Z",
     "start_time": "2023-10-06T12:37:30.403746Z"
    }
   },
   "outputs": [],
   "source": [
    "sdt = res.index[0]\n",
    "sdtime = (dtxt(sdt)['datetime']\n",
    "           .replace('-08-', '-8-').replace('-09-', '-9-'))\n",
    "ltdt = res.index[-1]\n",
    "ltdtime = (dtxt(ltdt)['datetime']\n",
    "           .replace('-08-', '-8-').replace('-09-', '-9-'))\n",
    "node = []\n",
    "d = {'PA_EPOP': ['blue!80!purple', 'cyan'], \n",
    "     'PA_EPOP_M': ['green!50!black', 'green!50!black'], \n",
    "     'PA_EPOP_W': ['yellow!40!orange', 'yellow!40!orange']}\n",
    "for s, [c1, c2] in d.items():\n",
    "    dt = f'\\scriptsize {dtxt(ltdt)[\"mon6\"]} \\\\\\\\' if s == 'PA_EPOP_M' else ''\n",
    "    v0 = res[s].iloc[0]\n",
    "    vlt = res[s].iloc[-1]\n",
    "    y = 0.15 if s == 'PA_EPOP_M' else '0'\n",
    "    x = -0.35 if s == 'PA_EPOP_M' else '-0.05'\n",
    "    n0 = ('\\\\node[label={[yshift=0cm, xshift=0.05cm, align=right]180:'+\n",
    "          f'{{\\scriptsize {v0:.1f}}}}}, circle, draw={c1}, fill={c2}, '+\n",
    "          f'inner sep=1pt] at (axis cs:{sdtime}, {v0}) '+\n",
    "          '{};\\n'+\n",
    "          f'\\\\node[label={{[yshift={y}cm, xshift={x}cm, align=right]0:'+\n",
    "          f'{{{dt}\\scriptsize {vlt:.1f}}}}}, circle, draw={c1}, fill={c2}, '+\n",
    "          f'inner sep=1pt] at (axis cs:{ltdtime}, {vlt}) '+\n",
    "          '{};')\n",
    "    node.append(n0)\n",
    "nodes = '\\n'.join([n for n in node])\n",
    "write_txt(text_dir / 'epop_summary_nodes.txt', nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment by reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:31.943707Z",
     "start_time": "2023-10-06T12:37:30.410844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are several \\textbf{reasons for unemployment}. In September 2023, 2.9 million people, or 1.7 percent of the labor force, were unemployed from losing their job (see\\cbox{red!75!orange!70!white}). An additional 0.5 percent voluntarily left a job (see\\cbox{blue!72!black}). Re-entrants, people who left the labor force but are looking for a new job, comprised 1.2 percent (see\\cbox{blue!70!teal!70!gray!62!white}). Lastly, 0.3 percent of the labor force were new entrants to the labor market, looking for their first job (see\\cbox{purple!80!red!85!black}).\n",
      "\n",
      " In September 2023, temporary layoffs were 0.5 percent of the labor force. Permanent job losses were 0.9 percent of labor force. \n"
     ]
    }
   ],
   "source": [
    "srs = ['Job Loser', 'Job Leaver', 'Re-entrant', 'New entrant', \n",
    "       'Temporary Layoff', 'Permanent Separation', 'Level']\n",
    "d1 = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':]\n",
    "\n",
    "df = d1[srs].div(d1['LF'], axis='index') * 100\n",
    "dfa = df.resample('AS').mean()\n",
    "dfa.index = dfa.index + pd.DateOffset(months=6)\n",
    "dfa.to_csv(data_dir / 'unemp_reason.csv', index_label='date', \n",
    "          float_format='%g')\n",
    "\n",
    "lt = df.iloc[-3:]\n",
    "lt.index = [dtxt(i)['mon7'] for i in lt.index]\n",
    "lt = pd.concat([df.rolling(12).mean().iloc[-1].rename('12m avg'), lt.T], axis=1).T\n",
    "lt.to_csv(data_dir / 'unemp_reason_mon.csv', index_label='date', \n",
    "          float_format='%g')\n",
    "\n",
    "x_val = dtxt(dfa.index[-1])['datetime']\n",
    "x_valpr = dtxt(dfa.index[-2])['datetime']\n",
    "y_val = dfa.Level.iloc[-1]\n",
    "prelim = '(p)' if df.index[-1].month != 12 else ''\n",
    "yrp = f'{dtxt(dfa.index[-1])[\"year\"][2:]}{prelim}'\n",
    "barh = ('\\\\addplot[ybar, bar width=5.4pt, draw=black, fill=white!0] '+\n",
    "        f'plot coordinates{{({x_val},{y_val})}};\\n'+\n",
    "        f'\\\\absnode{{{x_valpr}}}{{-0.25}}{{\\scriptsize \\color{{black!70}} {yrp}}};')\n",
    "write_txt(text_dir / 'unemp_rsn_ltbar.txt', barh)\n",
    "\n",
    "cols = ['Job Loser', 'New entrant', 'Re-entrant', 'Job Leaver']\n",
    "sdf = lt[cols].iloc[-1]\n",
    "height = ((sdf.cumsum() - (sdf / 2) + 0.25)).to_dict()\n",
    "val = sdf.to_dict()\n",
    "nodes = [f'\\\\absnode{{3.3}}{{{height[i]}}}{{\\scriptsize {val[i]:.1f}}}' for i in cols]\n",
    "nodetext = '\\n'.join(nodes)\n",
    "write_txt(text_dir / 'unemp_rsn_ltval.txt', nodetext)\n",
    "\n",
    "colors = {'Job Loser': 'red!75!orange!70!white', 'New entrant': 'purple!80!red!85!black', \n",
    "          'Re-entrant': 'blue!70!teal!70!gray!62!white', 'Job Leaver': 'blue!72!black'}\n",
    "cl = {k: c_box(v) for k, v in colors.items()}\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "lt = df.iloc[-1]\n",
    "jlsh = lt['Job Loser']\n",
    "jl = (d1['Job Loser'].iloc[-1] / 1_000)\n",
    "jle = lt['Job Leaver']\n",
    "re = lt['Re-entrant']\n",
    "ne = lt['New entrant']\n",
    "text = ('There are several \\\\textbf{reasons for unemployment}. In '+\n",
    "        f'{ltdt}, {jl:.1f} million people, or {jlsh:.1f} percent of '+\n",
    "        'the labor force, were unemployed from losing their job '+\n",
    "        f'{cl[\"Job Loser\"]}. An additional {jle:.1f} percent '+\n",
    "        f'voluntarily left a job {cl[\"Job Leaver\"]}. Re-entrants, '+\n",
    "        'people who left the labor force but are looking for a new '+\n",
    "        f'job, comprised {re:.1f} percent {cl[\"Re-entrant\"]}. Lastly, '+\n",
    "        f'{ne:.1f} percent of the labor force were new entrants to '+\n",
    "        f'the labor market, looking for their first job '+\n",
    "        f'{cl[\"New entrant\"]}.')\n",
    "write_txt(text_dir / 'unemp_rsn.txt', text)\n",
    "print(text)\n",
    "\n",
    "lf = ['Employed', 'Unemployed']\n",
    "naw_rate = lambda x: np.average(x['NOTATWORK'], weights=x['BASICWGT'])\n",
    "\n",
    "columns = ['LFS', 'MONTH', 'YEAR', 'BASICWGT', 'NOTATWORK']\n",
    "\n",
    "naw = (pd.concat([(pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "              .query('LFS in @lf'))\n",
    "           for year in range(2009, 2024)])\n",
    "        .groupby(['YEAR', 'MONTH'])\n",
    "        .apply(naw_rate) * 100)\n",
    "naw.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in naw.index]\n",
    "df['Employed, Not at Work'] = naw\n",
    "\n",
    "tbl = df.iloc[-3:].T.iloc[:, ::-1]\n",
    "tbl.columns = [dtxt(i)['mon2'] for i in tbl.columns]\n",
    "tbl['12m Avg.'] = df.rolling(12).mean().iloc[-1]\n",
    "tbl['Apr 2020'] = df.loc['2020-04-01']\n",
    "tbl['2020'] = df.loc['2020'].mean()\n",
    "tbl['2019'] = df.loc['2019'].mean()\n",
    "tbl['2009 --`11'] = df.loc['2009': '2011'].mean()\n",
    "tbl = tbl.round(1)\n",
    "d = {'Level': '\\ Unemployed, Any Reason',\n",
    "     'Job Loser': f'\\hspace{{2mm}}\\cbox{{{colors[\"Job Loser\"]}}} Job Loser',\n",
    "     'Temporary Layoff': '\\hspace{9mm}Temporary Layoff',\n",
    "     'Permanent Separation': '\\hspace{9mm}Permanent Separation',\n",
    "     'Re-entrant': f'\\hspace{{2mm}}\\cbox{{{colors[\"Re-entrant\"]}}} Re-entrant',\n",
    "     'New entrant': f'\\hspace{{2mm}}\\cbox{{{colors[\"New entrant\"]}}} New entrant',\n",
    "     'Job Leaver': f'\\hspace{{2mm}}\\cbox{{{colors[\"Job Leaver\"]}}} Job Leaver'}\n",
    "\n",
    "final = tbl.loc[d.keys()].rename(d)\n",
    "\n",
    "final.loc['\\\\textit{See also:}', final.columns] = [''] * 8\n",
    "final.loc['\\ \\ Employed, Not at Work*'] = tbl.loc['Employed, Not at Work']\n",
    "final.to_csv(data_dir / 'unempreason_table.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "tl = lt['Temporary Layoff']\n",
    "pjl = lt['Permanent Separation']\n",
    "\n",
    "text = (f'In {ltdt}, temporary layoffs were {tl:.1f} percent of '+\n",
    "        f'the labor force. Permanent job losses were {pjl:.1f} '+\n",
    "        'percent of labor force. ')\n",
    "write_txt(text_dir / 'unemp_rsn2.txt', text)\n",
    "print('\\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployed long-term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:31.961404Z",
     "start_time": "2023-10-06T12:37:31.945365Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of September 2023, BLS \\href{https://www.bls.gov/webapps/legacy/cpsatab12.htm}{reports} that 0.46 percent of the age 16 and older population have been unemployed for 27 weeks or longer, compared to 0.42 percent in September 2022 (see {\\color{blue}\\textbf{---}}). This measure of \\textbf{long-term unemployment} peaked at 2.96 percent of the population in April 2010, but had fallen to 0.42 percent in December 2019. \n",
      " \n",
      "In September 2023, 0.81 percent of those age 16 and older have been unemployed for at least 15 weeks (see {\\color{violet!90!black}\\textbf{---}}), following 0.81 percent in August 2023, and 0.76 percent in July 2023. One-year prior, in September 2022, 0.70 percent are unemployed for 15 weeks or more. \n"
     ]
    }
   ],
   "source": [
    "srs = ['LT', 'MT', 'POP']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, srs]\n",
    "\n",
    "data = (df.divide(df['POP'], axis=0) * 100).drop(['POP'], axis=1)\n",
    "data.to_csv(data_dir / 'ltu.csv', index_label='date', float_format='%g')\n",
    "\n",
    "node = end_node(data['LT'], 'blue', date='m', digits=2, offset=0.35)\n",
    "write_txt(text_dir / 'ltu_node.txt', node)\n",
    "\n",
    "node = end_node(data['MT'], 'violet!90!black', digits=2, date='m', offset=0.35)\n",
    "write_txt(text_dir / 'ltu_node2.txt', node)\n",
    "\n",
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "pdate = dtxt(data.index[-13])['mon1']\n",
    "hdate = dtxt(data['LT'].idxmax())['mon1']\n",
    "prdt = dtxt(data.index[-2])['mon1']\n",
    "prdt2 = dtxt(data.index[-3])['mon1']\n",
    "\n",
    "recent_min = data.loc['2015':'2020-02-01', 'LT'].min()\n",
    "recent_min_dt = dtxt(data.loc['2015':'2020-02-01', 'LT'].idxmin())['mon1']\n",
    "\n",
    "text = (f'As of {ldate}, BLS '+\n",
    "        '\\href{https://www.bls.gov/webapps/legacy/cpsatab12.htm}{reports} '+\n",
    "        f'that {data[\"LT\"].iloc[-1]:.2f} percent of the age 16 and older '+\n",
    "         'population have been unemployed for 27 weeks or longer, '+\n",
    "        f'compared to {data[\"LT\"].iloc[-13]:.2f} percent in {pdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}). This measure of \\\\textbf{long-term '+\n",
    "        f'unemployment}} peaked at {data[\"LT\"].max():.2f} percent of the '+\n",
    "        f'population in {hdate}, but had fallen to {recent_min:.2f} percent '+\n",
    "        f'in {recent_min_dt}. \\n \\nIn {ldate}, {data[\"MT\"].iloc[-1]:.2f} '+\n",
    "        'percent of those age 16 and older have been unemployed for at '+\n",
    "        'least 15 weeks (see {\\color{violet!90!black}\\\\textbf{---}}), following '+\n",
    "        f'{data[\"MT\"].iloc[-2]:.2f} percent in {prdt}, '+\n",
    "        f'and {data[\"MT\"].iloc[-3]:.2f} percent in {prdt2}. One-year prior, in '+\n",
    "        f'{pdate}, {data[\"MT\"].iloc[-13]:.2f} percent are unemployed for 15 '+\n",
    "        'weeks or more. ')\n",
    "write_txt(text_dir / 'ltu.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:31.977399Z",
     "start_time": "2023-10-06T12:37:31.962671Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among those who are unemployed in September 2023, the average (mean) \\textbf{duration of unemployment} is 21.5 weeks (see {\\color{blue!60!cyan}\\textbf{---}}), and the typical (median) duration of unemployment is 9.2 weeks (see {\\color{green!75!blue}\\textbf{---}}). Over the year prior to COVID-19, ending February 2020, the average duration of unemployment was 21.7 weeks and the typical duration was 9.3 weeks.\n"
     ]
    }
   ],
   "source": [
    "s = {'Median': 'green!75!blue', 'Mean': 'blue!60!cyan'}\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, s.keys()]\n",
    "df.to_csv(data_dir / 'unempdur.csv', index_label='date', \n",
    "          float_format='%g')\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "lt = df.iloc[-1]\n",
    "\n",
    "adj = node_adj(df)\n",
    "smax = df.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in s.keys()}\n",
    "nodes  ='\\n'.join([end_node(df[series], color, \n",
    "                            date=date[series], \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in s.items()])\n",
    "write_txt(text_dir / 'unempdur_nodes.txt', nodes) \n",
    "\n",
    "pc_yr = df.loc['2019-03-01':'2020-02-01'].mean()\n",
    "text = (f'Among those who are unemployed in {ltdt}, the average '+\n",
    "        f'(mean) \\\\textbf{{duration of unemployment}} is {lt.Mean:.1f} '+\n",
    "        f'weeks {c_line(s[\"Mean\"])}, and the typical (median) '+\n",
    "        f'duration of unemployment is {lt.Median:.1f} weeks '+\n",
    "        f'{c_line(s[\"Median\"])}. Over the year '+\n",
    "        'prior to COVID-19, ending February 2020, the '+\n",
    "        'average duration of unemployment was '+\n",
    "        f'{pc_yr.Mean:.1f} weeks and the typical '+\n",
    "        f'duration was {pc_yr.Median:.1f} weeks.')\n",
    "write_txt(text_dir / 'unempdur.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part-Time Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:31.996154Z",
     "start_time": "2023-10-06T12:37:31.978786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Around 26 million people work part-time, defined as fewer than 35 hours per week, and the reasons for doing so vary. \n",
      "\n",
      "In September 2023, 4.1 million people worked part-time for economic reasons, equivalent to 2.4 percent of the labor force (see {\\color{red}\\textbf{---}}). In 2019, an average of 2.7 percent of the labor force worked part-time for economic reasons. In 2010, following the great recession, the rate was 5.8 percent.\n",
      "\n",
      "Voluntary part-time workers total 22.2 million in September 2023, or 13.2 percent of the labor force (see {\\color{orange!80!yellow}\\textbf{---}}). The category is 13.1 percent of the labor force in 2019, on average.\n"
     ]
    }
   ],
   "source": [
    "srs = ['PTECON', 'PTNONECON', 'LF']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, srs])\n",
    "df['TOTAL'] = df['PTECON'] + df['PTNONECON']\n",
    "# Total part-time for summary text\n",
    "text = (f'Around {df.TOTAL.iloc[-1] / 1000:.0f} million people '+\n",
    "        'work part-time, defined as fewer than 35 hours per week, '+\n",
    "        'and the reasons for doing so vary.')\n",
    "write_txt(text_dir / 'pt_tot.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "# Share of labor force\n",
    "data = (df.divide(df.LF, axis=0) * 100)\n",
    "data = data.loc['1994':, ['PTECON', 'PTNONECON', 'TOTAL']]\n",
    "data.to_csv(data_dir / 'parttime.csv', index_label='date')\n",
    "\n",
    "color = 'red'\n",
    "col2 = 'orange!80!yellow'\n",
    "node = end_node(data.PTECON, color, percent=True)\n",
    "node2 = end_node(data.PTNONECON, col2, percent=True, \n",
    "                 date='m', full_year=True, offset=-0.3)\n",
    "nodes = node + '\\n' + node2\n",
    "write_txt(text_dir / 'pt_nodes.txt', nodes)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "lttot = df.PTECON.iloc[-1] / 1_000\n",
    "ltvpt = df.PTNONECON.iloc[-1] / 1_000\n",
    "ltsh = data.PTECON.iloc[-1]\n",
    "val19 = data.loc['2019', 'PTECON'].mean()\n",
    "val10 = data.loc['2010', 'PTECON'].mean()\n",
    "ltvsh = value_text(data.PTNONECON.iloc[-1], 'plain')\n",
    "vsh19 = value_text(data.loc['2019', 'PTNONECON'].mean(), 'plain')\n",
    "also = 'also ' if ltvsh == vsh19 else ''\n",
    "\n",
    "text = (f'In {ltdt}, {lttot:.1f} million people worked part-time '+\n",
    "        f'for economic reasons, equivalent to {ltsh:.1f} percent '+\n",
    "        f'of the labor force {c_line(color)}. In 2019, an average '+\n",
    "        f'of {val19:.1f} percent of the labor force worked part-time '+\n",
    "        'for economic reasons. In 2010, following the great '+\n",
    "        f'recession, the rate was {val10:.1f} percent.\\n\\nVoluntary '+\n",
    "        f'part-time workers total {ltvpt:.1f} million in {ltdt}, or '+\n",
    "        f'{ltvsh} of the labor force {c_line(col2)}. The '+\n",
    "        f'category is {also}{vsh19} of the labor force in '+\n",
    "        '2019, on average.')\n",
    "write_txt(text_dir / 'parttime.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Jobholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:32.009202Z",
     "start_time": "2023-10-06T12:37:31.997288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In September 2023, a seasonally-adjusted total of 8.2 million people \\textbf{worked more than one job} during the survey reference week, equivalent to five percent of workers. Over the three months ending September 2023, an average of 5.0 percent of workers were multiple jobholders (see {\\color{blue!50!violet!80!black}\\textbf{---}}). In 2019, an average of 5.1 percent of workers had more than one job during the survey reference week. \n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, ['MJHsa', 'EMPsa']])\n",
    "data = ((df.MJHsa / df.EMPsa) * 100).dropna().rename('MJH')\n",
    "d3m = data.rolling(3).mean()\n",
    "d3m.to_csv(data_dir / 'mjh.csv', index_label='date')\n",
    "color = 'blue!50!violet!80!black'\n",
    "node = end_node(d3m, color, percent=True, size=1.2, date='m')\n",
    "write_txt(text_dir / 'mjh_node.txt', node)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "totval = df.MJHsa.iloc[-1] / 1_000\n",
    "ltval = value_text(data.iloc[-1], 'plain')\n",
    "l3val = f'{d3m.iloc[-1]:.1f}'\n",
    "l19val = data.loc['2019'].mean()\n",
    "comp_date = '2020-02-01'\n",
    "same = 'Over' # Less awkward text when latest and 3ma match\n",
    "if ltval == l3val:\n",
    "    same = 'Likewise, over'\n",
    "\n",
    "text = (f'In {ltdt}, a seasonally-adjusted total of {totval:.1f} '+\n",
    "        'million people \\\\textbf{worked '+\n",
    "        'more than one job} during the survey reference week, '+\n",
    "        f'equivalent to {ltval} of workers. '+\n",
    "        f'{same} the three months ending {ltdt}, an average of '+\n",
    "        f'{l3val} percent of workers were multiple '\n",
    "        f'jobholders {c_line(color)}. In 2019, an average of '+\n",
    "        f'{l19val:.1f} percent of workers had more than one job '+\n",
    "        'during the survey reference week. ')\n",
    "write_txt(text_dir / 'mjh.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Employed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:32.031701Z",
     "start_time": "2023-10-06T12:37:32.010379Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1988':, ['seinc', 'seuninc', 'LFnsa']])\n",
    "\n",
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1988':, ['LF']])\n",
    "\n",
    "df3 = pd.read_csv(data_dir / 'se_inc_hist.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "\n",
    "uninc = (df['seuninc'].divide(df2['LF'], axis=0) * 100).rename('uninc')\n",
    "inc = (df['seinc'].divide(df['LFnsa'], axis=0) * 100).rename('inc')\n",
    "INC = (df3.INC.divide(df['LFnsa'], axis=0) / 10).rename('INC')\n",
    "res = uninc.to_frame().join(inc).join(INC).loc['1989':]\n",
    "res.to_csv(data_dir / 'selfemp.csv', index_label='date')\n",
    "dft = res[['inc', 'uninc']]\n",
    "\n",
    "adj = node_adj(dft)\n",
    "smax = dft.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'inc': 'green!80!black', \n",
    "          'uninc': 'purple'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(dft[series], color, \n",
    "                            date=date[series], \n",
    "                            percent=True, full_year=True, \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'selfemp_nodes.txt', nodes)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:32.042896Z",
     "start_time": "2023-10-06T12:37:32.033057Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of September 2023, there are 9.7 million \\textbf{unincorporated self-employed}, equivalent to 5.8 percent of the labor force (see {\\color{purple}\\textbf{---}}). Over the past year, the unincorporated self-employed made up an average of 5.9 percent of the labor force, compared to an average of 5.8 percent in 2019. From 1989 to 1994, the category made up an average of 8.0 percent of the labor force.  \n",
      "\n",
      "The \\textbf{incorporated self-employed} total 6.7 million in September 2023, equivalent to 4.0 percent of the labor force (see {\\color{green!80!black}\\textbf{---}}). In 2019, the category made up 3.8 percent of the labor force. Incorporated self-employed are not reported by BLS prior to 2000, but can be calculated from the CPS, and make up a average of 2.8 percent of the labor force from 1989 to 1994. \n"
     ]
    }
   ],
   "source": [
    "ltdt = dtxt(res.index[-1])['mon1']\n",
    "seutot = df['seuninc'].iloc[-1] / 1_000\n",
    "seush = res['uninc'].iloc[-1]\n",
    "seu1yr = res['uninc'].iloc[-12:].mean()\n",
    "seu19 = res.loc['2019', 'uninc'].mean()\n",
    "seu89 = res.loc['1989':'1994', 'uninc'].mean()\n",
    "\n",
    "text = (f'As of {ltdt}, there are {seutot:.1f} million \\\\textbf{{unincorporated '+\n",
    "        f'self-employed}}, equivalent to {seush:.1f} percent of the labor '+\n",
    "        f'force {c_line(colors[\"uninc\"])}. Over the past year, the '+\n",
    "        f'unincorporated self-employed made up an average of {seu1yr:.1f} '+\n",
    "        f'percent of the labor force, compared to an average of {seu19:.1f} '+\n",
    "        'percent in 2019. From 1989 to 1994, the category made up an '+\n",
    "        f'average of {seu89:.1f} percent of the labor force. ')\n",
    "write_txt(text_dir / 'selfemp1.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "seitot = df['seinc'].iloc[-1] / 1_000\n",
    "seish = res['inc'].iloc[-1]\n",
    "sei19 = res.loc['2019', 'inc'].mean()\n",
    "sei89 = res.loc['1989':'1994', 'INC'].mean()\n",
    "\n",
    "text = (f'The \\\\textbf{{incorporated self-employed}} total {seitot:.1f} million '+\n",
    "        f'in {ltdt}, equivalent to {seish:.1f} percent of the labor force '+\n",
    "        f'{c_line(colors[\"inc\"])}. In 2019, the category made up {sei19:.1f} percent '+\n",
    "        'of the labor force. Incorporated self-employed are not reported by '+\n",
    "        'BLS prior to 2000, but can be calculated from the CPS, and make up a '+\n",
    "        f'average of {sei89:.1f} percent of the labor force from 1989 to 1994. ')\n",
    "print(text)\n",
    "write_txt(text_dir / 'selfemp2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Weekly Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:32.603424Z",
     "start_time": "2023-10-06T12:37:32.044298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:203: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in one or more of the estimated spectra.\n",
      "  warn(errors, X13Warning)\n",
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:203: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in the estimated spectrum of the regARIMA residuals.\n",
      "  warn(errors, X13Warning)\n"
     ]
    }
   ],
   "source": [
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "cps = pd.read_csv(data_dir / 'uslhrs.csv', \n",
    "                  index_col='name', parse_dates=True)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['TOTCES'] = df2['ceshrstot']\n",
    "data['TOTLFS'] = df2['avghrstot']\n",
    "data['SERVNSA'] = df2['avghrsserv']\n",
    "data['SERVSA'] = x13_arima_analysis(df2['avghrsserv'].dropna()).seasadj\n",
    "data['PNS'] = df2['ceshrspns']\n",
    "data['PTECONNSA'] = df2['avghrsptecon']\n",
    "data['PTECONSA'] = x13_arima_analysis(df2['avghrsptecon'].dropna()).seasadj\n",
    "data['TOTCPS'] = cps['Total']\n",
    "data['PA_CPSFT'] = cps['Age2554FT']\n",
    "data['FT_CPS'] = cps['FT']\n",
    "data['PA_CPSPT'] = cps['Age2554PT']\n",
    "data['PT_CPS'] = cps['PT']\n",
    "\n",
    "data.loc['1989':].to_csv(data_dir / 'hours.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:32.614725Z",
     "start_time": "2023-10-06T12:37:32.605209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve data\n",
    "data = pd.read_csv(data_dir / 'hours.csv', index_col='date', \n",
    "                   parse_dates=True)\n",
    "ltval = data['TOTLFS'].iloc[-1]\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "feb20val = data.loc['2020-02-01', 'TOTLFS']\n",
    "compare = compare_text(ltval, feb20val, [0.2, 1.5, 3.0])\n",
    "avg90 = data.loc['1998':'2000', 'TOTLFS'].mean()\n",
    "gfclow = data.loc['2005': '2012', 'TOTLFS'].min()\n",
    "gfclowdt = dtxt(data.loc['2005': '2012', 'TOTLFS'].idxmin())['mon1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:32.642528Z",
     "start_time": "2023-10-06T12:37:32.616325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual hours worked by people at work in all industries during the survey reference week average 38.5 in September 2023 (see {\\color{blue}\\textbf{---}}), slightly below the 38.8 average actual hours worked in February 2020. Average actual hours for this group average 39.6 from 1998 through 2000, and fell to a great recession low of 37.4 in February 2010.\n",
      "Those in service occupations work fewer hours on average, with 34.6 average weekly hours in September 2023, slightly below the 35.2 average in February 2020. Those part-time for economic reasons (see {\\color{red!90!black}\\textbf{---}}) work an average of 23.0 hours per week in September 2023. \n",
      "In September 2023, production and non-supervisory workers (see {\\color{orange}\\textbf{---}}), about four of every five employees, worked 33.8 hours per week on average, in line with the 33.6 average weekly hours in February 2020 and slightly below the 1998--2000 average of 34.4 hours.\n"
     ]
    }
   ],
   "source": [
    "text = ('Actual hours worked by people at work in all industries '+\n",
    "        f'during the survey reference week average {ltval:.1f} in {ltdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}), '+\n",
    "        f'{compare} the {feb20val:.1f} average actual hours worked in February '+\n",
    "        f'2020. Average actual hours for this group average {avg90:.1f} from '+\n",
    "        '1998 through 2000, and fell to a great recession low of '+\n",
    "        f'{gfclow:.1f} in {gfclowdt}.')\n",
    "write_txt(text_dir / 'hours_tot.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval2 = data.SERVSA.iloc[-1]\n",
    "feb20val2 = data.loc['2020-02-01', 'SERVSA']\n",
    "compare2 = compare_text(ltval2, feb20val2, [0.2, 0.6, 2.5])\n",
    "pteval = data.PTECONSA.iloc[-1]\n",
    "text = ('Those in service occupations work '+\n",
    "        f'fewer hours on average, with {ltval2:.1f} average '+\n",
    "        f'weekly hours in {ltdate}, {compare2} the {feb20val2:.1f} '+\n",
    "        'average in February 2020. Those part-time '+\n",
    "        'for economic reasons (see {\\color{red!90!black}\\\\textbf{---}}) '+\n",
    "        f'work an average of {pteval:.1f} hours per week in {ltdate}. ')\n",
    "write_txt(text_dir / 'hours_lfs2.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval3 = data.PNS.iloc[-1]\n",
    "feb20val3 = data.loc['2020-02-01', 'PNS']\n",
    "compare3 = compare_text(ltval3, feb20val3, [0.2, 0.6, 2.5])\n",
    "val98 = data.loc['1998':'2000', 'PNS'].mean()\n",
    "compare4 = compare_text(ltval3, val98, [0.2, 0.6, 2.5])\n",
    "text = (f'In {ltdate}, '+\n",
    "        'production and non-supervisory workers (see {\\color{orange}\\\\textbf{---}})'+\n",
    "        ', about four of every five employees, '+\n",
    "        f'worked {ltval3:.1f} hours per week on average, '+\n",
    "        f'{compare3} the {feb20val3:.1f} average weekly hours in February 2020 and '+\n",
    "        f'{compare4} the 1998--2000 average of {val98:.1f} hours.')\n",
    "write_txt(text_dir / 'hours_ces.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:32.681088Z",
     "start_time": "2023-10-06T12:37:32.651340Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'TOTCES': 'Total Actual, CES',\n",
    "     'PNS': '\\hspace{2mm} Production \\& Non-Supervisory, CES ({\\color{orange}\\\\textbf{---}} )',\n",
    "     'TOTLFS': 'Total Actual, LFS ({\\color{blue}\\\\textbf{---}})',\n",
    "     'PTECONSA': '\\hspace{2mm} Part-Time for Economic Reasons, LFS ({\\color{red!90!black}\\\\textbf{---}})',\n",
    "     'SERVSA': '\\hspace{2mm} Services Occupations, LFS',\n",
    "     'TOTCPS': 'Total Usual, CPS',\n",
    "     'FT_CPS': '\\hspace{2mm} Full-Time, All Ages, CPS',\n",
    "     'PA_CPSFT': '\\hspace{4mm} Full-Time, Age 25 to 54, CPS',\n",
    "     'PT_CPS': '\\hspace{2mm} Part-Time, All Ages, CPS',\n",
    "     'PA_CPSPT': '\\hspace{4mm} Part-Time, Age 25 to 54, CPS'}\n",
    "\n",
    "dft = data[d.keys()].rename(d, axis=1)\n",
    "tbl = dft.iloc[[-1, -2, -3, -13]].T\n",
    "tbl.columns = [dtxt(c)['mon8'] for c in tbl.columns]\n",
    "tbl['2019'] = dft.loc['2019'].mean()\n",
    "tbl['2015'] = dft.loc['2015'].mean()\n",
    "tbl['2010'] = dft.loc['2010'].mean()\n",
    "\n",
    "tbl.round(1).to_csv(data_dir / 'hoursworked_table.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flows, Newly Employed, Not looking for work previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T12:37:32.709356Z",
     "start_time": "2023-10-06T12:37:32.683226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In September 2023, 6.3 million people were newly employed (on a gross basis). Of these, 71.6 percent were not looking for work in the prior month (see {\\color{lime!80!green}\\textbf{---}}). Over the past three months, an average of 73.2 percent of the newly employed were not looking for work the month prior (see {\\color{green!60!teal!80!black}\\textbf{---}}).\n",
      "\n",
      "When unemployment is low, the newly employed are more likely to come from outside of the labor force. Four years ago, in September 2019, 73.1 percent of the newly employed had not looked for work the previous month.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date')).loc['1990':, ['NILF', 'UNEMP']]\n",
    "df['TOTAL'] = df.astype('float').sum(axis=1)\n",
    "sh = (df['NILF'] / df['TOTAL']).rename('total') * 100\n",
    "\n",
    "sh.to_csv(data_dir / 'lf_flow.csv', index_label='date', \n",
    "          header=True, float_format='%g')\n",
    "ma = sh.resample('QS').mean().rename('quarterly')\n",
    "ma.to_csv(data_dir / 'lf_flow_q.csv', index_label='date', \n",
    "          header=True, float_format='%g')\n",
    "\n",
    "col = 'green!60!teal!80!black'\n",
    "col2 = 'lime!80!green'\n",
    "node = end_node(ma, col, date='m', size=1.2)\n",
    "write_txt(text_dir / 'lf_flow_node.txt', node)\n",
    "\n",
    "totval = df['TOTAL'].iloc[-1] / 1000\n",
    "shval = sh.iloc[-1]\n",
    "maval = ma.iloc[-1] \n",
    "sh4y = sh.iloc[-49]\n",
    "\n",
    "ltdt = dtxt(sh.index[-1])['mon1']\n",
    "prdt = dtxt(sh.index[-49])['mon1']\n",
    "\n",
    "text = (f'In {ltdt}, {totval:.1f} million people were newly '+\n",
    "        f'employed (on a gross basis). Of these, {shval:.1f} '+\n",
    "        f'percent were not looking for work in the prior month '+\n",
    "        f'{c_line(col2)}. Over the past three months, an average '+\n",
    "        f'of {maval:.1f} percent of the newly employed were not '+\n",
    "        f'looking for work the month prior {c_line(col)}.\\n\\nWhen '+\n",
    "        'unemployment is low, the newly employed are more '+\n",
    "        'likely to come from outside of the labor force. Four '+\n",
    "        f'years ago, in {prdt}, {sh4y:.1f} percent of the newly '+\n",
    "        'employed had not looked for work the previous month.')\n",
    "write_txt(text_dir / 'lf_flow.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
