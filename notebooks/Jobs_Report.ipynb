{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Jobs Report Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:42:48.346088Z",
     "start_time": "2022-03-04T13:42:47.708388Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:04.354842Z",
     "start_time": "2022-03-04T13:42:52.331414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "February 2022\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS14000003': 'White', \n",
    "          'LNS14000006': 'Black',\n",
    "          'LNS14000009': 'Hispanic',\n",
    "          'LNS14032183': 'Asian',\n",
    "          'LNS14000000': 'Total',\n",
    "          'LNS13327709': 'U6',\n",
    "          'LNS13000000': 'Level',\n",
    "          'LNU03008636': 'LT',\n",
    "          'LNU03008516': 'MT',\n",
    "          'LNU00000000': 'POP',\n",
    "          'LNS12300060': 'PA_EPOP',\n",
    "          'LNS13023621': 'Job Loser',\n",
    "          'LNS13023653': 'Temporary Layoff',\n",
    "          'LNS13026638': 'Permanent Separation',\n",
    "          'LNS13023705': 'Job Leaver', \n",
    "          'LNS13023557': 'Re-entrant',\n",
    "          'LNS13023569': 'New entrant',\n",
    "          'LNS13008276': 'Median',\n",
    "          'LNS13008275': 'Mean',\n",
    "          'LNS17200000': 'NILF',\n",
    "          'LNS17100000': 'UNEMP',\n",
    "          'LNS11000000': 'LF',\n",
    "          'LNS12032194': 'PTECON'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1988, 2022)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main.csv', index_label='date')\n",
    "print(dtxt(df.index[-1])['mon1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:16.239203Z",
     "start_time": "2022-03-04T13:43:06.575864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'CES0500000003': 'ALL', \n",
    "          'CES0500000008': 'PNS',\n",
    "          'LNS12005054': 'avghrstot',\n",
    "          'LNU02033699': 'avghrsserv',\n",
    "          'CES0500000002': 'ceshrstot',\n",
    "          'CES0600000002': 'ceshrsgoods',\n",
    "          'CES0800000002': 'ceshrsserv',\n",
    "          'CES0500000007': 'ceshrspns',\n",
    "          'CES9000000001': 'govjobs',\n",
    "          'CES9091000001': 'fedjobs',\n",
    "          'CES9092000001': 'stjobs',\n",
    "          'CES9093000001': 'locjobs',\n",
    "          'LNU02033232': 'avghrsptecon',\n",
    "          'LNU02026619': 'MJH',\n",
    "          'LNS12026619': 'MJHsa',\n",
    "          'LNU02000000': 'EMP',\n",
    "          'LNS12000000': 'EMPsa',\n",
    "          'LNU00000001': 'MenPop',\n",
    "          'LNU00000002': 'WomenPop',\n",
    "          'LNU01000001': 'MenLF',\n",
    "          'LNU01000002': 'WomenLF',\n",
    "          'LNS11300001': 'MenLFPR',\n",
    "          'LNS11300002': 'WomenLFPR'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1988, 2022)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:20.206272Z",
     "start_time": "2022-03-04T13:43:18.771743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS17100001': 'MenUE',\n",
    "          'LNS17100002': 'WomenUE',\n",
    "          'LNS17200001': 'MenNE',\n",
    "          'LNS17200002': 'WomenNE',\n",
    "          'LNS17400001': 'MenEU',\n",
    "          'LNS17400002': 'WomenEU',\n",
    "          'LNS17600001': 'MenNU',\n",
    "          'LNS17600002': 'WomenNU',\n",
    "          'LNS17800001': 'MenEN',\n",
    "          'LNS17800002': 'WomenEN',\n",
    "          'LNS17900001': 'MenUN',\n",
    "          'LNS17900002': 'WomenUN',\n",
    "          'LNS12000001': 'MenE',\n",
    "          'LNS12000002': 'WomenE',\n",
    "          'LNS13000001': 'MenU',\n",
    "          'LNS13000002': 'WomenU',\n",
    "          'LNS15000001': 'MenN',\n",
    "          'LNS15000002': 'WomenN'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (2018, 2022)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main3.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Gross Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:22.242989Z",
     "start_time": "2022-03-04T13:43:22.224979Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main3.csv', parse_dates=['date'])\n",
    "        .set_index('date')) / 1000\n",
    "\n",
    "cols = ['MenEU', 'WomenEU', 'MenEN', 'WomenEN', 'MenUE', 'WomenUE',\n",
    "        'MenUN', 'WomenUN', 'MenNE', 'WomenNE', 'MenNU', 'WomenNU']\n",
    "\n",
    "cols2 = []\n",
    "for col in cols:\n",
    "    name = f'{col}{col[-2]}'\n",
    "    cols2.append(name)\n",
    "    df[name] = (df[col] / df[f'{col[:-2]}{col[-2]}'].shift()) * 100\n",
    "\n",
    "df.loc['2013-01-01':, cols2].to_csv(data_dir / 'grosslf.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:25.084149Z",
     "start_time": "2022-03-04T13:43:25.051430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLS \\href{https://www.bls.gov/news.release/empsit.nr0.htm}{reports} 6.3 million unemployed people in February 2022, and an unemployment rate of 3.8 percent (see {\\color{blue!50!cyan}\\textbf{---}}), slightly below the January 2022 rate of 4.0 percent, and substantially below the February 2021 rate of 6.2 percent. \n",
      "\n",
      "In February 2022, the labor under-utilization rate is 7.2 percent (see {\\color{blue}\\textbf{---}}). \n",
      "\n",
      "Unemployment is much more common for disadvantaged groups, with the black or African American unemployment rate typically double the white unemployment rate. A very tight labor market may have the effect of reducing racial discrimination in hiring. However, disadvantaged groups are more likely to lose jobs in a downturn. As a result, the full-employment portion of the business cycle is quite short for many people. Since February 2020, the black unemployment rate has increased by 0.6 percentage point to 6.6 percent (see {\\color{green!50!teal!60!black}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'jobs_report_main.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "srs = ['Total', 'U6']\n",
    "df.loc['1989':, srs].to_csv(data_dir / 'unemp2.csv', index_label='date')\n",
    "\n",
    "srs = ['White', 'Black', 'Hispanic']\n",
    "df.loc['1989':, srs].to_csv(data_dir / 'unemp.csv', index_label='date')\n",
    "\n",
    "s = series_info(df['Level'])\n",
    "s2 = series_info(df['Total'])\n",
    "s3 = series_info(df['Black'])\n",
    "s4 = series_info(df['U6'])\n",
    "compare = compare_text(df['Total'].iloc[-1], df['Total'].iloc[-2], [0.15, 1.5, 3.0])\n",
    "compare2 = compare_text(df['Total'].iloc[-1], df['Total'].iloc[-13], [0.15, 1.5, 3.0])\n",
    "pryrdt = dtxt(df.index[-13])['mon1']\n",
    "\n",
    "if compare[-5:] != compare2[-5:]:\n",
    "    conj = f', but {compare2} the {pryrdt} rate of {df[\"Total\"].iloc[-13]:.1f} percent'\n",
    "elif compare != compare2:\n",
    "    conj = f', and {compare2} the {pryrdt} rate of {df[\"Total\"].iloc[-13]:.1f} percent'\n",
    "else:\n",
    "    conj = ''\n",
    "    \n",
    "text = ('BLS \\href{https://www.bls.gov/news.release/empsit.nr0.htm}{reports} '+\n",
    "        f'{s[\"val_latest\"]/1000:.1f} million '+\n",
    "        f'unemployed people in {s[\"date_latest_ft\"]}, '+\n",
    "        f'and an unemployment rate of {s2[\"val_latest\"]} percent '+\n",
    "        '(see {\\color{blue!50!cyan}\\\\textbf{---}}), '+\n",
    "        f'{compare} the {s[\"date_prev_ft\"]} rate of {s2[\"val_prev\"]} percent'+\n",
    "        f'{conj}.')\n",
    "write_txt(text_dir / 'unemp1.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "mval = f', {s4[\"last_matched\"]}.' if s4['days_since_match'] > 1000 else '.'\n",
    "text = (f'In {s[\"date_latest_ft\"]}, the labor under-utilization rate is '+\n",
    "        f'{s4[\"val_latest\"]} percent '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}})'+\n",
    "        f'{mval}')\n",
    "write_txt(text_dir / 'unemp2.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "write_txt(text_dir / 'u6_node.txt', \n",
    "          end_node(df['U6'], 'blue', date='m', percent=True, offset=0.4))\n",
    "write_txt(text_dir / 'u3_node.txt', end_node(df['Total'], 'blue!50!cyan', percent=True))\n",
    "\n",
    "black_ch = df['Black'].iloc[-1] - df.loc['2020-02-01', 'Black']\n",
    "bch = value_text(black_ch, style='increase_by', ptype='pp')\n",
    "text = ('Unemployment is much more common for disadvantaged groups, '+\n",
    "        'with the black or African American unemployment rate typically '+\n",
    "        'double the white unemployment rate. '+\n",
    "        'A very tight labor market may have the effect of reducing racial '+\n",
    "        'discrimination in hiring. However, disadvantaged groups are more '+\n",
    "        'likely to lose jobs in a downturn. As a result, the full-employment '+\n",
    "        'portion of the business cycle is quite short for many people. '\n",
    "        'Since February 2020, the black unemployment rate '+\n",
    "        f'has {bch} to {s3[\"val_latest\"]:.1f} percent '+\n",
    "        '(see {\\color{green!50!teal!60!black}\\\\textbf{---}}).')\n",
    "write_txt(text_dir / 'unemp3.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:26.070584Z",
     "start_time": "2022-03-04T13:43:26.044990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feb `22</th>\n",
       "      <th>Jan `22</th>\n",
       "      <th>Dec `21</th>\n",
       "      <th>Nov `21</th>\n",
       "      <th>Oct `21</th>\n",
       "      <th>Sep `21</th>\n",
       "      <th>GFC peak</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Under-utilization Rate (U6)</th>\n",
       "      <td>7.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17.2</td>\n",
       "      <td>Dec `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unemployment Rate (U3)</th>\n",
       "      <td>3.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Oct `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\textit{by race/ethnicity:}</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} White</th>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>9.2</td>\n",
       "      <td>Oct `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Black</th>\n",
       "      <td>6.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>16.8</td>\n",
       "      <td>Mar `10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Hispanic</th>\n",
       "      <td>4.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Aug `09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\\hspace{2mm} Asian</th>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Dec `09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Feb `22 Jan `22 Dec `21 Nov `21 Oct `21 Sep `21  \\\n",
       "Under-utilization Rate (U6)     7.2     7.1     7.3     7.7     8.2     8.5   \n",
       "Unemployment Rate (U3)          3.8     4.0     3.9     4.2     4.6     4.7   \n",
       "\\textit{by race/ethnicity:}                                                   \n",
       "\\hspace{2mm} White              3.3     3.4     3.2     3.7     3.9     4.2   \n",
       "\\hspace{2mm} Black              6.6     6.9     7.1     6.5     7.8     7.8   \n",
       "\\hspace{2mm} Hispanic           4.4     4.9     4.9     5.2     5.7     6.1   \n",
       "\\hspace{2mm} Asian              3.1     3.6     3.8     3.9     4.2     4.2   \n",
       "\n",
       "                            GFC peak     Date  \n",
       "Under-utilization Rate (U6)     17.2  Dec `09  \n",
       "Unemployment Rate (U3)          10.0  Oct `09  \n",
       "\\textit{by race/ethnicity:}                    \n",
       "\\hspace{2mm} White               9.2  Oct `09  \n",
       "\\hspace{2mm} Black              16.8  Mar `10  \n",
       "\\hspace{2mm} Hispanic           13.0  Aug `09  \n",
       "\\hspace{2mm} Asian               8.4  Dec `09  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srs = ['U6', 'Total', 'White', 'Black', 'Hispanic', 'Asian']\n",
    "untab = df[srs].iloc[-6:].iloc[::-1].T\n",
    "untab.columns = untab.columns.strftime('%b `%y')\n",
    "untab['GFC peak'] = df.loc['2005':'2013', srs].max()\n",
    "untab['Date'] = df.loc['2005':'2013', srs].idxmax().dt.strftime('%b `%y')\n",
    "d = {'Total': 'Unemployment Rate (U3)',\n",
    "     'U6': 'Under-utilization Rate (U6)',\n",
    "     'White': '\\hspace{2mm} White',\n",
    "     'Black': '\\hspace{2mm} Black',\n",
    "     'Hispanic': '\\hspace{2mm} Hispanic',\n",
    "     'Asian': '\\hspace{2mm} Asian'}\n",
    "untab.index = untab.index.map(d)\n",
    "\n",
    "untab.loc['\\\\textit{by race/ethnicity:}', untab.columns] = [''] * 8\n",
    "untab = untab.iloc[0:2].append(untab.iloc[-1]).append(untab.iloc[2:6])\n",
    "untab.columns.name = None\n",
    "untab.to_csv(data_dir / 'unemp1.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "untab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Participation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:32.239533Z",
     "start_time": "2022-03-04T13:43:32.218862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the latest data, covering February 2022, 62.3 percent of people age 16 and older are in the labor force (see {\\color{green!70!blue}\\textbf{---}}), compared to 62.2 percent in January and 61.9 percent in December 2021. In February 2020, when US confirmed cases of COVID-19 were still low, the labor force participation rate was 63.4 percent.\n",
      "\n",
      "In February 2022, 68.3 percent of men age 16+ are in the labor force (see {\\color{blue!90!cyan}\\textbf{---}}), compared to 56.6 percent of women (see {\\color{orange!90!red}\\textbf{---}}). Since February 2020, labor force participation has decreased one percentage point among men, and decreased 1.2 percentage points among women.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))[['MenLFPR', 'WomenLFPR']]\n",
    "df['TotLFPR'] = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                             parse_dates=['date'])\n",
    "                   .assign(TotLFPR = lambda x: (x.LF / x.POP)*100)\n",
    "                   .set_index('date'))['TotLFPR']\n",
    "df.loc['1989':].to_csv(data_dir / 'lfpr.csv', index_label='date')\n",
    "\n",
    "col = {'MenLFPR': 'blue!90!cyan',\n",
    "       'WomenLFPR': 'orange!90!red',\n",
    "       'TotLFPR': 'green!70!blue'}\n",
    "nodes = (end_node(df['MenLFPR'], col['MenLFPR'], \n",
    "                  percent=True, date='m', full_year=True, \n",
    "                  offset=0.35) + '\\n' + \n",
    "         '\\n'.join(end_node(df[name], color, percent=True) \n",
    "                   for name, color in col.items() if name != 'MenLFPR'))\n",
    "write_txt(text_dir / 'lfpr_nodes.txt', nodes)\n",
    "\n",
    "tot = df['TotLFPR']\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "write_txt(text_dir / 'lfpr_blsdate.txt', ltdt)\n",
    "prdt, prdt2 = (dtxt(df.index[i])['mon3'] \n",
    "               if df.index[-1].year == df.index[i].year \n",
    "               else dtxt(df.index[i])['mon1'] \n",
    "               for i in [-2, -3])\n",
    "cpdt = '2020-02-01'\n",
    "compdt = dtxt(cpdt)['mon1']\n",
    "feb20val = tot.loc[cpdt]\n",
    "mltval = df['MenLFPR'].iloc[-1]\n",
    "wltval = df['WomenLFPR'].iloc[-1]\n",
    "mchval = mltval - df['MenLFPR'].loc['2020-01-01']\n",
    "wchval = wltval - df['WomenLFPR'].loc['2020-01-01']\n",
    "mch = value_text(mchval, style='increase', ptype='pp')\n",
    "wch = value_text(wchval, style='increase', ptype='pp')\n",
    "cl = {k: c_line(v) for k, v in col.items()}\n",
    "text = (f'In the latest data, covering {ltdt}, {tot.iloc[-1]:.1f} '+\n",
    "        'percent of people age 16 and older are in the labor force '+\n",
    "        f'{cl[\"TotLFPR\"]}, compared to {tot.iloc[-2]:.1f} percent in '+\n",
    "        f'{prdt} and {tot.iloc[-3]:.1f} percent in {prdt2}. In '+\n",
    "        f'{compdt}, when US confirmed cases of COVID-19 were still '+\n",
    "        f'low, the labor force participation rate was {feb20val:.1f} '+\n",
    "        f'percent.\\n\\nIn {ltdt}, {mltval:.1f} percent of men age '+\n",
    "        f'16+ are in the labor force {cl[\"MenLFPR\"]}, compared to '+\n",
    "        f'{wltval:.1f} percent of women {cl[\"WomenLFPR\"]}. Since '+\n",
    "        f'{compdt}, labor force participation has {mch} among men, '+\n",
    "        f'and {wch} among women.')\n",
    "write_txt(text_dir / 'lfpr_text.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:34.706121Z",
     "start_time": "2022-03-04T13:43:34.637255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In February 2022, 79.5 percent of 25--54 years olds were employed, compared to 79.1 percent in January 2022. Over the past year, the age 25--54 employment rate increased 2.9 percentage points. The February 2022 rate was 1.9 percentage points (equivalent to 2.5 million workers) below the average rate of 81.4 during the tight labor market of 1999--2000.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, 'PA_EPOP'])\n",
    "df.to_csv(data_dir / 'epop.csv', index_label='date')\n",
    "\n",
    "color = 'blue!90!cyan'\n",
    "node = end_node(df, color, date='m', percent=True, full_year=True)\n",
    "write_txt(text_dir / 'epop_node.txt', node)\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "ltval = df.iloc[-1]\n",
    "prval = df.iloc[-2]\n",
    "prdate = dtxt(df.index[-2])['mon1']\n",
    "prtxt = f'compared to {prval} percent in {prdate}'\n",
    "compval = df.loc['2019-06-01': '2020-03-01'].max()\n",
    "last = series_info(df)['last_matched']\n",
    "text2 = prtxt if ltval < compval else last\n",
    "chtxt = value_text(df.diff(12).iloc[-1], ptype='pp', threshold=0.1)\n",
    "\n",
    "pop = (cps_1mo(cps_dir, cps_date(), ['BASICWGT', 'AGE'])\n",
    "       .query('25 <= AGE <=54').BASICWGT.sum()) / 1_000\n",
    "rt99 = df.loc['1999': '2000'].mean()\n",
    "ch99 = rt99 - ltval\n",
    "ch99w = (ch99 / 100) * pop\n",
    "ch99t = (f'{round(ch99w / 1000, 1)} million' \n",
    "         if ch99w > 999 else f'{round(ch99w, -1)} thousand')\n",
    "text = (f'In {ltdate}, {ltval} percent of 25--54 years olds were '+\n",
    "        f'employed, {text2}. Over the past year, the age 25--54 '+\n",
    "        f'employment rate {chtxt}. The {ltdate} rate was {ch99:.1f} '+\n",
    "        f'percentage points (equivalent to {ch99t} workers) below '+\n",
    "        f'the average rate of {rt99:.1f} during the tight labor '+\n",
    "        'market of 1999--2000.')\n",
    "write_txt(text_dir / 'epop_text.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment by reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:37.022853Z",
     "start_time": "2022-03-04T13:43:37.004216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In February 2022, 1.9 percent of the labor force were unemployed because of losing a job or having a temporary job end. Of these, 0.5 percent of the labor force are unemployed due to temporary layoff, equivalent to 14.2 percent of the unemployed. Additionally, 0.6 percent of the labor force were re-entrants, 1.2 percent were new entrants, and 0.3 percent were job leavers. \n"
     ]
    }
   ],
   "source": [
    "srs = ['Job Loser', 'Job Leaver', 'Re-entrant', 'New entrant', \n",
    "       'Temporary Layoff', 'Permanent Separation', 'Level']\n",
    "d1 = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':]\n",
    "\n",
    "df = d1[srs].div(d1['LF'], axis='index') * 100\n",
    "#.resample('QS').mean()\n",
    "df.to_csv(data_dir / 'unemp_reason.csv', index_label='date', float_format='%g')\n",
    "\n",
    "loser = df['Job Loser'].iloc[-1]\n",
    "tl = df['Temporary Layoff'].iloc[-1]\n",
    "tlsh = (d1['Temporary Layoff'] / d1['Level']).iloc[-1] * 100\n",
    "leaver = df['Job Leaver'].iloc[-1]\n",
    "reent = df['Re-entrant'].iloc[-1]\n",
    "newent = df['New entrant'].iloc[-1]\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "\n",
    "text = (f'In {ltdate}, {loser:.1f} percent of the labor force '+\n",
    "        'were unemployed because of losing a job or having a temporary '+\n",
    "        f'job end. Of these, {tl:.1f} percent of the labor force are unemployed due '+\n",
    "        f'to temporary layoff, equivalent to {tlsh:.1f} percent of the unemployed. '+\n",
    "        f'Additionally, {leaver:.1f} percent of the labor force were re-entrants, '+\n",
    "        f'{reent:.1f} percent were new entrants, and {newent:.1f} '+\n",
    "        'percent were job leavers. ')\n",
    "write_txt(text_dir / 'unemp_reason.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:38.426980Z",
     "start_time": "2022-03-04T13:43:37.834699Z"
    }
   },
   "outputs": [],
   "source": [
    "lf = ['Employed', 'Unemployed']\n",
    "naw_rate = lambda x: np.average(x['NOTATWORK'], weights=x['BASICWGT'])\n",
    "\n",
    "naw = pd.Series(dtype='float64')\n",
    "\n",
    "columns = ['LFS', 'MONTH', 'YEAR', 'BASICWGT', 'NOTATWORK']\n",
    "for year in range(2017, 2023):\n",
    "    data = (pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "        .query('LFS in @lf'))\n",
    "    data1 = data.groupby(['YEAR', 'MONTH']).apply(naw_rate) * 100\n",
    "    data1.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data1.index]\n",
    "    naw = naw.append(data1)\n",
    "\n",
    "df['Employed, Not at Work'] = naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:40.071164Z",
     "start_time": "2022-03-04T13:43:40.042869Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'Level': 'Unemployed, Any Reason',\n",
    "     'Job Loser': '\\hspace{2mm}Job Loser',\n",
    "     'Temporary Layoff': '\\hspace{4mm}Temporary Layoff',\n",
    "     'Permanent Separation': '\\hspace{4mm}Permanent Separation',\n",
    "     'Re-entrant': '\\hspace{2mm}Re-entrant',\n",
    "     'New entrant': '\\hspace{2mm}New entrant',\n",
    "     'Job Leaver': '\\hspace{2mm}Job Leaver'}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "loc_list = [-1, -2, -3, -4, -5, -13, -14, -15, -16, -17]\n",
    "\n",
    "for key, value in d.items():\n",
    "    for i in loc_list:\n",
    "        final.loc[value, dtxt(df.index[i])['mon6']] = df[key].iloc[i].round(1)\n",
    "        \n",
    "final.loc['\\\\textit{See also:}', final.columns] = [''] * 10\n",
    "final.loc['Employed, Not at Work', final.columns] = [df['Employed, Not at Work'].iloc[i].round(1) \n",
    "                                                     for i in loc_list]\n",
    "\n",
    "final.to_csv(data_dir / 'unempreason_table.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-09T17:23:02.752467Z",
     "start_time": "2022-02-09T17:23:02.743523Z"
    }
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployed long-term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:42.204799Z",
     "start_time": "2022-03-04T13:43:42.186998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of February 2022, BLS \\href{https://www.bls.gov/webapps/legacy/cpsatab12.htm}{reports} that 0.67 percent of the age 16+ population have been unemployed for 27 weeks or longer, compared to 1.62 percent in February 2021 (see {\\color{blue}\\textbf{---}}). This measure of long-term unemployment peaked at 2.96 percent of the population in April 2010, but had fallen to 0.36 percent in April 2020. \n",
      " \n",
      "In February 2022, 1.00 percent of the age 16+ population have been unemployed for at least 15 weeks (see {\\color{violet!90!black}\\textbf{---}}), following 0.97 percent in January 2022, and 1.00 percent in December 2021.\n"
     ]
    }
   ],
   "source": [
    "srs = ['LT', 'MT', 'POP']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, srs]\n",
    "\n",
    "data = (df.divide(df['POP'], axis=0) * 100).drop(['POP'], axis=1)\n",
    "data.to_csv(data_dir / 'ltu.csv', index_label='date', float_format='%g')\n",
    "\n",
    "write_txt(text_dir / 'ltu_node.txt', end_node(data['LT'], 'blue', percent=True))\n",
    "write_txt(text_dir / 'ltu_node2.txt', end_node(data['MT'], 'violet!90!black', percent=True))\n",
    "\n",
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "pdate = dtxt(data.index[-13])['mon1']\n",
    "hdate = dtxt(data['LT'].idxmax())['mon1']\n",
    "prdt = dtxt(data.index[-2])['mon1']\n",
    "prdt2 = dtxt(data.index[-3])['mon1']\n",
    "\n",
    "recent_min = data.loc['2015':, 'LT'].min()\n",
    "recent_min_dt = dtxt(data.loc['2015':, 'LT'].idxmin())['mon1']\n",
    "\n",
    "text = (f'As of {ldate}, BLS '+\n",
    "        '\\href{https://www.bls.gov/webapps/legacy/cpsatab12.htm}{reports} '+\n",
    "        f'that {data[\"LT\"].iloc[-1]:.2f} percent of the age 16+ '+\n",
    "         'population have been unemployed for 27 weeks or longer, '+\n",
    "        f'compared to {data[\"LT\"].iloc[-13]:.2f} percent in {pdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}). This measure of long-term '+\n",
    "        f'unemployment peaked at {data[\"LT\"].max():.2f} percent of the '+\n",
    "        f'population in {hdate}, but had fallen to {recent_min:.2f} percent '+\n",
    "        f'in {recent_min_dt}. \\n \\nIn {ldate}, {data[\"MT\"].iloc[-1]:.2f} '+\n",
    "        'percent of the age 16+ population have been unemployed for at '+\n",
    "        'least 15 weeks (see {\\color{violet!90!black}\\\\textbf{---}}), following '+\n",
    "        f'{data[\"MT\"].iloc[-2]:.2f} percent in {prdt}, '+\n",
    "        f'and {data[\"MT\"].iloc[-3]:.2f} percent in {prdt2}.')\n",
    "write_txt(text_dir / 'ltu.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:44.895483Z",
     "start_time": "2022-03-04T13:43:44.880879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Among those who are unemployed, the average (mean) duration of unemployment is 26.6 weeks (see {\\color{blue!60!cyan}\\textbf{---}}), and the typical (median) duration of unemployment is 9.6 weeks (see {\\color{green!75!blue}\\textbf{---}}), as of February 2022. Over the year prior to COVID-19, ending February 2020, the average duration of unemployment was 21.7 weeks and the typical duration was 9.3 weeks.\n"
     ]
    }
   ],
   "source": [
    "srs = ['Median', 'Mean']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, srs]\n",
    "\n",
    "df.to_csv(data_dir / 'unempdur.csv', index_label='date', \n",
    "          float_format='%g')\n",
    "\n",
    "ldate = dtxt(df.index[-1])['mon1']\n",
    "\n",
    "median = df['Median'].iloc[-1]\n",
    "mean = df['Mean'].iloc[-1]\n",
    "\n",
    "acol = 'blue!60!cyan'\n",
    "mcol = 'green!75!blue'\n",
    "cats = [('Mean', acol), ('Median', mcol)]\n",
    "nodes = '\\n'.join([end_node(df[n], c) for n, c in cats])\n",
    "write_txt(text_dir / 'unempdur_nodes.txt', nodes)\n",
    "\n",
    "pc_yr = df.loc['2019-03-01':'2020-02-01'].mean()\n",
    "text = ('Among those who are unemployed, the average '+\n",
    "        f'(mean) duration of unemployment is {mean:.1f} '+\n",
    "        f'weeks {c_line(acol)}, and the typical (median) '+\n",
    "        f'duration of unemployment is {median:.1f} weeks '+\n",
    "        f'{c_line(mcol)}, as of {ldate}. Over the year '+\n",
    "        'prior to COVID-19, ending February 2020, the '+\n",
    "        'average duration of unemployment was '+\n",
    "        f'{pc_yr.Mean:.1f} weeks and the typical '+\n",
    "        f'duration was {pc_yr.Median:.1f} weeks.')\n",
    "write_txt(text_dir / 'unempdur.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Time for Economic Reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:47.298931Z",
     "start_time": "2022-03-04T13:43:47.278855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In February 2022, 4.1 million people worked part time because of economic reasons, equivalent to 2.5 percent of the labor force (see {\\color{red}\\textbf{---}}), the highest level since November 2021 and slightly below the February 2020 rate of 2.7 percent. During the great recession, the involuntary part-time share of the labor force peaked at 6.0 percent in September 2010.\n"
     ]
    }
   ],
   "source": [
    "srs = ['PTECON', 'LF']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, srs])\n",
    "\n",
    "data = ((df.PTECON / df.LF) * 100).rename('PTECON')\n",
    "data.to_csv(data_dir / 'ptecon.csv', index_label='date')\n",
    "\n",
    "color = 'red'\n",
    "node = end_node(data, color, date='m', percent=True, \n",
    "                offset=True)\n",
    "write_txt(text_dir / 'ptecon_node.txt', node)\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "totval = df.PTECON.iloc[-1] / 1_000\n",
    "ltval = data.iloc[-1]\n",
    "comp_date = '2020-02-01'\n",
    "lastmatch = series_info(data)['last_matched']\n",
    "feb20val = data.loc[comp_date]\n",
    "compare = compare_text(ltval, feb20val, [0.1, 0.9, 4.0])\n",
    "feb20date = dtxt(pd.to_datetime(comp_date))['mon1']\n",
    "gfcval = data.loc[:comp_date].max()\n",
    "gfcmaxdate = dtxt(data.loc[:comp_date].idxmax())['mon1']\n",
    "\n",
    "text = (f'In {ltdate}, {totval:,.1f} million people worked '+\n",
    "        f'part time because of economic reasons, equivalent '+\n",
    "        f'to {ltval:.1f} percent of the labor force '+\n",
    "        f'{c_line(color)}, {lastmatch} and {compare} the '+\n",
    "        f'{feb20date} rate of {feb20val:.1f} percent. '+\n",
    "        'During the great recession, the involuntary '+\n",
    "        'part-time share of the labor force peaked at '+\n",
    "        f'{gfcval:.1f} percent in {gfcmaxdate}.')\n",
    "write_txt(text_dir / 'ptecon.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Jobholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:49.896314Z",
     "start_time": "2022-03-04T13:43:49.880137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In February 2022, a seasonally-adjusted total of 7.4 million people worked more than one job during the survey reference week, equivalent to 4.7 percent of workers. Over the three months ending February 2022, an average of 4.7 percent of workers were multiple jobholders (see {\\color{cyan!50!blue}\\textbf{---}}). In 2019, 5.1 percent of workers had more than one job during the survey reference week. \n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "        .loc['1989':, ['MJHsa', 'EMPsa']])\n",
    "data = ((df.MJHsa / df.EMPsa) * 100).dropna().rename('MJH')\n",
    "d3m = data.rolling(3).mean()\n",
    "d3m.to_csv(data_dir / 'mjh.csv', index_label='date')\n",
    "color = 'cyan!50!blue'\n",
    "node = end_node(d3m, color, percent=True, size=1.2)\n",
    "write_txt(text_dir / 'mjh_node.txt', node)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "totval = df.MJHsa.iloc[-1] / 1_000\n",
    "ltval = data.iloc[-1]\n",
    "l3val = d3m.iloc[-1]\n",
    "l19val = data.loc['2019'].mean()\n",
    "comp_date = '2020-02-01'\n",
    "\n",
    "text = (f'In {ltdt}, a seasonally-adjusted total of {totval:.1f} '+\n",
    "        'million people worked '+\n",
    "        'more than one job during the survey reference week, '+\n",
    "        f'equivalent to {ltval:.1f} percent of workers. '+\n",
    "        f'Over the three months ending {ltdt}, an average of '+\n",
    "        f'{l3val:.1f} percent of workers were multiple '\n",
    "        f'jobholders {c_line(color)}. In 2019, {l19val:.1f} '+\n",
    "        'percent of workers had more than one job during '+\n",
    "        'the survey reference week. ')\n",
    "write_txt(text_dir / 'mjh.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Weekly Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:53.014533Z",
     "start_time": "2022-03-04T13:43:52.371720Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:187: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in one or more of the estimated spectra.\n",
      "  warn(errors, X13Warning)\n",
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:187: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in the estimated spectrum of the regARIMA residuals.\n",
      "  warn(errors, X13Warning)\n"
     ]
    }
   ],
   "source": [
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['TOTCES'] = df2['ceshrstot']\n",
    "data['TOTLFS'] = df2['avghrstot']\n",
    "data['SERVNSA'] = df2['avghrsserv']\n",
    "data['SERVSA'] = x13_arima_analysis(df2['avghrsserv'].dropna()).seasadj\n",
    "data['PNS'] = df2['ceshrspns']\n",
    "data['PTECONNSA'] = df2['avghrsptecon']\n",
    "data['PTECONSA'] = x13_arima_analysis(df2['avghrsptecon'].dropna()).seasadj\n",
    "\n",
    "data.loc['1989':].to_csv(data_dir / 'hours.csv', index_label='date')\n",
    "\n",
    "ltval = data['TOTLFS'].iloc[-1]\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "feb20val = data.loc['2020-02-01', 'TOTLFS']\n",
    "compare = compare_text(ltval, feb20val, [0.2, 1.5, 3.0])\n",
    "avg90 = data.loc['1998':'2000', 'TOTLFS'].mean()\n",
    "gfclow = data.loc['2005': '2012', 'TOTLFS'].min()\n",
    "gfclowdt = dtxt(data.loc['2005': '2012', 'TOTLFS'].idxmin())['mon1']\n",
    "#data.plot(color=['blue', 'lime', 'darkgreen', 'orange', 'lightpink', 'red'], figsize=(3, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:53.693436Z",
     "start_time": "2022-03-04T13:43:53.685397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual hours worked by people at work in all industries during the survey reference week average 39.0 in February 2022 (see {\\color{blue}\\textbf{---}}) in line with the 38.9 average actual hours worked in February 2020. Average actual hours for this group average 39.6 from 1998 through 2000, and fell to a great recession low of 37.4 in February 2010.\n",
      "Those in service occupations (see {\\color{green!90!blue!70!black}\\textbf{---}}) work fewer hours on average, with 34.9 average weekly hours in February 2022, slightly below the 35.1 average in February 2020. Those part-time for economic reasons (see {\\color{red!90!black}\\textbf{---}}) work an average of 23.1 hours per week in February 2022. \n",
      "In February 2022, production and non-supervisory workers (see {\\color{orange}\\textbf{---}}), about four of every five employees, worked 34.1 hours per week on average, slightly above the 33.7 average weekly hours in February 2020 and slightly below the 1998--2000 average of 34.4 hours.\n"
     ]
    }
   ],
   "source": [
    "text = ('Actual hours worked by people at work in all industries '+\n",
    "        f'during the survey reference week average {ltval:.1f} in {ltdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}) '+\n",
    "        f'{compare} the {feb20val:.1f} average actual hours worked in February 2020. '+\n",
    "        f'Average actual hours for this group average {avg90:.1f} from '+\n",
    "        '1998 through 2000, and fell to a great recession low of '+\n",
    "        f'{gfclow:.1f} in {gfclowdt}.')\n",
    "\n",
    "write_txt(text_dir / 'hours_tot.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval2 = data.SERVSA.iloc[-1]\n",
    "feb20val2 = data.loc['2020-02-01', 'SERVSA']\n",
    "compare2 = compare_text(ltval2, feb20val2, [0.2, 0.6, 2.5])\n",
    "pteval = data.PTECONSA.iloc[-1]\n",
    "\n",
    "text = ('Those in service occupations (see '+\n",
    "        '{\\color{green!90!blue!70!black}\\\\textbf{---}}) '+\n",
    "        f'work fewer hours on average, with {ltval2:.1f} average '+\n",
    "        f'weekly hours in {ltdate}, {compare2} the {feb20val2:.1f} '+\n",
    "        'average in February 2020. Those part-time '+\n",
    "        'for economic reasons (see {\\color{red!90!black}\\\\textbf{---}}) '+\n",
    "        f'work an average of {pteval:.1f} hours per week in {ltdate}. ')\n",
    "\n",
    "write_txt(text_dir / 'hours_lfs2.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval3 = data.PNS.iloc[-1]\n",
    "feb20val3 = data.loc['2020-02-01', 'PNS']\n",
    "compare3 = compare_text(ltval3, feb20val3, [0.2, 0.6, 2.5])\n",
    "val98 = data.loc['1998':'2000', 'PNS'].mean()\n",
    "compare4 = compare_text(ltval3, val98, [0.2, 0.6, 2.5])\n",
    "\n",
    "text = (f'In {ltdate}, '+\n",
    "        'production and non-supervisory workers (see {\\color{orange}\\\\textbf{---}})'+\n",
    "        ', about four of every five employees, '+\n",
    "        f'worked {ltval3:.1f} hours per week on average, '+\n",
    "        f'{compare3} the {feb20val3:.1f} average weekly hours in February 2020 and '+\n",
    "        f'{compare4} the 1998--2000 average of {val98:.1f} hours.')\n",
    "\n",
    "write_txt(text_dir / 'hours_ces.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:56.531061Z",
     "start_time": "2022-03-04T13:43:56.511951Z"
    }
   },
   "outputs": [],
   "source": [
    "data['TOTCPS'] = pd.read_csv(data_dir / 'uslhrs.csv', index_col='name', parse_dates=True)\n",
    "\n",
    "d = {'TOTCES': 'Total Actual, CES',\n",
    "     'TOTLFS': 'Total Actual, LFS ({\\color{blue}\\\\textbf{---}})',\n",
    "     'TOTCPS': 'Total Usual, CPS',\n",
    "     'PNS': 'Production \\& Non-Supervisory, CES ({\\color{orange}\\\\textbf{---}} )',\n",
    "     'SERVSA': 'Services Occupations, LFS ({\\color{green!90!blue!70!black}\\\\textbf{---}} )',\n",
    "     'PTECONSA': 'Part-time for Economic Reasons, LFS ({\\color{red!90!black}\\\\textbf{---}})'}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "loc_list = [-1, -2, -3, -13, -14, -15, -25]\n",
    "\n",
    "for key, value in d.items():\n",
    "    for i in loc_list:\n",
    "        final.loc[value, dtxt(data.index[i])['mon6']] = data[key].iloc[i].round(1)\n",
    "\n",
    "final.to_csv(data_dir / 'hoursworked_table.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flows, Newly Employed, Not looking for work previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:43:59.099653Z",
     "start_time": "2022-03-04T13:43:59.079345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In February 2022, 6.9 million people were newly employed (on a gross basis). Of these, 69.8 percent were not looking for work in the prior month (see {\\color{lime!80!green}\\textbf{---}}). Over the past three months, an average of 70.9 percent of the newly employed were not looking for work the month prior (see {\\color{green!60!teal!80!black}\\textbf{---}}). When unemployment is low, the newly employed are more likely to come from outside of the labor force. Three years ago, in February 2019, 72.7 percent of the newly employed had not looked for work the previous month.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date')).loc['1990':, ['NILF', 'UNEMP']]\n",
    "df['TOTAL'] = df.astype('float').sum(axis=1)\n",
    "sh = (df['NILF'] / df['TOTAL']).rename('total') * 100\n",
    "\n",
    "sh.to_csv(data_dir / 'lf_flow.csv', index_label='date', \n",
    "          header=True, float_format='%g')\n",
    "ma = sh.resample('QS').mean().rename('quarterly')\n",
    "ma.to_csv(data_dir / 'lf_flow_q.csv', index_label='date', \n",
    "          header=True, float_format='%g')\n",
    "\n",
    "col = 'green!60!teal!80!black'\n",
    "col2 = 'lime!80!green'\n",
    "node = end_node(ma, col, percent=True, size=1.2)\n",
    "write_txt(text_dir / 'lf_flow_node.txt', node)\n",
    "\n",
    "totval = df['TOTAL'].iloc[-1] / 1000\n",
    "shval = sh.iloc[-1]\n",
    "maval = ma.iloc[-1] \n",
    "sh3y = sh.iloc[-37]\n",
    "\n",
    "ltdt = dtxt(sh.index[-1])['mon1']\n",
    "prdt = dtxt(sh.index[-37])['mon1']\n",
    "\n",
    "text = (f'In {ltdt}, {totval:.1f} million people were newly '+\n",
    "        f'employed (on a gross basis). Of these, {shval:.1f} '+\n",
    "        f'percent were not looking for work in the prior month '+\n",
    "        f'{c_line(col2)}. Over the past three months, an average '+\n",
    "        f'of {maval:.1f} percent of the newly employed were not '+\n",
    "        f'looking for work the month prior {c_line(col)}. When '+\n",
    "        'unemployment is low, the newly employed are more '+\n",
    "        'likely to come from outside of the labor force. Three '+\n",
    "        f'years ago, in {prdt}, {sh3y:.1f} percent of the newly '+\n",
    "        'employed had not looked for work the previous month.')\n",
    "write_txt(text_dir / 'lf_flow.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Hourly Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:44:03.216405Z",
     "start_time": "2022-03-04T13:44:03.199180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the year ending February 2022, nominal wages increased by 5.1 percent for all employees (see {\\color{magenta}\\textbf{---}}) and increased by 6.7 percent for production and non-supervisory workers (see {\\color{blue!80!black}\\textbf{---}}), according to the Bureau of Labor Statistics. Comparing the latest three months to the previous three months, nominal wages increased at an annual rate of 5.6 percent for all employees and increased at an annual rate of 6.8 percent for production and non-supervisory employees.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date'))[['ALL', 'PNS']]\n",
    "data = (df.pct_change(12) * 100)\n",
    "d3 = m3rate(df).rename({'ALL': 'ALL_3M', 'PNS': 'PNS_3M'}, axis=1)\n",
    "data = data.join(d3).loc['1989':]\n",
    "data.to_csv(data_dir / 'ahe.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "lt = data.iloc[-1]\n",
    "all_lt = value_text(lt.ALL, style='increase_by')\n",
    "pns_lt = value_text(lt.PNS, style='increase_by')\n",
    "all_3m = value_text(lt.ALL_3M, style='increase_by', adj='annual')\n",
    "pns_3m = value_text(lt.PNS_3M, style='increase_by', adj='annual')\n",
    "cla = c_line('magenta')\n",
    "clp = c_line('blue!80!black')\n",
    "text = (f'Over the year ending {ltdt}, nominal wages {all_lt} '+\n",
    "        f'for all employees {cla} and {pns_lt} for production '+\n",
    "        f'and non-supervisory workers {clp}, according to the '+\n",
    "        'Bureau of Labor Statistics. Comparing the latest '+\n",
    "        f'three months to the previous three months, nominal wages '+\n",
    "        f'{all_3m} for all employees and {pns_3m} for production '+\n",
    "        'and non-supervisory employees.')\n",
    "write_txt(text_dir / 'ahe_summary.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AHE by Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:44:06.789178Z",
     "start_time": "2022-03-04T13:44:05.713000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "series = {'CES3000000008': 'Manufacturing',\n",
    "          'CES1000000008': 'Mining \\& Logging',\n",
    "          'CES4422000008': 'Utilities',\n",
    "          'CES4142000008': 'Wholesale Trade',\n",
    "          'CES5000000008': 'Information',\n",
    "          'CES5500000008': 'Financial Activities',\n",
    "          'CES6000000008': 'Professional \\& Business Services',\n",
    "          'CES6500000008': 'Education \\& Health Services',\n",
    "          'CES0500000008': 'Total Private',\n",
    "          'CES2000000008': 'Construction',\n",
    "          'CES7000000008': 'Leisure \\& Hospitality',\n",
    "          'CES4300000008': 'Transportation \\& Warehousing',\n",
    "          'CES4200000008': 'Retail Trade'}\n",
    "\n",
    "years = (2017, 2022)\n",
    "df = bls_api(series, years, bls_key)\n",
    "df.to_csv(data_dir / 'ahe_industry_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:44:07.597849Z",
     "start_time": "2022-03-04T13:44:07.586816Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By industry, 4 of 12 groups experienced real wage growth (wage growth above the increase in prices indicated by the consumer price index). The leisure \\& hospitality industry had the fastest nominal growth rate, at 14.3 percent, followed by 11.1 percent in transportation \\& warehousing and 8.1 percent in education \\& health services. \n"
     ]
    }
   ],
   "source": [
    "s = pd.read_csv(data_dir / 'cpi.csv')\n",
    "df = (pd.read_csv(data_dir / 'ahe_industry_raw.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "allitems = s['ALL'].iloc[-1]\n",
    "data = (df.pct_change(12).iloc[-1] * 100.0).sort_values(ascending=False)\n",
    "\n",
    "(data.to_csv(data_dir / 'ahe_ind.csv', index_label='name', header=True))\n",
    "\n",
    "write_txt(text_dir / 'ahe_bar_date.txt', df.index[-1].strftime('%B %Y'))\n",
    "\n",
    "real = (data - allitems).drop('Total Private')\n",
    "ltd = {i: (data.index[i].lower(), data.iloc[i]) for i in [0, 1, 2]}\n",
    "\n",
    "txt1 = (f'By industry, {len(real.loc[real > 0])} of {len(real)} groups '+\n",
    "         'experienced real wage growth (wage growth above the increase in '+\n",
    "        f'prices indicated by the consumer price index). The {ltd[0][0]} '+\n",
    "        f'industry had the fastest nominal growth rate, at {ltd[0][1]:.1f} percent, followed '+\n",
    "        f'by {ltd[1][1]:.1f} percent in {ltd[1][0]} and {ltd[2][1]:.1f} percent in {ltd[2][0]}. ')\n",
    "write_txt(text_dir / 'ahe_comp.txt', txt1)\n",
    "print(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-21T22:36:57.026419Z",
     "start_time": "2022-02-21T22:36:56.817440Z"
    }
   },
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T03:37:06.667891Z",
     "start_time": "2022-02-22T03:37:06.656270Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'ces_data.csv', \n",
    "                 index_col='date', \n",
    "                 parse_dates=True).loc['2017':]\n",
    "data = (df.drop(['ALL', 'Total Private'], axis=1)\n",
    "          .divide(df['Total Private'], axis=0)) * 100\n",
    "data.columns = [c[:3] for c in data.columns]\n",
    "data.to_csv(data_dir / 'ces_ind_sh.csv', \n",
    "            index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CES data - Payrolls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:44:12.842936Z",
     "start_time": "2022-03-04T13:44:11.244711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "series = {'CES0000000001': 'ALL',\n",
    "          'CES3000000001': 'Manufacturing',\n",
    "          'CES1000000001': 'Mining \\& Logging',\n",
    "          'CES4422000001': 'Utilities',\n",
    "          'CES4142000001': 'Wholesale Trade',\n",
    "          'CES5000000001': 'Information',\n",
    "          'CES5500000001': 'Financial Activities',\n",
    "          'CES6000000001': 'Professional \\& Business Serv.',\n",
    "          'CES6500000001': 'Education \\& Health Services',\n",
    "          'CES0500000001': 'Total Private',\n",
    "          'CES2000000001': 'Construction',\n",
    "          'CES7000000001': 'Leisure \\& Hospitality',\n",
    "          'CES4300000001': 'Transportation \\& Warehousing',\n",
    "          'CES4200000001': 'Retail Trade'}\n",
    "df = bls_api(series, (2015, 2022), bls_key)\n",
    "df.to_csv(data_dir / 'ces_data.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:44:14.844927Z",
     "start_time": "2022-03-04T13:44:14.819242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The US added 678,000 total payroll jobs in February 2022 (see\\cbox{blue!60!purple}), compared to 481,000 added in January 2022, and an average of 582,000 added over the past three months. US payrolls shed a combined 22.0 million jobs in March and April 2020, and have since recovered 19.9 million jobs (90.4 percent).\n",
      "\n",
      "To maintain a steady employment rate with population growth, the US needs to add around 150,000 jobs per month. In 2019, the US was adding an average of 164,000 jobs per month. \n",
      "\n",
      "In February 2022, there were a seasonally adjusted total of 150.4 million such nonfarm payroll jobs. \n"
     ]
    }
   ],
   "source": [
    "pop = pd.read_csv(data_dir / 'jobs_report_main.csv', \n",
    "                  index_col='date', parse_dates=True).loc['2015':, 'POP']\n",
    "gov = (pd.read_csv(data_dir / 'jobs_report_main2.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "         .loc['2015':, 'govjobs'].rename('Government'))\n",
    "df = pd.read_csv(data_dir / 'ces_data.csv', \n",
    "                 index_col='date', parse_dates=True).join([pop, gov])\n",
    "data = df['ALL'].diff().loc['2019':]\n",
    "data.div(1000).to_csv(data_dir / 'nfp.csv', index_label='date')\n",
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "pdate = dtxt(data.index[-2])['mon1']\n",
    "vals = [data.iloc[-1], data.iloc[-2], data.iloc[-3:].mean()]\n",
    "ltal, pral, pr3al = ['added' if val > 0 else 'lost' for val in vals]\n",
    "ltv, prv, pr3v, pr19v = [f'{abs(v):,.0f},000' for v in vals + \n",
    "                         [data.loc['2019'].mean()]]\n",
    "\n",
    "emp, tot = df.loc['2015':, 'ALL'], df.loc['2015':, 'POP']\n",
    "final2 = ((((emp / tot).shift(1) * tot).round(-3) / 1_000)\n",
    "          .rolling(12).mean())\n",
    "\n",
    "lpop = final2.iloc[-3:].mean().round(-1) * 1_000\n",
    "covloss = abs(data.loc['2020-03-01':'2020-04-01'].sum())  / 1_000\n",
    "since = data.loc['2020-05-01':].sum() / 1_000\n",
    "rec_pct = (since / covloss)\n",
    "rpct = f' ({rec_pct * 100:.1f} percent)' if rec_pct < 1 else ''\n",
    "text = (f'The US {ltal} {ltv} total payroll jobs in {ldate} '+\n",
    "        '(see\\cbox{blue!60!purple}), '+\n",
    "        f'compared to {prv} {pral} in {pdate}, and an average of '+\n",
    "        f'{pr3v} {pr3al} over the past three months. US payrolls shed a '+\n",
    "        f'combined {covloss:.1f} million jobs in March and April 2020, '+\n",
    "        f'and have since recovered {since:.1f} million jobs{rpct}.\\n\\n'+\n",
    "        'To maintain a steady employment rate with population growth, '+\n",
    "        f'the US needs to add around {lpop:,.0f} jobs per month. In 2019, '+\n",
    "        f'the US was adding an average of {pr19v} jobs per month.')\n",
    "write_txt(text_dir / 'nfp_basic_text.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "lval = df.ALL.iloc[-1] / 1_000\n",
    "text = (f'In {ldate}, there were a seasonally adjusted total of {lval:.1f} '+\n",
    "        f'million such nonfarm payroll jobs. ')\n",
    "write_txt(text_dir / 'nfp_tot.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:44:17.276130Z",
     "start_time": "2022-03-04T13:44:17.258740Z"
    }
   },
   "outputs": [],
   "source": [
    "data = (pd.read_csv(data_dir / 'ces_data.csv', \n",
    "                    index_col='date', parse_dates=True)\n",
    "          .drop(['Total Private'], axis=1)\n",
    "          .rename({'ALL': '\\\\textbf{Total}'}, axis=1))\n",
    "lvl = data.iloc[[-1, -25]].T\n",
    "lvl.columns = [dtxt(i)['mon2'] for i in lvl.columns]\n",
    "lvl.columns.name = ''\n",
    "ch = data.diff().iloc[[-1, -2, -3]].T\n",
    "ch.columns = [dtxt(i)['mon2'] + ' ' for i in ch.columns]\n",
    "ch.columns.name = ''\n",
    "final = lvl.join(ch)\n",
    "final['2019 Avg'] = data.diff().loc['2019'].mean()    \n",
    "final['May `20--'] = data.iloc[-1] - data.loc['2020-04-01']\n",
    "final['Mar and Apr `20'] = data.diff().loc['2020-03-01':'2020-04-01'].sum()\n",
    "\n",
    "final = (final.sort_values(dtxt(data.index[-1])['mon2'], ascending=False)\n",
    "         .applymap('{:,.0f}'.format))\n",
    "final.to_csv(data_dir/'nfp.tex', sep='&', \n",
    "             line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-04T13:44:20.152095Z",
     "start_time": "2022-03-04T13:44:20.127865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In February 2022, there were 22.2 million government jobs, equivalent to 8.4 for every 100 people in the age 16+ population (see {\\color{blue!50!cyan}\\textbf{---}}). The previous year, in February 2021, there were 21.8 million government jobs, equivalent to 8.4 percent of the age 16 or older population. During the 1990s, there were 9.7 government jobs per person age 16 or older. If the rate was the same today, there would be 3.5 million additional government workers.\n",
      "\n",
      "By level of government, there were 14.1 million local government workers in February 2022, equivalent to 5.3 percent of those age 16 or older (see {\\color{red}\\textbf{---}}). In the same period, there were 5.2 million state government workers (2.0 percent of 16+ year olds, see {\\color{orange}\\textbf{---}}), and 2.9 million federal government workers (1.1 percent, see {\\color{green!80!blue}\\textbf{---}}).\n",
      "\n",
      "Since 2019, the US has lost 533,000 total government jobs. Of these, 567,000, or 106.4 percent of the shortfall, are local government jobs. During the same period, state governments lost 5,000 jobs, while the federal government added 39,000 jobs.\n"
     ]
    }
   ],
   "source": [
    "pop = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date'))['POP']\n",
    "jobcats = ['govjobs', 'locjobs', 'stjobs', 'fedjobs']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', index_col='date', \n",
    "                   parse_dates=['date'])[jobcats])\n",
    "sh = df.divide(pop, axis=0) * 100\n",
    "sh.loc['1989':].to_csv(data_dir / 'govjobs.csv', index_label='date')\n",
    "\n",
    "grps = {'govjobs': 'blue!50!cyan', 'fedjobs': 'green!80!blue',\n",
    "        'stjobs': 'orange', 'locjobs': 'red'}\n",
    "for cat, col in grps.items():\n",
    "    node = (end_node(sh[cat], col, date='m', percent=True) \n",
    "            if cat == 'govjobs' \n",
    "            else end_node(sh[cat], col, percent=True))\n",
    "    write_txt(text_dir / f'{cat}_node.txt', node)\n",
    "    \n",
    "ltdate = dtxt(sh.index[-1])['mon1']\n",
    "pryrdate = dtxt(sh.index[-13])['mon1']\n",
    "ltval = df.govjobs.iloc[-1] / 1000 \n",
    "pryrval = df.govjobs.iloc[-13] / 1000 \n",
    "ltsh = sh.govjobs.iloc[-1]\n",
    "pryrsh = sh.govjobs.iloc[-13]\n",
    "ltfed = df.fedjobs.iloc[-1] / 1000 \n",
    "ltst = df.stjobs.iloc[-1] / 1000 \n",
    "ltloc = df.locjobs.iloc[-1] / 1000 \n",
    "ltfedsh = sh.fedjobs.iloc[-1] \n",
    "ltstsh = sh.stjobs.iloc[-1]\n",
    "ltlocsh = sh.locjobs.iloc[-1]\n",
    "diff = df.govjobs.iloc[-1] - df.govjobs.loc['2019-12-01']#.mean()\n",
    "gl = 'gained' if diff > 0 else 'lost'\n",
    "difftxt = (f'{gl} {abs(diff):.0f},000' if abs(diff) < 1000 \n",
    "           else f'{gl} {abs(diff) / 1000:.1f} million')\n",
    "txt3 = f'Since 2019, the US has {difftxt} total government jobs. '\n",
    "sh90 = sh.loc['1990':'1999', 'govjobs'].mean()\n",
    "diff90 = ((sh90 / 100)\n",
    "          * pop.iloc[-1]) - df.govjobs.iloc[-1]\n",
    "\n",
    "txt1 = (f'In {ltdate}, there were {ltval:.1f} million government jobs, '+\n",
    "        f'equivalent to {ltsh:.1f} for every 100 people in the age 16+ population '+\n",
    "        f'(see {{\\color{{{grps[\"govjobs\"]}}}\\\\textbf{{---}}}}). The previous year, '+\n",
    "        f'in {pryrdate}, there were {pryrval:.1f} million government jobs, '+\n",
    "        f'equivalent to {pryrsh:.1f} percent of the age 16 or older population. '+\n",
    "        f'During the 1990s, there were {sh90:.1f} government jobs per person '+\n",
    "        'age 16 or older. If the rate was the same today, there would be '+\n",
    "        f'{diff90 / 1_000:.1f} million additional government workers.'+\n",
    "        f'\\n\\nBy level of government, there were {ltloc:.1f} million '+\n",
    "        f'local government workers in {ltdate}, equivalent to '+\n",
    "        f'{ltlocsh:.1f} percent of those age 16 or older '+\n",
    "        f'(see {{\\color{{{grps[\"locjobs\"]}}}\\\\textbf{{---}}}}). '+\n",
    "        f'In the same period, there were {ltst:.1f} million state '+\n",
    "        f'government workers ({ltstsh:.1f} percent of 16+ year olds, '+\n",
    "        f'see {{\\color{{{grps[\"stjobs\"]}}}\\\\textbf{{---}}}}), and '+\n",
    "        f'{ltfed:.1f} million federal government workers ({ltfedsh:.1f} '+\n",
    "        f'percent, see {{\\color{{{grps[\"fedjobs\"]}}}\\\\textbf{{---}}}}).')\n",
    "\n",
    "ch19 = df.iloc[-1] - df.loc['2019-12-01']#.mean()\n",
    "locchsh = (ch19.locjobs / ch19.govjobs) * 100\n",
    "stchtxt = value_text(ch19.stjobs, style='added_lost', ptype=None, digits=0)\n",
    "fedchtxt = value_text(ch19.fedjobs, style='added_lost', ptype=None, digits=0)\n",
    "locchtxt = value_text(ch19.locjobs, style='added_lost', ptype=None, digits=0)\n",
    "aw = 'and' if ch19.fedjobs < 0 else 'while'\n",
    "if (ch19.govjobs < 0) and (ch19.locjobs < 0):\n",
    "    txt = (f'Of these, {abs(ch19.locjobs):,.0f},000, or {locchsh:.1f} '+\n",
    "           'percent of the shortfall, are local government jobs. '+\n",
    "           'During the same period, ')\n",
    "else:\n",
    "    txt = f'During the same period, local governments {locchtxt},000 jobs, '\n",
    "    \n",
    "txt2 = (f'state governments {stchtxt},000 jobs, {aw} '+\n",
    "        f'the federal government {fedchtxt},000 jobs.')\n",
    "text = txt1 + '\\n\\n' + txt3 + txt + txt2\n",
    "write_txt(text_dir / 'govjobs.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
