{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Jobs Report Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:41:51.019565Z",
     "start_time": "2021-05-06T15:41:50.379331Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:22.167999Z",
     "start_time": "2021-04-03T13:24:14.071984Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS14000003': 'White', \n",
    "          'LNS14000006': 'Black',\n",
    "          'LNS14000009': 'Hispanic',\n",
    "          'LNS14032183': 'Asian',\n",
    "          'LNS14000000': 'Total',\n",
    "          'LNS13327709': 'U6',\n",
    "          'LNS13000000': 'Level',\n",
    "          'LNU03008636': 'LT',\n",
    "          'LNU03008516': 'MT',\n",
    "          'LNU00000000': 'POP',\n",
    "          'LNS12300060': 'PA_EPOP',\n",
    "          'LNS13023621': 'Job Loser',\n",
    "          'LNS13023653': 'Temporary Layoff',\n",
    "          'LNS13026638': 'Permanent Separation',\n",
    "          'LNS13023705': 'Job Leaver', \n",
    "          'LNS13023557': 'Re-entrant',\n",
    "          'LNS13023569': 'New entrant',\n",
    "          'LNS13008276': 'Median',\n",
    "          'LNS13008275': 'Mean',\n",
    "          'LNS17200000': 'NILF',\n",
    "          'LNS17100000': 'UNEMP',\n",
    "          'LNS11000000': 'LF',\n",
    "          'LNS12032194': 'PTECON'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1988, 2021)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main.csv', index_label='date')\n",
    "print(dtxt(df.index[-1])['mon1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T20:20:40.016934Z",
     "start_time": "2021-04-16T20:20:31.712100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'CES0500000003': 'ALL', \n",
    "          'CES0500000008': 'PNS',\n",
    "          'LNS12005054': 'avghrstot',\n",
    "          'LNU02033699': 'avghrsserv',\n",
    "          'CES0500000002': 'ceshrstot',\n",
    "          'CES0600000002': 'ceshrsgoods',\n",
    "          'CES0800000002': 'ceshrsserv',\n",
    "          'CES0500000007': 'ceshrspns',\n",
    "          'CES9000000001': 'govjobs',\n",
    "          'LNU02033232': 'avghrsptecon',\n",
    "          'LEU0252911200': 'p10uwe',\n",
    "          'LEU0252911300': 'p25uwe',\n",
    "          'LEU0252881500': 'p50uwe',\n",
    "          'LEU0252911400': 'p75uwe',\n",
    "          'LEU0252911500': 'p90uwe',\n",
    "          'LEU0254466800': 'nuwe',\n",
    "          'LNU02026619': 'MJH',\n",
    "          'LNU02000000': 'EMP',\n",
    "          'LNU00000001': 'MenPop',\n",
    "          'LNU00000002': 'WomenPop',\n",
    "          'LNU01000001': 'MenLF',\n",
    "          'LNU01000002': 'WomenLF',\n",
    "          'LNS11300001': 'MenLFPR',\n",
    "          'LNS11300002': 'WomenLFPR'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1988, 2021)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:31.462200Z",
     "start_time": "2021-04-03T13:24:30.423980Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS17100001': 'MenUE',\n",
    "          'LNS17100002': 'WomenUE',\n",
    "          'LNS17200001': 'MenNE',\n",
    "          'LNS17200002': 'WomenNE',\n",
    "          'LNS17400001': 'MenEU',\n",
    "          'LNS17400002': 'WomenEU',\n",
    "          'LNS17600001': 'MenNU',\n",
    "          'LNS17600002': 'WomenNU',\n",
    "          'LNS17800001': 'MenEN',\n",
    "          'LNS17800002': 'WomenEN',\n",
    "          'LNS17900001': 'MenUN',\n",
    "          'LNS17900002': 'WomenUN',\n",
    "          'LNS12000001': 'MenE',\n",
    "          'LNS12000002': 'WomenE',\n",
    "          'LNS13000001': 'MenU',\n",
    "          'LNS13000002': 'WomenU',\n",
    "          'LNS15000001': 'MenN',\n",
    "          'LNS15000002': 'WomenN'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (2018, 2021)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'jobs_report_main3.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Gross Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:31.490075Z",
     "start_time": "2021-04-03T13:24:31.463625Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main3.csv', parse_dates=['date'])\n",
    "        .set_index('date')) / 1000\n",
    "\n",
    "cols = ['MenEU', 'WomenEU', 'MenEN', 'WomenEN', 'MenUE', 'WomenUE',\n",
    "        'MenUN', 'WomenUN', 'MenNE', 'WomenNE', 'MenNU', 'WomenNU']\n",
    "\n",
    "cols2 = []\n",
    "for col in cols:\n",
    "    name = f'{col}{col[-2]}'\n",
    "    cols2.append(name)\n",
    "    df[name] = (df[col] / df[f'{col[:-2]}{col[-2]}'].shift()) * 100\n",
    "\n",
    "df.loc['2013-01-01':, cols2].to_csv(data_dir / 'grosslf.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:31.523376Z",
     "start_time": "2021-04-03T13:24:31.491040Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "srs = ['Total', 'U6']\n",
    "df.loc['1989':, srs].to_csv(data_dir / 'unemp2.csv', index_label='date')\n",
    "\n",
    "srs = ['White', 'Black', 'Hispanic']\n",
    "df.loc['1989':, srs].to_csv(data_dir / 'unemp.csv', index_label='date')\n",
    "\n",
    "s = series_info(df['Level'])\n",
    "s2 = series_info(df['Total'])\n",
    "s3 = series_info(df['Black'])\n",
    "s4 = series_info(df['U6'])\n",
    "compare = compare_text(df['Total'].iloc[-1], df['Total'].iloc[-2], [0.15, 1.5, 3.0])\n",
    "compare2 = compare_text(df['Total'].iloc[-1], df['Total'].iloc[-13], [0.15, 1.5, 3.0])\n",
    "pryrdt = dtxt(df.index[-13])['mon1']\n",
    "\n",
    "if compare[-5:] != compare2[-5:]:\n",
    "    conj = f', but {compare2} the {pryrdt} rate of {df[\"Total\"].iloc[-13]:.1f} percent'\n",
    "elif compare != compare2:\n",
    "    conj = f', and {compare2} the {pryrdt} rate of {df[\"Total\"].iloc[-13]:.1f} percent'\n",
    "else:\n",
    "    conj = ''\n",
    "    \n",
    "text = ('BLS \\href{https://www.bls.gov/news.release/empsit.nr0.htm}{reports} '+\n",
    "        f'{s[\"val_latest\"]/1000:.1f} million '+\n",
    "        f'unemployed persons in {s[\"date_latest_ft\"]}, '+\n",
    "        f'and an unemployment rate of {s2[\"val_latest\"]} percent '+\n",
    "        '(see {\\color{blue!50!cyan}\\\\textbf{---}}), '+\n",
    "        f'{compare} the {s[\"date_prev_ft\"]} rate of {s2[\"val_prev\"]} percent'+\n",
    "        f'{conj}.')\n",
    "write_txt(text_dir / 'unemp1.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "mval = f', {s4[\"last_matched\"]}.' if s4['days_since_match'] > 1000 else '.'\n",
    "text = (f'In {s[\"date_latest_ft\"]}, the labor under-utilization rate is '+\n",
    "        f'{s4[\"val_latest\"]} percent '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}})'+\n",
    "        f'{mval}')\n",
    "write_txt(text_dir / 'unemp2.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "write_txt(text_dir / 'u6_node.txt', end_node(df['U6'], 'blue'))\n",
    "write_txt(text_dir / 'u3_node.txt', end_node(df['Total'], 'blue!50!cyan'))\n",
    "\n",
    "black_ch = df['Black'].iloc[-1] - df.loc['2020-02-01', 'Black']\n",
    "text = ('Unemployment is much more common for disadvantaged groups, '+\n",
    "        'with the black or African American unemployment rate typically double '+\n",
    "        'the white unemployment rate. '+\n",
    "        'A very tight labor market may have the effect of reducing racial '+\n",
    "        'discrimination in hiring. However, disadvantaged groups are more likely to '+\n",
    "        'lose jobs in a downturn. As a result, the full-employment portion '+\n",
    "        'of the business cycle is quite short for many people. '\n",
    "        'Since February 2020, the black unemployment rate '+\n",
    "        f'has increased by {black_ch:.1f} percentage '+\n",
    "        f'points to {s3[\"val_latest\"]:.1f} percent '+\n",
    "        '(see {\\color{green!50!teal!60!black}\\\\textbf{---}}).')\n",
    "write_txt(text_dir / 'unemp3.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:31.552966Z",
     "start_time": "2021-04-03T13:24:31.524500Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = ['U6', 'Total', 'White', 'Black', 'Hispanic', 'Asian']\n",
    "untab = df[srs].iloc[-6:].iloc[::-1].T\n",
    "untab.columns = untab.columns.strftime('%b `%y')\n",
    "untab['GFC peak'] = df.loc['2005':'2013', srs].max()\n",
    "untab['Date'] = df.loc['2005':'2013', srs].idxmax().dt.strftime('%b `%y')\n",
    "d = {'Total': 'Unemployment Rate (U3)',\n",
    "     'U6': 'Under-utilization Rate (U6)',\n",
    "     'White': '\\hspace{2mm} White',\n",
    "     'Black': '\\hspace{2mm} Black',\n",
    "     'Hispanic': '\\hspace{2mm} Hispanic',\n",
    "     'Asian': '\\hspace{2mm} Asian'}\n",
    "untab.index = untab.index.map(d)\n",
    "\n",
    "untab.loc['\\\\textit{by race/ethnicity:}', untab.columns] = [''] * 8\n",
    "untab = untab.iloc[0:2].append(untab.iloc[-1]).append(untab.iloc[2:6])\n",
    "untab.columns.name = None\n",
    "untab.to_csv(data_dir / 'unemp1.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "untab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Force Participation Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:31.576957Z",
     "start_time": "2021-04-03T13:24:31.554681Z"
    }
   },
   "outputs": [],
   "source": [
    "tcol = 'green!80!blue'\n",
    "mcol = 'blue!80!cyan'\n",
    "wcol = 'orange'\n",
    "\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))[['MenLFPR', 'WomenLFPR']]\n",
    "\n",
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "         .assign(TotLFPR = lambda x: (x.LF / x.POP)*100)\n",
    "         .set_index('date'))['TotLFPR']\n",
    "\n",
    "df['TotLFPR'] = df2\n",
    "df.loc['1989':].to_csv(data_dir / 'lfpr.csv', index_label='date')\n",
    "\n",
    "write_txt(text_dir / 'totlfpr_node.txt', end_node3(df['TotLFPR'], tcol))\n",
    "write_txt(text_dir / 'menlfpr_node.txt', end_node3(df['MenLFPR'], mcol))\n",
    "write_txt(text_dir / 'womenlfpr_node.txt', end_node3(df['WomenLFPR'], wcol))\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "ltval = df['TotLFPR'].iloc[-1]\n",
    "prval = df['TotLFPR'].iloc[-2]\n",
    "if dtxt(df.index[-1])['year'] == dtxt(df.index[-2])['year']:\n",
    "    prmonth = dtxt(df.index[-2])['mon3']\n",
    "else:\n",
    "    prmonth = dtxt(df.index[-2])['mon1']\n",
    "prval2 = df['TotLFPR'].iloc[-3]\n",
    "if dtxt(df.index[-1])['year'] == dtxt(df.index[-3])['year']:\n",
    "    prmonth2 = dtxt(df.index[-3])['mon3']\n",
    "else:\n",
    "    prmonth2 = dtxt(df.index[-3])['mon1']\n",
    "feb20val = df['TotLFPR'].loc['2020-02-01']\n",
    "\n",
    "text = (f'In the latest data, covering {ltdate}, {ltval:.1f} percent of people age 16 and '+\n",
    "        'older are in the labor force (see {\\\\color{green!80!blue}\\\\textbf{---}}), '+\n",
    "        f'compared to {prval:.1f} percent in {prmonth} '+\n",
    "        f'and {prval2:.1f} percent in {prmonth2}. In February 2020, when US '+\n",
    "        'confirmed cases of COVID-19 were still low, this labor force participation '+\n",
    "        f'rate was {feb20val:.1f} percent. ')\n",
    "print(text)\n",
    "write_txt(text_dir / 'lfpr_text.txt', text)\n",
    "\n",
    "mltval = df['MenLFPR'].iloc[-1]\n",
    "wltval = df['WomenLFPR'].iloc[-1]\n",
    "mchval = mltval - df['MenLFPR'].loc['2020-01-01']\n",
    "wchval = wltval - df['WomenLFPR'].loc['2020-01-01']\n",
    "mch = value_text(mchval, style='increase', ptype='pp')\n",
    "wch = value_text(wchval, style='increase', ptype='pp')\n",
    "\n",
    "text = (f'In {ltdate}, {mltval:.1f} percent of men age 16+ are in '+\n",
    "        'the labor force (see {\\\\color{blue!80!cyan}\\\\textbf{---}}), '+\n",
    "        f'compared to {wltval:.1f} percent of women '+\n",
    "        '(see {\\\\color{orange}\\\\textbf{---}}). Since February '+\n",
    "        f'2020, labor force participation has {mch} among men, '+\n",
    "        f'and {wch} among women.')\n",
    "print(text)\n",
    "write_txt(text_dir / 'lfpr_text2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:31.595132Z",
     "start_time": "2021-04-03T13:24:31.578399Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, 'PA_EPOP']\n",
    "\n",
    "df.to_csv(data_dir / 'epop.csv', index_label='date')\n",
    "\n",
    "write_txt(text_dir / 'epop_node.txt', end_node(df, 'blue!90!cyan', date=True))\n",
    "\n",
    "#node = f'{dtxt(df.index[-1])[\"mon5\"]}:\\\\\\{df.iloc[-1]:.1f}\\%'\n",
    "#write_txt(text_dir / 'epop.txt', node)\n",
    "\n",
    "d = series_info(df)\n",
    "\n",
    "text = f'In {d[\"date_latest_ft\"]}, {d[\"val_latest\"]} percent'\n",
    "\n",
    "if (d['days_since_match'] > 725) | (d['days_since_match'] == 0):\n",
    "    text2 = d['last_matched']\n",
    "else:\n",
    "    text2 = f'compared to {d[\"val_prev\"]} percent in {d[\"date_prev_ft\"]}'\n",
    "    \n",
    "if d['change_year_ago'] > 0:\n",
    "    direction = 'increased'\n",
    "    value = d['change_year_ago']\n",
    "    label = (f'Over the past year, the age 25-54 employment rate has '+\n",
    "             f'{direction} by {value:.1f} percentage points.')\n",
    "elif d['change_year_ago'] < 0:\n",
    "    direction = 'fallen'\n",
    "    value = abs(d['change_year_ago'])\n",
    "    label = (f'Over the past year, the age 25-54 employment rate has '+\n",
    "             f'{direction} by {value:.1f} percentage points.')\n",
    "else:\n",
    "    label = 'The age 25-54 employment rate is unchanged over the past year. '\n",
    "    \n",
    "pop = 126277\n",
    "diff1 = d['late90s'] - d['val_latest']\n",
    "diff = (d['late90s'] - d['val_latest']) / 100 * pop\n",
    "\n",
    "if diff > 999:\n",
    "    diff_text = f'{round(diff / 1000, 1)} million'\n",
    "else: \n",
    "    diff_text = f'{round(diff, -1)} thousand'\n",
    "    \n",
    "label2 = (f'The current age 25-54 employment rate is {diff1:.1f} percentage '+\n",
    "          f'points (equivalent to {diff_text} workers) below the average during '+\n",
    "          '1998--99, a period with a particularly tight labor market. ')\n",
    "\n",
    "textval = f'{text} of 25-54 years olds were employed, {text2}. {label} {label2}'\n",
    "print(textval)\n",
    "\n",
    "write_txt(text_dir / 'epop_text.txt', textval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment by reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T00:15:57.865096Z",
     "start_time": "2021-04-09T00:15:57.830576Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = ['Job Loser', 'Job Leaver', 'Re-entrant', 'New entrant', \n",
    "       'Temporary Layoff', 'Permanent Separation', 'Level']\n",
    "d1 = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':]\n",
    "\n",
    "df = d1[srs].div(d1['LF'], axis='index') * 100\n",
    "#.resample('QS').mean()\n",
    "df.to_csv(data_dir / 'unemp_reason.csv', index_label='date', float_format='%g')\n",
    "\n",
    "loser = df['Job Loser'].iloc[-1]\n",
    "tl = df['Temporary Layoff'].iloc[-1]\n",
    "tlsh = (d1['Temporary Layoff'] / d1['Level']).iloc[-1] * 100\n",
    "leaver = df['Job Leaver'].iloc[-1]\n",
    "reent = df['Re-entrant'].iloc[-1]\n",
    "newent = df['New entrant'].iloc[-1]\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "\n",
    "text = (f'In {ltdate}, {loser:.1f} percent of the labor force '+\n",
    "        'were unemployed because of losing a job or having a temporary '+\n",
    "        f'job end. Of these, {tl:.1f} percent of the labor force are unemployed due '+\n",
    "        f'to temporary layoff, equivalent to {tlsh:.1f} percent of the unemployed. '+\n",
    "        f'Additionally, {leaver:.1f} percent of the labor force were re-entrants, '+\n",
    "        f'{reent:.1f} percent were new entrants, and {newent:.1f} '+\n",
    "        'percent were job leavers. ')\n",
    "write_txt(text_dir / 'unemp_reason.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T00:16:00.568545Z",
     "start_time": "2021-04-09T00:16:00.024729Z"
    }
   },
   "outputs": [],
   "source": [
    "lf = ['Employed', 'Unemployed']\n",
    "naw_rate = lambda x: np.average(x['NOTATWORK'], weights=x['BASICWGT'])\n",
    "\n",
    "naw = pd.Series(dtype='float64')\n",
    "\n",
    "columns = ['LFS', 'MONTH', 'YEAR', 'BASICWGT', 'NOTATWORK']\n",
    "for year in range(2017, 2022):\n",
    "    data = (pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "        .query('LFS in @lf'))\n",
    "    data1 = data.groupby(['YEAR', 'MONTH']).apply(naw_rate) * 100\n",
    "    data1.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data1.index]\n",
    "    naw = naw.append(data1)\n",
    "\n",
    "df['Employed, Not at Work'] = naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T00:16:02.338394Z",
     "start_time": "2021-04-09T00:16:02.287079Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'Level': 'Unemployed, Any Reason',\n",
    "     'Job Loser': '\\hspace{2mm}Job Loser',\n",
    "     'Temporary Layoff': '\\hspace{4mm}Temporary Layoff',\n",
    "     'Permanent Separation': '\\hspace{4mm}Permanent Separation',\n",
    "     'Re-entrant': '\\hspace{2mm}Re-entrant',\n",
    "     'New entrant': '\\hspace{2mm}New entrant',\n",
    "     'Job Leaver': '\\hspace{2mm}Job Leaver'}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "loc_list = [-1, -2, -3, -4, -5, -13, -14, -15, -16, -17]\n",
    "\n",
    "for key, value in d.items():\n",
    "    for i in loc_list:\n",
    "        final.loc[value, dtxt(df.index[i])['mon6']] = df[key].iloc[i].round(1)\n",
    "        \n",
    "final.loc['\\\\textit{See also:}', final.columns] = [''] * 10\n",
    "final.loc['Employed, Not at Work', final.columns] = [df['Employed, Not at Work'].iloc[i].round(1) \n",
    "                                                     for i in loc_list]\n",
    "\n",
    "final.to_csv(data_dir / 'unempreason_table.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T00:16:03.150819Z",
     "start_time": "2021-04-09T00:16:03.120986Z"
    }
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployed long-term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:32.192424Z",
     "start_time": "2021-04-03T13:24:32.175975Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = ['LT', 'MT', 'POP']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, srs]\n",
    "\n",
    "data = (df.divide(df['POP'], axis=0) * 100).drop(['POP'], axis=1)\n",
    "data.to_csv(data_dir / 'ltu.csv', index_label='date', float_format='%g')\n",
    "\n",
    "write_txt(text_dir / 'ltu_node.txt', end_node(data['LT'], 'blue'))\n",
    "write_txt(text_dir / 'ltu_node2.txt', end_node(data['MT'], 'red'))\n",
    "\n",
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "pdate = dtxt(data.index[-13])['mon1']\n",
    "hdate = dtxt(data['LT'].idxmax())['mon1']\n",
    "prdt = dtxt(data.index[-2])['mon1']\n",
    "prdt2 = dtxt(data.index[-3])['mon1']\n",
    "\n",
    "recent_min = data.loc['2015':, 'LT'].min()\n",
    "recent_min_dt = dtxt(data.loc['2015':, 'LT'].idxmin())['mon1']\n",
    "\n",
    "text = (f'As of {ldate}, BLS '+\n",
    "        '\\href{https://www.bls.gov/webapps/legacy/cpsatab12.htm}{reports} '+\n",
    "        f'that {data[\"LT\"].iloc[-1]:.2f} percent of the age 16+ '+\n",
    "         'population have been unemployed for 27 weeks or longer, '+\n",
    "        f'compared to {data[\"LT\"].iloc[-13]:.2f} percent in {pdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}). This measure of long-term '+\n",
    "        f'unemployment peaked at {data[\"LT\"].max():.2f} percent of the '+\n",
    "        f'population in {hdate}, but had fallen to {recent_min:.2f} percent '+\n",
    "        f'in {recent_min_dt}. \\n \\nIn {ldate}, {data[\"MT\"].iloc[-1]:.2f} '+\n",
    "        'percent of the age 16+ population are unemployed for at '+\n",
    "        f'least 15 weeks, following {data[\"MT\"].iloc[-2]:.2f} percent in {prdt}, '+\n",
    "        f'and {data[\"MT\"].iloc[-3]:.2f} percent in {prdt2}.')\n",
    "write_txt(text_dir / 'ltu.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of Unemployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T17:01:38.296169Z",
     "start_time": "2021-04-16T17:01:38.262463Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = ['Median', 'Mean']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, srs]\n",
    "\n",
    "df.to_csv(data_dir / 'unempdur.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ldate = dtxt(df.index[-1])['mon1']\n",
    "\n",
    "median = df['Median'].iloc[-1]\n",
    "mean = df['Mean'].iloc[-1]\n",
    "\n",
    "text = ('Among those who are unemployed, '+\n",
    "        f'the average (mean) duration of unemployment is {mean:.1f} weeks '+\n",
    "        '(see {\\color{orange}\\\\textbf{---}}), and the typical (median) '+\n",
    "        f'duration of unemployment is {median:.1f} weeks '+\n",
    "        '(see {\\color{green!75!blue}\\\\textbf{---}}), as '+\n",
    "        f'of {ldate}.')\n",
    "write_txt(text_dir / 'unempdur.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part Time for Economic Reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:32.225795Z",
     "start_time": "2021-04-03T13:24:32.206719Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = ['PTECON', 'LF']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, srs]\n",
    "\n",
    "data = (df['PTECON'] / df['LF']) * 100\n",
    "data.name = 'PTECON'\n",
    "data.to_csv(data_dir / 'ptecon.csv', index_label='date')\n",
    "\n",
    "write_txt(text_dir / 'ptecon_node.txt', end_node(data, 'red'))\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "totval = df.PTECON.iloc[-1] * 1000\n",
    "ltval = data.iloc[-1]\n",
    "comp_date = '2020-02-01'\n",
    "lastmatch = series_info(data)['last_matched']\n",
    "feb20val = data.loc[comp_date]\n",
    "compare = compare_text(ltval, feb20val, [0.1, 0.9, 4.0])\n",
    "feb20date = dtxt(pd.to_datetime(comp_date))['mon1']\n",
    "gfcval = data.loc[:comp_date].max()\n",
    "gfcmaxdate = dtxt(data.loc[:comp_date].idxmax())['mon1']\n",
    "\n",
    "text = (f'As of {ltdate}, {totval:,.0f} people are working part time '+\n",
    "        f'because of economic reasons, equivalent to {ltval:.1f} percent '+\n",
    "        'of the labor force (see {\\color{red}\\\\textbf{---}}), '+\n",
    "        f'{lastmatch} and {compare} the {feb20date} rate of {feb20val:.1f} percent. '+\n",
    "        'During the great recession, the involuntary part-time share of '+\n",
    "        f'the labor force peaked at {gfcval:.1f} percent in {gfcmaxdate}.')\n",
    "write_txt(text_dir / 'ptecon.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Jobholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:32.244680Z",
     "start_time": "2021-04-03T13:24:32.226716Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = ['MJH', 'EMP']\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1989':, srs]\n",
    "\n",
    "data = ((df['MJH'] / df['EMP']) * 100).dropna()\n",
    "data.name = 'MJH'\n",
    "data.to_csv(data_dir / 'mjh.csv', index_label='date')\n",
    "\n",
    "write_txt(text_dir / 'mjh_node.txt', end_node(data, 'cyan!50!blue'))\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "totval = df.MJH.iloc[-1] * 1000\n",
    "ltval = data.iloc[-1]\n",
    "comp_date = '2020-02-01'\n",
    "lastmatch = series_info(data)['last_matched']\n",
    "feb20val = data.loc[comp_date]\n",
    "compare = compare_text(ltval, feb20val, [0.1, 0.4, 2.0])\n",
    "feb20date = dtxt(pd.to_datetime(comp_date))['mon1']\n",
    "gfcval = data.loc[:comp_date].max()\n",
    "gfcmaxdate = dtxt(data.loc[:comp_date].idxmax())['mon1']\n",
    "\n",
    "text = (f'In {ltdate}, {totval:,.0f} people are working more than one job, '+\n",
    "        f'equivalent to {ltval:.1f} percent of workers '+\n",
    "        '(see {\\color{cyan!50!blue}\\\\textbf{---}}), '+\n",
    "        f'{lastmatch} and {compare} the {feb20date} rate of {feb20val:.1f} percent. '+\n",
    "        'The multiple jobholder share of '+\n",
    "        f'workers peaked at {gfcval:.1f} percent in {gfcmaxdate}.')\n",
    "write_txt(text_dir / 'mjh.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Weekly Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T00:07:57.960797Z",
     "start_time": "2021-04-16T00:07:56.750678Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "data['TOTLFS'] = df2['avghrstot']\n",
    "data['SERVNSA'] = df2['avghrsserv']\n",
    "data['SERVSA'] = x13_arima_analysis(df2['avghrsserv'].dropna()).seasadj\n",
    "data['PNS'] = df2['ceshrspns']\n",
    "data['PTECONNSA'] = df2['avghrsptecon']\n",
    "data['PTECONSA'] = x13_arima_analysis(df2['avghrsptecon'].dropna()).seasadj\n",
    "\n",
    "data.loc['1989':].to_csv(data_dir / 'hours.csv', index_label='date')\n",
    "\n",
    "data.plot(color=['blue', 'lime', 'darkgreen', 'orange', 'lightpink', 'red'], figsize=(3, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:33.510330Z",
     "start_time": "2021-04-03T13:24:33.503302Z"
    }
   },
   "outputs": [],
   "source": [
    "ltval = data['TOTLFS'].iloc[-1]\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "feb20val = data.loc['2020-02-01', 'TOTLFS']\n",
    "compare = compare_text(ltval, feb20val, [0.2, 1.5, 3.0])\n",
    "avg90 = data.loc['1998':'2000', 'TOTLFS'].mean()\n",
    "gfclow = data.loc['2005': '2012', 'TOTLFS'].min()\n",
    "gfclowdt = dtxt(data.loc['2005': '2012', 'TOTLFS'].idxmin())['mon1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:33.524775Z",
     "start_time": "2021-04-03T13:24:33.511355Z"
    }
   },
   "outputs": [],
   "source": [
    "text = ('Weekly hours for the total group of '+\n",
    "        f'people at work in all industries average {ltval:.1f} in {ltdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}) '+\n",
    "        f'{compare} the {feb20val:.1f} average weekly hours in February 2020. '+\n",
    "        f'Weekly hours for this group average {avg90:.1f} from 1998 through 2000, '+\n",
    "        f'and fell to a great recession low of {gfclow:.1f} in {gfclowdt}.')\n",
    "\n",
    "write_txt(text_dir / 'hours_tot.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval2 = data.SERVSA.iloc[-1]\n",
    "feb20val2 = data.loc['2020-02-01', 'SERVSA']\n",
    "compare2 = compare_text(ltval2, feb20val2, [0.2, 0.6, 2.5])\n",
    "pteval = data.PTECONSA.iloc[-1]\n",
    "\n",
    "text = ('Those in service occupations (see '+\n",
    "        '{\\color{green!90!blue!70!black}\\\\textbf{---}}) '+\n",
    "        f'work fewer hours on average, with {ltval2:.1f} average '+\n",
    "        f'weekly hours in {ltdate}, {compare2} the {feb20val2:.1f} '+\n",
    "        'average in February 2020. Those part-time '+\n",
    "        'for economic reasons (see {\\color{red!90!black}\\\\textbf{---}}) '+\n",
    "        f'work an average of {pteval:.1f} hours per week in {ltdate}. ')\n",
    "\n",
    "write_txt(text_dir / 'hours_lfs2.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval3 = data.PNS.iloc[-1]\n",
    "feb20val3 = data.loc['2020-02-01', 'PNS']\n",
    "compare3 = compare_text(ltval3, feb20val3, [0.2, 0.6, 2.5])\n",
    "val98 = data.loc['1998':'2000', 'PNS'].mean()\n",
    "compare4 = compare_text(ltval3, val98, [0.2, 0.6, 2.5])\n",
    "\n",
    "text = (f'In {ltdate}, '+\n",
    "        'production and non-supervisory workers (see {\\color{orange}\\\\textbf{---}})'+\n",
    "        ', about four of every five employees, '+\n",
    "        f'worked {ltval3:.1f} hours per week on average, '+\n",
    "        f'{compare3} the {feb20val3:.1f} average weekly hours in February 2020 and '+\n",
    "        f'{compare4} the 1998--2000 average of {val98:.1f} hours.')\n",
    "\n",
    "write_txt(text_dir / 'hours_ces.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:33.550178Z",
     "start_time": "2021-04-03T13:24:33.525659Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1990':, ['NILF', 'UNEMP']]\n",
    "df['TOTAL'] = df.astype('float').sum(axis=1)\n",
    "sh = (df['NILF'] / df['TOTAL']).rename('total') * 100\n",
    "\n",
    "sh.to_csv(data_dir / 'lf_flow.csv', index_label='date', header=True, float_format='%g')\n",
    "\n",
    "ma = sh.resample('QS').mean().rename('quarterly')\n",
    "\n",
    "ma.to_csv(data_dir / 'lf_flow_q.csv', index_label='date', header=True)\n",
    "write_txt(text_dir / 'lf_flow_node.txt', end_node(ma, 'green!60!teal!90!black'))\n",
    "\n",
    "totval = df['TOTAL'].iloc[-1] / 1000\n",
    "nilfval = df['NILF'].iloc[-1] / 1000\n",
    "unval = df['UNEMP'].iloc[-1] / 1000\n",
    "\n",
    "shval = sh.iloc[-1]\n",
    "maval = ma.iloc[-1] \n",
    "sh3y = sh.iloc[-37]\n",
    "\n",
    "ltdate = dtxt(sh.index[-1])['mon1']\n",
    "yragodt = dtxt(sh.index[-37])['mon1']\n",
    "\n",
    "text = (f'In {ltdate}, {totval:.1f} million people were newly employed (on a gross basis). '+\n",
    "        f'Of these, {shval:.1f} percent were not looking for work in the prior month '+\n",
    "        '(see {\\color{lime!50!green!60!white}\\\\textbf{---}}). Over the past three months, an average '+\n",
    "        f'of {maval:.1f} percent of the newly employed were not looking for work the month prior '+\n",
    "        '(see {\\color{green!60!teal!90!black}\\\\textbf{---}}). With low unemployment, new employees '+\n",
    "        'are being pulled from outside of the labor force and bypassing unemployment. '+\n",
    "        f'Three years ago, in {yragodt}, {sh3y:.1f} percent '+\n",
    "        'of the newly employed were not looking for work month prior.')\n",
    "\n",
    "write_txt(text_dir / 'lf_flow.txt', text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wage Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:42:01.409342Z",
     "start_time": "2021-05-06T15:41:57.079475Z"
    }
   },
   "outputs": [],
   "source": [
    "data1, data2 = pd.Series(dtype='float64'), pd.Series(dtype='float64')\n",
    "columns = ['MONTH', 'YEAR', 'AGE', 'PWORWGT', 'WKEARN', 'HRSUSL1', 'WORKFT']\n",
    "for year in range(1989, 2022):\n",
    "    df = (pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "        .query('WKEARN > 0 and WORKFT == 1'))\n",
    "    data = df.groupby(['YEAR', 'MONTH']).apply(binned_wage)\n",
    "    data.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data.index]\n",
    "    data1 = data1.append(data)\n",
    "    \n",
    "df = pd.DataFrame({'All': data1})\n",
    "df = df.rolling(3).mean()\n",
    "\n",
    "df.rolling(3).mean().to_csv(data_dir / 'uwe_bd.csv', index_label='date')\n",
    "dfgr = (df.pct_change(12).dropna() * 100).rolling(3).mean()\n",
    "dfgr.to_csv(data_dir / 'uwe_bd_gr.csv', index_label='date')\n",
    "\n",
    "srs = ['p10uwe']\n",
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['1988':, srs].dropna()\n",
    "df2.name = 'p10uwe'\n",
    "\n",
    "df2.to_csv(data_dir / 'uwe_bls.csv', index_label='date')\n",
    "df2gr = (df2.pct_change(4).dropna() * 100)\n",
    "df2gr.to_csv(data_dir / 'uwe_bls_gr.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:42:04.277797Z",
     "start_time": "2021-05-06T15:42:04.253091Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLS \\href{https://www.bls.gov/webapps/legacy/cpswktab5.htm}{calculations} (see {\\color{blue!65!black}\\textbf{---}}) for 2021 Q1 show nominal first decile usual weekly earnings of \\$486.00, compared to \\$468.00 in 2020 Q1, resulting in one-year growth of 3.8 percent. In the previous quarter, 2020 Q4, first decile usual weekly earnings grew by 4.5 percent over the year. Author's calculations from the CPS (see {\\color{lime!65!green}\\textbf{---}}) show three-month moving average first decile usual weekly earnings of \\$488.00 in March 2021, \\$487.00 in February 2021, and \\$468.00 in March 2020. One-year growth was 5.0 percent for the three months ending March 2021, 6.0 percent for the three months ending February 2021, and 6.0 percent for the three months ending January 2021.\n"
     ]
    }
   ],
   "source": [
    "ldate1 = dtxt(df.index[-1])['mon1']\n",
    "lval1 = df['All'].iloc[-1].round()\n",
    "lgrval1 = dfgr['All'].iloc[-1].round()\n",
    "prdate1 = dtxt(df.index[-2])['mon1']\n",
    "prval1 = df['All'].iloc[-2].round()\n",
    "prgrval1 = dfgr['All'].iloc[-2].round()\n",
    "pr2date1 = dtxt(df.index[-3])['mon1']\n",
    "pr2val1 = df['All'].iloc[-3].round()\n",
    "pr2grval1 = dfgr['All'].iloc[-3].round()\n",
    "pr3date1 = dtxt(df.index[-13])['mon1']\n",
    "pr3val1 = df['All'].iloc[-13].round()\n",
    "\n",
    "\n",
    "ldate2 = dtxt(df2.index[-1])['qtr1']\n",
    "lval2 = df2['p10uwe'].iloc[-1]\n",
    "prdate2 = dtxt(df2.index[-5])['qtr1']\n",
    "pr2date2 = dtxt(df2.index[-2])['qtr1']\n",
    "prval2 = df2['p10uwe'].iloc[-5]\n",
    "lgrval2 = df2gr['p10uwe'].iloc[-1]\n",
    "lgr2val2 = df2gr['p10uwe'].iloc[-2]\n",
    "\n",
    "text = ('BLS \\href{https://www.bls.gov/webapps/legacy/cpswktab5.htm}{calculations} '+\n",
    "        f'(see {{\\color{{blue!65!black}}\\\\textbf{{---}}}}) for {ldate2} '+\n",
    "        'show nominal first decile usual weekly '+\n",
    "        f'earnings of \\${lval2:.2f}, compared to \\${prval2:.2f} in {prdate2}, resulting '+\n",
    "        f'in one-year growth of {lgrval2:.1f} percent. In the previous quarter, {pr2date2}, '+\n",
    "        f'first decile usual weekly earnings grew by {lgr2val2:.1f} percent over the year. '+\n",
    "        \"Author's calculations from the CPS (see {\\color{lime!65!green}\\\\textbf{---}}) \"+\n",
    "        'show three-month moving average first decile usual weekly '+\n",
    "        f'earnings of \\${lval1:.2f} in {ldate1}, \\${prval1:.2f} in {prdate1}, '+\n",
    "        f'and \\${pr3val1:.2f} in {pr3date1}. One-year growth was {lgrval1:.1f} percent for '+\n",
    "        f'the three months ending {ldate1}, {prgrval1:.1f} percent for the '+\n",
    "        f'three months ending {prdate1}, and {pr2grval1:.1f} percent for the '+\n",
    "        f'three months ending {pr2date1}.')\n",
    "write_txt(text_dir / 'uwe_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wages Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-06T15:42:14.414326Z",
     "start_time": "2021-05-06T15:42:14.387306Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = {'First decile': 'p10uwe', 'First quartile': 'p25uwe', 'Median': 'p50uwe', \n",
    "       'Third quartile': 'p75uwe', 'Ninth decile': 'p90uwe'}\n",
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date')).loc['2000':, srs.values()].dropna()\n",
    "\n",
    "final = pd.DataFrame()\n",
    "for i in [-1, -2, -3, -4, -5, -9, -13, -17, -21]:\n",
    "    final[dtxt(df.index[i])['qtr1']] = df.pct_change(4).iloc[i] * 100\n",
    "\n",
    "final.index = srs.keys()\n",
    "final.round(1).to_csv(data_dir / 'wage_dist_bls.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "final = pd.DataFrame()\n",
    "for i in [-1, -2, -3, -4, -5, -9, -13, -17, -21]:\n",
    "    final[dtxt(df.index[i])['qtr1']] = df.iloc[i]\n",
    "\n",
    "final.index = srs.keys()\n",
    "final.round(0).astype('int').to_csv(data_dir / 'wage_dist_bls2.tex', sep='&', \n",
    "                                    line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Hourly Earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-15T01:15:18.407581Z",
     "start_time": "2021-04-15T01:15:18.361455Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "data = (df[['ALL', 'PNS']].pct_change(12) * 100).loc['1989':]\n",
    "data.to_csv(data_dir / 'ahe.csv', index_label='date')\n",
    "\n",
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "alllt = data['ALL'].iloc[-1]\n",
    "all_lt = f'{[\"increased\" if alllt >= 0 else \"decreased\"][0]} by {abs(alllt):.1f} percent'\n",
    "pnslt = data['PNS'].iloc[-1]\n",
    "pns_lt = f'{[\"increased\" if pnslt >= 0 else \"decreased\"][0]} by {abs(pnslt):.1f} percent'\n",
    "\n",
    "s = series_info(df['ALL'])\n",
    "all3m = (((s['last_3m'] / s['prev_3m'])**4) - 1) * 100\n",
    "all_3m = f'{[\"increased\" if all3m >= 0 else \"decreased\"][0]} at an annual rate of {abs(all3m):.1f} percent'\n",
    "\n",
    "s = series_info(df['PNS'])\n",
    "pns3m = (((s['last_3m'] / s['prev_3m'])**4) - 1) * 100\n",
    "pns_3m = f'{[\"increased\" if pns3m >= 0 else \"decreased\"][0]} at an annual rate of {abs(pns3m):.1f} percent'\n",
    "\n",
    "text = (f'Over the year ending {ldate}, nominal wages {all_lt} '+\n",
    "        'for all employees (see {\\color{magenta}\\\\textbf{---}}) '+\n",
    "        f'and {pns_lt} for production and non-supervisory workers '+\n",
    "        '(see {\\color{blue!80!black}\\\\textbf{---}}), according to the '+\n",
    "        'Bureau of Labor Statistics. Comparing the latest '+\n",
    "        f'three months to the previous three months, nominal wages {all_3m} '+\n",
    "        f'for all employees and {pns_3m} for production and non-supervisory '+\n",
    "        'employees.')\n",
    "\n",
    "write_txt(text_dir / 'ahe_summary.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AHE by Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:39.080662Z",
     "start_time": "2021-04-03T13:24:38.136029Z"
    }
   },
   "outputs": [],
   "source": [
    "series = {'CES3000000008': 'Manufacturing',\n",
    "          'CES1000000008': 'Mining \\& Logging',\n",
    "          'CES4422000008': 'Utilities',\n",
    "          'CES4142000008': 'Wholesale Trade',\n",
    "          'CES5000000008': 'Information',\n",
    "          'CES5500000008': 'Financial Activities',\n",
    "          'CES6000000008': 'Professional \\& Business Services',\n",
    "          'CES6500000008': 'Education \\& Health Services',\n",
    "          'CES0500000008': 'Total Private',\n",
    "          'CES2000000008': 'Construction',\n",
    "          'CES7000000008': 'Leisure \\& Hospitality',\n",
    "          'CES4300000008': 'Transportation \\& Warehousing',\n",
    "          'CES4200000008': 'Retail Trade'}\n",
    "\n",
    "years = (2017, 2021)\n",
    "df = bls_api(series, years, bls_key)\n",
    "df.to_csv(data_dir / 'ahe_industry_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-16T20:28:19.581329Z",
     "start_time": "2021-04-16T20:28:19.536710Z"
    }
   },
   "outputs": [],
   "source": [
    "s = pd.read_csv(data_dir / 'cpi.csv')\n",
    "df = (pd.read_csv(data_dir / 'ahe_industry_raw.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "allitems = s['ALL'].iloc[-1]\n",
    "data = (df.pct_change(12).iloc[-1] * 100.0).sort_values(ascending=False)\n",
    "\n",
    "(data.to_csv(data_dir / 'ahe_ind.csv', index_label='name', header=True))\n",
    "\n",
    "write_txt(text_dir / 'ahe_bar_date.txt', df.index[-1].strftime('%B %Y'))\n",
    "\n",
    "real = (data - allitems).drop('Total Private')\n",
    "ltd = {i: (data.index[i].lower(), data.iloc[i]) for i in [0, 1, 2]}\n",
    "\n",
    "txt1 = (f'By industry, {len(real.loc[real > 0])} of {len(real)} groups '+\n",
    "         'experienced real wage growth (wage growth above the increase in '+\n",
    "        f'prices indicated by the consumer price index). The {ltd[0][0]} '+\n",
    "        f'industry had the fastest nominal growth rate, at {ltd[0][1]:.1f} percent, followed '+\n",
    "        f'by {ltd[1][1]:.1f} percent in {ltd[1][0]} and {ltd[2][1]:.1f} percent in {ltd[2][0]}. ')\n",
    "write_txt(text_dir / 'ahe_comp.txt', txt1)\n",
    "print(txt1)\n",
    "\n",
    "if data.min() < 0:\n",
    "    dm = f'{data.min() - 1:.1f}'\n",
    "else:\n",
    "    dm = 0\n",
    "\n",
    "text = ('\\\\noindent \\hspace*{-2mm} \\\\begin{tikzpicture}'+\n",
    "        '\\\\begin{axis}[\\\\barplotnogrid axis y line=left, \\\\barylab{4.0cm}{1.5ex}'+\n",
    "        'width=6.2cm, bar width=1.8ex, height=7.2cm, xtick={0}, xmajorgrids,'+\n",
    "        f'enlarge y limits={{abs=3mm}}, enlarge x limits=0.02, xmin={dm},'+\n",
    "        f'\\dbar{{x}}{{{allitems:.2f}}}, clip=false,'+\n",
    "        'yticklabels from table={\\\\ahe}{name},'+\n",
    "        'yticklabel style={font=\\\\footnotesize},'+\n",
    "        'nodes near coords style={/pgf/number format/.cd, fixed zerofill,'+\n",
    "        'precision=1, assume math mode}]'+\n",
    "        '\\\\addplot[fill=blue!80!black, draw=none] '+\n",
    "        'table [y expr=-\\coordindex, x index=1] {\\\\ahe};'+\n",
    "        f'\\\\node[right] at ({allitems:.2f}, -12.6) {{\\\\footnotesize \\\\textcolor{{black!80}}{{CPI}}}};'+\n",
    "        '\\end{axis}'+\n",
    "        '\\end{tikzpicture}\\\\\\ '+\n",
    "        '\\\\footnotesize{Source: Bureau of Labor Statistics} \\hspace{48mm} \\\\tbllink{ahe_ind.csv}')\n",
    "write_txt(text_dir / 'ahe_chart.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CES data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:41.327653Z",
     "start_time": "2021-04-03T13:24:39.110479Z"
    }
   },
   "outputs": [],
   "source": [
    "series = {'CES0000000001': 'ALL',\n",
    "          'LNU00000000': 'TOT',\n",
    "          'CES3000000001': 'Manufacturing',\n",
    "          'CES1000000001': 'Mining \\& Logging',\n",
    "          'CES4422000001': 'Utilities',\n",
    "          'CES4142000001': 'Wholesale Trade',\n",
    "          'CES5000000001': 'Information',\n",
    "          'CES5500000001': 'Financial Activities',\n",
    "          'CES6000000001': 'Professional \\& Business Serv.',\n",
    "          'CES6500000001': 'Education \\& Health Services',\n",
    "          'CES0500000001': 'Total Private',\n",
    "          'CES2000000001': 'Construction',\n",
    "          'CES7000000001': 'Leisure \\& Hospitality',\n",
    "          'CES4300000001': 'Transportation \\& Warehousing',\n",
    "          'CES4200000001': 'Retail Trade',\n",
    "          'CES9000000001': 'Government'}\n",
    "years = (2011, 2021)\n",
    "df = bls_api(series, years, bls_key)\n",
    "df.to_csv(data_dir / 'ces_data.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:41.346641Z",
     "start_time": "2021-04-03T13:24:41.328867Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'ces_data.csv').set_index('date')\n",
    "data = df['ALL'].diff().loc['2017':]\n",
    "data.div(1000).to_csv(data_dir / 'nfp.csv', index_label='date', header='ALL')\n",
    "ldate = dtxt(data.index[-1])['mon1']\n",
    "pdate = dtxt(data.index[-2])['mon1']\n",
    "\n",
    "lval = data.iloc[-1]\n",
    "if lval > 0:\n",
    "    lvaltxt = 'added'\n",
    "else:\n",
    "    lvaltxt = 'lost'\n",
    "pval = data.iloc[-2]\n",
    "if pval > 0:\n",
    "    pvaltxt = 'added'\n",
    "else:\n",
    "    pvaltxt = 'lost'\n",
    "l3val = data.iloc[-3:].mean()\n",
    "if l3val > 0:\n",
    "    l3valtxt = 'added'\n",
    "else:\n",
    "    l3valtxt = 'lost'\n",
    "\n",
    "emp = df.loc['2015':, 'ALL']\n",
    "tot = df.loc['2015':, 'TOT']\n",
    "\n",
    "final2 = (((emp / tot).shift(1) * tot).round(-3) / 1000).rolling(12).mean()\n",
    "final2.to_csv(data_dir / 'nfp_pop.csv', index_label='date', header=['TOT'])\n",
    "\n",
    "lpop = final2.iloc[-3:].mean().round(-1)\n",
    "\n",
    "covloss = abs(data.loc['2020-03-01':'2020-04-01'].sum())  / 1000\n",
    "since = data.loc['2020-05-01':].sum() / 1000\n",
    "\n",
    "rec_pct = since / covloss\n",
    "if rec_pct < 1:\n",
    "    rpct = f' ({rec_pct*100:.1f} percent)'\n",
    "else:\n",
    "    rpct = ''\n",
    "    \n",
    "pre = data.loc['2019-03-01':'2020-02-01'].mean()\n",
    "\n",
    "text = (f'The US {lvaltxt} {abs(lval):,.0f},000 jobs in {ldate}, compared to '+\n",
    "        f'{abs(pval):,.0f},000 {pvaltxt} in {pdate}, and an average of '+\n",
    "        f'{abs(l3val):,.0f},000 {l3valtxt} over '+\n",
    "        f'the past three months. US payrolls shed a combined {covloss:.1f} million jobs '+\n",
    "        f'in March and April 2020 and have since recovered {since:.1f} million jobs{rpct}.'+\n",
    "        '\\n \\nTo maintain a steady employment rate with '+\n",
    "        'population growth, the US needs to '+\n",
    "        f'add around {lpop:.0f},000 jobs per month. During the 12 months prior to the COVID-'+\n",
    "        'related job losses '+\n",
    "        f'the US was adding an average of {pre:,.0f},000 jobs per month.')\n",
    "write_txt(text_dir / 'nfp_basic_text.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:41.371872Z",
     "start_time": "2021-04-03T13:24:41.347680Z"
    }
   },
   "outputs": [],
   "source": [
    "data = (pd.read_csv(data_dir / 'ces_data.csv')\n",
    "          .set_index('date')\n",
    "          .drop(['TOT', 'Total Private'], axis=1)\n",
    "          .rename({'ALL': '\\\\textbf{Total}'}, axis=1))\n",
    "\n",
    "final = pd.DataFrame()\n",
    "for i in [-1, -13]:\n",
    "    final[dtxt(data.index[i])['mon2']] = data.iloc[i]\n",
    "    \n",
    "final[dtxt(data.index[-1])['mon2'] + ' '] = data.diff().iloc[-1]\n",
    "for i in [-2, -3]:\n",
    "    final[dtxt(data.index[i])['mon2']] = data.diff().iloc[i]\n",
    "    \n",
    "final['Mar `19 to Feb `20 avg'] = data.diff().loc['2019-03-01':'2020-02-01'].mean()    \n",
    "    \n",
    "final['Since May 2020'] = data.iloc[-1] - data.loc['2020-04-01']\n",
    "final['Mar and Apr `20'] = data.diff().loc['2020-03-01':'2020-04-01'].sum()\n",
    "\n",
    "final = final.sort_values(dtxt(data.index[-1])['mon2'], ascending=False).astype(int).applymap('{:,.0f}'.format)\n",
    "final.to_csv(data_dir / 'nfp.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-03T13:24:41.388959Z",
     "start_time": "2021-04-03T13:24:41.372879Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = (pd.read_csv(data_dir / 'jobs_report_main.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "\n",
    "df2 = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "\n",
    "gj = df2['govjobs']\n",
    "data = ((gj / df1['POP']) * 100)\n",
    "data.name = 'GOVJOBS'\n",
    "data.to_csv(data_dir / 'govjobs.csv', index_label='date', header=True)\n",
    "node = end_node(data, 'blue!50!cyan', date=True)\n",
    "write_txt(text_dir / 'govjobs_node.txt', node)\n",
    "\n",
    "ltdate = dtxt(gj.index[-1])['mon1']\n",
    "pryrdate = dtxt(gj.index[-13])['mon1']\n",
    "\n",
    "ltval = gj.iloc[-1] / 1000 \n",
    "pryrval = gj.iloc[-13] / 1000 \n",
    "ltsh = data.iloc[-1]\n",
    "pryrsh = data.iloc[-13]\n",
    "\n",
    "diff = gj.iloc[-1] - gj.loc['2020-02-01']\n",
    "if diff > 950:\n",
    "    difftxt = f'gained {diff / 1000:.1f} million'\n",
    "elif diff > 0:\n",
    "    difftxt = f'gained {diff:.0f},000'\n",
    "elif diff < -950:\n",
    "    difftxt = f'lost {abs(diff) / 1000:.1f} million'\n",
    "else:\n",
    "    difftxt = f'lost {abs(diff):.0f},000'\n",
    "    \n",
    "text = (f'In {ltdate}, there were {ltval:.1f} million government jobs, '+\n",
    "        f'equivalent to {ltsh:.1f} for every 100 people in the age 16+ population '+\n",
    "        '(see {\\color{blue!50!cyan}\\\\textbf{---}}). The previous year, in '+\n",
    "        f'{pryrdate}, there were {pryrval:.1f} million government jobs, '+\n",
    "        f'equivalent to {pryrsh:.1f} percent of the age 16 or older population. '+\n",
    "        f'Since February 2020, the US has {difftxt} total government jobs. ')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
