{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T15:10:04.359318Z",
     "start_time": "2019-12-17T15:10:03.840433Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('../src')\n",
    "\n",
    "import requests\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openings, Quits, Hires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T15:10:16.073385Z",
     "start_time": "2019-12-17T15:10:14.452116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "series = {'JTS00000000JOL': 'Openings', \n",
    "          'JTS00000000HIL': 'Hires', \n",
    "          'JTS00000000QUL': 'Quits',\n",
    "          'JTS00000000TSL': 'Separations',\n",
    "          'LNS13000000': 'Unemp',\n",
    "          'JTS72000000QUR': 'AFS_QU',\n",
    "          'JTS00000000QUR': 'TOT_QU'}\n",
    "\n",
    "df = bls_api(series, (2000, 2019), bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-17T15:10:17.775902Z",
     "start_time": "2019-12-17T15:10:17.755608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In November 2019, there were 6.8 million total job openings and 5.8 million hires completed. In the same month there were 5.6 million total separations, of which 3.5 million were voluntary. In comparison, there are 5.8 million unemployed persons in November 2019. The ratio of job openings to unemployed persons was 1.2 in the latest month, compared to 0.8 in the same month three years prior.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels_srs = ['Openings', 'Hires', 'Quits', 'Separations', 'Unemp']\n",
    "rates_srs = ['AFS_QU', 'TOT_QU']\n",
    "\n",
    "levels_data = df[levels_srs].dropna() / 1000\n",
    "levels_data.to_csv(data_dir / 'jolts.csv', index_label='date')\n",
    "\n",
    "ltdata = levels_data.iloc[-1]\n",
    "\n",
    "ltdate = dtxt(ltdata.name)['mon1']\n",
    "ltopen = ltdata['Openings']\n",
    "lthire = ltdata['Hires']\n",
    "ltquit = ltdata['Quits']\n",
    "ltsep = ltdata['Separations']\n",
    "ltun = ltdata['Unemp']\n",
    "\n",
    "ratio = ltdata['Openings'] / ltdata['Unemp']\n",
    "ratio3 = levels_data['Openings'].iloc[-37] / levels_data['Unemp'].iloc[-37]\n",
    "\n",
    "text = (f'In {ltdate}, there were {ltopen:.1f} million total job openings '+\n",
    "        f'and {lthire:.1f} million hires completed. In the same month '+\n",
    "        f'there were {ltsep:.1f} million total separations, of '+\n",
    "        f'which {ltquit:.1f} million were voluntary. In comparison, '+\n",
    "        f'there are {ltun:.1f} million unemployed persons in {ltdate}. The ratio '+\n",
    "        f'of job openings to unemployed persons was {ratio:.1f} in the latest '+\n",
    "        f'month, compared to {ratio3:.1f} in the same month three years prior.')\n",
    "\n",
    "write_txt(text_dir / 'jolts2.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In November 2019, the total quits rate in all industries was 2.3 percent. The accommodations and food services quits rate was 4.6 percent; the series high for the industry group was 6.3 percent in January 2001.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates_data = df[rates_srs].dropna()\n",
    "\n",
    "rates_data.to_csv(data_dir / 'quits.csv', index_label='date')\n",
    "\n",
    "ltdata = rates_data.iloc[-1]\n",
    "\n",
    "afs_max = rates_data['AFS_QU'].max()\n",
    "afs_idxmax = dtxt(rates_data['AFS_QU'].idxmax())['mon1']\n",
    "\n",
    "text = (f'In {ltdate}, the total quits rate in all industries was {ltdata.TOT_QU} percent. '+\n",
    "        f'The accommodations and food services quits rate was {ltdata.AFS_QU} '+\n",
    "        f'percent; the series high for the industry group was {afs_max} percent in {afs_idxmax}.')\n",
    "\n",
    "write_txt(text_dir / 'quits_afs.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:28:50.975073Z",
     "start_time": "2019-11-01T00:28:50.930143Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A191RL']\n",
    "\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s).sort_index()\n",
    "\n",
    "df.loc['1989':].to_csv(data_dir / 'gdp.csv', index_label='date')\n",
    "\n",
    "date = dtxt(df.index[-1])['qtr1']\n",
    "\n",
    "txt = f'{date}: {df[\"A191RL\"].iloc[-1]}\\%'\n",
    "\n",
    "write_txt(data_dir / 'gdp.txt', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private fixed investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:28:54.915730Z",
     "start_time": "2019-11-01T00:28:54.841627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Private fixed investment contribution to growth\n",
    "s = ['A008RY', 'A011RY', 'A014RY']\n",
    "\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "\n",
    "df.loc['1989':].to_csv(data_dir / 'inv.csv', index_label='date')\n",
    "\n",
    "ldate = df.index[-1]\n",
    "datetext = dtxt(ldate)[\"qtr1\"]\n",
    "\n",
    "tot_contr = cont_subt(df.loc[ldate, ['A008RY', 'A011RY']].sum())\n",
    "\n",
    "bus_contr = cont_subt(df.loc[ldate, 'A008RY'], 'end')\n",
    "\n",
    "res_contr = cont_subt(df.loc[ldate, 'A011RY'], 'end')\n",
    "\n",
    "inv_contr = cont_subt(df.loc[ldate, 'A014RY'], 'end')\n",
    "\n",
    "text = (f'During the quarter, private fixed investment {tot_contr} real GDP growth. '+\n",
    "        f'Non-residential fixed investment {bus_contr}, while '+\n",
    "        f'residential fixed investment {res_contr}. The change in private '+\n",
    "        f'inventories {inv_contr}.')\n",
    "\n",
    "write_txt(text_dir / 'inv_text2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In levels and share of GDP\n",
    "s = ['A191RC', 'A007RC', 'A008RC', 'A011RC']\n",
    "\n",
    "df = nipa_df(retrieve_table('T10105')['Data'], s)\n",
    "\n",
    "ldate = df.index[-1]\n",
    "\n",
    "inv_tot = df.loc[ldate, 'A007RC'] / 1_000_000\n",
    "\n",
    "gdp_tot = df.loc[ldate, 'A191RC'] / 1_000_000\n",
    "\n",
    "res_tot = df.loc[ldate, 'A011RC'] / 1_000\n",
    "\n",
    "bus_tot = df.loc[ldate, 'A008RC'] / 1_000_000\n",
    "\n",
    "inv_sh = (inv_tot / gdp_tot) * 100\n",
    "\n",
    "res_sh = (res_tot / 1_000 / gdp_tot) * 100\n",
    "\n",
    "bus_sh = (bus_tot / gdp_tot) * 100\n",
    "\n",
    "text = (f'In {dtxt(ldate)[\"qtr2\"]}, private fixed investment, '+\n",
    "        f'which does not include inventory investment, totals \\${inv_tot:.1f} trillion, '+\n",
    "        f'equivalent to {inv_sh:.1f} percent of GDP. Non-residential (business) fixed '+\n",
    "        f'investment totals \\${bus_tot:.1f} trillion, or {bus_sh:.1f} percent of GDP, '+\n",
    "        f'while residential fixed investment totals \\${res_tot:.1f} billion ({res_sh:.1f} '+\n",
    "        'percent of GDP).')\n",
    "\n",
    "write_txt(text_dir / 'inv_text.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T02:34:45.331609Z",
     "start_time": "2019-11-05T02:34:45.242543Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nonpetroleum goods and services imports (see {\\\\color{green!60!teal!80!black}\\\\textbf{---}}) were equivalent to 13.2 percent of GDP in the fourth quarter of 2019, while exports of nonpetroleum goods and services (see {\\\\color{blue!90!cyan}\\\\textbf{---}}) were equivalent to 10.5 percent of GDP.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and Export share of GDP\n",
    "s = ['B020RC', 'B021RC', 'B648RC', 'LA000006']\n",
    "s2 = ['A191RC']\n",
    "df = nipa_df(retrieve_table('T40205')['Data'], s)\n",
    "df['A191RC'] = nipa_df(retrieve_table('T10105')['Data'], s2)\n",
    "df['EX'] = df['B020RC'] - df['LA000006']\n",
    "df['IM'] = df['B021RC'] - df['B648RC']\n",
    "data = df.div(df['A191RC'], axis=0) * 100\n",
    "data.loc['1989':].to_csv(data_dir / 'eximgdp.csv', index_label='date')\n",
    "\n",
    "date = f'{qtrs[data.index[-1].quarter]} quarter of {data.index[-1].year}'\n",
    "valex = data['EX'].iloc[-1]\n",
    "valim = data['IM'].iloc[-1]\n",
    "\n",
    "text = (f'Nonpetroleum goods and services imports (see {{\\color{{green!60!teal!80!black}}'+\n",
    "        f'\\\\textbf{{---}}}}) were equivalent to {valim:.1f} percent of GDP in the {date}, '+\n",
    "        f'while exports of nonpetroleum goods and services (see {{\\\\color{{blue!90!cyan}}'+\n",
    "        f'\\\\textbf{{---}}}}) were equivalent to {valex:.1f} percent of GDP.')\n",
    "\n",
    "write_txt(text_dir / 'exim.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T21:24:16.550047Z",
     "start_time": "2019-11-10T21:24:16.547056Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T10502'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goods Import Penetration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['A353RC']\n",
    "\n",
    "G = nipa_df(retrieve_table('T10205')['Data'], s).sort_index()\n",
    "\n",
    "s = ['A253RC', 'A255RC', 'B647RC', 'LA000004', 'A650RC', 'B651RC', 'A652RC', 'A653RC', 'B648RC']\n",
    "\n",
    "MX = nipa_df(retrieve_table('T40205')['Data'], s).sort_index()\n",
    "\n",
    "D = G['A353RC'] - MX['A253RC'] + MX['A255RC']\n",
    "result = (MX['A255RC'] / D)\n",
    "\n",
    "import_categories = ['B647RC', 'LA000004', 'A650RC', 'B651RC', \n",
    "                     'A652RC', 'A653RC', 'B648RC']\n",
    "Msh = MX[import_categories].div(MX['A255RC'], axis=0)\n",
    "\n",
    "Msh['Consumer'] = Msh['B647RC'] + Msh['A652RC'] + Msh['B651RC']\n",
    "Msh['Capital'] = Msh['LA000004'] - Msh['B648RC'] + Msh['A650RC'] + Msh['A653RC']\n",
    "\n",
    "\n",
    "final = Msh[['Consumer', 'Capital', 'B648RC']].multiply(result, axis=0) * 100\n",
    "\n",
    "final.loc['1989':].to_csv(data_dir / 'goodsimpsh.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch11 = (final.loc['2011-01-01'] - final.iloc[0])\n",
    "\n",
    "chlt = (final.iloc[-1] - final.loc['2011-01-01'])\n",
    "\n",
    "chtxt = {}\n",
    "for i, v in chlt.items():\n",
    "    if v >= 0.1:\n",
    "        chtxt[i] = f'increased by the equivalent of {v:.1f} percent'\n",
    "    elif v <= -0.1:\n",
    "        chtxt[i] = f'decreased by the equivalent of {abs(v):.1f} percent'\n",
    "    else:\n",
    "        chtxt[i] = 'was virtually unchanged'\n",
    "        \n",
    "text = (f'From 1989 to 2011, imports of consumer goods increased by the equivalent of {ch11[\"Consumer\"]:.1f} '+\n",
    " 'percent of domestic consumption of goods (see\\cbox{cyan!40!white}); petroleum and products imports '+\n",
    " f'increased by the equilavent of {ch11[\"B648RC\"]:.1f} percent (see\\cbox{{purple}}); '+\n",
    " 'and all other goods, primarily capital good, industrial supplies, and materials, increased by the equivalent '+\n",
    " f'of {ch11[\"Capital\"]:.1f} percent (see\\cbox{{blue!50!cyan}}). Since 2011, imports of '+\n",
    " f'consumer goods {chtxt[\"Consumer\"]} of domestic goods demand; '+\n",
    " f'imports of petroleum and products {chtxt[\"B648RC\"]}; and other '+\n",
    " f'imports {chtxt[\"Capital\"]}.')\n",
    "\n",
    "write_txt(text_dir / 'goodsimpsh.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA - Financial Account Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bea_api_ita(ind_list, bea_key):\n",
    "    ''' Return tables in table list for years in range'''\n",
    "    import requests\n",
    "    from datetime import datetime\n",
    "\n",
    "    years = ','.join(map(str, range(1989, 2020)))\n",
    "\n",
    "    api_results = []\n",
    "\n",
    "    for ind in ind_list:\n",
    "        url = f'https://www.bea.gov/api/data/?&UserID={bea_key}'\\\n",
    "              f'&method=GetData&datasetname=ITA&Indicator={ind}'\\\n",
    "              f'&Frequency=QSA&Year={years}&ResultFormat=json'\n",
    "\n",
    "        r = requests.get(url)\n",
    "\n",
    "        api_results.append((ind, r.text))\n",
    "\n",
    "    return api_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_list = ['FinAssetsExclFinDeriv', 'FinLiabsExclFinDeriv', 'FinDeriv', 'StatDisc']\n",
    "\n",
    "api_results = bea_api_ita(ind_list, bea_key)\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "results = pd.DataFrame({name: {i['TimePeriod']: i['DataValue'] \n",
    "                               for i in json.loads(series)['BEAAPI']['Results']['Data']} \n",
    "                        for name, series in api_results})\n",
    "results.index = pd.to_datetime(results.index)\n",
    "results = results.replace(r'^\\s*$', np.nan, regex=True).astype('float').rolling(4).sum()\n",
    "results['FAB'] = results['FinLiabsExclFinDeriv'] - results['FinAssetsExclFinDeriv']\n",
    "results['TOT'] = results[['FAB', 'StatDisc', 'FinDeriv']].sum(axis=1)\n",
    "final = (results.divide(gdp, axis=0).dropna(how='all') * 100).fillna(0)\n",
    "final[['FAB', 'StatDisc', 'FinDeriv', 'TOT']].to_csv(data_dir / 'fab.csv', index_label='date')\n",
    "\n",
    "s = final.iloc[-1]\n",
    "liab = s.FinLiabsExclFinDeriv\n",
    "assets = s.FinAssetsExclFinDeriv\n",
    "\n",
    "ldate = dtxt(final.index[-1])['qtr1']\n",
    "\n",
    "text = (f'Over the year ending {ldate}, net domestic acquisitions of foreign assets were '+\n",
    "        f'equivalent to {assets:.1f} percent of GDP, while net domestic incurrence of foreign '+\n",
    "        f'liabilities total {liab:.1f} percent of GDP. Domestic net borrowing totals '+\n",
    "        f'{s.TOT:.1f} percent of GDP.')\n",
    "\n",
    "write_txt(text_dir / 'fab.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:28:58.326392Z",
     "start_time": "2019-11-01T00:28:58.236434Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['DPCERY', 'A006RY', 'A822RY', 'A019RY']\n",
    "\n",
    "(nipa_df(retrieve_table('T10502')['Data'], s).loc['1989':]\n",
    " .to_csv(data_dir / 'comp.csv', index_label='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:00.544648Z",
     "start_time": "2019-11-01T00:29:00.502083Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A939RC', 'A939RX']\n",
    "\n",
    "df = nipa_df(retrieve_table('T70100')['Data'], s)\n",
    "df['value'] = (df['A939RX'] / df['A939RX'].iloc[-1])  * df['A939RC'].iloc[-1]\n",
    "df[['value']].loc['1989':].to_csv(data_dir / 'gdppc.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:01.781494Z",
     "start_time": "2019-11-01T00:29:01.616041Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A261RX', 'W256RX']\n",
    "rgdi = nipa_df(retrieve_table('T11706')['Data'], s).dropna()\n",
    "\n",
    "s = ['A261RC', 'A4002C', 'W056RC', 'A107RC', 'W271RC', 'A262RC']\n",
    "df = nipa_df(retrieve_table('T11000')['Data'], s).dropna()\n",
    "\n",
    "# Calculate indirect taxes net of transfers\n",
    "df['indirect'] = df['W056RC'] - df['A107RC']\n",
    "df = df.drop(['A107RC', 'W056RC'], axis=1)\n",
    "\n",
    "# Calculate GDI deflator from real GDI series\n",
    "deflator = rgdi['A261RX'] / df['A261RC']\n",
    "deflator = deflator / deflator.iloc[-1]\n",
    "df = df.multiply(deflator, axis=0)\n",
    "\n",
    "# Calculate contributions to growth\n",
    "dft = df.diff()\n",
    "dft = dft.div(dft['A261RC'], axis=0)\n",
    "contr = dft.multiply((((df['A261RC'].pct_change() + 1) ** 4) - 1) * 100, axis=0)\n",
    "contr.loc['1989':].to_csv(data_dir / 'gdi.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:04.471023Z",
     "start_time": "2019-11-01T00:29:04.378802Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['DGDSRY', 'DHCERY', 'DHUTRY', 'A011RY']\n",
    "\n",
    "(nipa_df(retrieve_table('T10502')['Data'], s)\n",
    " .assign(OTHSER = lambda x: x['DHCERY'] - x['DHUTRY'],\n",
    "         HOUSING = lambda x: x['A011RY'] + x['DHUTRY'])\n",
    " .drop('DHCERY', axis=1).loc['1989':]\n",
    " .to_csv(data_dir / 'pce.csv', index_label='date', float_format='%g'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade Contribution to GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:05.737386Z",
     "start_time": "2019-11-01T00:29:05.632016Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A019RY', 'A253RY', 'A646RY', 'A255RY', 'A656RY']\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "df.loc['1989':].to_csv(data_dir / 'nx.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:06.359811Z",
     "start_time": "2019-11-01T00:29:06.354778Z"
    }
   },
   "outputs": [],
   "source": [
    "sl = [('A253RY', 'main'), ('A646RY', 'end'), \n",
    "      ('A255RY', 'main'), ('A656RY', 'end')]\n",
    "\n",
    "d = {}\n",
    "\n",
    "for s, style in sl:\n",
    "    # Latest total value\n",
    "    value = df[s].iloc[-1]\n",
    "    d[s] = cont_subt(value, style=style)\n",
    "\n",
    "# Text for household expenditure section\n",
    "q = {1: 'first', 2: 'second', 3: 'third', 4: 'fourth'}\n",
    "    \n",
    "ldate = dtxt(df.index[-1])['qtr2']\n",
    "\n",
    "\n",
    "text = (f\"Goods exports {d['A253RY']} GDP growth in {ldate} while \"+\n",
    "        f\"services exports {d['A646RY']}. Good imports {d['A255RY']} \"+\n",
    "        f\"GDP growth and services imports {d['A656RY']}.\")\n",
    "\n",
    "write_txt(text_dir / 'trade.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:09.448258Z",
     "start_time": "2019-11-01T00:29:09.373163Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['Y001RY', 'A009RY', 'Y033RY']\n",
    "\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "df.loc['1989':].to_csv(data_dir / 'businv.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durable goods new orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:50:04.198769Z",
     "start_time": "2019-10-31T23:50:03.401830Z"
    }
   },
   "outputs": [],
   "source": [
    "# New orders for capital goods excluding defense or aircraft\n",
    "key = census_key\n",
    "base = 'https://api.census.gov/data/timeseries/eits/advm3'\n",
    "param = 'cell_value,time_slot_id'\n",
    "t = '&time=from+1992'\n",
    "cat = '&category_code=NXA'\n",
    "dtc = '&data_type_code=NO'\n",
    "oth = '&for=us&seasonally_adj=yes'\n",
    "\n",
    "url = f'{base}?get={param}&key={key}{cat}{dtc}{t}{oth}'\n",
    "\n",
    "r = requests.get(url).json()\n",
    "\n",
    "df = pd.DataFrame({'date': [pd.to_datetime(i[4]) for i in r[1:]], \n",
    "                   'value': [float(i[0]) for i in r[1:]]}).sort_values('date')\n",
    "\n",
    "df = df.set_index('date')\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])\n",
    "\n",
    "result = ((df['value'].resample('QS').sum() * 4  / gdp['A191RC']).dropna() * 100).iloc[1:]\n",
    "(result.rename('value').loc['1989':].to_csv(data_dir / 'dgno.csv', index_label='date', header=True))\n",
    "\n",
    "ldate = dtxt(df.index[-1])['mon1']\n",
    "date_latest = dtxt(df.index[-1])['datetime']\n",
    "month_short = df.index[-1].strftime('%b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_yr_ch = (df.pct_change(12) * 100).dropna()['value'].iloc[-1]\n",
    "\n",
    "if one_yr_ch >= 0.1:\n",
    "    val = f'increased by {one_yr_ch:.1f} percent'\n",
    "elif one_yr_ch <= -0.1:\n",
    "    val = f'decreased by {abs(one_yr_ch):.1f} percent'\n",
    "else:\n",
    "    val = 'were virtually unchanged'\n",
    "\n",
    "text = ('New orders for manufactured core capital goods excluding aircraft '+\n",
    "        f'totalled \\${df.iloc[-1][0] / 1000:,.0f} billion in {ldate}, '+\n",
    "        f'equivalent to {result.iloc[-1]:.1f} percent of GDP. New orders '+\n",
    "        f'{val} over the past year.')\n",
    "\n",
    "write_txt(text_dir / 'dgno.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New orders for manufactured core capital goods excluding aircraft totalled \\\\$69 billion in December 2019, equivalent to 3.8 percent of GDP. New orders increased by 1.0 percent over the past year.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('xtick={{1992-01-01}, {1995-01-01}, {2000-01-01}, {2005-01-01}, '+\n",
    "f'{{2010-01-01}}, {{2015-01-01}}, {{{date_latest}}}}}, '+\n",
    "f'xticklabels={{`92, `95, `00, `05, `10, `15, {month_short}}}, ')\n",
    "\n",
    "text_full = ('\\\\begin{tikzpicture}'+\n",
    "'\\\\begin{axis}[\\\\bbar{y}{0}, \\dateaxisticks ytick={4, 6, 8}, width=7.0cm, height=5.0cm,'+\n",
    "'ymin=2.9, '+\n",
    "text + \n",
    "'minor xtick={}]'+\n",
    "'\\\\rbars'+\n",
    "'\\\\thickline{purple!50!violet}{date}{value}{data/dgno.csv}'+\n",
    "'\\end{axis}'+\n",
    "'\\end{tikzpicture}')\n",
    "\n",
    "write_txt(text_dir / 'dgno.tex', text_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retail sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New orders for capital goods excluding defense or aircraft\n",
    "key = census_key\n",
    "base = 'https://api.census.gov/data/timeseries/eits/marts/'\n",
    "param = 'cell_value,time_slot_id,category_code'\n",
    "t = '&time=from+1992'\n",
    "dtc = '&data_type_code=SM'\n",
    "oth = '&for=us&seasonally_adj=yes'\n",
    "\n",
    "url = f'{base}?get={param}&key={key}{dtc}{t}{oth}'\n",
    "\n",
    "r = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the \\\\href{https://www.census.gov/retail/index.html}{Census Bureau}, retail and food service sales totalled \\\\$529.6 billion in December 2019, equivalent to roughly 29.2 percent of GDP on an annualized basis. Over the past year, retail and food service sales increased by 5.8 percent, without adjusting for prices. Nonstore sales, which include online retailers, have increased by 19.2 percent over the same period, and total \\\\$66.8 billion, or roughly 3.7 percent of GDP. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for series in ['44000', '44X72', '44W72', '454']:\n",
    "    df[series] = pd.Series(\n",
    "        {pd.to_datetime(i[4]): \n",
    "         float(i[0]) for i in r[1:] if i[2] == series}\n",
    "    ).sort_index()\n",
    "    \n",
    "data = (df.pct_change(12) * 100).dropna()\n",
    "data['NS_3M'] = data['454'].rolling(3).mean()\n",
    "\n",
    "s = ['A191RC']\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], s)\n",
    "\n",
    "data.to_csv(data_dir / 'marts.csv', index_label='date', float_format='%g')\n",
    "\n",
    "totval = df['44X72'].iloc[-1]\n",
    "shgdp = (totval * 12 / gdp.iloc[-1] * 100)[-1]\n",
    "totgr = data['44X72'].iloc[-1]\n",
    "datelt = df.index[-1].strftime('%B %Y')\n",
    "if totgr > 0.1:\n",
    "    grtxt = f'increased by {totgr:.1f} percent'\n",
    "elif totgr < 0.1:\n",
    "    grtxt = f'decreased by {abs(totgr):.1f} percent'\n",
    "else:\n",
    "    grtxt = 'was virtually unchanged'\n",
    "    \n",
    "totval2 = df['454'].iloc[-1]\n",
    "shgdp2 = (totval2 * 12 / gdp.iloc[-1] * 100)[-1]\n",
    "totgr2 = data['454'].iloc[-1]\n",
    "if totgr2 > 0.1:\n",
    "    grtxt2 = f'increased by {totgr2:.1f} percent'\n",
    "elif totgr2 < 0.1:\n",
    "    grtxt2 = f'decreased by {abs(totgr2):.1f} percent'\n",
    "else:\n",
    "    grtxt2 = 'was virtually unchanged'\n",
    "    \n",
    "text = ('According to the \\href{https://www.census.gov/retail/index.html}{Census Bureau}, '+\n",
    "        'retail and food service '+\n",
    "        f'sales totalled \\${totval/1000:,.1f} billion in {datelt}, equivalent '+\n",
    "        f'to roughly {shgdp:.1f} percent of GDP on an annualized basis. '+\n",
    "        'Over the past year, retail and '+\n",
    "        f'food service sales {grtxt}, without adjusting for prices. Nonstore '+\n",
    "        f'sales, which include online retailers, have {grtxt2} over the same period, and '\n",
    "        f'total \\${totval2/1000:,.1f} billion, or roughly {shgdp2:.1f} percent of GDP. ')\n",
    "\n",
    "write_txt(text_dir / 'marts.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retail Sales by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = census_key\n",
    "base = 'https://api.census.gov/data/timeseries/eits/marts/'\n",
    "param = 'cell_value,time_slot_id,category_code'\n",
    "t = '&time=from+1992'\n",
    "dtc = '&data_type_code=SM'\n",
    "oth = '&for=us&seasonally_adj=no'\n",
    "\n",
    "url = f'{base}?get={param}&key={key}{dtc}{t}{oth}'\n",
    "\n",
    "r = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict = {'441': 'Motor Vehicles \\& Parts', '442': 'Furniture \\& Home Furnishings', \n",
    "               '443': 'Electronics \\& Appliance', '444': 'Building \\& Garden Equipment', \n",
    "               '445': 'Food \\& Beverage Stores', '446': 'Health \\& Personal Care', \n",
    "               '447': 'Gasoline Stations', '448': 'Clothing and Accessories', \n",
    "               '451': 'Sports/Hobby/Music/Books', '452': 'General Merchandise', \n",
    "               '454': 'Nonstore', '722': 'Food Service \\& Drinking Places'}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for series in series_dict.keys():\n",
    "    df[series] = pd.Series(\n",
    "        {pd.to_datetime(i[4]): \n",
    "         float(i[0]) for i in r[1:] if i[2] == series}\n",
    "    ).sort_index()\n",
    "    \n",
    "dpi = nipa_df(retrieve_table('T20100')['Data'], ['A067RC'])['A067RC']\n",
    "data = df.resample('QS').sum().rolling(4).sum().dropna().divide(dpi, axis=0).dropna() * 100\n",
    "results = pd.concat([data.loc['2015-01-01'], data.loc['2019-10-01']], axis=1).sort_values('2019-10-01', ascending=False)\n",
    "results.index = results.index.map(series_dict)\n",
    "results.round(2).to_csv(data_dir / 'rs_comp.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residential construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New orders for capital goods excluding defense or aircraft\n",
    "key = census_key\n",
    "base = 'https://api.census.gov/data/timeseries/eits/resconst/'\n",
    "param = 'cell_value,time_slot_id,category_code'\n",
    "t = '&time=from+1989'\n",
    "dtc = '&data_type_code=TOTAL'\n",
    "oth = '&for=us&seasonally_adj=yes'\n",
    "\n",
    "url = f'{base}?get={param}&key={key}{dtc}{t}{oth}'\n",
    "\n",
    "r = requests.get(url).json()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for series in ['APERMITS', 'ASTARTS']:\n",
    "    df[series] = pd.Series(\n",
    "        {pd.to_datetime(i[4]): \n",
    "         float(i[0]) for i in r[1:] if i[2] == series}\n",
    "    ).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / 'permits.csv', index_label='date')\n",
    "\n",
    "s = series_info(df['APERMITS'])\n",
    "s['val_5yr_ago'] = df['APERMITS'].iloc[-61]\n",
    "\n",
    "if s['days_since_match'] > 100:\n",
    "    hlt = f\", {s['last_matched']}\"\n",
    "else:\n",
    "    hlt = ''\n",
    "    \n",
    "month = s['date_latest'].strftime('%B')\n",
    "\n",
    "d = {}\n",
    "for i in ['val_prev', 'val_year_ago', 'val_5yr_ago']:\n",
    "    mo_ch = s[\"val_latest\"] - s[i]\n",
    "    mo_pch = (s[\"val_latest\"] / s[i] - 1) * 100\n",
    "    if mo_ch >= 0.1:\n",
    "        txt = f'increased by {abs(mo_ch)*1000:,.0f} ({mo_pch:.1f} percent)'\n",
    "    elif mo_ch <= -0.1:\n",
    "        txt = f'decreased by {abs(mo_ch)*1000:,.0f} ({mo_pch:.1f} percent'\n",
    "    else:\n",
    "        txt = 'was virtually unchanged'\n",
    "        \n",
    "    d[i] = txt\n",
    "    \n",
    "text = (f'In {s[\"date_latest_ft\"]}, {s[\"val_latest\"]*1000:,.0f} new '+\n",
    "        f'residential building permits were issued{hlt}. '+\n",
    "        f'Permits issued {d[\"val_prev\"]} over the previous month, '+\n",
    "        f'{d[\"val_year_ago\"]} over last {month}, and '+\n",
    "        f'{d[\"val_5yr_ago\"]} total over the past five years.')\n",
    "\n",
    "write_txt(text_dir / 'permits.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In December 2019, 1,420,000 new residential building permits were issued. Permits issued decreased by 54,000 (-3.7 percent over the previous month, increased by 81,000 (6.0 percent) over last December, and increased by 346,000 (32.2 percent) total over the past five years.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government spending and investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:16.184663Z",
     "start_time": "2019-11-01T00:29:16.181990Z"
    }
   },
   "outputs": [],
   "source": [
    "n = {'A822RY': 'Total',\n",
    "     'A823RY': '\\hspace{1mm}Federal total',\n",
    "     'A824RY': '\\hspace{1mm}\\cbox{blue!60!black}National defense',\n",
    "     'A997RY': '\\hspace{7mm}Consumption expenditures',\n",
    "     'A788RY': '\\hspace{7mm}Gross investment',\n",
    "     'A825RY': '\\hspace{1mm}\\cbox{green!85!black}Nondefense',\n",
    "     'A542RY': '\\hspace{7mm}Consumption expenditures',\n",
    "     'A798RY': '\\hspace{7mm}Gross investment',\n",
    "     'A829RY': '\\hspace{-2mm}\\cbox{purple!70!magenta}State \\& local',\n",
    "     'A991RY': '\\hspace{5mm}Consumption expenditures',\n",
    "     'A799RY': '\\hspace{5mm}Gross investment'}\n",
    "\n",
    "s = n.keys()\n",
    "\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "df.loc['1989':].to_csv(data_dir / 'gov.csv', index_label='date')\n",
    "\n",
    "d = series_info(df['A822RY'])\n",
    "\n",
    "if d['val_latest'] > 0:\n",
    "    text1 = f'contributed {d[\"val_latest\"]} percentage points to' \n",
    "elif d['val_latest'] < 0:\n",
    "    text1 = f'subtracted {abs(d[\"val_latest\"])} percentage points to'\n",
    "else:\n",
    "    text1 = 'did not contribute to'\n",
    "    \n",
    "d2 = {}\n",
    "for i in ['A824RY', 'A825RY', 'A829RY']:\n",
    "    if df[i].iloc[-1] > 0:\n",
    "        ctxt = f'contributed {df[i].iloc[-1]:.2f} percentage points'\n",
    "    elif df[i].iloc[-1] < 0:\n",
    "        ctxt = f'subtracted {abs(df[i].iloc[-1]):.2f} percentage points'\n",
    "    else:\n",
    "        ctxt = 'did not contribute '\n",
    "    d2[i] = ctxt\n",
    "    \n",
    "text = 'Government consumption expeditures and gross investment, which provide services and infrastructure, '\n",
    "\n",
    "gov = (f'{text}{text1} real GDP growth in {d[\"date_latest_ft\"]}, compared to an '+\n",
    "       f'average contribution of {d[\"one_year_mean\"]:.2f} percentage points over '+\n",
    "       f'the past year and an average of {d[\"mean\"]:.2f} percentage points since 1989. '+\n",
    "       f'In {d[\"date_latest_ft\"]}, federal defense (see\\cbox{{blue!60!black}}) {d2[\"A824RY\"]}, '+\n",
    "       f'federal nondefense (see\\cbox{{green!85!black}}) {d2[\"A825RY\"]}, and state and '+\n",
    "       f'local government (see\\cbox{{purple!70!magenta}}) {d2[\"A829RY\"]}.')\n",
    "\n",
    "write_txt(text_dir / 'gov.txt', gov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df[n.keys()]\n",
    "\n",
    "data = result.iloc[-5:].iloc[::-1].T\n",
    "\n",
    "cols = [f' {q.year} Q{q.quarter}' \n",
    "        if i == 0 else f'`{str(q.year)[2:]} Q{q.quarter}'\n",
    "        for i, q in enumerate(data.columns)]\n",
    "\n",
    "data.columns = cols\n",
    "data['3-year'] = result.rolling(13).mean().iloc[-1].round(2)\n",
    "data['10-year'] = result.rolling(41).mean().iloc[-1].round(2)\n",
    "data['30-year'] = result.rolling(121).mean().iloc[-1].round(2)\n",
    "data.index = data.index.map(n)\n",
    "data = data.applymap('{:.2f}'.format)\n",
    "data.to_csv(data_dir / 'gov.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:18:43.344214Z",
     "start_time": "2019-11-01T00:18:43.326706Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government receipts and expenditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:29.092805Z",
     "start_time": "2019-11-01T00:29:29.017408Z"
    }
   },
   "outputs": [],
   "source": [
    "# State and local government\n",
    "s = ['W024RC', 'W023RC']\n",
    "\n",
    "df = nipa_df(retrieve_table('T30300')['Data'], s)\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "df['GDP'] = gdp\n",
    "\n",
    "(df.div(df['GDP'], axis=0) * 100).loc['1989':].to_csv(data_dir / 'slggdp.csv', index_label='date', float_format='%g')\n",
    "df = df.dropna() / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldate = dtxt(df.index[-1])['qtr1']\n",
    "gdp = df.GDP.iloc[-1]\n",
    "gdp3y = df.GDP.iloc[-13]\n",
    "gdpgr = ((gdp / gdp3y) - 1) * 100\n",
    "exp = df.W024RC.iloc[-1]\n",
    "exp3y = df.W024RC.iloc[-13]\n",
    "expsh = exp / gdp * 100\n",
    "exp3ysh = exp3y / gdp3y * 100\n",
    "expgr = ((exp / exp3y) - 1) * 100\n",
    "rec = df.W023RC.iloc[-1]\n",
    "rec3y = df.W023RC.iloc[-13]\n",
    "recsh = rec / gdp * 100\n",
    "rec3ysh = rec3y / gdp3y * 100\n",
    "recgr = ((rec / rec3y) - 1) * 100\n",
    "diff = rec - exp\n",
    "diffsh = diff / gdp * 100\n",
    "diff3y = rec3y - exp3y\n",
    "diffgr = ((diff / diff3y) - 1) * 100\n",
    "if diff < 0:\n",
    "    txt = 'deficit'\n",
    "else:\n",
    "    txt = 'surplus'\n",
    "\n",
    "recshch = recsh - rec3ysh\n",
    "rectxt = f'{[\"increased\" if recshch >= 0 else \"decreased\"][0]} by a total of {abs(recshch):.2f} percentage points'\n",
    "\n",
    "expshch = expsh - exp3ysh\n",
    "exptxt = f'{[\"increased\" if expshch >= 0 else \"decreased\"][0]} by a total of {abs(expshch):.2f} percentage points'\n",
    "\n",
    "diffch = recshch - expshch\n",
    "\n",
    "difftxt = [f'shrink by {diffch:.2f} percent of GDP' if diffch >= 0.1 \n",
    "             else f'widen by {abs(diffch):.2f} percent of GDP' if diffch <= -0.1 \n",
    "             else 'be unchanged'][0]\n",
    "\n",
    "\n",
    "text = (f'Consolidated state and local government expenditures total \\${exp:.1f} trillion, '+\n",
    "        f'or {expsh:.1f} percent of GDP, in {ldate}, and receipts total '+\n",
    "        f'\\${rec:.1f} trillion, equivalent to {recsh:.1f} percent of GDP. The combined state'+\n",
    "        f' and local government {txt} was '+\n",
    "        f'\\${abs(diff) * 1000:.0f} billion or {abs(diffsh):.2f} percent of GDP. '+\n",
    "        f'Over the past three years, the expenditures to GDP ratio {exptxt} at the '+\n",
    "        f'consolidated state and local level, and the ratio of '+\n",
    "        f'receipts to GDP has {rectxt}, causing the {txt} to {difftxt}.')\n",
    "\n",
    "write_txt(text_dir / 'govexprec1.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:31.169034Z",
     "start_time": "2019-11-01T00:29:31.092413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Federal government\n",
    "s = ['W005RC', 'W013RC']\n",
    "\n",
    "df = nipa_df(retrieve_table('T30200')['Data'], s)\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "df['GDP'] = gdp\n",
    "\n",
    "(df.div(df['GDP'], axis=0) * 100).to_csv(data_dir / 'fedgdp.csv', index_label='date', float_format='%g')\n",
    "df = df / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldate = dtxt(df.index[-1])['qtr1']\n",
    "gdp = df.GDP.iloc[-1]\n",
    "gdp3y = df.GDP.iloc[-13]\n",
    "gdpgr = ((gdp / gdp3y) - 1) * 100\n",
    "exp = df.W013RC.iloc[-1]\n",
    "exp3y = df.W013RC.iloc[-13]\n",
    "expsh = exp / gdp * 100\n",
    "exp3ysh = exp3y / gdp3y * 100\n",
    "expgr = ((exp / exp3y) - 1) * 100\n",
    "rec = df.W005RC.iloc[-1]\n",
    "rec3y = df.W005RC.iloc[-13]\n",
    "recsh = rec / gdp * 100\n",
    "rec3ysh = rec3y / gdp3y * 100\n",
    "recgr = ((rec / rec3y) - 1) * 100\n",
    "diff = rec - exp\n",
    "diffsh = diff / gdp * 100\n",
    "diff3y = rec3y - exp3y\n",
    "diffgr = ((diff / diff3y) - 1) * 100\n",
    "if diff < 0:\n",
    "    txt = 'deficit'\n",
    "else:\n",
    "    txt = 'surplus'\n",
    "\n",
    "recshch = recsh - rec3ysh\n",
    "rectxt = f'{[\"increased\" if recshch >= 0 else \"decreased\"][0]} by a total of {abs(recshch):.1f} percentage points'\n",
    "\n",
    "expshch = expsh - exp3ysh\n",
    "exptxt = f'{[\"increased\" if expshch >= 0 else \"decreased\"][0]} by a total of {abs(expshch):.1f} percentage points'\n",
    "\n",
    "diffch = recshch - expshch\n",
    "\n",
    "difftxt = [f'shrink by {diffch:.1f} percent of GDP' if diffch >= 0.1 \n",
    "             else f'widen by {abs(diffch):.1f} percent of GDP' if diffch <= -0.1 \n",
    "             else 'be unchanged'][0]\n",
    "\n",
    "text = (f'In {ldate}, federal government expenditures total \\${exp:.1f} trillion, '+\n",
    "        f'equivalent to {expsh:.1f} percent of GDP, and receipts total '+\n",
    "        f'\\${rec:.1f} trillion, or {recsh:.1f} percent of GDP. The federal {txt} was therefore '+\n",
    "        f'\\${abs(diff):.1f} trillion or {abs(diffsh):.1f} percent of GDP. '+\n",
    "        f'Over the past three years, the ratio of expenditures to GDP {exptxt}, and the ratio of '+\n",
    "        f'receipts to GDP has {rectxt}, causing the {txt} to {difftxt}.')\n",
    "\n",
    "write_txt(text_dir / 'govexprec2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Debt by Holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T20:42:58.449627Z",
     "start_time": "2019-12-15T20:42:54.735870Z"
    }
   },
   "outputs": [],
   "source": [
    "series = ['FDHBATN', 'GFDEBTN', 'FDHBFRBN', 'FDHBPIN', 'FDHBFIN']\n",
    "start = '1988-01-01'\n",
    "ftype = '&file_type=json'\n",
    "base = 'https://api.stlouisfed.org/fred/series/observations?'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for srs in series:\n",
    "    param = f'series_id={srs}&observation_start={start}&api_key={fred_key}'\n",
    "   \n",
    "\n",
    "    url = f'{base}{param}{ftype}'\n",
    "    r = requests.get(url).json()['observations']\n",
    "    data = pd.Series({i['date']: (float(i['value']) / 1000.0) if srs in series[:2] else float(i['value']) for i in r})\n",
    "    \n",
    "    df[srs] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T20:42:59.662879Z",
     "start_time": "2019-12-15T20:42:59.612612Z"
    }
   },
   "outputs": [],
   "source": [
    "df['PD'] = df['FDHBPIN'] - df['FDHBFIN']\n",
    "df['IG'] = df['GFDEBTN'] - (df['FDHBFRBN'] + df['FDHBPIN'])\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "data = df.div(gdp / 1000.0, axis=0).dropna()\n",
    "\n",
    "(data[['PD', 'FDHBFIN', 'FDHBFRBN', 'IG']] * 100).to_csv(data_dir / 'pubdebt.csv', index_label='date')\n",
    "\n",
    "ld = pd.to_datetime(df.index[-1])\n",
    "ldate = dtxt(ld)['qtr2']\n",
    "\n",
    "sh = df.div(df['GFDEBTN'], axis=0).iloc[-1] * 100\n",
    "lv = df.iloc[-1] / 1000\n",
    "dl = data.iloc[-1] * 100\n",
    "\n",
    "text = (f'In {ldate}, total public debt was \\${lv.GFDEBTN:.1f} trllion, '+\n",
    "        f'equivalent to {dl.GFDEBTN:.1f} percent of GDP. Of this, \\${lv.PD:.1f} '+\n",
    "        f'trillion, or {sh.PD:.1f} percent of the total, is held by '+\n",
    "        'private domestic investors (see\\cbox{green!60!black}). An additional '+\n",
    "        f'\\${lv.FDHBFIN:.1f} trillion, or {sh.FDHBFIN:.1f} percent '+\n",
    "        'of the total, is held by foreign investors (see\\cbox{orange!70!white}). '+\n",
    "        'The remainder is held by the Federal Reserve (see\\cbox{blue}) '+\n",
    "        'and various government agencies and trusts (see\\cbox{cyan!50!white}), '+\n",
    "        'such as the Social Security Trust Fund. ')\n",
    "\n",
    "write_txt(text_dir / 'pubdebt.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aggregate real personal income increased at an annualized rate of 1.64 percent in 2019 Q4. Labor income contributed 1.62 percentage points to overall growth, capital income subtracted 0.10 percentage points, and welfare income contributed 0.11 percentage points. '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ['DPCERG']\n",
    "\n",
    "d = nipa_df(retrieve_table('T20304')['Data'], s)['DPCERG']\n",
    "deflator = d.iloc[-1] / d\n",
    "\n",
    "s = ['A065RC', 'A033RC', 'A041RC', 'A048RC', 'W210RC', 'A577RC', 'A061RC']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "      .assign(CAPITAL = lambda x: x['A041RC'] + x['A048RC'] + x['W210RC'],\n",
    "              TRANSFER = lambda x: x['A577RC'] - x['A061RC'])\n",
    "      .drop(['A061RC', 'A041RC', 'A048RC', 'W210RC', 'A577RC'], axis=1)\n",
    "      .multiply(deflator, axis=0))\n",
    "growth_contrib(df, 'A065RC').loc['1989':].to_csv(data_dir / 'pi.csv', index_label='date')\n",
    "\n",
    "\n",
    "data = growth_contrib(df, 'A065RC').rename({'A065RC': 'TOTAL', 'A033RC': 'LABOR'}, axis=1)\n",
    "\n",
    "val3y = data.rolling(12).mean().iloc[-1]\n",
    "\n",
    "ltdate = dtxt(data.index[-1])['qtr1']\n",
    "\n",
    "\n",
    "d = {}\n",
    "\n",
    "for i in data.keys():\n",
    "    val = data[i].iloc[-1]\n",
    "    if val >= 0.1:\n",
    "        d[i] = f'contributed {val:.2f} percentage points to'\n",
    "    elif val <= 0.1:\n",
    "        d[i] = f'subtracted {abs(val):.2f} percentage points from'\n",
    "    else:\n",
    "        d[i] = 'did not contribute significantly to'\n",
    "        \n",
    "d['TOTAL'] = (d['TOTAL']\n",
    "              .replace('contributed', 'increased at an annualized rate of')\n",
    "              .replace('subtracted', 'decreased at an annualized rate of')\n",
    "              .replace('percentage points', 'percent')\n",
    "              .replace(' to', '').replace(' from', ''))\n",
    "\n",
    "for i in ['TRANSFER', 'CAPITAL']:\n",
    "    d[i] = d[i].replace(' to', '').replace(' from', '')\n",
    "    \n",
    "    \n",
    "d2 = {}\n",
    "\n",
    "for i in data.keys():\n",
    "    val = val3y[i]\n",
    "    if val >= 0.1:\n",
    "        d2[i] = f'contributed an average of {val:.2f} percentage points'\n",
    "    elif val <= 0.1:\n",
    "        d2[i] = f'subtracted an average of {abs(val):.2f} percentage points'\n",
    "    else:\n",
    "        d2[i] = 'did not contribute significantly, on average'\n",
    "        \n",
    "text = (f'Aggregate real personal income {d[\"TOTAL\"]} in {ltdate}. '+\n",
    "        f'Labor income {d[\"LABOR\"]} overall growth, '+\n",
    "        f'capital income {d[\"CAPITAL\"]}, and welfare income {d[\"TRANSFER\"]}. ')\n",
    "\n",
    "write_txt(text_dir / 'pi.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Spending Growth Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:36:01.148553Z",
     "start_time": "2019-11-03T17:36:01.014154Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['B230RC']\n",
    "\n",
    "population = nipa_df(retrieve_table('T20100')['Data'], s)['B230RC']\n",
    "\n",
    "s = ['DPCERG']\n",
    "\n",
    "d = nipa_df(retrieve_table('T20304')['Data'], s)['DPCERG']\n",
    "deflator = d.iloc[-1] / d\n",
    "\n",
    "s = ['A067RC', 'A068RC', 'A071RC', 'DPCERC']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "      .assign(OTHER = lambda x: -(x['A068RC'] - x['DPCERC']),\n",
    "              SAVING = lambda x: -x['A071RC'])\n",
    "      .drop(['A068RC'], axis=1)\n",
    "      .divide(population, axis=0)\n",
    "      .multiply(deflator, axis=0))\n",
    "\n",
    "data = growth_contrib(df, 'DPCERC').rolling(4).mean()\n",
    "data3y = growth_contrib(df, 'DPCERC').rolling(12).mean()\n",
    "data.loc['1989':].to_csv(data_dir / 'pcedecomp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:32:26.502517Z",
     "start_time": "2019-11-03T17:32:26.485449Z"
    }
   },
   "outputs": [],
   "source": [
    "date = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "\n",
    "pce = round(data['DPCERC'].iloc[-1], 1)\n",
    "if pce > 0:\n",
    "    pcedir = 'increased'\n",
    "elif pce < 0:\n",
    "    pcedir = 'decreased'\n",
    "else: \n",
    "    pcedir = ''\n",
    "pcetext = f'{pcedir} at an average rate of {abs(pce):.1f} percent' \n",
    "if pce == 0:\n",
    "    pcetext = 'was unchanged'\n",
    "    \n",
    "slist = ['A067RC', 'SAVING', 'OTHER']\n",
    "d = {}\n",
    "for i in slist:\n",
    "    d[i] = round(data[i].iloc[-1], 1)\n",
    "    tname = f'{i}txt'\n",
    "    if d[i] > 0:\n",
    "        tmpdir = 'added'\n",
    "    elif d[i] < 0:\n",
    "        tmpdir = 'subtracted'\n",
    "    else:\n",
    "        tmpdir = ''\n",
    "    tmptxt = f'{tmpdir} {abs(d[i]):.1f} percentage points'\n",
    "    if d[i] == 0:\n",
    "        tmptxt = \"didn't affect the total\"\n",
    "    d[tname] = tmptxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:35:29.078572Z",
     "start_time": "2019-11-03T17:35:29.072301Z"
    }
   },
   "outputs": [],
   "source": [
    "pcetxt1 = (f'Real per capita consumer spending {pcetext} over the '+\n",
    "           f'four quarters ending {date}. Changes to disposable income '+\n",
    "           f'{d[\"A067RCtxt\"]}, changes to saving {d[\"SAVINGtxt\"]}, and '+\n",
    "           f'changes to other outlays {d[\"OTHERtxt\"]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:38:56.924300Z",
     "start_time": "2019-11-03T17:38:56.922057Z"
    }
   },
   "outputs": [],
   "source": [
    "pcetxt2 = ('Over the past three years, real per capita consumer spending '+\n",
    "           f'growth has averaged {data3y[\"DPCERC\"].iloc[-1]:.1f} percent, '+\n",
    "           f'with income growth contribuing an average of {data3y[\"A067RC\"].iloc[-1]:.1f} '+\n",
    "           'percentage points and saving subtracting an average of '+\n",
    "           f'{abs(data3y[\"SAVING\"].iloc[-1]):.1f} percentage points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:40:58.269710Z",
     "start_time": "2019-11-03T17:40:58.249173Z"
    }
   },
   "outputs": [],
   "source": [
    "pcetxt = f'{pcetxt1} {pcetxt2}'\n",
    "\n",
    "write_txt(text_dir / 'pcedecomp.txt', pcetxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sectoral Accounts\n",
    "\n",
    "**NOTE:** Need to convert \"deficit\", \"borrower\" etc to parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:59:18.561746Z",
     "start_time": "2019-12-16T22:59:18.426611Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['W162RC', 'W994RC', 'AD01RC', 'W995RC', 'W996RC', 'AD03RC']\n",
    "df = (nipa_df(retrieve_table('T50100')['Data'], s).div(\n",
    "      nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC'], axis=0)) * 100\n",
    "\n",
    "df[['W995RC', 'W996RC', 'AD03RC']].dropna().to_csv(data_dir / 'sectbal2.csv', index_label='date')\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['PRIV'] = df['W994RC']\n",
    "data['GOV'] = df['AD01RC']\n",
    "data['ROW'] = -df['W162RC']\n",
    "data = data.dropna()\n",
    "date = dtxt(data.index[-1])['qtr1']\n",
    "\n",
    "data.dropna().to_csv(data_dir / 'sectbal.csv', index_label='date')\n",
    "\n",
    "priv_curr = abs(data['PRIV'].iloc[-1])\n",
    "priv_prev = abs(data.loc['2015-01-01', 'PRIV'])\n",
    "gov_curr = abs(data['GOV'].iloc[-1])\n",
    "gov_prev = abs(data.loc['2015-01-01', 'GOV'])\n",
    "row_curr = abs(data['ROW'].iloc[-1])\n",
    "row_prev = abs(data.loc['2015-01-01', 'ROW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:59:21.723963Z",
     "start_time": "2019-12-16T22:59:21.720631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2019 Q3, the US private sector was a net lender (running a surplus) of the equivalent of 5.0 percent of GDP, compared to 2.3 percent in 2015 Q1. The rest of the world was a net lender to the US, to the equivalent of 2.4 percent of GDP in 2019 Q3 compared to 2.4 percent in 2015 Q1. Balancing these transactions, the government (federal, state, and local combined) was a net borrower (running a deficit) of the equivalent of 7.4 percent of GDP, compared to 4.7 percent in 2015. \n"
     ]
    }
   ],
   "source": [
    "sectbaltxt = (f\"In {date}, the US private sector was a net lender (running a surplus) of \"+\n",
    "              f\"the equivalent of {priv_curr:.1f} percent of GDP, compared to {priv_prev:.1f} \"+\n",
    "              \"percent in 2015 Q1. The rest of the world was a net lender to the US, to the \"+\n",
    "              f\"equivalent of {row_curr:.1f} percent of GDP in {date} compared to {row_prev:.1f} \"+\n",
    "              f\"percent in 2015 Q1. Balancing these transactions, the government (federal, state, \"+\n",
    "              f\"and local combined) was a net borrower (running a deficit) of the equivalent \"+\n",
    "              f\"of {gov_curr:.1f} percent of GDP, compared to {gov_prev:.1f} percent in 2015. \")\n",
    "print(sectbaltxt)\n",
    "\n",
    "write_txt(text_dir / 'sectbal.txt', sectbaltxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T23:05:35.683520Z",
     "start_time": "2019-12-16T23:05:35.678923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Within the private sector, households were net lenders of the equivalent of 4.7 percent of GDP in 2019 Q3, while the net financial balance of private businesses--corporate and noncorporate--was 0.3 percent of GDP.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = df.dropna().index[-1]\n",
    "ltdate = dtxt(dt)['qtr1']\n",
    "hhsh = df.loc[dt, 'W996RC']\n",
    "pbussh = f\"{df.loc[dt, 'W995RC']:.1f} percent of GDP\"\n",
    "\n",
    "if (df.loc[dt, 'W995RC'] > -0.1) & (df.loc[dt, 'W995RC'] < 0.1):\n",
    "    pbussh = 'unchanged'\n",
    "    \n",
    "text = (f'Within the private sector, households were net lenders of the equivalent of {hhsh:.1f} '+\n",
    "        f'percent of GDP in {ltdate}, while the net financial balance of private '+\n",
    "        f'businesses--corporate and noncorporate--was {pbussh}.')  \n",
    "\n",
    "write_txt(text_dir / 'sectbal2.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=Z1&series=40e2091b3afe9c4e164d4380765c6842&lastobs=&'\n",
    "srs = 'rel=Z1&series=b682bef8ceb8d78b170ce12e692f06dc&lastobs=&' # More detailed\n",
    "dt = 'from=03/01/1988&to=12/31/2019&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "n = {'Total': 'Total',\n",
    "     'FL104190005.Q': '\\hspace{-2mm}\\cbox{lime!70}Corporate Business',\n",
    "     'FL104122005.Q': '\\hspace{4mm} Debt Securities',\n",
    "     'FL104123005.Q': '\\hspace{4mm} Loans',\n",
    "     'FL114190005.Q': '\\hspace{-2mm}\\cbox{green!72!black}Non-corporate Business',\n",
    "     'FL113165505.Q': '\\hspace{4mm} Commercial Mortgages',\n",
    "     'FL154190005.Q': '\\hspace{-2mm}\\cbox{orange!70}Household \\& Nonprofit',\n",
    "     'FL153165105.Q': '\\hspace{4mm} Home Mortgages',\n",
    "     'FL153166000.Q': '\\hspace{4mm} Consumer Credit',\n",
    "     'FL214190005.Q': '\\hspace{-2mm}\\cbox{cyan!52}State \\& Local Government',\n",
    "     'FL314190005.Q': '\\hspace{-2mm}\\cbox{blue!70}Federal Government'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "subseries = ['FL104190005.Q', 'FL114190005.Q', 'FL154190005.Q', \n",
    "             'FL214190005.Q', 'FL314190005.Q']\n",
    "\n",
    "df['Total'] = df[subseries].sum(axis=1)\n",
    "\n",
    "s = ['DPCERG']\n",
    "pce = nipa_df(retrieve_table('T20304')['Data'], s)\n",
    "pr = (pce['DPCERG'] / pce['DPCERG'].iloc[-1])\n",
    "data = df.divide(pr, axis=0).dropna().loc['1988':]\n",
    "\n",
    "result = growth_contrib_ann(data, 'Total').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Domestic liabilities increased by 3.8 percent over the year ending 2019 Q3, after adjusting for inflation. Over the past three years, total domestic liabilities increased at an average annual rate of 3.0 percent. The federal government contributed 0.8 percentage points per year on average (see\\\\cbox{blue!70}), while the state and local government subtracted 0.1 percentage points per year on average (see\\\\cbox{cyan!52}). Households and nonprofits contributed 0.3 percentage points per year on average over this three year period (see\\\\cbox{orange!70}), corporate businesses contributed 1.5 percentage points per year on average (see\\\\cbox{lime!70}) and non-corporate businesses contributed 0.5 percentage points per year on average (see\\\\cbox{green!72!black}).'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_csv(data_dir / 'liabgr.csv', index_label='date')\n",
    "\n",
    "datelt = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "ltval = result['Total'].iloc[-1]\n",
    "\n",
    "if ltval >= 0.1:\n",
    "    totlt = f'increased by {ltval:.1f} percent'\n",
    "elif ltval <= 0.1:\n",
    "    totlt = f'decreased by {abs(ltval):.1f} percent'\n",
    "else:\n",
    "    totlt = 'was virtually unchanged'\n",
    "    \n",
    "txt = {}\n",
    "txt2 = {}\n",
    "txt3 = {}\n",
    "\n",
    "df3 = result.rolling(12).mean().iloc[-1]\n",
    "\n",
    "for i in result.keys():\n",
    "    dtmp = df3[i]\n",
    "    if dtmp >= 0.1:\n",
    "        txt[i] = f'contributed {dtmp:.1f} percentage points per year on average'\n",
    "        txt2[i] = f'increased at an average annual rate of {dtmp:.1f} percent'\n",
    "        txt3[i] = f'contributed an annual average of {dtmp:.1f} percentage points'\n",
    "    elif dtmp <= 0.1:\n",
    "        txt[i] = f'subtracted {abs(dtmp):.1f} percentage points per year on average'\n",
    "        txt2[i] = f'increased at an average annual rate of {abs(dtmp):.1f} percent'\n",
    "        txt3[i] = f'subtracted an annual average of {abs(dtmp):.1f} percentage points'\n",
    "    else:\n",
    "        txt[i] = 'did not contribute significantly to the total'\n",
    "        txt2[i] = f'were virtually unchanged'\n",
    "        txt3[i] = 'did not contribute significantly to the total'\n",
    "        \n",
    "text = (f'Domestic liabilities {totlt} '+\n",
    "        f'over the year ending {datelt}, after adjusting for inflation. '+\n",
    "        f'Over the past three years, total domestic liabilities {txt2[\"Total\"]}. '+\n",
    "        f'The federal government {txt[\"FL314190005.Q\"]} (see\\cbox{{blue!70}}), '+\n",
    "        f'while the state and local government {txt[\"FL214190005.Q\"]} (see\\cbox{{cyan!52}}). '+\n",
    "        f'Households and nonprofits {txt[\"FL154190005.Q\"]} over this three '+\n",
    "        f'year period (see\\cbox{{orange!70}}), corporate businesses '+\n",
    "        f'{txt[\"FL104190005.Q\"]} (see\\cbox{{lime!70}}) and '+\n",
    "        f'non-corporate businesses {txt[\"FL114190005.Q\"]} (see\\cbox{{green!72!black}}).')\n",
    "\n",
    "write_txt(text_dir / 'liabgr.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[n.keys()]\n",
    "\n",
    "data = result.iloc[-5:].iloc[::-1].T\n",
    "\n",
    "cols = [f' {q.year} Q{q.quarter}' \n",
    "        if i == 0 else f'`{str(q.year)[2:]} Q{q.quarter}'\n",
    "        for i, q in enumerate(data.columns)]\n",
    "\n",
    "data.columns = cols\n",
    "data['3-year'] = result.rolling(13).mean().iloc[-1].round(2)\n",
    "data['10-year'] = result.rolling(41).mean().iloc[-1].round(2)\n",
    "data['30-year'] = result.rolling(121).mean().iloc[-1].round(2)\n",
    "data.index = data.index.map(n)\n",
    "data = data.applymap('{:.2f}'.format)\n",
    "data.to_csv(data_dir / 'liabgr.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Account Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T00:18:51.088235Z",
     "start_time": "2019-11-04T00:18:50.873013Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of 2019 Q3, the US runs a current account deficit of 2.4 percent of GDP, primarily as the result of a trade deficit on goods of 4.2 percent of GDP.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = ['A191RC']\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], s)\n",
    "\n",
    "s = ['A124RC', 'A253RC', 'A255RC', 'A646RC', 'B656RC', 'B645RC',\n",
    "     'A655RC', 'A123RC']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T40100')['Data'], s)\n",
    "      .assign(GOODS = lambda x: x['A253RC'] - x['A255RC'],\n",
    "              SERVICES = lambda x: x['A646RC'] - x['B656RC'],\n",
    "              INCOME = lambda x: x['B645RC'] - x['A655RC'],\n",
    "              TRANSFERS = lambda x: - x['A123RC'])\n",
    "      .drop(s[1:], axis=1).drop_duplicates())\n",
    "\n",
    "data = (df.div(nipa_df(retrieve_table('T10105')['Data'], ['A191RC']\n",
    "               )['A191RC'], axis=0).dropna().loc['1989':].multiply(100).round(2))\n",
    "\n",
    "data.loc['1989':].to_csv(data_dir / 'cab.csv', index_label='date')\n",
    "\n",
    "cab = abs(data['A124RC'].iloc[-1])\n",
    "tb = abs(data['GOODS'].iloc[-1])\n",
    "ld = dtxt(data.index[-1])['qtr1']\n",
    "\n",
    "text = (f'As of {ld}, the US runs a current account deficit of {cab:.1f} '+\n",
    "        'percent of GDP, primarily as the result of a trade deficit on '+\n",
    "        f'goods of {tb:.1f} percent of GDP.')\n",
    "\n",
    "write_txt(text_dir / 'cab.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T00:18:55.197181Z",
     "start_time": "2019-11-04T00:18:55.189648Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly consumer spending growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/rpcepop_hist.csv', index_col='DATE', parse_dates=True)\n",
    "\n",
    "series = {'PCEC96': 'PCE', \n",
    "          'POPTHM': 'POP'}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for srs, name in series.items():\n",
    "    url = f'http://research.stlouisfed.org/fred2/series/{srs}/downloaddata/{srs}.csv'\n",
    "    s = pd.read_csv(url, index_col='DATE', parse_dates=True)['VALUE']\n",
    "    df[name] = s\n",
    "    \n",
    "df['PCEPOP'] = df['PCE'] / df['POP']\n",
    "data2 = data['rpcepop'].append((df.PCEPOP.pct_change(12) * 100).dropna().rename('rpcepop'))\n",
    "\n",
    "data2.to_csv(data_dir / 'pcegrowth.csv', header=['rpcepop'], index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal saving rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T18:23:29.951306Z",
     "start_time": "2019-11-03T18:23:29.164081Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of December 2019, the Bureau of Economic Analysis \\href{https://www.bea.gov/data/income-saving/personal-saving-rate}{reports} a rate of personal saving of 7.6 percent. Over the past three years, the personal saving rate increased by a total of 1.3 percentage points.\n"
     ]
    }
   ],
   "source": [
    "series = 'PSAVERT'\n",
    "\n",
    "url = f'http://research.stlouisfed.org/fred2/series/{series}/downloaddata/{series}.csv'\n",
    "\n",
    "df = pd.read_csv(url, index_col='DATE', parse_dates=True)\n",
    "\n",
    "data = df.loc['1989':]\n",
    "\n",
    "data.to_csv(data_dir / 'psavert.csv', index_label='date')\n",
    "\n",
    "datelt = data.index[-1].strftime('%B %Y')\n",
    "latest = data.iloc[-1][0]\n",
    "ch3yr = data.diff(36).iloc[-1][0]\n",
    "\n",
    "if ch3yr >= 0.1:\n",
    "    txt = f'increased by a total of {ch3yr:.1f} percentage points'\n",
    "elif ch3yr <= 0.1:\n",
    "    txt = f'decreased by a total of {abs(ch3yr):.1f} percentage points'\n",
    "else:\n",
    "    txt = 'was virtually unchanged'\n",
    "\n",
    "text = (f'As of {datelt}, the Bureau of Economic Analysis '+\n",
    "        '\\href{https://www.bea.gov/data/income-saving/personal-saving-rate}{reports} a rate '+\n",
    "        f'of personal saving of {latest:.1f} percent. Over the past three years, '+\n",
    "        f'the personal saving rate {txt}.')\n",
    "\n",
    "write_txt(text_dir / 'psavert.txt', text)\n",
    "\n",
    "print(text)\n",
    "\n",
    "date = data.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "text2 = (f'\\\\node[label={{0:{{\\scriptsize {latest}\\%}}}}, circle, red, fill, inner sep=1.0pt] at'+\n",
    "         f'(axis cs:{date}, {latest}) {{}};')\n",
    "\n",
    "write_txt(text_dir / 'psavert_node.txt', text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wealth to GDP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.685570Z",
     "start_time": "2019-10-30T23:45:27.584Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ratio of US total wealth, excluding public lands, to GDP increased to 4.66 in 2019 Q3 from 3.65 in 1989 Q1. The market value of corporate equities (see\\\\cbox{{magenta!50!violet}}) increased to a 1.89 multiple of GDP in 2019 Q3 from 0.56 in 1989 Q1. The market value of residential real estate (see\\\\cbox{{green!80!blue}}) increased to 1.53 times GDP from 1.33 in 1989. The other category (see\\\\cbox{{cyan!35!white}}), which includes tangible assets other than residential real estate less US financial obligations to the rest of the world, decreased to 1.24 from 1.76 in 1989.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=Z1&series=71f2e13e70c5d96bb5da3a65053d836e&lastobs=&'\n",
    "dt = 'from=03/01/1988&to=12/31/2019&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d = {'LM155035005.Q': 'Real Estate', \n",
    "     'FL892090005.Q': 'Total', \n",
    "     'LM883164105.Q': 'Corporate Equities'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['Other'] = df['Total'] * 2 - df.sum(axis=1)\n",
    "\n",
    "data = (df.div(nipa_df(retrieve_table('T10105')['Data'], ['A191RC']\n",
    "               )['A191RC'], axis=0)).dropna().loc['1989':]\n",
    "data.loc['1989':].to_csv(data_dir / 'wealthgdp.csv', index_label='date')\n",
    "\n",
    "d89 = data.iloc[0].round(2)\n",
    "dlt = data.iloc[-1].round(2)\n",
    "\n",
    "date = dtxt(data.index[-1])['qtr1']\n",
    "\n",
    "wealthtxt = ('The ratio of US total wealth, excluding public lands, to GDP '+\n",
    "             f\"increased to {dlt['Total']} in {date} from {d89['Total']} in 1989 Q1. \"+\n",
    "             \"The market value of corporate equities (see\\cbox{{magenta!50!violet}}) \"+\n",
    "             f\"increased to a {dlt['Corporate Equities']} multiple of GDP in {date} \"+\n",
    "             f\"from {d89['Corporate Equities']} in 1989 Q1. The market value of \"+\n",
    "             \"residential real estate (see\\cbox{{green!80!blue}}) increased to \"+\n",
    "             f\"{dlt['Real Estate']} times GDP from {d89['Real Estate']} in 1989. \"+\n",
    "             \"The other category (see\\cbox{{cyan!35!white}}), which includes tangible \"+\n",
    "             \"assets other than residential real estate less US financial obligations \"+\n",
    "             f\"to the rest of the world, decreased to {dlt['Other']} from {d89['Other']} in 1989.\")\n",
    "\n",
    "write_txt(text_dir / 'wealthgdp.txt', wealthtxt)\n",
    "\n",
    "wealthtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:10:55.756953Z",
     "start_time": "2019-11-05T00:10:55.451661Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=Z1&series=d720788442f3511d102b43eee2bddb41&lastobs=&'\n",
    "dt = 'from=03/01/1988&to=12/31/2019&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d = {'FL104122005.Q': 'Debt Securities',\n",
    "     'FL143168005.Q': 'Bank Loans',\n",
    "     'FL143165005.Q': 'Mortgages',\n",
    "     'FL143169005.Q': 'Nonbank Loans',\n",
    "     'FL144104005.Q': 'Total',\n",
    "     'FL104104005.Q': 'Total Corporate',\n",
    "     'FL114123005.Q': 'Total Noncorporate',\n",
    "     'FL794122005.Q': 'Financial Debt Securities',\n",
    "     'FL794123005.Q': 'Financial Loans',\n",
    "     'FL794104005.Q': 'Financial Total',\n",
    "     'FL423161705.Q': 'Agency MBS'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['Bank Loans and Mortgages'] = df['Bank Loans'] + df['Mortgages']\n",
    "\n",
    "df['Other'] = df['Financial Debt Securities'] - df['Agency MBS']\n",
    "\n",
    "data = (df.div(nipa_df(retrieve_table('T10105')['Data'], ['A191RC']\n",
    "               )['A191RC'], axis=0)).dropna() * 100\n",
    "data.loc['1989':].to_csv(data_dir / 'busdebtgdp2.csv', index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:10:57.449073Z",
     "start_time": "2019-11-05T00:10:57.442603Z"
    }
   },
   "outputs": [],
   "source": [
    "lt_date = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "total = df['Total'].iloc[-1] / 1_000\n",
    "corp = df['Total Corporate'].iloc[-1] / 1_000\n",
    "corp_sh = corp / total * 100\n",
    "tot_gdp = data['Total'].iloc[-1]\n",
    "tot_gdp_3 = data['Total'].iloc[-13]\n",
    "\n",
    "date_3 = f'{data.index[-13].year} Q{data.index[-13].quarter}'\n",
    "tot_3 = tot_gdp - tot_gdp_3\n",
    "ds_3 = data['Debt Securities'].iloc[-1] - data['Debt Securities'].iloc[-13]\n",
    "nb_3 = data['Nonbank Loans'].iloc[-1] - data['Nonbank Loans'].iloc[-13]\n",
    "\n",
    "if tot_3 >= 1:\n",
    "    tot_text = 'increased faster than'\n",
    "    tot_text2 = 'increased'\n",
    "elif (tot_3 < 1) & (tot_3 >= -1):\n",
    "    tot_text = 'grown at about the same rate as'\n",
    "    tot_text2 = 'grew'\n",
    "else:\n",
    "    tot_text = 'fallen relative to'\n",
    "    tot_text2 = 'fell'\n",
    "    \n",
    "finmax = data['Financial Total'].max()\n",
    "finmaxdt = f'{data[\"Financial Total\"].idxmax().year} Q{data[\"Financial Total\"].idxmax().quarter}'\n",
    "finlt = data['Financial Total'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:11:00.058342Z",
     "start_time": "2019-11-05T00:11:00.055526Z"
    }
   },
   "outputs": [],
   "source": [
    "busdebt = (f'As of {lt_date}, nonfinancial business debt--the debt security '+\n",
    "           'and loan liabilities of nonfinancial businesses--both corporate and '+\n",
    "           f'non-corporate--totals \\${total:,.0f} billion, with \\${corp:,.0f} '+\n",
    "           f'billion ({corp_sh:,.1f}\\%) held by corporate businesses. Over the '+\n",
    "           f'past three years, nonfinancial business debt has {tot_text} overall '+\n",
    "           'economic activity. As a share of GDP, nonfinancial business debt '+\n",
    "           f'{tot_text2} by {tot_3:.1f} percentage points to {tot_gdp:.1f} percent '+\n",
    "           f'in {lt_date} from {tot_gdp_3:.1f} percent in {date_3}. The vast '+\n",
    "           f'majority of the increase, {nb_3:.1f} percentage points, comes from '+\n",
    "           'nonbank loans (see\\\\cbox{{blue}}).')\n",
    "\n",
    "write_txt(text_dir / 'busdebtgdp.txt', busdebt)\n",
    "\n",
    "fintext = ('Domestic financial sector debt has fallen as a share of '+\n",
    "           f'GDP to {finlt:.1f} percent in {lt_date} from a housing-bubble '+\n",
    "           f'peak of {finmax:.1f} percent in {finmaxdt}.')\n",
    "\n",
    "write_txt(text_dir / 'findebtgdp.txt', fintext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:12:54.821399Z",
     "start_time": "2019-11-14T21:12:54.564967Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=Z1&series=21a69f49792f26a66791418647f75234&lastobs=&'\n",
    "dt = 'from=03/01/1988&to=12/31/2019&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d = {'FL153165105.Q': 'Mortgages',\n",
    "     'FL153166000.Q': 'Consumer Credit',\n",
    "     'FL154190005.Q': 'Total'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1).divide(1000)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['Other'] = df['Total'] - df['Consumer Credit'] - df['Mortgages']\n",
    "\n",
    "table_store_fa = df.divide(1000)\n",
    "\n",
    "dpi = nipa_df(retrieve_table('T20100')['Data'], ['A067RC'])['A067RC']\n",
    "data = (df.div(dpi, axis=0)).dropna() * 100_000\n",
    "data.loc['1989':].to_csv(data_dir / 'hhdebt.csv', index_label='date')\n",
    "\n",
    "table_store_fa_dpi = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:12:56.410395Z",
     "start_time": "2019-11-14T21:12:56.399020Z"
    }
   },
   "outputs": [],
   "source": [
    "date = dtxt(data.index[-1])['qtr1']\n",
    "maxdate = dtxt(data.Total.idxmax())['qtr1']\n",
    "\n",
    "totval = (df['Total'].iloc[-1] / 1000)\n",
    "mortval = (df['Mortgages'].iloc[-1] / 1000)\n",
    "mortsh = mortval / totval * 100\n",
    "ccval = (df['Consumer Credit'].iloc[-1] / 1000)\n",
    "ccsh = ccval / totval * 100\n",
    "\n",
    "totrt = data['Total'].iloc[-1]\n",
    "maxrt = data['Total'].max()\n",
    "\n",
    "dpi3 = dpi.pct_change(12).iloc[-1] * 100\n",
    "rt3 = df.Total.pct_change(12).iloc[-1] * 100\n",
    "ch3 = data.Total.diff(12).iloc[-1]\n",
    "\n",
    "if dpi3 > 0.4:\n",
    "    dpi3txt = f'increased {abs(dpi3):.1f} percent'\n",
    "elif dpi3 < -0.4:\n",
    "    dpi3txt = f'decreased {abs(dpi3):.1f} percent'\n",
    "else:\n",
    "    dpi3txt = 'been virtually unchanged'\n",
    "    \n",
    "if rt3 > 0.4:\n",
    "    rt3txt = f'increased {abs(rt3):.1f} percent'\n",
    "elif rt3 < -0.4:\n",
    "    rt3txt = f'decreased {abs(rt3):.1f} percent'\n",
    "else:\n",
    "    rt3txt = 'been virtually unchanged'\n",
    "    \n",
    "if ch3 > 0.4:\n",
    "    ch3txt = f'increased by {abs(ch3):.1f} percentage points'\n",
    "elif ch3 < -0.4:\n",
    "    ch3txt = f'fallen by {abs(ch3):.1f} percentage points'\n",
    "else:\n",
    "    ch3txt = 'been virtually unchanged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:00.262328Z",
     "start_time": "2019-11-14T21:13:00.258535Z"
    }
   },
   "outputs": [],
   "source": [
    "text1 = ('The Federal Reserve \\href{https://www.federalreserve.gov/releases/z1/current/default.htm}{reports} '+\n",
    "         f'total liabilities of households and nonprofits of \\${totval:,.2f} trillion in {date}. '+\n",
    "         f'The vast majority--\\${mortval:,.2f} trillion or {mortsh:.1f} percent of the total--are '+\n",
    "         'home mortgages (see\\cbox{blue!60!violet}). Consumer credit liabilities (see\\cbox{magenta}) '+\n",
    "         'which include auto loans, credit card debt, student loans, and other personal loans, total '+\n",
    "         f'\\${ccval:,.2f} trillion ({ccsh:.1f}\\% of the total). The remaining liabilities '+\n",
    "         '(see\\cbox{orange!80!yellow}) are primarily attributable to nonprofits.')\n",
    "\n",
    "text2 = ('The ratio of household and nonprofit debt to disposable personal income has fallen to '+\n",
    "         f'{totrt:.1f} percent in {date} from its housing-bubble peak of {maxrt:.1f} percent in {maxdate}. '+\n",
    "         f'Over the past three years, nominal household and nonprofit debt has {rt3txt} while nominal '+\n",
    "         f'disposable personal income has {dpi3txt}. As a result, the ratio of household and nonprofit '+\n",
    "         f'debt to disposable personal income has {ch3txt}.')\n",
    "\n",
    "write_txt(text_dir / 'hhdebt1.txt', text1)    \n",
    "write_txt(text_dir / 'hhdebt2.txt', text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:01.608480Z",
     "start_time": "2019-11-14T21:13:01.602747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Federal Reserve \\\\href{https://www.federalreserve.gov/releases/z1/current/default.htm}{reports} total liabilities of households and nonprofits of \\\\$16.39 trillion in 2019 Q3. The vast majority--\\\\$10.52 trillion or 64.2 percent of the total--are home mortgages (see\\\\cbox{blue!60!violet}). Consumer credit liabilities (see\\\\cbox{magenta}) which include auto loans, credit card debt, student loans, and other personal loans, total \\\\$4.13 trillion (25.2\\\\% of the total). The remaining liabilities (see\\\\cbox{orange!80!yellow}) are primarily attributable to nonprofits.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The ratio of household and nonprofit debt to disposable personal income has fallen to 99.1 percent in 2019 Q3 from its housing-bubble peak of 136.1 percent in 2007 Q4. Over the past three years, nominal household and nonprofit debt has increased 10.2 percent while nominal disposable personal income has increased 16.1 percent. As a result, the ratio of household and nonprofit debt to disposable personal income has fallen by 5.6 percentage points.'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:04.066171Z",
     "start_time": "2019-11-14T21:13:04.017640Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'hhdebt2.csv', index_col='Date', parse_dates=True)\n",
    "df['Mortgage Total'] = df['Mortgage'] + df['HE Revolving']\n",
    "dpi = nipa_df(retrieve_table('T20100')['Data'], ['A067RC'])['A067RC']  / 1_000_000\n",
    "data = (df.div(dpi, axis=0)).dropna(how='all') * 100\n",
    "data2 = data\n",
    "data = data.drop(['Other', 'Mortgage Total'], axis=1)\n",
    "data.loc['1989':].to_csv(data_dir / 'hhcdebt.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:05.367730Z",
     "start_time": "2019-11-14T21:13:05.360632Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Consumer credit charts\n",
    "d = {'Mortgage': 'gray', 'HE Revolving': 'gray', \n",
    "     'Auto Loan': 'blue!60!cyan', 'Credit Card': 'red', \n",
    "     'Student Loan': 'green!80!blue', 'Total': 'gray'}\n",
    "yr3ch = data.diff(12).iloc[-1].sort_values(ascending=True)\n",
    "ltdate = data.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "ltdate2 = f'`{str(data.index[-1].year)[-2:]} Q{data.index[-1].quarter}'\n",
    "ltdate3 = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "dates = f'{data.index[-13].year} Q{data.index[-13].quarter}--`{str(data.index[-1].year)[-2:]} Q{data.index[-1].quarter}'\n",
    "\n",
    "yticklist = \",\".join(yr3ch.index)\n",
    "\n",
    "col = {}\n",
    "ind = {}\n",
    "coord = {}\n",
    "\n",
    "for i, k in enumerate(yr3ch):\n",
    "    coord[i+1] = round(k, 2)\n",
    "    ind[i+1] = i+1\n",
    "    col[i+1] = d[yr3ch.index[i]]\n",
    "    \n",
    "autocolor = d['Auto Loan']\n",
    "studcolor = d['Student Loan']\n",
    "cccolor = d['Credit Card']\n",
    "\n",
    "autoval = data[\"Auto Loan\"].iloc[-1].round(4)\n",
    "studval = data[\"Student Loan\"].iloc[-1].round(4)\n",
    "ccval = data[\"Credit Card\"].iloc[-1].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:08.180452Z",
     "start_time": "2019-11-14T21:13:08.176987Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Text for charts\n",
    "text = (f'''\\\\noindent \\\\normalsize \\hspace{{5mm}} Total Change, \\small {dates} \\\\normalsize \\hspace{{18mm}} Consumer Debt Trends \\\\footnotesize \n",
    "\\\\vspace{{1mm}}\n",
    "\n",
    "\\hspace{{2.1cm}} \\\\begin{{tikzpicture}}[trim axis left]\n",
    "\t\\\\begin{{axis}}[\\\\barplotnogrid axis y line=left, \\\\barylab{{3.7cm}}{{1.5ex}}\n",
    "\t\twidth=4.6cm, bar width=2.2ex, y=4.0ex, \n",
    "\t\tenlarge y limits={{abs=0.35cm}}, \n",
    "\t\tenlarge x limits=0.33, \\\\bbar{{x}}{{0}},\n",
    "        x tick style={{draw=none}},\n",
    "        ytick={{1,2,3,4,5,6}},\n",
    "\t\tyticklabels={{{yticklist}}},\n",
    "\t\tyticklabel style={{font=\\small, xshift=-4pt}},\n",
    "\t\tevery axis plot/.append style={{bar shift=0pt, fill}},\n",
    "\t\tnodes near coords style={{/pgf/number format/.cd,fixed zerofill,precision=1, assume math mode}}]\n",
    "\t\t\\\\addplot[{col[1]}] coordinates {{{(coord[1], ind[1])}}};\n",
    "\t\t\\\\addplot[{col[2]}] coordinates {{{(coord[2], ind[2])}}};\n",
    "\t\t\\\\addplot[{col[3]}] coordinates {{{(coord[3], ind[3])}}};\n",
    "\t\t\\\\addplot[{col[4]}] coordinates {{{(coord[4], ind[4])}}};\n",
    "\t\t\\\\addplot[{col[5]}] coordinates {{{(coord[5], ind[5])}}};\n",
    "\t\t\\\\addplot[{col[6]}] coordinates {{{(coord[6], ind[6])}}};\n",
    "\t\\end{{axis}}\n",
    "\\end{{tikzpicture}}\n",
    "\\hfill\n",
    "\\\\begin{{tikzpicture}}\n",
    "\t\\\\begin{{axis}}[\\\\bbar{{y}}{{0}}, \\dateaxisticks ytick={{2, 4, 6, 8, 10}}, \n",
    "\t\tclip=false, width=6.7cm, \n",
    "\t\txtick={{{{1999-01-01}}, {{2005-01-01}}, {{2010-01-01}}, {{2015-01-01}}, {{{ltdate}}}}},\n",
    "        minor xtick={{}}, \n",
    "        xticklabels={{`99, `05, `10, `15, {ltdate2}}}, enlarge y limits={{lower, 0.2}}, \n",
    "        enlarge x limits={{0.04}}]\n",
    "\t\\\\rebars\n",
    "\t\\stdline{{{autocolor}}}{{date}}{{Auto Loan}}{{data/hhcdebt.csv}}\n",
    "    \\\\node[label={{0:{{\\scriptsize {autoval:.1f}}}}}, circle, {autocolor}, fill, inner sep=1.5pt] at \n",
    "        (axis cs:{{{ltdate}}},{{{autoval}}}){{}};\n",
    "\t\\stdline{{{studcolor}}}{{date}}{{Student Loan}}{{data/hhcdebt.csv}}\n",
    "    \\\\node[label={{0:{{\\scriptsize {studval:.1f}}}}}, circle, {studcolor}, fill, inner sep=1.5pt] at \n",
    "        (axis cs:{{{ltdate}}},{{{studval}}}){{}};\n",
    "\t\\stdline{{{cccolor}}}{{date}}{{Credit Card}}{{data/hhcdebt.csv}}\n",
    "    \\\\node[label={{0:{{\\scriptsize {ccval:.1f}}}}}, circle, {cccolor}, fill, inner sep=1.5pt] at \n",
    "        (axis cs:{{{ltdate}}},{{{ccval}}}){{}};\n",
    "\t\\stdnode{{4.2cm}}{{1.85cm}}{{\\scriptsize \\color{{{autocolor}}}{{auto}}}}\n",
    "\t\\stdnode{{1.2cm}}{{0.9cm}}{{\\scriptsize \\color{{{studcolor}}}{{student}}}}\n",
    "\t\\stdnode{{3.9cm}}{{0.82cm}}{{\\scriptsize \\color{{{cccolor}}}{{credit card}}}}\n",
    "\t\\end{{axis}}\n",
    "\\end{{tikzpicture}}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:08.975083Z",
     "start_time": "2019-11-14T21:13:08.972832Z"
    }
   },
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'hhcdebt2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:09.986127Z",
     "start_time": "2019-11-14T21:13:09.980897Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Consumer credit text\n",
    "totval = df['Total'].iloc[-1]\n",
    "totval2 = data['Total'].iloc[-1]\n",
    "\n",
    "totvalch = df['Total'].diff(12).iloc[-1]\n",
    "dpich = dpi.diff(12).iloc[-1]\n",
    "\n",
    "if totvalch >= 0.1:\n",
    "    tvdir = f'increased by \\${abs(totvalch):.2f} trillion'\n",
    "elif totvalch <= -0.1:\n",
    "    tvdir = f'decreased by \\${abs(totvalch):.2f} trillion'\n",
    "else:\n",
    "    tvdir = 'was virtually unchanged'\n",
    "    \n",
    "if dpich >= 0.1:\n",
    "    dpidir = f'an increase of \\${abs(dpich):.2f} trillion'\n",
    "elif dpich <= -0.1:\n",
    "    dpidir = f'a decrease of \\${abs(dpich):.2f} trillion'\n",
    "else:\n",
    "    dpidir = 'virtually no change'\n",
    "    \n",
    "totvalch2 = data['Total'].diff(12).iloc[-1]\n",
    "\n",
    "\n",
    "if totvalch2 >= 0.1:\n",
    "    tvdir2 = f'has risen by {abs(totvalch2):.1f} percentage points'\n",
    "elif totvalch2 <= -0.1:\n",
    "    tvdir2 = f'has fallen by {abs(totvalch2):.1f} percentage points'\n",
    "else:\n",
    "    tvdir2 = 'was virtually unchanged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:10.773671Z",
     "start_time": "2019-11-14T21:13:10.771082Z"
    }
   },
   "outputs": [],
   "source": [
    "cctxt1 = f'Federal Reserve Bank of New York (FRBNY) \\href{{https://www.newyorkfed.org/microeconomics/hhdc/background.html}}{{analysis}} of Equifax data shows \\\\${totval} trillion in total consumer debt in {ltdate3}, which is equivalent to {totval2:.1f} percent of disposable personal income.'\n",
    "\n",
    "cctxt2 = f'Over the past three years, total consumer debt has {tvdir} compared to {dpidir} in disposable personal income. As a result, the ratio of total consumer debt to disposable personal income {tvdir2} over this period.'\n",
    "\n",
    "text2 = f'{cctxt1} {cctxt2}'\n",
    "\n",
    "write_txt(text_dir / 'hhcdebt3.txt', text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:12.886862Z",
     "start_time": "2019-11-14T21:13:12.884172Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Federal Reserve Bank of New York (FRBNY) \\\\href{https://www.newyorkfed.org/microeconomics/hhdc/background.html}{analysis} of Equifax data shows \\\\$13.952 trillion in total consumer debt in 2019 Q3, which is equivalent to 84.4 percent of disposable personal income. Over the past three years, total consumer debt has increased by \\\\$1.60 trillion compared to an increase of \\\\$2.31 trillion in disposable personal income. As a result, the ratio of total consumer debt to disposable personal income has fallen by 2.6 percentage points over this period.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = {}\n",
    "sh = {}\n",
    "gr = {}\n",
    "\n",
    "for series in ['Mortgage Total', 'Auto Loan', 'Student Loan', 'Credit Card']:\n",
    "    tot[series] = df[series].iloc[-1] * 1000\n",
    "    sh[series] = data2[series].iloc[-1]\n",
    "    grtmp = (data2[series].diff(12)).iloc[-1]\n",
    "    if round(grtmp, 1) >= 0.1:\n",
    "        gr[series] = f'an increase of {grtmp:.1f} percentage points'\n",
    "    elif round(grtmp, 1) <= -0.1:\n",
    "        gr[series] = f'a decrease of {abs(grtmp):.1f} percentage points'\n",
    "    else:\n",
    "        gr[series] = 'virtually no change'\n",
    "        \n",
    "mgr = data2['Mortgage Total'].diff(12).iloc[-1]        \n",
    "gr['Mortgage Total'] = f'fell by {abs(mgr):.1f} percentage points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3 = ('According to the same FRBNY data, mortgage debt, including home '+\n",
    "        f'equity lines of credit, totalled \\${tot[\"Mortgage Total\"]:,.0f} '+\n",
    "        f'billion in {ltdate3}, equivalent to {sh[\"Mortgage Total\"]:.1f} '+\n",
    "        f'percent of disposable personal income (DPI). Student loans '+\n",
    "        f'totalled \\${tot[\"Student Loan\"]:,.0f} billion, or '+\n",
    "        f'{sh[\"Student Loan\"]:.1f} percent of DPI; auto loans totalled '+\n",
    "        f'\\${tot[\"Auto Loan\"]:,.0f} billion ({sh[\"Auto Loan\"]:.1f} percent '+\n",
    "        f'of DPI); and credit card debt totalled '+\n",
    "        f'\\${tot[\"Credit Card\"]:,.0f} billion ({sh[\"Credit Card\"]:.1f} percent of DPI).' )\n",
    "\n",
    "\n",
    "txt4 = ('Over the past three years, the ratio of total mortgage debt to disposable '+\n",
    "        f'personal income {gr[\"Mortgage Total\"]}, compared to '+\n",
    "        f'{gr[\"Student Loan\"]} for student loans, '+\n",
    "        f'{gr[\"Auto Loan\"]} for auto loans, and '+\n",
    "        f'{gr[\"Credit Card\"]} for credit card debt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over the past three years, the ratio of total mortgage debt to disposable personal income fell by 2.6 percentage points, compared to an increase of 0.1 percentage points for student loans, virtually no change for auto loans, and an increase of 0.1 percentage points for credit card debt'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'hhcdebt4.txt', txt3)\n",
    "write_txt(text_dir / 'hhcdebt5.txt', txt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:22:50.803835Z",
     "start_time": "2019-11-14T21:22:50.776360Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Household debt and consumer credit table\n",
    "dtlt = pd.to_datetime(df.index[-1])\n",
    "dt2 = pd.to_datetime(df.index[-2])\n",
    "dt3y = pd.to_datetime(df.index[-13])\n",
    "dt13 = pd.to_datetime('2013-01-01')\n",
    "dt03 = pd.to_datetime('2003-01-01')\n",
    "\n",
    "dts = [dtlt, dt2]\n",
    "\n",
    "dts2 = [dtlt, dt2, dt3y, dt13, dt03]\n",
    "\n",
    "for x in [df, data2]:\n",
    "    x['Mortgage Total'] = x['Mortgage'] + x['HE Revolving']\n",
    "    x['Non-Mortgage Total'] = (x['Auto Loan'] + x['Credit Card'] \n",
    "                               + x['Student Loan'] + x['Other'])\n",
    "\n",
    "    \n",
    "# Attempt to handle CCP coming out first\n",
    "for x in [table_store_fa, table_store_fa_dpi]:\n",
    "    if dtlt not in x.index:\n",
    "        x.at[dtlt, :] = '--'\n",
    "\n",
    "d1 = {'Total': 'Financial Accounts Total*',\n",
    "      'Mortgages': '\\hspace{2mm} \\cbox{blue!60!violet} Mortgage Debt Total',\n",
    "      'Consumer Credit': '\\hspace{2mm} \\cbox{magenta} Consumer Credit',\n",
    "      'Other': '\\hspace{2mm} \\cbox{orange!80!yellow} Other'}\n",
    "\n",
    "d2 = {'Total': 'Consumer Credit Panel Total',\n",
    "      'Mortgage Total': '\\hspace{2mm} Mortgage Debt Total',\n",
    "      'Mortgage': '\\hspace{4mm} Mortgage',\n",
    "      'HE Revolving': '\\hspace{4mm} Home Equity Revolving',\n",
    "      'Non-Mortgage Total': '\\hspace{2mm} Consumer Credit',\n",
    "      'Auto Loan': f'\\hspace{{4mm}} \\cbox{{{autocolor}}} Auto Loan',\n",
    "      'Credit Card': f'\\hspace{{4mm}} \\cbox{{{cccolor}}} Credit Card',\n",
    "      'Student Loan': f'\\hspace{{4mm}} \\cbox{{{studcolor}}} Student Loan',\n",
    "      'Other': '\\hspace{4mm} Other'}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "for dt in dts:\n",
    "    dtmp = f'{dt.year} Q{dt.quarter}'\n",
    "    for srs in [table_store_fa]:\n",
    "        for k, v in d1.items():\n",
    "            if srs.loc[dt, k] != '--':\n",
    "                final.at[v, dtmp] = f'\\${srs.loc[dt, k]:.2f}T'\n",
    "            else: final.at[v, dtmp] = srs.loc[dt, k]\n",
    "    for srs in [df]:\n",
    "        for k, v in d2.items():            \n",
    "            final.at[v, dtmp] = f'\\${srs.loc[dt, k]:.2f}T' \n",
    "            \n",
    "for dt in dts2:\n",
    "    dtmp = f'`{str(dt.year)[2:]} Q{dt.quarter}'\n",
    "    for srs in [table_store_fa_dpi]:\n",
    "        for k, v in d1.items():\n",
    "            if srs.loc[dt, k] != '--':\n",
    "                final.at[v, dtmp] = round(srs.loc[dt, k], 1)\n",
    "            else: \n",
    "                final.at[v, dtmp] = srs.loc[dt, k]\n",
    "    for srs in [data2]:\n",
    "        for k, v in d2.items():\n",
    "            final.at[v, dtmp] = round(srs.loc[dt, k], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:22:51.470193Z",
     "start_time": "2019-11-14T21:22:51.467011Z"
    }
   },
   "outputs": [],
   "source": [
    "final.to_csv(data_dir / 'hhcdebt.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T19:55:55.127341Z",
     "start_time": "2019-11-10T19:55:55.122619Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income as return on total HH assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:47:26.349851Z",
     "start_time": "2019-12-16T22:47:21.005529Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=Z1&series=906ccd6e7fcae1e4f20ac00b86ade272&lastobs=&'\n",
    "dt = 'from=03/01/1988&to=12/31/2019&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d = {'LM152010005.Q': 'Nonfinancial',\n",
    "     'FL154090005.Q': 'Financial'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['Total'] = df['Nonfinancial'] + df['Financial']\n",
    "s = ['A067RC']\n",
    "\n",
    "df['DPI'] = nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "df['DPINF'] = df['Nonfinancial'].divide(df['Total'], axis=0)\n",
    "df['DPIF'] = df['Financial'].divide(df['Total'], axis=0)\n",
    "df['DPIsh'] = df['DPI'].divide(df['Total'], axis=0)\n",
    "df['DPINFsh'] = df['DPINF'] * df['DPIsh']\n",
    "df['DPIFsh'] = df['DPIF'] * df['DPIsh']\n",
    "\n",
    "df = df * 100\n",
    "\n",
    "df.to_csv(data_dir / 'dpish.csv', index_label='date', float_format='%g')\n",
    "\n",
    "dt = df.index[-1]\n",
    "ltdate = dtxt(dt)['qtr1']\n",
    "tot = df.loc[dt, 'DPIsh']\n",
    "tot90s = df.loc['1990':'1999', 'DPIsh'].mean()\n",
    "\n",
    "text = (f'As of {ltdate}, disposable income was equivalent to {tot:.1f} percent '+\n",
    "        f'of total assets, compared to an average rate of {tot90s:.1f} percent during '+\n",
    "        'the 1990s.')\n",
    "\n",
    "write_txt(text_dir / 'dpishta.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic Detail for Housing Wealth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:55:45.089914Z",
     "start_time": "2019-11-11T13:55:43.276664Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/releases/efa/state-census-region-housing-wealth.csv'\n",
    "\n",
    "regions = ['Northeast', 'Midwest', 'West', 'South', 'US']\n",
    "\n",
    "data = pd.read_csv(url, index_col=0)\n",
    "data.index = pd.to_datetime([f'{i[:4]}-{int(i[-1]) * 3 - 2}-01' for i in data.index])\n",
    "data = data.rename({'National': 'US'}, axis=1)[regions]\n",
    "\n",
    "series = {'EOWNOCCNEQ176N': 'Northeast_Q', \n",
    "          'EOWNOCCMWQ176N': 'Midwest_Q', \n",
    "          'EOWNOCCSOQ176N': 'South_Q', \n",
    "          'EOWNOCCWEQ176N': 'West_Q', \n",
    "          'EOWNOCCUSQ176N': 'US_Q'}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for srs, name in series.items():\n",
    "    url = f'http://research.stlouisfed.org/fred2/series/{srs}/downloaddata/{srs}.csv'\n",
    "    s = pd.read_csv(url, index_col='DATE', parse_dates=True)['VALUE']\n",
    "    df[name] = s\n",
    "    \n",
    "results = pd.DataFrame()\n",
    "for region in regions:\n",
    "    regionq = f'{region}_Q'\n",
    "    regionp = f'{region}_P'\n",
    "    \n",
    "    total_value = data[region]\n",
    "    \n",
    "    quantity = df[regionq]\n",
    "    \n",
    "    unit_price = total_value / quantity\n",
    "    \n",
    "    growth = total_value.pct_change(4) * 100\n",
    "    \n",
    "    price_growth = unit_price.pct_change(4) * 100\n",
    "    \n",
    "    quantity_growth = growth - price_growth\n",
    "    \n",
    "    results[regionq] = quantity_growth \n",
    "    results[regionp] = price_growth \n",
    "\n",
    "results = results.dropna()\n",
    "\n",
    "results.to_csv(data_dir / 'val_ooh.csv', index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household formation estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T20:54:53.282570Z",
     "start_time": "2019-12-15T20:54:52.791364Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "files = ['histtab8.xlsx', 'hist_tab_8a_v2018.xlsx']\n",
    "url = 'https://www.census.gov/housing/hvs/data/'\n",
    "\n",
    "results = {}\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_excel(url + file).iloc[4:, :5]\n",
    "    data.columns = ['category', 'Q1', 'Q2', 'Q3', 'Q4']\n",
    "    years = []\n",
    "    for h in data[data['Q1'] == '1st Qtr'].index - 1:\n",
    "        year_raw = data.loc[h, 'Q1']\n",
    "        if type(year_raw) == int:\n",
    "            year = year_raw\n",
    "        elif type(year_raw) == str:\n",
    "            year = int(year_raw[:4])\n",
    "        elif type(year) == float:\n",
    "            year = year + 1\n",
    "        years.append(year)\n",
    "    data.loc[data['Q1'] == '1st Qtr', 'category'] = years\n",
    "    data = data.dropna(subset=['category'])\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    levels = pd.DataFrame()\n",
    "    for series in ['Owner', 'Renter']:\n",
    "        srs = data.loc[data['category'].astype('str').str.contains(series)]\n",
    "        srs.index = years\n",
    "        srs = srs[['Q1', 'Q2', 'Q3', 'Q4']].unstack().swaplevel()\n",
    "        srs.index = pd.to_datetime([f'{i[0]}-{i[1]}' for i in srs.index])\n",
    "        srs = srs.sort_index()\n",
    "        df[series] = srs\n",
    "        levels[series] = srs\n",
    "    df = df.dropna()\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    \n",
    "    # Convert to share of total change\n",
    "    for s in ['Owner', 'Renter']:  \n",
    "        df[s] = ((df[s] - df[s].shift(4))\n",
    "                  /df['Total'].shift(4)) * 100\n",
    "        \n",
    "    df = (df.reset_index()\n",
    "            .drop_duplicates(subset='index', keep='last')\n",
    "            .set_index('index'))\n",
    "    \n",
    "    results[file] = df[['Owner', 'Renter']].dropna().rolling(4).mean().loc['1989':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T20:54:55.884698Z",
     "start_time": "2019-12-15T20:54:55.875903Z"
    }
   },
   "outputs": [],
   "source": [
    "final = results['histtab8.xlsx'].loc[:'2001'].append(results['hist_tab_8a_v2018.xlsx'].loc['2002':])\n",
    "final['pop'] = (nipa_df(retrieve_table('T70100')['Data'], ['B230RC'])\n",
    "                .pct_change(4).dropna() * 100)\n",
    "\n",
    "final.to_csv(data_dir / 'hhform.csv', index_label='date')\n",
    "\n",
    "levels = levels.dropna()\n",
    "ldate = f'{levels.index[-1].year} Q{levels.index[-1].quarter}'\n",
    "pdate = f'{levels.index[-2].year} Q{levels.index[-2].quarter}'\n",
    "tot = levels.iloc[-1].sum() / 1000\n",
    "rtot = levels['Renter'].iloc[-1] / 1000\n",
    "rsh = rtot / tot * 100\n",
    "otot = levels['Owner'].iloc[-1] / 1000\n",
    "osh = otot / tot * 100\n",
    "\n",
    "ch = levels.diff(4).rolling(4).mean().iloc[-1]\n",
    "incdec = ['increase' if ch.sum() >= 0 else 'decrease']\n",
    "chtot = [f'{abs(ch.sum()) / 1000:.1f} million' if ch.sum() > 1000 else f'{abs(ch.sum()):.0f} thousand'][0]\n",
    "\n",
    "t = {name: [f'{abs(s) / 1000:.1f} million {[\"net new\" if s >= 0 else \"net fewer\"][0]}' \n",
    "            if s > 1000 \n",
    "            else f'{abs(s):.0f} thousand {[\"net new\" if s >= 0 else \"net fewer\"][0]}'][0]\n",
    "     for name, s in [('tot', ch.sum()), ('rent', ch.Renter), ('own', ch.Owner)]}\n",
    "\n",
    "text = (f'As of {ldate}, there are {tot:.1f} million total occupied '+\n",
    "        f'housing units in the US, of which {rtot:.1f} million ({rsh:.1f} percent) '+\n",
    "        f'are rented, and {otot:.1f} million ({osh:.1f} percent) are '+\n",
    "        'owner-occupied. There was an average annual net total '+\n",
    "        f'{incdec[0]} of {chtot} housing units '+\n",
    "        f'over the year ending {ldate}, the result of {t[\"rent\"]} '+\n",
    "        f'renter households and {t[\"own\"]} '+\n",
    "        f'owner-occupied households. ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T20:56:00.071338Z",
     "start_time": "2019-12-15T20:56:00.066238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of 2019 Q4, there are 124.0 million total occupied housing units in the US, of which 43.3 million (34.9 percent) are rented, and 80.7 million (65.1 percent) are owner-occupied. There was an average annual net total increase of 1.4 million housing units over the year ending 2019 Q4, the result of 298 thousand net new renter households and 1.1 million net new owner-occupied households. Over the year ending 2019 Q4, the total number of occupied housing units increased by 1.1 percent, compared to an increase of 1.2 percent in 2019 Q3. Owner-occupied units contributed 0.9 percent to total household formation on average over the year (see\\\\cbox{yellow!60!orange}), compared to a a contribution of 0.2 percent from rented units (see\\\\cbox{magenta!90!blue}).'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totgr = final[['Owner', 'Renter']].sum(axis=1).iloc[-1]\n",
    "ogr = final['Owner'].iloc[-1]\n",
    "rgr = final['Renter'].iloc[-1]\n",
    "\n",
    "final['Total'] = final[['Owner', 'Renter']].sum(axis=1)\n",
    "\n",
    "t2 = {name: [f\"{['increased' if s >= 0 else 'decreased'][0]} by {abs(s):.1f} percent\"][0] \n",
    "      for name, s in final.iloc[-1].iteritems()}\n",
    "\n",
    "t3 = {name: [f\"{['an increase' if s >= 0 else 'a decreased'][0]} of {abs(s):.1f} percent\"][0] \n",
    "      for name, s in final.iloc[-2].iteritems()}\n",
    "\n",
    "t4 = {name: [f\"{['a contribution' if s >= 0 else 'a reduction'][0]} of {abs(s):.1f} percent\"][0] \n",
    "      for name, s in final.iloc[-2].iteritems()}\n",
    "\n",
    "t5 = {name: [f\"{[f'contributed {abs(s):.1f} percent to' if s >= 0 else f'subtracted {abs(s):.1f} percent from'][0]}\"][0] \n",
    "      for name, s in final.iloc[-1].iteritems()}\n",
    "\n",
    "text2 = (f'Over the year ending {ldate}, the total number of occupied housing units '+\n",
    "         f'{t2[\"Total\"]}, compared to {t3[\"Total\"]} in {pdate}. Owner-occupied '+\n",
    "         f'units {t5[\"Owner\"]} total household formation on average over the year '+\n",
    "         '(see\\cbox{yellow!60!orange}), compared to a '+\n",
    "         f'{t4[\"Renter\"]} from rented units (see\\cbox{{magenta!90!blue}}).')\n",
    "\n",
    "txt = text + text2\n",
    "\n",
    "write_txt(text_dir / 'hhform1.txt', txt)\n",
    "\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T21:32:21.272688Z",
     "start_time": "2019-11-03T21:32:21.268715Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T20100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporate Profits Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-16T22:26:03.999417Z",
     "start_time": "2019-12-16T22:26:03.993142Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A032RC', 'A438RC', 'A054RC', 'B056RC', 'A127RC']\n",
    "cprof = nipa_df(retrieve_table('T11200')['Data'], s) / 1000000\n",
    "\n",
    "cprof['NNI'] = cprof['A032RC'] - cprof['A438RC']\n",
    "cprof['TAX'] = cprof['A054RC'] / cprof['NNI'] * 100 \n",
    "cprof['DIV'] = cprof['B056RC'] / cprof['NNI'] * 100 \n",
    "cprof['RE'] = cprof['A127RC'] / cprof['NNI'] * 100 \n",
    "\n",
    "cprof[['TAX', 'DIV', 'RE']].loc['1989':].to_csv(data_dir / 'cprof.csv', index_label='date')\n",
    "\n",
    "dt = cprof.index[-1]\n",
    "ltdate = dtxt(cprof.index[-1])['qtr2']\n",
    "tot = cprof.loc[dt, ['A054RC', 'B056RC', 'A127RC']].sum()\n",
    "totsh = tot / cprof.loc[dt, 'NNI'] * 100\n",
    "div = cprof.loc[dt, 'B056RC']\n",
    "divsh = div / cprof.loc[dt, 'NNI'] * 100\n",
    "ret = cprof.loc[dt, 'A127RC']\n",
    "tax = cprof.loc[dt, 'A054RC']\n",
    "\n",
    "text = (f'In {ltdate}, aggregate corporate profits were \\${tot:.2f} trillion, or {totsh:.1f} '+\n",
    "        f'percent of net national income. Of this, \\${div:.2f} trillion, equivalent to {divsh:.1f} '+\n",
    "        'percent of net national product, were paid out as dividends (see\\cbox{blue!70!purple}), '+\n",
    "        f'\\${ret*1000:.0f} billion were retained (see\\cbox{{cyan!50!white}}), and \\${tax*1000:.0f} billion '+\n",
    "        'went to corporate income tax (see\\cbox{red!80!orange}). ')\n",
    "\n",
    "write_txt(text_dir / 'cprof.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporate profits source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:30:06.166913Z",
     "start_time": "2019-11-01T00:30:06.029974Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['W170RC', 'A262RC', 'W986RC', 'A922RC']\n",
    "df1 = nipa_df(retrieve_table('T50100')['Data'], s)\n",
    "\n",
    "s = ['A123RC']\n",
    "df2 = nipa_df(retrieve_table('T40100')['Data'], s)\n",
    "\n",
    "s = ['A001RC']\n",
    "df3 = nipa_df(retrieve_table('T10705')['Data'], s)\n",
    "\n",
    "cprof = pd.DataFrame()\n",
    "cprof['ROW Saving'] = (df2['A123RC'] / df3['A001RC']) * 100\n",
    "cprof['HH Saving'] = (- df1['W986RC'] / df3['A001RC']) * 100\n",
    "cprof['Gov Saving'] = (- df1['A922RC'] / df3['A001RC']) * 100\n",
    "cprof['Investment'] = ((df1['W170RC'] - df1['A262RC']) / df3['A001RC']) * 100\n",
    "\n",
    "cprof.loc['1989':].to_csv(data_dir / 'cprof2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.704755Z",
     "start_time": "2019-10-30T23:45:27.663Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T50100'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T17:22:29.201984Z",
     "start_time": "2019-11-06T17:22:25.977027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'PRS85006092': 'value',\n",
    "          'PRS85006032': 'hours',\n",
    "          'PRS85006042': 'output'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1989, 2019)\n",
    "df = bls_api(series, dates, bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T17:35:01.313905Z",
     "start_time": "2019-11-06T17:35:01.288785Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / 'lprod.csv', index_label='date')\n",
    "\n",
    "d = series_info(df['value'])\n",
    "\n",
    "s = {}\n",
    "\n",
    "for srs in list(series.values()):\n",
    "    s[srs] = {}\n",
    "    tmp = series_info(df[srs])\n",
    "    for i in ['val_latest', 'val_prev']:\n",
    "        if tmp[i] > 0:\n",
    "            s[srs][i] = f'increased at an annual rate of {tmp[i]:.1f} percent'\n",
    "            s[srs][i+'2'] = f'an increase of {tmp[i]:.1f} percent'\n",
    "        elif tmp[i] < 0:\n",
    "            s[srs][i] = f'decreased at an annual rate of {abs(d[\"val_latest\"]):.1f} percent'\n",
    "            s[srs][i+'2'] = f'a decrease of {abs(tmp[i]):.1f} percent'\n",
    "        else:\n",
    "            s[srs][i] = 'was unchanged'\n",
    "            s[srs][i+'2'] = 'no change'   \n",
    "    \n",
    "\n",
    "text = (f'In {d[\"date_latest_ft\"]}, labor productivity {s[\"value\"][\"val_latest\"]} '+\n",
    "        f'(see\\cbox{{teal}}), as the result of {s[\"output\"][\"val_latest2\"]} in real ouput and '+\n",
    "        f'{s[\"hours\"][\"val_latest2\"]} in hours worked. In the prior quarter, '+\n",
    "        f'{d[\"date_prev_ft\"]}, labor productivity {s[\"value\"][\"val_prev\"]}, as '+\n",
    "        f'real output {s[\"output\"][\"val_prev\"]} and hours of work {s[\"hours\"][\"val_prev\"]}. '+\n",
    "        f'Over the past five years, '+\n",
    "        f'labor productivity growth has averaged {d[\"five_year_mean\"]:.1f} percent, '+\n",
    "        f'compared to a 1989-onward average of {d[\"mean\"]:.1f} percent.')\n",
    "\n",
    "write_txt(text_dir / 'lprod.txt', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T17:35:20.254508Z",
     "start_time": "2019-11-06T17:35:20.246370Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Labor Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T21:33:21.255545Z",
     "start_time": "2019-11-03T21:33:19.143067Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS12005054': 'Hours', 'LNS12000000': 'Employment'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1989, 2019)\n",
    "emp_hrs = bls_api(series, dates, bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T21:45:10.324640Z",
     "start_time": "2019-11-03T21:45:10.319025Z"
    }
   },
   "outputs": [],
   "source": [
    "emp_hrs['Total'] = emp_hrs['Hours'] * emp_hrs['Employment']\n",
    "emp = emp_hrs['Total'].resample('QS').mean()\n",
    "\n",
    "s = ['A033RC']\n",
    "coe = nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "\n",
    "s = ['DPCERG']\n",
    "pce = nipa_df(retrieve_table('T20304')['Data'], s)\n",
    "\n",
    "data = coe.join(pce).join(emp).dropna()\n",
    "data['real_coe'] = data['A033RC'] / (data['DPCERG'] / data['DPCERG'].iloc[-1])\n",
    "data['coe_inp'] = data['real_coe'] / data['Total']\n",
    "data['wage'] = data['coe_inp'] * data['Total'].iloc[0]\n",
    "data['work'] = data['real_coe'] - data['wage']\n",
    "# Calculate contributions to growth\n",
    "result = growth_contrib(data, 'real_coe')[['work', 'wage']]\n",
    "result.dropna().loc['1989':].to_csv(data_dir / 'gli.csv', index_label='date')\n",
    "\n",
    "date = f'{result.index[-1].year} Q{result.index[-1].quarter}'\n",
    "totval = result.iloc[-1].sum()\n",
    "wage = result['wage'].iloc[-1]\n",
    "work = result['work'].iloc[-1]\n",
    "\n",
    "if totval > 0:\n",
    "    txt1 = f'increased at an annualized and inflation-adjusted rate of {totval:.2f} percent in {date}.'\n",
    "elif totval < 0:\n",
    "    txt1 = f'decreased at an annualized and inflation-adjusted rate of {abs(totval):.2f} percent in {date}.'\n",
    "else:\n",
    "    txt1 = f'was unchanged, after adjusting for inflation, in {date}.'\n",
    "    \n",
    "if wage > 0:\n",
    "    txt2 = f'Changes in wages contributed {wage:.2f} percentage points'\n",
    "elif wage < 0:\n",
    "    txt2 = f'Changes in wages subtracted {abs(wage):.2f} percentage points'\n",
    "else: \n",
    "    txt2 = 'Changes in wages did not contribute'\n",
    "    \n",
    "if work > 0:\n",
    "    txt3 = f', and changes in total hours worked contributed {work:.2f} percentage points.'\n",
    "elif work < 0:\n",
    "    txt3 = f', amd changes in total hours worked subtracted {abs(work):.2f} percentage points.'\n",
    "else: \n",
    "    txt3 = ', and changes in total hours worked did not contribute.'    \n",
    "    \n",
    "text = f'{txt1} {txt2}{txt3}'\n",
    "write_txt(text_dir / 'gli.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Population and Age Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T20:08:00.463936Z",
     "start_time": "2019-10-26T20:07:59.801790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries and adjust settings\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import Normalize\n",
    "acsdir = '/home/brian/Documents/ACS/'\n",
    "\n",
    "plt.rc('font', family='Lato')\n",
    "\n",
    "# Match PUMAs to commuter zones (file from Dorn)\n",
    "cz_match = pd.read_stata(acsdir + 'data/cw_puma2010_czone.dta')\n",
    "cz_dict = {cz: [(puma, afactor) \n",
    "                for puma, z, afactor \n",
    "                in cz_match[cz_match['czone'] == cz].values] \n",
    "           for cz in cz_match['czone'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T20:08:03.968141Z",
     "start_time": "2019-10-26T20:08:01.499457Z"
    }
   },
   "outputs": [],
   "source": [
    "variables = {'DP05_0024E': 'Age 65+',\n",
    "             'DP05_0019E': 'Age 0-17',\n",
    "             'DP03_0114E': 'Other NILF',\n",
    "             'DP05_0001E': 'Total'}\n",
    "srs = ','.join(variables.keys())\n",
    "area = 'for=public%20use%20microdata%20area:*'\n",
    "base = 'https://api.census.gov/data/2018/acs/acs1/profile'\n",
    "url = f'{base}?get={srs}&{area}&key={census_key}'\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T20:08:06.633465Z",
     "start_time": "2019-10-26T20:08:06.618334Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(r.json()[1:])\n",
    "df.columns = r.json()[0]\n",
    "df['PUMA'] = [float(f\"{i[-2]}{i[-1]}\") for i in r.json()[1:]]\n",
    "df = df.set_index('PUMA')[variables.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T23:28:35.948402Z",
     "start_time": "2019-10-12T23:28:33.660718Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for cz, puma_list in cz_dict.items(): \n",
    "    pop = 0\n",
    "    u18 = 0\n",
    "    o64 = 0\n",
    "    nlf = 0\n",
    "    for puma, afactor in puma_list:\n",
    "        data = dict(df.loc[puma].astype(int) * afactor)\n",
    "        pop += data['DP05_0001E']\n",
    "        u18 += data['DP05_0019E']\n",
    "        o64 += data['DP05_0024E']\n",
    "        nlf += data['DP03_0114E']\n",
    "    \n",
    "    u18sh = u18 / pop\n",
    "    o64sh = o64 / pop\n",
    "    nlfsh = nlf / pop\n",
    "    results = {'Total': pop, 'Age 0-17': u18sh, 'Age 65+': o64sh, 'NILF': nlfsh}\n",
    "    d[cz] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T23:34:00.280363Z",
     "start_time": "2019-10-12T23:34:00.234043Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(d).T\n",
    "result['Sum'] = result[['Age 0-17', 'Age 65+', 'NILF']].sum(axis=1)\n",
    "maxval = result['Age 0-17'].max()\n",
    "minval = result['Age 0-17'].min()\n",
    "\n",
    "maxval2 = result['Age 65+'].max()\n",
    "minval2 = result['Age 65+'].min()\n",
    "\n",
    "maxval3 = result['NILF'].max()\n",
    "minval3 = result['NILF'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T00:55:53.101832Z",
     "start_time": "2019-10-13T00:55:52.692246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map and legend settings\n",
    "m = Basemap(llcrnrlon=-121, llcrnrlat=20, urcrnrlon=-64, urcrnrlat=49,\n",
    "            projection='lcc', lat_1=33, lat_2=45, lon_0=-95, resolution='c')\n",
    "\n",
    "cmap = plt.cm.Blues\n",
    "norm = Normalize(vmin=minval, vmax=maxval)\n",
    "\n",
    "cmap2 = plt.cm.Greens\n",
    "norm2 = Normalize(vmin=minval2, vmax=maxval2)\n",
    "\n",
    "cmap3 = plt.cm.Greens\n",
    "norm3 = Normalize(vmin=minval3, vmax=maxval3)\n",
    "\n",
    "hi_cz = [35600, 34701, 34703, 34702, 34703]\n",
    "ak_cz = [34101, 34114, 34102, 34112, 34104, 34107, 34115, \n",
    "         34109, 34109, 34102, 34111, 34108, 34107, 34102, \n",
    "         34106, 34113, 34105, 34111, 34110, 34109, 34115, \n",
    "         34103, 34112, 34110, 34115]\n",
    "\n",
    "pts = np.arange(1, 101, 1)\n",
    "pct = (np.percentile(\n",
    "    np.repeat(result['Age 0-17'].values, \n",
    "              result.Total.div(1000).astype(int).values), pts))\n",
    "pct2 = (np.percentile(\n",
    "    np.repeat(result['Age 65+'].values, \n",
    "              result.Total.div(1000).astype(int).values), pts))\n",
    "pct3 = (np.percentile(\n",
    "    np.repeat(result['NILF'].values, \n",
    "              result.Total.div(1000).astype(int).values), pts))\n",
    "\n",
    "max_val = f'{maxval * 100:.1f}%'\n",
    "min_val = f'{minval * 100:.1f}%'\n",
    "\n",
    "max_val2 = f'{maxval2 * 100:.1f}%'\n",
    "min_val2 = f'{minval2 * 100:.1f}%'\n",
    "\n",
    "max_val3 = f'{maxval3 * 100:.1f}%'\n",
    "min_val3 = f'{minval3 * 100:.1f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T01:45:46.308858Z",
     "start_time": "2019-10-13T01:45:44.477486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Draw map\n",
    "fig = plt.figure(figsize=(5.0,2.5))\n",
    "\n",
    "m.drawmapboundary()\n",
    "m.readshapefile(acsdir + 'shapefiles/cz1990', 'cz', drawbounds=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "for info, shape in zip(m.cz_info, m.cz):\n",
    "    fc = cmap(norm(d[info['cz']]['Age 0-17']))\n",
    "    fc2 = cmap2(norm2(d[info['cz']]['Age 65+']))\n",
    "    fc3 = cmap3(norm3(d[info['cz']]['NILF']))\n",
    "    if info['cz'] in hi_cz:\n",
    "        shape = [[x + 5200000, y - 1400000] for x, y in shape]\n",
    "    elif info['cz'] in ak_cz:\n",
    "        shape = [(x * 0.34 + 1280000, \n",
    "                  y * 0.34 - 1300000) for x, y in shape]\n",
    "    #ax.add_patch(Polygon(shape, fc=fc))\n",
    "    ax.add_patch(Polygon(shape, fc=fc2))\n",
    "    #ax.add_patch(Polygon(shape, fc=fc3))\n",
    "\n",
    "ax.axis('off')    \n",
    "\n",
    "ax_inset = inset_axes(ax, width='-10%', height='50%', loc=4, borderpad=1.8) \n",
    "for i, pt in enumerate(pct2):\n",
    "    rect = Rectangle(xy=(pt, i / 100), width=-pt, height=0.1, \n",
    "                     fc=cmap2(norm2(pt)), ec=None)\n",
    "    ax_inset.add_patch(rect)    \n",
    "\n",
    "ax_inset.text(0.6, 1.05, max_val2, fontsize=7)\n",
    "ax_inset.text(0.6, -0.12, min_val2, fontsize=7)\n",
    "ax_inset.axis('off')\n",
    "plt.savefig(data_dir / 'over64pop.pgf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shiller real return trailing 20-year average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('http://www.econ.yale.edu/~shiller/data/ie_data.xls', sheet_name='Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "df = df.iloc[679:1795, np.r_[0, 7, 8]]\n",
    "df.columns = ['Date', 'Price', 'Dividend']\n",
    "df.index = pd.to_datetime([f'{val:.2f}' for val in df['Date'].values])\n",
    "df = df.loc[~df.index.duplicated(keep='first')]\n",
    "df['DY'] = (df['Dividend'] / df['Price']).rolling(180).mean()\n",
    "df['Pch'] = df['Price'].pct_change(180)\n",
    "df['Pch'] = (df['Pch']+1)**(1/15) - 1\n",
    "df = df.dropna()\n",
    "df['Return'] = (df['DY'] + df['Pch']) * 100\n",
    "df.loc['1989':].dropna().to_csv(data_dir / 'sp500rr4.csv', index_label='date', float_format='%g')\n",
    "\n",
    "text = ('According to historical stock market return '+\n",
    "        '\\href{www.econ.yale.edu/~shiller/data.htm}{data} from Robert Shiller, '+\n",
    "        'the inflation-adjusted trailing twenty year annual rate of return '+\n",
    "        f'of the S\\&P 500 was {df[\"Return\"].iloc[-1]:.1f} percent as '+\n",
    "        f'of {df.index[-1].strftime(\"%B %Y\")}. Real returns are currently low relative '+\n",
    "        'to the average trailing twenty year real annual return of '+\n",
    "        f'{df[\"Return\"].loc[\"1995\":\"2005\"].mean():.1f} percent during 1995--2005.')\n",
    "\n",
    "write_txt(text_dir / 'sp500rr3.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=Z1&series=5f48b7338e558e73e11dc78be7354a87&lastobs=&'\n",
    "dt = 'from=03/01/1988&to=12/31/2019&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split('; ')[1]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "sel_col = ['FA156012005.Q', 'FL152000005.Q', 'LM152010005.Q', 'LM155035015.Q', \n",
    "           'FL155035065.Q', 'LM155111005.Q', 'FL154090005.Q', 'FL154000025.Q',\n",
    "           'LM153064475.Q', 'LM152090205.Q']\n",
    "\n",
    "names = ['DPI', 'TOT', 'NFA', 'HRE', 'REQ', 'CDG', 'TFA', 'DEP', 'CEQ', 'NEQ']\n",
    "\n",
    "df = clean_data.loc[:,sel_col]\n",
    "df.columns = names\n",
    "\n",
    "df['NPA'] = clean_data.loc[:,['LM165013765.Q', 'LM165015205.Q', 'LM165035005.Q']].sum(axis=1)\n",
    "df['DSL'] = clean_data.loc[:,['LM154022375.Q', 'FL154023005.Q']].sum(axis=1)\n",
    "df['TEQ'] = df['NEQ'] + df['CEQ']\n",
    "df['OFA'] = df['TFA'] - df['DEP'] - df['DSL'] - df['TEQ']\n",
    "df['OTH'] = df['TOT'] - df['HRE'] - df['DEP'] - df['DSL'] - df['TEQ']\n",
    "\n",
    "pce = nipa_df(retrieve_table('T20304')['Data'], ['DPCERG']).loc[df.index,'DPCERG']\n",
    "pr = (pce / pce.iloc[-1])\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC']).loc[df.index,'A191RC']\n",
    "\n",
    "dfgdp = df.div(gdp, axis=0).dropna() *100\n",
    "dfgdp.loc['1989':].to_csv(data_dir / 'hhassetsgdp.csv', index_label='date', float_format='%g')\n",
    "\n",
    "ldate = f'{df.index[-1].year} Q{df.index[-1].quarter}'\n",
    "pdate = f'{df.index[-5].year} Q{df.index[-5].quarter}'\n",
    "i = df.iloc[-1] / 1000000\n",
    "g = dfgdp.iloc[-1] / 100\n",
    "s = (df.div(df.TOT, axis=0) * 100).iloc[-1]\n",
    "\n",
    "text = ('Assets '+\n",
    "        f'of households and nonprofits were valued at \\${i.TOT:.1f} trillion in {ldate}, '+\n",
    "        f'equivalent to {g.TOT*100:.0f} percent--or {g.TOT:.2f} years--of GDP. '+\n",
    "        f'Of this, \\${i.NFA:.1f} trillion, or {s.NFA:.1f} percent of the total, '+\n",
    "        f'are tangible assets and \\${i.TFA:.1f} trillion, or {s.TFA:.1f} percent, '+\n",
    "        'are financial assets.')\n",
    "text2 = (\"Tangible, or non-financial, assets include peoples' homes as well \"+\n",
    "         'as consumer durable goods, such as cars, furniture, and appliances. '+\n",
    "         f'The market value of owner-occupied real estate is \\${i.HRE:.1f} trillion in {ldate}, '+\n",
    "         f'equivalent to {g.HRE:.2f} years of GDP (see\\cbox{{green!60!teal}}). Consumer durable goods have a '+\n",
    "         f'replacement value of \\${i.CDG:.1f} trillion, or {g.CDG:.2f} years of GDP. '+\n",
    "         'Tangible assets are reported for the combined household and nonprofit sector '+\n",
    "         'and include real estate and equipment belonging to nonprofits, '+\n",
    "         f'which totals \\${i.NPA:.1f} trillion in {ldate}. ')\n",
    "text3 = ('Financial assets include equity in businesses--corporate and non-coporate--with a market value of '+\n",
    "         f'\\${i.TEQ:.1f} trillion, or {g.TEQ:.2f} years of GDP (see\\cbox{{blue!65!black}}), in {ldate}. Debt '+\n",
    "         f'securities and loan assets total \\${i.DSL:.1f} trillion, or {g.DSL:.2f} '+\n",
    "         'years of GDP (see\\cbox{{blue!55!cyan}}). Cash and deposits, including money market accounts, '+\n",
    "         f'total \\${i.DEP:.1f} trillion, or {g.DEP:.2f} years of GDP (see\\cbox{{cyan!40!white}}). All '+\n",
    "         f'other financial assets total \\${i.OFA:.1f} trillion.')\n",
    "\n",
    "write_txt(text_dir / 'hhasset1.txt', text)\n",
    "write_txt(text_dir / 'hhasset2.txt', text2)\n",
    "write_txt(text_dir / 'hhasset3.txt', text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = df.div(pr, axis=0)\n",
    "growth = growth_contrib_ann(real_data, 'TOT')\n",
    "\n",
    "(growth.dropna()[['HRE', 'DEP', 'DSL', 'TEQ', 'OTH']].loc['1989':]\n",
    " .to_csv(data_dir / 'hh_asset_growth.csv', index_label='date'))\n",
    "\n",
    "gr = growth.iloc[-1]\n",
    "grtot = [f'grew by {gr.TOT:.1f} percent' if gr.TOT >=0.1 \n",
    "         else f'decreased in value by {abs(gr.TOT):.1f} percent' if gr.TOT <= -0.1\n",
    "         else 'did not change substanatially in value'][0]\n",
    "\n",
    "grhre = [f'contributed {gr.HRE:.1f} percentage points to' if gr.HRE >=0.1\n",
    "         else f'subtracted {abs(gr.HRE):.1f} percentage points from' if gr.HRE <=-0.1\n",
    "         else 'did not contribute significantly to'][0]\n",
    "\n",
    "grteq = [f'contributed {gr.TEQ:.1f} percentage points' if gr.TEQ >=0.1\n",
    "         else f'subtracted {abs(gr.TEQ):.1f} percentage points' if gr.TEQ <=-0.1\n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "text = (f'Household and nonprofit assets {grtot} '+\n",
    "        f'over the year ending {ldate}. Owner-occupied real estate {grhre} '+\n",
    "        'total growth, and business equity '+\n",
    "        f'{grteq}.')\n",
    "\n",
    "write_txt(text_dir / 'hhasset4.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = {'TOT': '& Total Assets', 'NFA': '& \\hspace{2mm} Non-financial assets', \n",
    "      'HRE': '\\cbox{green!60!teal} & \\hspace{4mm} Owner-occupied real estate', \n",
    "      'CDG': ' & \\hspace{4mm} Consumer durable goods',\n",
    "      'NPA': ' & \\hspace{4mm} Nonprofit assets',\n",
    "      'TFA': ' & \\hspace{2mm} Financial assets',\n",
    "      'DEP': '\\cbox{cyan!40!white} & \\hspace{4mm} Deposits, incl. money market',\n",
    "      'DSL': '\\cbox{blue!55!cyan} & \\hspace{4mm} Debt securities and loans',\n",
    "      'TEQ': '\\cbox{blue!65!black} & \\hspace{4mm} Business equity',\n",
    "      'CEQ': ' & \\hspace{6mm} Corporate equities',\n",
    "      'NEQ': ' & \\hspace{6mm} Noncorporate business equity'}\n",
    "\n",
    "table = pd.DataFrame()\n",
    "table[ldate] = pd.Series({idx: f'\\${val:.1f}' if idx == 'TOT' else f'{val:.1f}' for idx, val in i.iteritems()})\n",
    "table[ldate+' '] = dfgdp.iloc[-1]\n",
    "table[pdate+' '] = dfgdp.iloc[-5]\n",
    "table['One-year'] = real_data.pct_change(4).iloc[-1] * 100\n",
    "table['Three-year'] = ((real_data.pct_change(12) + 1)**(1/3) - 1).iloc[-1] * 100\n",
    "table['20-year'] = ((real_data.pct_change(80) + 1)**(1/20) - 1).iloc[-1] * 100\n",
    "\n",
    "table.index.name = '& '\n",
    "\n",
    "table.loc[nd.keys()].rename(nd).round(1).to_csv(data_dir / 'hhasset.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-15T21:04:54.666338Z",
     "start_time": "2019-12-15T21:04:54.490298Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=Z1&series=5274f1fc3a4900aba158b78578142b2a&lastobs=&'\n",
    "dt = 'from=03/01/1988&to=12/31/2019&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d = {'FL152090005.Q': 'NW',\n",
    "     'FL152000005.Q': 'ASSETS',\n",
    "     'FL154190005.Q': 'LIAB',\n",
    "     'FA156012005.Q': 'DPI'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df = df / 1000000\n",
    "\n",
    "datelt = f'{df.index[-1].year} Q{df.index[-1].quarter}'\n",
    "\n",
    "i = df.iloc[-1]\n",
    "\n",
    "text = (f'In {datelt}, household and nonprofit institution net worth was '+\n",
    "        f'\\${i.NW:.1f} trillion, equivalent to {i.NW / i.DPI:.1f} years of disposable '+\n",
    "        f'personal income; the result of total assets of \\${i.ASSETS:.1f} trillion '+\n",
    "        f'and total liabilities of \\${i.LIAB:.1f} trillion.')\n",
    "\n",
    "write_txt(text_dir / 'nw1.txt', text)\n",
    "\n",
    "pce = nipa_df(retrieve_table('T20304')['Data'], ['DPCERG'])['DPCERG']\n",
    "\n",
    "pr = df.join(pce)['DPCERG'] / df.join(pce)['DPCERG'].iloc[-1]\n",
    "\n",
    "data = df.divide(pr, axis=0)\n",
    "\n",
    "srs = ['NW', 'DPI']\n",
    "\n",
    "result = pd.concat([data[i].dropna().pct_change(4).dropna() * 100 \n",
    "            for i in srs], axis=1)\n",
    "(result.to_csv(data_dir / 'rdpi_nw.csv', index_label='date'))\n",
    "\n",
    "gr = {}\n",
    "gr2 = {}\n",
    "for s in srs:\n",
    "    val = result[s].iloc[-1]\n",
    "    val2 = result[s].iloc[-13:].mean()\n",
    "    if val >= 0.1:\n",
    "        gr[s] = f'increased by {val:.1f} percent'\n",
    "    elif val <= -0.1:\n",
    "        gr[s] = f'decreased by {abs(val):.1f} percent'\n",
    "    else:\n",
    "        gr[s] = 'was virtually unchanged'\n",
    "    if val2 >= 0.1:\n",
    "        gr2[s] = f'grew at an average rate of {val2:.1f} percent'\n",
    "    elif val2 <= -0.1:\n",
    "        gr2[s] = f'decreased at an average rate of {abs(val2):.1f} percent'\n",
    "    else:\n",
    "        gr2[s] = 'was virtually unchanged'\n",
    "        \n",
    "text = (f'In {datelt}, inflation-adjusted net worth {gr[\"NW\"]}'+\n",
    "        ' (see\\cbox{cyan!40!white}), while '+\n",
    "        f'inflation adjusted after-tax income {gr[\"DPI\"]} '+\n",
    "        '(see {\\color{blue!50!violet}\\\\textbf{---}}). Over the past '+\n",
    "        f'three years, real net worth {gr2[\"NW\"]}, while real '+\n",
    "        f'after-tax income {gr2[\"DPI\"]}')\n",
    "\n",
    "write_txt(text_dir / 'nw2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net worth contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=Z1&series=73021951e1b749df8a5de36975a7926d&lastobs=&'\n",
    "dt = 'from=03/01/1988&to=12/31/2019&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data.loc[:, ['FC152090005.Q', 'FU155060005.Q', 'FV158090005.Q', \n",
    "                 'FU156012005.Q', 'FR158000005.Q']]\n",
    "df.columns = ['NW', 'NI', 'OVC', 'DPI', 'RV']\n",
    "\n",
    "df = df.rolling(4).sum().dropna()\n",
    "rate = (df['NI'] / df['DPI']).mean()\n",
    "rate2 = (df['NI'] / df['DPI']).iloc[-1]\n",
    "\n",
    "df['INC'] = df['DPI'] * rate\n",
    "df['INV'] = df['NI'] - df['INC']\n",
    "df['NWL'] = clean_data['FL152090005.Q']\n",
    "\n",
    "growth = (df[['OVC', 'INC', 'INV', 'RV']]\n",
    "          .div(df['NWL'].shift(4), axis=0).dropna() * 100)\n",
    "\n",
    "growth.to_csv(data_dir / 'nw_gr.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = {1: 'first', 2: 'second', 3: 'third', 4: 'fourth'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldate = dtxt(growth.index[-1])['qtr1']\n",
    "ltdate = dtxt(growth.index[-1])['qtr2']\n",
    "\n",
    "hg = growth['RV'].iloc[-1]\n",
    "inc = growth['INC'].iloc[-1]\n",
    "inv = growth['INV'].iloc[-1]\n",
    "oth = growth['OVC'].iloc[-1]\n",
    "ni = inc + inv\n",
    "\n",
    "hgtxt = [f'contributed {hg:.1f} percentage points to' if hg >= 0.1 \n",
    "         else f'subtracted {abs(hg):.1f} percentage points from' if hg <= -0.1 \n",
    "         else 'did not contribute significantly to'][0]\n",
    "\n",
    "inctxt = [f'contributed {inc:.1f} percentage points' if inc >= 0.1 \n",
    "         else f'subtracted {abs(inc):.1f} percentage points' if inc <= -0.1 \n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "invtxt = [f'and an additional {inv:.1f} percentage points were added' if inv >= 0.1 \n",
    "         else f'but {abs(inv):.1f} percentage points were subtracted' if inv <= -0.1 \n",
    "         else 'cyclical activity in investment did not seem to play a role'][0]\n",
    "\n",
    "othtxt = [f'contributed {othg:.1f} percentage points' if oth >= 0.1 \n",
    "         else f'subtracted {abs(oth):.1f} percentage points' if oth <= -0.1 \n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "hg3 = growth['RV'].iloc[-13:].mean()\n",
    "inc3 = growth['INC'].iloc[-13:].mean()\n",
    "inv3 = growth['INV'].iloc[-13:].mean()\n",
    "oth3 = growth['OVC'].iloc[-13:].mean()\n",
    "ni3 = inc3 + inv3\n",
    "\n",
    "hg3txt = [f'contributed {hg3:.1f} percentage points' if hg3 >= 0.1 \n",
    "         else f'subtracted {abs(hg3):.1f} percentage points' if hg3 <= -0.1 \n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "oth3txt = [f'contributed {oth3:.1f} percentage points' if oth3 >= 0.1 \n",
    "         else f'subtracted {abs(oth3):.1f} percentage points' if oth3 <= -0.1 \n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "ni3txt = [f'contributed {ni:.1f} percentage points' if ni >= 0.1 \n",
    "         else f'subtracted {abs(ni):.1f} percentage points' if ni <= -0.1 \n",
    "         else 'did not contribute significantly'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In the {ltdate}, holding gains {hgtxt} overall nominal net worth '+\n",
    "        f'growth. Income net invested at the 1989-onward average {rate*100:.1f} percent '+\n",
    "        f'rate {inctxt}; {invtxt} as household net investment was {rate2*100:.1f} '+\n",
    "        f'percent of disposable person income in {ldate}. Other '+\n",
    "        f'volume changes {othtxt}. Over the past three years, holding '+\n",
    "        f'gains have {hg3txt} on average; net investment (combined) has '+\n",
    "        f'{ni3txt}; and other volume changes {oth3txt}.')\n",
    "\n",
    "write_txt(text_dir / 'nwcontrib.txt', text)\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Money Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=H6&series=fafc1295c552e99d2b907eb62278e4ca&lastobs=&'\n",
    "dt = 'from=01/01/1988&to=12/31/2020&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "final2 = {}\n",
    "data = clean_data[['M2_N.WM', 'MMFIN_N.WM']].sum(axis=1)\n",
    "month_list = clean_data.resample('MS').mean().pct_change(12).dropna().index\n",
    "short_month = ''\n",
    "for date in month_list:\n",
    "    month_len = len(data.loc[date.strftime('%Y-%m')])\n",
    "    prevyr = f'{date.year - 1}-{date.month}'\n",
    "    weeks_in_short_month = 4\n",
    "    end_date = date\n",
    "    if month_len < 4:\n",
    "        end_date = date\n",
    "        short_month = date.strftime('%B %Y')\n",
    "        val = data.loc[date.strftime('%Y-%m')].mean()\n",
    "        prv = data.loc[prevyr].iloc[:month_len]\n",
    "        prev = prv.mean()\n",
    "        weeks_in_short_month = len(prv)\n",
    "    elif month_len >= 4:\n",
    "        val = data.loc[date.strftime('%Y-%m')].mean()\n",
    "        prev = data.loc[prevyr].mean()\n",
    "        end_full = date\n",
    "    final2[date] = (val / prev - 1) * 100\n",
    "    \n",
    "final = pd.Series(final2, name='value')\n",
    "final.to_csv(data_dir / 'm2imf.csv', index_label='date', header='True')\n",
    "\n",
    "s = series_info(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In January 2020, the M2 plus institutional money funds measure increased over the equivalent previous year value by 8.5 percent.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week_conv = {1: f'the first week of {short_month}', \n",
    "             2: f'the first two weeks of {short_month}', \n",
    "             3: f'the first three weeks of {short_month}',\n",
    "             4: end_full.strftime('%B %Y')}\n",
    "\n",
    "if final.iloc[-1] >= 0.1:\n",
    "    txt = f'increased over the equivalent previous year value by {final.iloc[-1]:.1f} percent'\n",
    "elif final.iloc[-1] <= -0.1:\n",
    "    txt = f'decreased over the equivalent previous year value by {abs(final.iloc[-1]):.1f} percent'   \n",
    "else:\n",
    "    txt = 'was virtually unchanged over the previous year value'\n",
    "    \n",
    "if s['days_since_match'] > 300:\n",
    "    txt2 = f\", {s['last_matched'].replace('highest level', 'fastest growth rate')}.\"\n",
    "else:\n",
    "    txt2 = '.'\n",
    "    \n",
    "text = (f'In {week_conv[weeks_in_short_month]}, '+\n",
    "        f'the M2 plus institutional money funds measure {txt}{txt2}')\n",
    "\n",
    "write_txt(text_dir / 'm2imf.txt', text)\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "m2sh = (clean_data['M2_N.WM'].iloc[-1] / (gdp.iloc[-1] / 1000)) * 100\n",
    "imfsh = (clean_data['MMFIN_N.WM'].iloc[-1] / (gdp.iloc[-1] / 1000)) * 100\n",
    "\n",
    "text2 = (f'In the week of {clean_data.index[-1].strftime(\"%B %d, %Y\")}, '+\n",
    "         f'the M2 measure of money averaged \\${clean_data[\"M2_N.WM\"].iloc[-1] / 1000:.1f} '+\n",
    "         f'trillion, equivalent to {m2sh:.1f} percent of GDP. Institution money market '\n",
    "         +f'accounts, which are not included in M2, can be combined with M2 to create a '+\n",
    "         f'slightly-broader-than-M2 measure of the money stock. These funds averaged '+\n",
    "         f'\\${clean_data[\"MMFIN_N.WM\"].iloc[-1] / 1000:.1f} trillion in the same week, '+\n",
    "         f'equivalent to {imfsh:.1f} percent of GDP. ')\n",
    "\n",
    "write_txt(text_dir / 'm2imf2.txt', text2)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the week of January 27, 2020, the M2 measure of money averaged \\\\$15.4 trillion, equivalent to 70.6 percent of GDP. Institution money market accounts, which are not included in M2, can be combined with M2 to create a slightly-broader-than-M2 measure of the money stock. These funds averaged \\\\$2.3 trillion in the same week, equivalent to 10.6 percent of GDP. '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHFA Housing Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://www.fhfa.gov/HPI_master.csv')\n",
    "\n",
    "data = df.query('frequency == \"monthly\" and place_name == \"United States\"')[['yr', 'period', 'index_sa']]\n",
    "\n",
    "data.index = [pd.to_datetime(f'{i.yr:.0f}-{i.period:.0f}-01') for idx, i in data.iterrows()]\n",
    "\n",
    "(data['index_sa'].pct_change(12) * 100).to_csv(data_dir / 'hpi.csv', index_label='date', header='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equity Payout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=5dbfee986a7636f1bc997a80c313cabc&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'\n",
    "\n",
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "srs = {'FA103164103.Q': 'Buybacks',\n",
    "       'FA106121075.Q': 'Dividends'}\n",
    "\n",
    "data = clean_data.rename(srs, axis=1)\n",
    "data['Buybacks'] = -data['Buybacks']\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "results = data.divide(gdp, axis=0)\n",
    "\n",
    "(results.dropna() * 100).loc['1989':].to_csv(data_dir / 'eq_payout.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
