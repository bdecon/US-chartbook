{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:12:42.059186Z",
     "start_time": "2019-11-14T21:12:41.675279Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import requests\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS14000003': 'White', \n",
    "          'LNS14000006': 'Black', \n",
    "          'LNS14000009': 'Hispanic',\n",
    "          'LNS14000000': 'Total',\n",
    "          'LNS13000000': 'Level'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1989, 2019)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "srs = ['White', 'Black', 'Hispanic']\n",
    "df[srs].to_csv(data_dir / 'unemp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = series_info(df['Level'])\n",
    "s2 = series_info(df['Total'])\n",
    "s3 = series_info(df['Black'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('Unemployment is currently very low. BLS '+\n",
    "        '\\href{https://www.bls.gov/news.release/empsit.nr0.htm}{reports} '+\n",
    "        f' {s[\"val_latest\"]/1000:.1f} million '+\n",
    "        f'unemployed persons in {s[\"date_latest_ft\"]}, '+\n",
    "        f'and an unemployment rate of {s2[\"val_latest\"]} percent. '+\n",
    "        'Over the past year, the black or African American unemployment rate '+\n",
    "        f'has fallen by {abs(s3[\"change_year_ago\"]):.1f} percentage '+\n",
    "        f'points to {s3[\"val_latest\"]:.1f} percent.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'unemp.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS12300060': 'PA_EPOP'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1989, 2019)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir / 'epop.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unemployment by reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS14023621': 'Job Loser', \n",
    "          'LNS14023705': 'Job Leaver', \n",
    "          'LNS14023557': 'Re-entrant',\n",
    "          'LNS14023569': 'New entrant'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1989, 2019)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "\n",
    "df.resample('QS').mean().to_csv(data_dir / 'unemp_reason.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loser = df['Job Loser'].iloc[-1]\n",
    "leaver = df['Job Leaver'].iloc[-1]\n",
    "reent = df['Re-entrant'].iloc[-1]\n",
    "newent = df['New entrant'].iloc[-1]\n",
    "ltdate = df.index[-1].strftime('%B %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In {ltdate}, {loser:.1f} percent of the labor force '+\n",
    "        'were unemployed because of losing a job or having a '+\n",
    "        f'job end, {leaver:.1f} percent were re-entrants, '+\n",
    "        f'{reent:.1f} percent new entrants, and {newent:.1f} '+\n",
    "        'percent job leavers. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'unemp_reason.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openings, Quits, Hires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'JTS00000000JOL': 'Openings', \n",
    "          'JTS00000000HIL': 'Hires', \n",
    "          'JTS00000000QUL': 'Quits',\n",
    "          'JTS00000000TSL': 'Separations',\n",
    "          'LNS13000000': 'Unemp'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (2000, 2019)\n",
    "df = bls_api(series, dates, bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df / 1000\n",
    "data[list(series.values())[:-1]].dropna().to_csv(data_dir / 'jolts.csv', index_label='date')\n",
    "\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltdate = data.index[-1].strftime('%B %Y')\n",
    "ltopen = data['Openings'].iloc[-1]\n",
    "lthire = data['Hires'].iloc[-1]\n",
    "ltquit = data['Quits'].iloc[-1]\n",
    "ltsep = data['Separations'].iloc[-1]\n",
    "ltun = data['Unemp'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = data['Openings'].iloc[-1] / data['Unemp'].iloc[-1]\n",
    "ratio3 = data['Openings'].iloc[-37] / data['Unemp'].iloc[-37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In {ltdate}, there were {ltopen:.1f} million total job openings '+\n",
    "        f'and {lthire:.1f} million hires completed. In the same month '+\n",
    "        f'there were {ltsep:.1f} million total separations, of '+\n",
    "        f'which {ltquit:.1f} million were voluntary. In comparison, '+\n",
    "        f'there are {ltun:.1f} million unemployed persons in {ltdate}. The ratio '+\n",
    "        f'of job openings to unemployed persons was {ratio:.1f} in the latest '+\n",
    "        f'month, compared to {ratio3:.1f} in the same month three years prior.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'jolts2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:28:50.975073Z",
     "start_time": "2019-11-01T00:28:50.930143Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A191RL']\n",
    "\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s).sort_index()\n",
    "\n",
    "df.to_csv(data_dir / 'gdp.csv', index_label='date')\n",
    "\n",
    "txt = f'{df.index[-1].year} Q{df.index[-1].quarter}: {df[\"A191RL\"].iloc[-1]}\\%'\n",
    "\n",
    "write_txt(data_dir / 'gdp.txt', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:28:52.112183Z",
     "start_time": "2019-11-01T00:28:52.096860Z"
    }
   },
   "outputs": [],
   "source": [
    "d = series_info(df['A191RL'])\n",
    "\n",
    "f'Real GDP grew at an annual rate of {d[\"val_latest\"]} percent in {d[\"date_latest_ft\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_info(df['A191RL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtxt(df.index[-1])['qtr1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private fixed investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:28:54.915730Z",
     "start_time": "2019-11-01T00:28:54.841627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Private fixed investment\n",
    "s = ['A008RY', 'A011RY', 'A014RY']\n",
    "\n",
    "(nipa_df(retrieve_table('T10502')['Data'], s)\n",
    " .to_csv(data_dir / 'inv.csv', index_label='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T02:34:45.331609Z",
     "start_time": "2019-11-05T02:34:45.242543Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Import and Export share of GDP\n",
    "s = ['B020RC', 'B021RC', 'B648RC', 'LA000006']\n",
    "s2 = ['A191RC']\n",
    "df = nipa_df(retrieve_table('T40205')['Data'], s)\n",
    "df['A191RC'] = nipa_df(retrieve_table('T10105')['Data'], s2)\n",
    "df['EX'] = df['B020RC'] - df['LA000006']\n",
    "df['IM'] = df['B021RC'] - df['B648RC']\n",
    "data = df.div(df['A191RC'], axis=0) * 100\n",
    "data.to_csv(data_dir / 'eximgdp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T02:40:24.139199Z",
     "start_time": "2019-11-05T02:40:24.121989Z"
    }
   },
   "outputs": [],
   "source": [
    "date = f'{qtrs[data.index[-1].quarter]} quarter of {data.index[-1].year}'\n",
    "valex = data['EX'].iloc[-1]\n",
    "valim = data['IM'].iloc[-1]\n",
    "\n",
    "text = (f'Nonpetroleum goods and services imports (see {{\\color{{green!60!teal!80!black}}'+\n",
    "        f'\\\\textbf{{---}}}}) were equivalent to {valim:.1f} percent of GDP in the {date}, '+\n",
    "        f'while exports of nonpetroleum goods and services (see {{\\\\color{{blue!90!cyan}}'+\n",
    "        f'\\\\textbf{{---}}}}) were equivalent to {valex:.1f} percent of GDP.')\n",
    "\n",
    "write_txt(text_dir / 'exim.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T21:24:16.550047Z",
     "start_time": "2019-11-10T21:24:16.547056Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T40100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goods Import Penetration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['A353RC']\n",
    "\n",
    "G = nipa_df(retrieve_table('T10205')['Data'], s).sort_index()\n",
    "\n",
    "s = ['A253RC', 'A255RC', 'B647RC', 'LA000004', 'A650RC', 'B651RC', 'A652RC', 'A653RC', 'B648RC']\n",
    "\n",
    "MX = nipa_df(retrieve_table('T40205')['Data'], s).sort_index()\n",
    "\n",
    "D = G['A353RC'] - MX['A253RC'] + MX['A255RC']\n",
    "result = (MX['A255RC'] / D)\n",
    "\n",
    "import_categories = ['B647RC', 'LA000004', 'A650RC', 'B651RC', \n",
    "                     'A652RC', 'A653RC', 'B648RC']\n",
    "Msh = MX[import_categories].div(MX['A255RC'], axis=0)\n",
    "\n",
    "Msh['Consumer'] = Msh['B647RC'] + Msh['A652RC'] + Msh['B651RC']\n",
    "Msh['Capital'] = Msh['LA000004'] - Msh['B648RC'] + Msh['A650RC'] + Msh['A653RC']\n",
    "\n",
    "\n",
    "final = Msh[['Consumer', 'Capital', 'B648RC']].multiply(result, axis=0) * 100\n",
    "\n",
    "final.to_csv(data_dir / 'goodsimpsh.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch11 = (final.loc['2011-01-01'] - final.iloc[0])\n",
    "\n",
    "chlt = (final.iloc[-1] - final.loc['2011-01-01'])\n",
    "\n",
    "chtxt = {}\n",
    "for i, v in chlt.items():\n",
    "    if v >= 0.1:\n",
    "        chtxt[i] = f'increased by the equivalent of {v:.1f} percent'\n",
    "    elif v <= -0.1:\n",
    "        chtxt[i] = f'decreased by the equivalent of {abs(v):.1f} percent'\n",
    "    else:\n",
    "        chtxt[i] = 'was virtually unchanged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'From 1989 to 2011, imports of consumer goods increased by the equivalent of {ch11[\"Consumer\"]:.1f} '+\n",
    " 'percent of domestic consumption of goods (see\\cbox{cyan!40!white}); petroleum and products imports '+\n",
    " f'increased by the equilavent of {ch11[\"B648RC\"]:.1f} percent (see\\cbox{{purple}}); '+\n",
    " 'and all other goods, primarily capital good, industrial supplies, and materials, increased by the equivalent '+\n",
    " f'of {ch11[\"Capital\"]:.1f} percent (see\\cbox{{blue!50!cyan}}). Since 2011, imports of '+\n",
    " f'consumer goods {chtxt[\"Consumer\"]} of domestic goods demand; '+\n",
    " f'imports of petroleum and products {chtxt[\"B648RC\"]}; and other '+\n",
    " f'imports {chtxt[\"Capital\"]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'goodsimpsh.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA - Financial Account Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bea_api_ita(ind_list, bea_key):\n",
    "    ''' Return tables in table list for years in range'''\n",
    "    import requests\n",
    "    from datetime import datetime\n",
    "\n",
    "    years = ','.join(map(str, range(1989, 2020)))\n",
    "\n",
    "    api_results = []\n",
    "\n",
    "    for ind in ind_list:\n",
    "        url = f'https://www.bea.gov/api/data/?&UserID={bea_key}'\\\n",
    "              f'&method=GetData&datasetname=ITA&Indicator={ind}'\\\n",
    "              f'&Frequency=QSA&Year={years}&ResultFormat=json'\n",
    "\n",
    "        r = requests.get(url)\n",
    "\n",
    "        api_results.append((ind, r.text))\n",
    "\n",
    "    return api_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_results = bea_api_ita(['FinAssetsExclFinDeriv', 'FinLiabsExclFinDeriv', 'FinDeriv', 'StatDisc'], bea_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({name: {i['TimePeriod']: i['DataValue'] \n",
    "                               for i in json.loads(series)['BEAAPI']['Results']['Data']} \n",
    "                        for name, series in api_results})\n",
    "results.index = pd.to_datetime(results.index)\n",
    "results = results.replace(r'^\\s*$', np.nan, regex=True).astype('float').rolling(4).sum()\n",
    "results['FAB'] = results['FinLiabsExclFinDeriv'] - results['FinAssetsExclFinDeriv']\n",
    "results['TOT'] = results[['FAB', 'StatDisc', 'FinDeriv']].sum(axis=1)\n",
    "final = (results.divide(gdp, axis=0).dropna(how='all') * 100).fillna(0)\n",
    "final[['FAB', 'StatDisc', 'FinDeriv', 'TOT']].to_csv(data_dir / 'fab.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = final.iloc[-1]\n",
    "liab = s.FinLiabsExclFinDeriv\n",
    "assets = s.FinAssetsExclFinDeriv\n",
    "\n",
    "ldate = f'{final.index[-1].year} Q{final.index[-1].quarter}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'Over the year ending {ldate}, net domestic acquisitions of foreign assets were '+\n",
    "        f'equivalent to {assets:.1f} percent of GDP, while net domestic incurrence of foreign '+\n",
    "        f'liabilities total {liab:.1f} percent of GDP. Domestic net borrowing totals '+\n",
    "        f'{s.TOT:.1f} percent of GDP.')\n",
    "\n",
    "write_txt(text_dir / 'fab.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:28:58.326392Z",
     "start_time": "2019-11-01T00:28:58.236434Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['DPCERY', 'A006RY', 'A822RY', 'A019RY']\n",
    "\n",
    "(nipa_df(retrieve_table('T10502')['Data'], s)\n",
    " .to_csv(data_dir / 'comp.csv', index_label='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:00.544648Z",
     "start_time": "2019-11-01T00:29:00.502083Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A939RC', 'A939RX']\n",
    "\n",
    "df = nipa_df(retrieve_table('T70100')['Data'], s)\n",
    "df['value'] = (df['A939RX'] / df['A939RX'].iloc[-1])  * df['A939RC'].iloc[-1]\n",
    "df[['value']].to_csv(data_dir / 'gdppc.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domestic Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:01.781494Z",
     "start_time": "2019-11-01T00:29:01.616041Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A261RX', 'W256RX']\n",
    "rgdi = nipa_df(retrieve_table('T11706')['Data'], s).dropna()\n",
    "\n",
    "s = ['A261RC', 'A4002C', 'W056RC', 'A107RC', 'W271RC', 'A262RC']\n",
    "df = nipa_df(retrieve_table('T11000')['Data'], s).dropna()\n",
    "\n",
    "# Calculate indirect taxes net of transfers\n",
    "df['indirect'] = df['W056RC'] - df['A107RC']\n",
    "df = df.drop(['A107RC', 'W056RC'], axis=1)\n",
    "\n",
    "# Calculate GDI deflator from real GDI series\n",
    "deflator = rgdi['A261RX'] / df['A261RC']\n",
    "deflator = deflator / deflator.iloc[-1]\n",
    "df = df.multiply(deflator, axis=0)\n",
    "\n",
    "# Calculate contributions to growth\n",
    "dft = df.diff()\n",
    "dft = dft.div(dft['A261RC'], axis=0)\n",
    "contr = dft.multiply((((df['A261RC'].pct_change() + 1) ** 4) - 1) * 100, axis=0)\n",
    "contr.round(2).to_csv(data_dir / 'gdi.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Spending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:04.471023Z",
     "start_time": "2019-11-01T00:29:04.378802Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['DGDSRY', 'DHCERY', 'DHUTRY', 'A011RY']\n",
    "\n",
    "(nipa_df(retrieve_table('T10502')['Data'], s)\n",
    " .assign(OTHSER = lambda x: x['DHCERY'] - x['DHUTRY'],\n",
    "         HOUSING = lambda x: x['A011RY'] + x['DHUTRY'])\n",
    " .drop('DHCERY', axis=1)\n",
    " .to_csv(data_dir / 'pce.csv', index_label='date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade Contribution to GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:05.737386Z",
     "start_time": "2019-11-01T00:29:05.632016Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A019RY', 'A253RY', 'A646RY', 'A255RY', 'A656RY']\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "df.to_csv(data_dir / 'nx.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:06.359811Z",
     "start_time": "2019-11-01T00:29:06.354778Z"
    }
   },
   "outputs": [],
   "source": [
    "sl = [('A253RY', 'main'), ('A646RY', 'end'), \n",
    "      ('A255RY', 'main'), ('A656RY', 'end')]\n",
    "\n",
    "d = {}\n",
    "\n",
    "for s, style in sl:\n",
    "    # Latest total value\n",
    "    value = df[s].iloc[-1]\n",
    "    d[s] = cont_subt(value, style=style)\n",
    "\n",
    "# Text for household expenditure section\n",
    "q = {1: 'first', 2: 'second', 3: 'third', 4: 'fourth'}\n",
    "    \n",
    "ld2 = f'{q[df.index[-1].quarter]} quarter of {df.index[-1].year}'\n",
    "\n",
    "\n",
    "text = (f\"Goods exports {d['A253RY']} GDP growth in the {ld2} while \"+\n",
    "        f\"services exports {d['A646RY']}. Good imports {d['A255RY']} \"+\n",
    "        f\"GDP growth and services imports {d['A656RY']}.\")\n",
    "\n",
    "write_txt(text_dir / 'trade.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:08.606211Z",
     "start_time": "2019-11-01T00:29:08.602304Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['Y001RY', 'A009RY', 'Y033RY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:09.448258Z",
     "start_time": "2019-11-01T00:29:09.373163Z"
    }
   },
   "outputs": [],
   "source": [
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "df.to_csv(data_dir / 'businv.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durable goods new orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:50:04.198769Z",
     "start_time": "2019-10-31T23:50:03.401830Z"
    }
   },
   "outputs": [],
   "source": [
    "# New orders for capital goods excluding defense or aircraft\n",
    "key = census_key\n",
    "base = 'https://api.census.gov/data/timeseries/eits/advm3'\n",
    "param = 'cell_value,time_slot_id'\n",
    "t = '&time=from+1992'\n",
    "cat = '&category_code=NXA'\n",
    "dtc = '&data_type_code=NO'\n",
    "oth = '&for=us&seasonally_adj=yes'\n",
    "\n",
    "url = f'{base}?get={param}&key={key}{cat}{dtc}{t}{oth}'\n",
    "\n",
    "r = requests.get(url).json()\n",
    "\n",
    "df = pd.DataFrame({'date': [pd.to_datetime(i[4]) for i in r[1:]], \n",
    "                   'value': [float(i[0]) for i in r[1:]]}).sort_values('date')\n",
    "\n",
    "df = df.set_index('date')\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ((df['value'].resample('QS').sum() * 4  / gdp['A191RC']).dropna() * 100).iloc[1:]\n",
    "(result.rename('value').to_csv(data_dir / 'dgno.csv', index_label='date', header=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ((df['value'].resample('QS').sum() * 4  / gdp['A191RC']).dropna() * 100).iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('New orders for manufactured core capital goods excluding aircraft '+\n",
    "        f'totalled \\${df.iloc[-1][0] / 1000:,.0f} billion in {df.index[-1].strftime(\"%B %Y\")}, '+\n",
    "        f'equivalent to {result.iloc[-1]:.1f} percent of GDP. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'dgno.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retail sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New orders for capital goods excluding defense or aircraft\n",
    "key = census_key\n",
    "base = 'https://api.census.gov/data/timeseries/eits/marts/'\n",
    "param = 'cell_value,time_slot_id,category_code'\n",
    "t = '&time=from+1992'\n",
    "dtc = '&data_type_code=SM'\n",
    "oth = '&for=us&seasonally_adj=yes'\n",
    "\n",
    "url = f'{base}?get={param}&key={key}{dtc}{t}{oth}'\n",
    "\n",
    "r = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for series in ['44000', '44X72', '44W72', '454']:\n",
    "    df[series] = pd.Series(\n",
    "        {pd.to_datetime(i[4]): \n",
    "         float(i[0]) for i in r[1:] if i[2] == series}\n",
    "    ).sort_index()\n",
    "    \n",
    "data = (df.pct_change(12) * 100).dropna()\n",
    "data['NS_3M'] = data['454'].rolling(3).mean()\n",
    "\n",
    "s = ['A191RC']\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(data_dir / 'marts.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "totval = df['44X72'].iloc[-1]\n",
    "shgdp = (totval * 12 / gdp.iloc[-1] * 100)[-1]\n",
    "totgr = data['44X72'].iloc[-1]\n",
    "datelt = df.index[-1].strftime('%B %Y')\n",
    "if totgr > 0.1:\n",
    "    grtxt = f'increased by {totgr:.1f} percent'\n",
    "elif totgr < 0.1:\n",
    "    grtxt = f'decreased by {abs(totgr):.1f} percent'\n",
    "else:\n",
    "    grtxt = 'was virtually unchanged'\n",
    "    \n",
    "totval2 = df['454'].iloc[-1]\n",
    "shgdp2 = (totval2 * 12 / gdp.iloc[-1] * 100)[-1]\n",
    "totgr2 = data['454'].iloc[-1]\n",
    "if totgr2 > 0.1:\n",
    "    grtxt2 = f'increased by {totgr2:.1f} percent'\n",
    "elif totgr2 < 0.1:\n",
    "    grtxt2 = f'decreased by {abs(totgr2):.1f} percent'\n",
    "else:\n",
    "    grtxt2 = 'was virtually unchanged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('According to the \\href{https://www.census.gov/retail/index.html}{Census Bureau}, '+\n",
    "        'retail and food service '+\n",
    "        f'sales totalled \\${totval/1000:,.1f} billion in {datelt}, equivalent '+\n",
    "        f'to roughly {shgdp:.1f} percent of GDP on an annualized basis. '+\n",
    "        'Over the past year, retail and '+\n",
    "        f'food service sales {grtxt}, without adjusting for prices. Nonstore '+\n",
    "        f'sales, which include online retailers, have {grtxt2} over the same period, and '\n",
    "        f'total \\${totval2/1000:,.1f} billion, or roughly {shgdp2:.1f} percent of GDP. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'marts.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the \\\\href{https://www.census.gov/retail/index.html}{Census Bureau}, retail and food service sales totalled \\\\$528.0 billion in November 2019, equivalent to roughly 29.4 percent of GDP on an annualized basis. Over the past year, retail and food service sales increased by 3.3 percent, without adjusting for prices. Nonstore sales, which include online retailers, have increased by 11.5 percent over the same period, and total \\\\$68.1 billion, or roughly 3.8 percent of GDP. '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retail Sales by Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = census_key\n",
    "base = 'https://api.census.gov/data/timeseries/eits/marts/'\n",
    "param = 'cell_value,time_slot_id,category_code'\n",
    "t = '&time=from+1992'\n",
    "dtc = '&data_type_code=SM'\n",
    "oth = '&for=us&seasonally_adj=no'\n",
    "\n",
    "url = f'{base}?get={param}&key={key}{dtc}{t}{oth}'\n",
    "\n",
    "r = requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_dict = {'441': 'Motor Vehicles \\& Parts', '442': 'Furniture \\& Home Furnishings', \n",
    "               '443': 'Electronics \\& Appliance', '444': 'Building \\& Garden Equipment', \n",
    "               '445': 'Food \\& Beverage Stores', '446': 'Health \\& Personal Care', \n",
    "               '447': 'Gasoline Stations', '448': 'Clothing and Accessories', \n",
    "               '451': 'Sports/Hobby/Music/Books', '452': 'General Merchandise', \n",
    "               '454': 'Nonstore', '722': 'Food Service \\& Drinking Places'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for series in series_dict.keys():\n",
    "    df[series] = pd.Series(\n",
    "        {pd.to_datetime(i[4]): \n",
    "         float(i[0]) for i in r[1:] if i[2] == series}\n",
    "    ).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = nipa_df(retrieve_table('T20100')['Data'], ['A067RC'])['A067RC']\n",
    "data = df.resample('QS').sum().rolling(4).sum().dropna().divide(dpi, axis=0).dropna() * 100\n",
    "results = pd.concat([data.loc['2015-01-01'], data.loc['2019-07-01']], axis=1).sort_values('2019-07-01', ascending=False)\n",
    "results.index = results.index.map(series_dict)\n",
    "results.round(2).to_csv(data_dir / 'rs_comp.csv', index_label='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>441</th>\n",
       "      <th>442</th>\n",
       "      <th>443</th>\n",
       "      <th>444</th>\n",
       "      <th>445</th>\n",
       "      <th>446</th>\n",
       "      <th>447</th>\n",
       "      <th>448</th>\n",
       "      <th>451</th>\n",
       "      <th>452</th>\n",
       "      <th>454</th>\n",
       "      <th>722</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1992-10-01</th>\n",
       "      <td>8.545521</td>\n",
       "      <td>1.068943</td>\n",
       "      <td>0.994496</td>\n",
       "      <td>2.675402</td>\n",
       "      <td>7.567590</td>\n",
       "      <td>1.832191</td>\n",
       "      <td>3.192860</td>\n",
       "      <td>2.453059</td>\n",
       "      <td>0.877565</td>\n",
       "      <td>5.062775</td>\n",
       "      <td>1.603354</td>\n",
       "      <td>4.143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-01-01</th>\n",
       "      <td>8.626638</td>\n",
       "      <td>1.068150</td>\n",
       "      <td>1.008842</td>\n",
       "      <td>2.662426</td>\n",
       "      <td>7.510427</td>\n",
       "      <td>1.818744</td>\n",
       "      <td>3.198483</td>\n",
       "      <td>2.446716</td>\n",
       "      <td>0.875804</td>\n",
       "      <td>5.064297</td>\n",
       "      <td>1.620430</td>\n",
       "      <td>4.120993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-04-01</th>\n",
       "      <td>8.833238</td>\n",
       "      <td>1.071808</td>\n",
       "      <td>1.027960</td>\n",
       "      <td>2.690636</td>\n",
       "      <td>7.465095</td>\n",
       "      <td>1.813808</td>\n",
       "      <td>3.210315</td>\n",
       "      <td>2.451408</td>\n",
       "      <td>0.878250</td>\n",
       "      <td>5.108593</td>\n",
       "      <td>1.633110</td>\n",
       "      <td>4.164341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-07-01</th>\n",
       "      <td>9.102671</td>\n",
       "      <td>1.083275</td>\n",
       "      <td>1.056573</td>\n",
       "      <td>2.735556</td>\n",
       "      <td>7.442898</td>\n",
       "      <td>1.823292</td>\n",
       "      <td>3.215650</td>\n",
       "      <td>2.463497</td>\n",
       "      <td>0.887874</td>\n",
       "      <td>5.188671</td>\n",
       "      <td>1.646841</td>\n",
       "      <td>4.239901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-10-01</th>\n",
       "      <td>9.305018</td>\n",
       "      <td>1.091143</td>\n",
       "      <td>1.084768</td>\n",
       "      <td>2.773585</td>\n",
       "      <td>7.368916</td>\n",
       "      <td>1.821864</td>\n",
       "      <td>3.194884</td>\n",
       "      <td>2.454541</td>\n",
       "      <td>0.896687</td>\n",
       "      <td>5.233694</td>\n",
       "      <td>1.688403</td>\n",
       "      <td>4.239493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-01</th>\n",
       "      <td>7.560724</td>\n",
       "      <td>0.736762</td>\n",
       "      <td>0.641250</td>\n",
       "      <td>2.365392</td>\n",
       "      <td>4.731642</td>\n",
       "      <td>2.153525</td>\n",
       "      <td>3.169992</td>\n",
       "      <td>1.684532</td>\n",
       "      <td>0.520306</td>\n",
       "      <td>4.416152</td>\n",
       "      <td>4.256665</td>\n",
       "      <td>4.600655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>7.529747</td>\n",
       "      <td>0.728572</td>\n",
       "      <td>0.632392</td>\n",
       "      <td>2.358665</td>\n",
       "      <td>4.715005</td>\n",
       "      <td>2.149679</td>\n",
       "      <td>3.195157</td>\n",
       "      <td>1.689485</td>\n",
       "      <td>0.496482</td>\n",
       "      <td>4.398700</td>\n",
       "      <td>4.300114</td>\n",
       "      <td>4.609784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>7.460037</td>\n",
       "      <td>0.717040</td>\n",
       "      <td>0.618815</td>\n",
       "      <td>2.347137</td>\n",
       "      <td>4.678730</td>\n",
       "      <td>2.141872</td>\n",
       "      <td>3.152290</td>\n",
       "      <td>1.667903</td>\n",
       "      <td>0.480278</td>\n",
       "      <td>4.351312</td>\n",
       "      <td>4.339268</td>\n",
       "      <td>4.597822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>7.449892</td>\n",
       "      <td>0.709770</td>\n",
       "      <td>0.605500</td>\n",
       "      <td>2.314468</td>\n",
       "      <td>4.672351</td>\n",
       "      <td>2.143494</td>\n",
       "      <td>3.138222</td>\n",
       "      <td>1.651575</td>\n",
       "      <td>0.471119</td>\n",
       "      <td>4.338132</td>\n",
       "      <td>4.418318</td>\n",
       "      <td>4.603972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>7.481959</td>\n",
       "      <td>0.705321</td>\n",
       "      <td>0.594761</td>\n",
       "      <td>2.294588</td>\n",
       "      <td>4.663809</td>\n",
       "      <td>2.136635</td>\n",
       "      <td>3.093781</td>\n",
       "      <td>1.631731</td>\n",
       "      <td>0.468452</td>\n",
       "      <td>4.305004</td>\n",
       "      <td>4.529589</td>\n",
       "      <td>4.602445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 441       442       443       444       445       446  \\\n",
       "1992-10-01  8.545521  1.068943  0.994496  2.675402  7.567590  1.832191   \n",
       "1993-01-01  8.626638  1.068150  1.008842  2.662426  7.510427  1.818744   \n",
       "1993-04-01  8.833238  1.071808  1.027960  2.690636  7.465095  1.813808   \n",
       "1993-07-01  9.102671  1.083275  1.056573  2.735556  7.442898  1.823292   \n",
       "1993-10-01  9.305018  1.091143  1.084768  2.773585  7.368916  1.821864   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2018-07-01  7.560724  0.736762  0.641250  2.365392  4.731642  2.153525   \n",
       "2018-10-01  7.529747  0.728572  0.632392  2.358665  4.715005  2.149679   \n",
       "2019-01-01  7.460037  0.717040  0.618815  2.347137  4.678730  2.141872   \n",
       "2019-04-01  7.449892  0.709770  0.605500  2.314468  4.672351  2.143494   \n",
       "2019-07-01  7.481959  0.705321  0.594761  2.294588  4.663809  2.136635   \n",
       "\n",
       "                 447       448       451       452       454       722  \n",
       "1992-10-01  3.192860  2.453059  0.877565  5.062775  1.603354  4.143442  \n",
       "1993-01-01  3.198483  2.446716  0.875804  5.064297  1.620430  4.120993  \n",
       "1993-04-01  3.210315  2.451408  0.878250  5.108593  1.633110  4.164341  \n",
       "1993-07-01  3.215650  2.463497  0.887874  5.188671  1.646841  4.239901  \n",
       "1993-10-01  3.194884  2.454541  0.896687  5.233694  1.688403  4.239493  \n",
       "...              ...       ...       ...       ...       ...       ...  \n",
       "2018-07-01  3.169992  1.684532  0.520306  4.416152  4.256665  4.600655  \n",
       "2018-10-01  3.195157  1.689485  0.496482  4.398700  4.300114  4.609784  \n",
       "2019-01-01  3.152290  1.667903  0.480278  4.351312  4.339268  4.597822  \n",
       "2019-04-01  3.138222  1.651575  0.471119  4.338132  4.418318  4.603972  \n",
       "2019-07-01  3.093781  1.631731  0.468452  4.305004  4.529589  4.602445  \n",
       "\n",
       "[108 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2015-01-01</th>\n",
       "      <th>2019-07-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Motor Vehicles \\&amp; Parts</th>\n",
       "      <td>7.66</td>\n",
       "      <td>7.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food \\&amp; Beverage Stores</th>\n",
       "      <td>4.98</td>\n",
       "      <td>4.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Food Service \\&amp; Drinking Places</th>\n",
       "      <td>4.34</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nonstore</th>\n",
       "      <td>3.53</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>General Merchandise</th>\n",
       "      <td>4.94</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gasoline Stations</th>\n",
       "      <td>3.77</td>\n",
       "      <td>3.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Building \\&amp; Garden Equipment</th>\n",
       "      <td>2.38</td>\n",
       "      <td>2.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health \\&amp; Personal Care</th>\n",
       "      <td>2.24</td>\n",
       "      <td>2.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Clothing and Accessories</th>\n",
       "      <td>1.86</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Furniture \\&amp; Home Furnishings</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electronics \\&amp; Appliance</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sports/Hobby/Music/Books</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 2015-01-01  2019-07-01\n",
       "Motor Vehicles \\& Parts                7.66        7.48\n",
       "Food \\& Beverage Stores                4.98        4.66\n",
       "Food Service \\& Drinking Places        4.34        4.60\n",
       "Nonstore                               3.53        4.53\n",
       "General Merchandise                    4.94        4.31\n",
       "Gasoline Stations                      3.77        3.09\n",
       "Building \\& Garden Equipment           2.38        2.29\n",
       "Health \\& Personal Care                2.24        2.14\n",
       "Clothing and Accessories               1.86        1.63\n",
       "Furniture \\& Home Furnishings          0.75        0.71\n",
       "Electronics \\& Appliance               0.77        0.59\n",
       "Sports/Hobby/Music/Books               0.62        0.47"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Residential construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New orders for capital goods excluding defense or aircraft\n",
    "key = census_key\n",
    "base = 'https://api.census.gov/data/timeseries/eits/resconst/'\n",
    "param = 'cell_value,time_slot_id,category_code'\n",
    "t = '&time=from+1989'\n",
    "dtc = '&data_type_code=TOTAL'\n",
    "oth = '&for=us&seasonally_adj=yes'\n",
    "\n",
    "url = f'{base}?get={param}&key={key}{dtc}{t}{oth}'\n",
    "\n",
    "r = requests.get(url).json()\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for series in ['APERMITS', 'ASTARTS']:\n",
    "    df[series] = pd.Series(\n",
    "        {pd.to_datetime(i[4]): \n",
    "         float(i[0]) for i in r[1:] if i[2] == series}\n",
    "    ).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / 'permits.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = series_info(df['APERMITS'])\n",
    "s['val_5yr_ago'] = df['APERMITS'].iloc[-61]\n",
    "\n",
    "if s['days_since_match'] > 100:\n",
    "    hlt = f\", {s['last_matched']}\"\n",
    "else:\n",
    "    hlt = ''\n",
    "    \n",
    "month = s['date_latest'].strftime('%B')\n",
    "\n",
    "d = {}\n",
    "for i in ['val_prev', 'val_year_ago', 'val_5yr_ago']:\n",
    "    mo_ch = s[\"val_latest\"] - s[i]\n",
    "    mo_pch = (s[\"val_latest\"] / s[i] - 1) * 100\n",
    "    if mo_ch >= 0.1:\n",
    "        txt = f'increased by {abs(mo_ch)*1000:,.0f} ({mo_pch:.1f} percent)'\n",
    "    elif mo_ch <= -0.1:\n",
    "        txt = f'decreased by {abs(mo_ch)*1000:,.0f} ({mo_pch:.1f} percent'\n",
    "    else:\n",
    "        txt = 'was virtually unchanged'\n",
    "        \n",
    "    d[i] = txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In {s[\"date_latest_ft\"]}, {s[\"val_latest\"]*1000:,.0f} new '+\n",
    "        f'residential building permits were issued{hlt}. '+\n",
    "        f'Permits issued {d[\"val_prev\"]} over the previous month, '+\n",
    "        f'{d[\"val_year_ago\"]} over last {month}, and '+\n",
    "        f'{d[\"val_5yr_ago\"]} total over the past five years.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'permits.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government spending and investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:14.877257Z",
     "start_time": "2019-11-01T00:29:14.788398Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A824RY', 'A825RY', 'A829RY', 'A822RY']\n",
    "\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "df.to_csv(data_dir / 'gov.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:16.184663Z",
     "start_time": "2019-11-01T00:29:16.181990Z"
    }
   },
   "outputs": [],
   "source": [
    "d = series_info(df['A822RY'])\n",
    "\n",
    "if d['val_latest'] > 0:\n",
    "    text1 = f'contributed {d[\"val_latest\"]} percentage points to' \n",
    "elif d['val_latest'] < 0:\n",
    "    text1 = f'subtracted {abs(d[\"val_latest\"])} percentage points to'\n",
    "else:\n",
    "    text1 = 'did not contribute to'\n",
    "    \n",
    "d2 = {}\n",
    "for i in ['A824RY', 'A825RY', 'A829RY']:\n",
    "    if df[i].iloc[-1] > 0:\n",
    "        ctxt = f'contributed {df[i].iloc[-1]:.2f} percentage points'\n",
    "    elif df[i].iloc[-1] < 0:\n",
    "        ctxt = f'subtracted {abs(df[i].iloc[-1]):.2f} percentage points'\n",
    "    else:\n",
    "        ctxt = 'did not contribute '\n",
    "    d2[i] = ctxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:17.558934Z",
     "start_time": "2019-11-01T00:29:17.555621Z"
    }
   },
   "outputs": [],
   "source": [
    "text = 'Government consumption expeditures and gross investment, which provide services and infrastructure, '\n",
    "\n",
    "gov = (f'{text}{text1} real GDP growth in {d[\"date_latest_ft\"]}, compared to an '+\n",
    "       f'average contribution of {d[\"one_year_mean\"]:.2f} percentage points over '+\n",
    "       f'the past year and an average of {d[\"mean\"]:.2f} percentage points since 1989. '+\n",
    "       f'In {d[\"date_latest_ft\"]}, federal defense (see\\cbox{{blue!60!black}}) {d2[\"A824RY\"]}, '+\n",
    "       f'federal nondefense (see\\cbox{{green!85!black}}) {d2[\"A825RY\"]}, and state and '+\n",
    "       f'local government (see\\cbox{{purple!70!magenta}}) {d2[\"A829RY\"]}.')\n",
    "\n",
    "write_txt(text_dir / 'gov.txt', gov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:18:43.344214Z",
     "start_time": "2019-11-01T00:18:43.326706Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government receipts and expenditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:29.092805Z",
     "start_time": "2019-11-01T00:29:29.017408Z"
    }
   },
   "outputs": [],
   "source": [
    "# State and local government\n",
    "s = ['W024RC', 'W023RC']\n",
    "\n",
    "df = nipa_df(retrieve_table('T30300')['Data'], s)\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "df['GDP'] = gdp\n",
    "\n",
    "(df.div(df['GDP'], axis=0) * 100).to_csv(data_dir / 'slggdp.csv', index_label='date')\n",
    "df = df / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldate = f'{df.index[-1].year} Q{df.index[-1].quarter}'\n",
    "gdp = df.GDP.iloc[-1]\n",
    "gdp3y = df.GDP.iloc[-13]\n",
    "gdpgr = ((gdp / gdp3y) - 1) * 100\n",
    "exp = df.W024RC.iloc[-1]\n",
    "exp3y = df.W024RC.iloc[-13]\n",
    "expsh = exp / gdp * 100\n",
    "exp3ysh = exp3y / gdp3y * 100\n",
    "expgr = ((exp / exp3y) - 1) * 100\n",
    "rec = df.W023RC.iloc[-1]\n",
    "rec3y = df.W023RC.iloc[-13]\n",
    "recsh = rec / gdp * 100\n",
    "rec3ysh = rec3y / gdp3y * 100\n",
    "recgr = ((rec / rec3y) - 1) * 100\n",
    "diff = rec - exp\n",
    "diffsh = diff / gdp * 100\n",
    "diff3y = rec3y - exp3y\n",
    "diffgr = ((diff / diff3y) - 1) * 100\n",
    "if diff < 0:\n",
    "    txt = 'deficit'\n",
    "else:\n",
    "    txt = 'surplus'\n",
    "\n",
    "recshch = recsh - rec3ysh\n",
    "rectxt = f'{[\"increased\" if recshch >= 0 else \"decreased\"][0]} by a total of {abs(recshch):.2f} percentage points'\n",
    "\n",
    "expshch = expsh - exp3ysh\n",
    "exptxt = f'{[\"increased\" if expshch >= 0 else \"decreased\"][0]} by a total of {abs(expshch):.2f} percentage points'\n",
    "\n",
    "diffch = recshch - expshch\n",
    "\n",
    "difftxt = [f'shrink by {diffch:.2f} percent of GDP' if diffch >= 0.1 \n",
    "             else f'widen by {abs(diffch):.2f} percent of GDP' if diffch <= -0.1 \n",
    "             else 'be unchanged'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'Consolidated state and local government expenditures total \\${exp:.1f} trillion, '+\n",
    "        f'or {expsh:.1f} percent of GDP, in {ldate}, and receipts total '+\n",
    "        f'\\${rec:.1f} trillion, equivalent to {recsh:.1f} percent of GDP. The combined state'+\n",
    "        f' and local government {txt} was '+\n",
    "        f'\\${abs(diff) * 1000:.0f} billion or {abs(diffsh):.2f} percent of GDP. '+\n",
    "        f'Over the past three years, the expenditures to GDP ratio {exptxt} at the '+\n",
    "        f'consolidated state and local level, and the ratio of '+\n",
    "        f'receipts to GDP has {rectxt}, causing the {txt} to {difftxt}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'govexprec1.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:31.169034Z",
     "start_time": "2019-11-01T00:29:31.092413Z"
    }
   },
   "outputs": [],
   "source": [
    "# Federal government\n",
    "s = ['W005RC', 'W013RC']\n",
    "\n",
    "df = nipa_df(retrieve_table('T30200')['Data'], s)\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "df['GDP'] = gdp\n",
    "\n",
    "(df.div(df['GDP'], axis=0) * 100).to_csv(data_dir / 'fedgdp.csv', index_label='date')\n",
    "df = df / 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldate = f'{df.index[-1].year} Q{df.index[-1].quarter}'\n",
    "gdp = df.GDP.iloc[-1]\n",
    "gdp3y = df.GDP.iloc[-13]\n",
    "gdpgr = ((gdp / gdp3y) - 1) * 100\n",
    "exp = df.W013RC.iloc[-1]\n",
    "exp3y = df.W013RC.iloc[-13]\n",
    "expsh = exp / gdp * 100\n",
    "exp3ysh = exp3y / gdp3y * 100\n",
    "expgr = ((exp / exp3y) - 1) * 100\n",
    "rec = df.W005RC.iloc[-1]\n",
    "rec3y = df.W005RC.iloc[-13]\n",
    "recsh = rec / gdp * 100\n",
    "rec3ysh = rec3y / gdp3y * 100\n",
    "recgr = ((rec / rec3y) - 1) * 100\n",
    "diff = rec - exp\n",
    "diffsh = diff / gdp * 100\n",
    "diff3y = rec3y - exp3y\n",
    "diffgr = ((diff / diff3y) - 1) * 100\n",
    "if diff < 0:\n",
    "    txt = 'deficit'\n",
    "else:\n",
    "    txt = 'surplus'\n",
    "\n",
    "recshch = recsh - rec3ysh\n",
    "rectxt = f'{[\"increased\" if recshch >= 0 else \"decreased\"][0]} by a total of {abs(recshch):.1f} percentage points'\n",
    "\n",
    "expshch = expsh - exp3ysh\n",
    "exptxt = f'{[\"increased\" if expshch >= 0 else \"decreased\"][0]} by a total of {abs(expshch):.1f} percentage points'\n",
    "\n",
    "diffch = recshch - expshch\n",
    "\n",
    "difftxt = [f'shrink by {diffch:.1f} percent of GDP' if diffch >= 0.1 \n",
    "             else f'widen by {abs(diffch):.1f} percent of GDP' if diffch <= -0.1 \n",
    "             else 'be unchanged'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In {ldate}, federal government expenditures total \\${exp:.1f} trillion, '+\n",
    "        f'equivalent to {expsh:.1f} percent of GDP, and receipts total '+\n",
    "        f'\\${rec:.1f} trillion, or {recsh:.1f} percent of GDP. The federal {txt} was therefore '+\n",
    "        f'\\${abs(diff):.1f} trillion or {abs(diffsh):.1f} percent of GDP. '+\n",
    "        f'Over the past three years, the ratio of expenditures to GDP {exptxt}, and the ratio of '+\n",
    "        f'receipts to GDP has {rectxt}, causing the {txt} to {difftxt}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'govexprec2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Debt by Holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = ['FDHBATN', 'GFDEBTN', 'FDHBFRBN', 'FDHBPIN', 'FDHBFIN']\n",
    "start = '1988-01-01'\n",
    "ftype = '&file_type=json'\n",
    "base = 'https://api.stlouisfed.org/fred/series/observations?'\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for srs in series:\n",
    "    param = f'series_id={srs}&observation_start={start}&api_key={fred_key}'\n",
    "   \n",
    "\n",
    "    url = f'{base}{param}{ftype}'\n",
    "    r = requests.get(url).json()['observations']\n",
    "    data = pd.Series({i['date']: (float(i['value']) / 1000.0) if srs in series[:2] else float(i['value']) for i in r})\n",
    "    \n",
    "    df[srs] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PD'] = df['FDHBPIN'] - df['FDHBFIN']\n",
    "df['IG'] = df['GFDEBTN'] - (df['FDHBFRBN'] + df['FDHBPIN'])\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "data = df.div(gdp / 1000.0, axis=0).dropna()\n",
    "\n",
    "(data[['PD', 'FDHBFIN', 'FDHBFRBN', 'IG']] * 100).to_csv(data_dir / 'pubdebt.csv', index_label='date')\n",
    "\n",
    "ld = pd.to_datetime(df.index[-1])\n",
    "ldate = f'{qtrs[ld.quarter]} quarter of {ld.year}'\n",
    "\n",
    "sh = df.div(df['GFDEBTN'], axis=0).iloc[-1] * 100\n",
    "lv = df.iloc[-1] / 1000\n",
    "dl = data.iloc[-1] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In the {ldate}, total public debt was \\${lv.GFDEBTN:.1f} trllion, '+\n",
    "        f'equivalent to {dl.GFDEBTN:.1f} percent of GDP. Of this, \\${lv.PD:.1f} '+\n",
    "        f'trillion, or {sh.PD:.1f} percent of the total, is held by '+\n",
    "        f'private domestic investors. An additional \\${lv.FDHBFIN:.1f} '+\n",
    "        f'trillion, or {sh.FDHBFIN:.1f} percent of the total, is held by '+\n",
    "        'foreign investors. The remainder is held by the Federal Reserve '+\n",
    "        'and various government agencies and trusts, such as the Social '+\n",
    "        'Security Trust Fund. ')\n",
    "\n",
    "write_txt(text_dir / 'pubdebt.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:33.617405Z",
     "start_time": "2019-11-01T00:29:33.460991Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['DPCERG']\n",
    "\n",
    "d = nipa_df(retrieve_table('T20304')['Data'], s)['DPCERG']\n",
    "deflator = d.iloc[-1] / d\n",
    "\n",
    "s = ['A065RC', 'A033RC', 'A041RC', 'A048RC', 'W210RC', 'A577RC', 'A061RC']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "      .assign(CAPITAL = lambda x: x['A041RC'] + x['A048RC'] + x['W210RC'],\n",
    "              TRANSFER = lambda x: x['A577RC'] - x['A061RC'])\n",
    "      .drop(['A061RC', 'A041RC', 'A048RC', 'W210RC', 'A577RC'], axis=1)\n",
    "      .multiply(deflator, axis=0))\n",
    "growth_contrib(df, 'A065RC').to_csv(data_dir / 'pi.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = growth_contrib(df, 'A065RC').rename({'A065RC': 'TOTAL', 'A033RC': 'LABOR'}, axis=1)\n",
    "\n",
    "val3y = data.rolling(12).mean().iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltdate = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "\n",
    "d = {}\n",
    "\n",
    "for i in data.keys():\n",
    "    val = data[i].iloc[-1]\n",
    "    if val >= 0.1:\n",
    "        d[i] = f'contributed {val:.2f} percentage points to'\n",
    "    elif val <= 0.1:\n",
    "        d[i] = f'subtracted {abs(val):.2f} percentage points from'\n",
    "    else:\n",
    "        d[i] = 'did not contribute significantly to'\n",
    "        \n",
    "d['TOTAL'] = (d['TOTAL']\n",
    "              .replace('contributed', 'increased at an annualized rate of')\n",
    "              .replace('subtracted', 'decreased at an annualized rate of')\n",
    "              .replace('percentage points', 'percent')\n",
    "              .replace(' to', '').replace(' from', ''))\n",
    "\n",
    "for i in ['TRANSFER', 'CAPITAL']:\n",
    "    d[i] = d[i].replace(' to', '').replace(' from', '')\n",
    "    \n",
    "    \n",
    "d2 = {}\n",
    "\n",
    "for i in data.keys():\n",
    "    val = val3y[i]\n",
    "    if val >= 0.1:\n",
    "        d2[i] = f'contributed an average of {val:.2f} percentage points'\n",
    "    elif val <= 0.1:\n",
    "        d2[i] = f'subtracted an average of {abs(val):.2f} percentage points'\n",
    "    else:\n",
    "        d2[i] = 'did not contribute significantly, on average'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'Aggregate real personal income {d[\"TOTAL\"]} in {ltdate}. '+\n",
    "        f'Labor income {d[\"LABOR\"]} overall growth, '+\n",
    "        f'capital income {d[\"CAPITAL\"]}, and welfare income {d[\"TRANSFER\"]}. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'pi.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Spending Growth Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:36:01.148553Z",
     "start_time": "2019-11-03T17:36:01.014154Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['B230RC']\n",
    "\n",
    "population = nipa_df(retrieve_table('T20100')['Data'], s)['B230RC']\n",
    "\n",
    "s = ['DPCERG']\n",
    "\n",
    "d = nipa_df(retrieve_table('T20304')['Data'], s)['DPCERG']\n",
    "deflator = d.iloc[-1] / d\n",
    "\n",
    "s = ['A067RC', 'A068RC', 'A071RC', 'DPCERC']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "      .assign(OTHER = lambda x: -(x['A068RC'] - x['DPCERC']),\n",
    "              SAVING = lambda x: -x['A071RC'])\n",
    "      .drop(['A068RC'], axis=1)\n",
    "      .divide(population, axis=0)\n",
    "      .multiply(deflator, axis=0))\n",
    "\n",
    "data = growth_contrib(df, 'DPCERC').rolling(4).mean()\n",
    "data3y = growth_contrib(df, 'DPCERC').rolling(12).mean()\n",
    "data.to_csv(data_dir / 'pcedecomp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:32:26.502517Z",
     "start_time": "2019-11-03T17:32:26.485449Z"
    }
   },
   "outputs": [],
   "source": [
    "date = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "\n",
    "pce = round(data['DPCERC'].iloc[-1], 1)\n",
    "if pce > 0:\n",
    "    pcedir = 'increased'\n",
    "elif pce < 0:\n",
    "    pcedir = 'decreased'\n",
    "else: \n",
    "    pcedir = ''\n",
    "pcetext = f'{pcedir} at an average rate of {abs(pce):.1f} percent' \n",
    "if pce == 0:\n",
    "    pcetext = 'was unchanged'\n",
    "    \n",
    "slist = ['A067RC', 'SAVING', 'OTHER']\n",
    "d = {}\n",
    "for i in slist:\n",
    "    d[i] = round(data[i].iloc[-1], 1)\n",
    "    tname = f'{i}txt'\n",
    "    if d[i] > 0:\n",
    "        tmpdir = 'added'\n",
    "    elif d[i] < 0:\n",
    "        tmpdir = 'subtracted'\n",
    "    else:\n",
    "        tmpdir = ''\n",
    "    tmptxt = f'{tmpdir} {abs(d[i]):.1f} percentage points'\n",
    "    if d[i] == 0:\n",
    "        tmptxt = \"didn't affect the total\"\n",
    "    d[tname] = tmptxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:35:29.078572Z",
     "start_time": "2019-11-03T17:35:29.072301Z"
    }
   },
   "outputs": [],
   "source": [
    "pcetxt1 = (f'Real per capita consumer spending {pcetext} over the '+\n",
    "           f'four quarters ending {date}. Changes to disposable income '+\n",
    "           f'{d[\"A067RCtxt\"]}, changes to saving {d[\"SAVINGtxt\"]}, and '+\n",
    "           f'changes to other outlays {d[\"OTHERtxt\"]}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:38:56.924300Z",
     "start_time": "2019-11-03T17:38:56.922057Z"
    }
   },
   "outputs": [],
   "source": [
    "pcetxt2 = ('Over the past three years, real per capita consumer spending '+\n",
    "           f'growth has averaged {data3y[\"DPCERC\"].iloc[-1]:.1f} percent, '+\n",
    "           f'with income growth contribuing an average of {data3y[\"A067RC\"].iloc[-1]:.1f} '+\n",
    "           'percentage points and saving subtracting an average of '+\n",
    "           f'{abs(data3y[\"SAVING\"].iloc[-1]):.1f} percentage points.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T17:40:58.269710Z",
     "start_time": "2019-11-03T17:40:58.249173Z"
    }
   },
   "outputs": [],
   "source": [
    "pcetxt = f'{pcetxt1} {pcetxt2}'\n",
    "\n",
    "write_txt(text_dir / 'pcedecomp.txt', pcetxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sectoral Accounts\n",
    "\n",
    "**NOTE:** Need to convert \"deficit\", \"borrower\" etc to parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:35.462598Z",
     "start_time": "2019-11-01T00:29:35.301107Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['W162RC', 'W994RC', 'AD01RC', 'W995RC', 'W996RC', 'AD03RC']\n",
    "df = (nipa_df(retrieve_table('T50100')['Data'], s).div(\n",
    "      nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC'], axis=0)) * 100\n",
    "\n",
    "df[['W995RC', 'W996RC', 'AD03RC']].to_csv(data_dir / 'sectbal2.csv', index_label='date')\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['PRIV'] = df['W994RC']\n",
    "data['GOV'] = df['AD01RC']\n",
    "data['ROW'] = -df['W162RC']\n",
    "data = data.dropna()\n",
    "date = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "\n",
    "data.dropna().to_csv(data_dir / 'sectbal.csv', index_label='date')\n",
    "\n",
    "priv_curr = abs(data['PRIV'].iloc[-1])\n",
    "priv_prev = abs(data.loc['2015-01-01', 'PRIV'])\n",
    "gov_curr = abs(data['GOV'].iloc[-1])\n",
    "gov_prev = abs(data.loc['2015-01-01', 'GOV'])\n",
    "row_curr = abs(data['ROW'].iloc[-1])\n",
    "row_prev = abs(data.loc['2015-01-01', 'ROW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:29:36.178257Z",
     "start_time": "2019-11-01T00:29:36.173937Z"
    }
   },
   "outputs": [],
   "source": [
    "sectbaltxt = f\"In {date}, the US private sector was a net lender (running a surplus) of the equivalent of {priv_curr:.1f} percent of GDP, compared to {priv_prev:.1f} percent in 2015 Q1. The rest of the world was a net lender to the US, to the equivalent of {row_curr:.1f} percent of GDP in {date} compared to {row_prev:.1f} percent in 2015 Q1. Balancing these transactions, the government (federal, state, and local combined) was a net borrower (running a deficit) of the equivalent of {gov_curr:.1f} percent of GDP, compared to {gov_prev:.1f} percent in 2015. \"\n",
    "print(sectbaltxt)\n",
    "\n",
    "write_txt(text_dir / 'sectbal.txt', sectbaltxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T01:28:00.791300Z",
     "start_time": "2019-11-11T01:28:00.789240Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=40e2091b3afe9c4e164d4380765c6842&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T11:25:14.471394Z",
     "start_time": "2019-11-11T11:25:14.272150Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {\n",
    "    'FL104190005.Q': 'Corporate Business',\n",
    "    'FL114190005.Q': 'Non-corporate Business',\n",
    "    'FL154190005.Q': 'Household and Nonprofit',\n",
    "    'FL214190005.Q': 'State and Local Government',\n",
    "    'FL314190005.Q': 'Federal Government'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['Total'] = df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T11:25:15.732082Z",
     "start_time": "2019-11-11T11:25:15.686083Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['DPCERG']\n",
    "pce = nipa_df(retrieve_table('T20304')['Data'], s)\n",
    "pr = (pce['DPCERG'] / pce['DPCERG'].iloc[-1])\n",
    "data = df.divide(pr, axis=0).dropna().loc['1989':]\n",
    "\n",
    "result = growth_contrib_ann(data, 'Total').dropna()\n",
    "\n",
    "result.to_csv(data_dir / 'liabgr.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datelt = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "ltval = result['Total'].iloc[-1]\n",
    "\n",
    "if ltval >= 0.1:\n",
    "    totlt = f'increased by {ltval:.1f} percent'\n",
    "elif ltval <= 0.1:\n",
    "    totlt = f'decreased by {abs(ltval):.1f} percent'\n",
    "else:\n",
    "    totlt = 'was virtually unchanged'\n",
    "    \n",
    "txt = {}\n",
    "txt2 = {}\n",
    "txt3 = {}\n",
    "\n",
    "df3 = result.rolling(12).mean().iloc[-1]\n",
    "\n",
    "for i in result.keys():\n",
    "    dtmp = df3[i]\n",
    "    if dtmp >= 0.1:\n",
    "        txt[i] = f'contributed {dtmp:.1f} percentage points per year on average'\n",
    "        txt2[i] = f'increased at an average annual rate of {dtmp:.1f} percent'\n",
    "        txt3[i] = f'contributed an annual average of {dtmp:.1f} percentage points'\n",
    "    elif dtmp <= 0.1:\n",
    "        txt[i] = f'subtracted {abs(dtmp):.1f} percentage points per year on average'\n",
    "        txt2[i] = f'increased at an average annual rate of {abs(dtmp):.1f} percent'\n",
    "        txt3[i] = f'subtracted an annual average of {abs(dtmp):.1f} percentage points'\n",
    "    else:\n",
    "        txt[i] = 'did not contribute significantly to the total'\n",
    "        txt2[i] = f'were virtually unchanged'\n",
    "        txt3[i] = 'did not contribute significantly to the total'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'Domestic liabilities {totlt} '+\n",
    "        f'over the year ending {datelt}, after adjusting for inflation. '+\n",
    "        f'Over the past three years, total domestic liabilities {txt2[\"Total\"]}. '+\n",
    "        f'The federal government {txt[\"Federal Government\"]} (see\\cbox{{blue!70}}), '+\n",
    "        f'while the state and local government {txt[\"State and Local Government\"]} (see\\cbox{{cyan!70}}). '+\n",
    "        f'Households and nonprofits {txt[\"Household and Nonprofit\"]} over this three '+\n",
    "        f'year period (see\\cbox{{orange!70}}), corporate businesses '+\n",
    "        f'{txt[\"Corporate Business\"]} (see\\cbox{{lime!70}})and '+\n",
    "        f'non-corporate businesses {txt[\"Non-corporate Business\"]} (see\\cbox{{green!80!black}}).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'liabgr.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interest rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=H15&series=398c5ba6279c57e57055c6a65c95e9d3&lastobs=&from=01/01/1989&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'RIFLGFCY10_N.B': 'Ten-year',\n",
    "    'RIFSPFF_N.B': 'Fed Funds',\n",
    "    'RIFLGFCM03_N.B': 'Three-month',\n",
    "    'RIFLGFCY02_N.B': 'Two-year'\n",
    "}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (df[df['Ten-year'] != 'ND'].astype('float')\n",
    "        .resample('M').mean().iloc[:-1]\n",
    "        .append(df.iloc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(data_dir / 'rates.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capacity Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=G17&series=316680f2d5251c61c995df7ae36b4b07&lastobs=&from=01/01/1989&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'CAPUTL.B00004.S': 'Manufacturing', 'CAPUTL.B50001.S': 'Total index'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / 'tcu.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In {df.index[-1].strftime(\"%B %Y\")}, the industrial capacity '+\n",
    "        f'utilization rate was {df[\"Total index\"].iloc[-1]:.1f} percent, '+\n",
    "        'and the manufacturing capacity utilization rate was '+\n",
    "        f'{df[\"Manufacturing\"].iloc[-1]:.1f} percent.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'tcu.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Account Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T00:18:51.088235Z",
     "start_time": "2019-11-04T00:18:50.873013Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "s = ['A191RC']\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], s)\n",
    "\n",
    "s = ['A124RC', 'A253RC', 'A255RC', 'A646RC', 'B656RC', 'B645RC',\n",
    "     'A655RC', 'A123RC']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T40100')['Data'], s)\n",
    "      .assign(GOODS = lambda x: x['A253RC'] - x['A255RC'],\n",
    "              SERVICES = lambda x: x['A646RC'] - x['B656RC'],\n",
    "              INCOME = lambda x: x['B645RC'] - x['A655RC'],\n",
    "              TRANSFERS = lambda x: - x['A123RC'])\n",
    "      .drop(s[1:], axis=1).drop_duplicates())\n",
    "\n",
    "data = (df.div(nipa_df(retrieve_table('T10105')['Data'], ['A191RC']\n",
    "               )['A191RC'], axis=0).dropna().loc['1989':].multiply(100).round(2))\n",
    "\n",
    "data.to_csv(data_dir / 'cab.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T00:18:51.962157Z",
     "start_time": "2019-11-04T00:18:51.955187Z"
    }
   },
   "outputs": [],
   "source": [
    "cab = abs(data['A124RC'].iloc[-1])\n",
    "tb = abs(data['GOODS'].iloc[-1])\n",
    "ld = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "\n",
    "text = f'As of {ld}, the US runs a current account deficit of {cab:.1f} percent of GDP, primarily as the result of a trade deficit on goods of {tb:.1f} percent of GDP.'\n",
    "\n",
    "write_txt(text_dir / 'cab.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T00:18:55.197181Z",
     "start_time": "2019-11-04T00:18:55.189648Z"
    }
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal saving rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T18:23:29.951306Z",
     "start_time": "2019-11-03T18:23:29.164081Z"
    }
   },
   "outputs": [],
   "source": [
    "series = 'PSAVERT'\n",
    "\n",
    "url = f'http://research.stlouisfed.org/fred2/series/{series}/downloaddata/{series}.csv'\n",
    "\n",
    "df = pd.read_csv(url, index_col='DATE', parse_dates=True)\n",
    "\n",
    "data = df.loc['1989':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T18:23:30.693702Z",
     "start_time": "2019-11-03T18:23:30.687996Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(data_dir / 'psavert.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datelt = data.index[-1].strftime('%B %Y')\n",
    "latest = data.iloc[-1][0]\n",
    "ch3yr = data.diff(36).iloc[-1][0]\n",
    "\n",
    "if ch3yr >= 0.1:\n",
    "    txt = f'increased by a total of {ch3yr:.1f} percentage points'\n",
    "elif ch3yr <= 0.1:\n",
    "    txt = f'decreased by a total of {abs(ch3yr):.1f} percentage points'\n",
    "else:\n",
    "    txt = 'was virtually unchanged'\n",
    "\n",
    "text = (f'As of {datelt}, the Bureau of Economic Analysis '+\n",
    "        '\\href{https://www.bea.gov/data/income-saving/personal-saving-rate}{reports} a rate '+\n",
    "        f'of personal saving of {latest:.1f} percent. Over the past three years, '+\n",
    "        f'the personal saving rate {txt}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'psavert.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = data.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "text2 = (f'\\\\node[label={{0:{{\\scriptsize {latest}\\%}}}}, circle, red, fill, inner sep=1.0pt] at'+\n",
    "         f'(axis cs:{date}, {latest}) {{}};')\n",
    "\n",
    "write_txt(text_dir / 'psavert_node.txt', text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Jobless Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T06:37:10.583245Z",
     "start_time": "2019-10-31T06:37:10.328723Z"
    }
   },
   "outputs": [],
   "source": [
    "series = 'ICSA'\n",
    "start = '1988-01-01'\n",
    "base = 'https://api.stlouisfed.org/fred/series/observations?'\n",
    "param = f'series_id={series}&observation_start={start}&api_key={fred_key}'\n",
    "ftype = '&file_type=json'\n",
    "\n",
    "url = f'{base}{param}{ftype}'\n",
    "r = requests.get(url).json()['observations']\n",
    "data = pd.DataFrame(pd.Series({i['date']: int(i['value']) / 1000 \n",
    "                               for i in r}).rename('weekly'))\n",
    "\n",
    "data['3M'] = data['weekly'].rolling(12).mean()\n",
    "\n",
    "data.to_csv(data_dir / 'icsa.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "totval = data['weekly'].iloc[-1]*1000\n",
    "datelt = dtxt(data.index[-1])['day1']\n",
    "latest3m = data[\"3M\"].iloc[-1]*1000\n",
    "prev3m = data[\"3M\"].iloc[-157]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('The Department of Labor \\href{{https://www.dol.gov/ui/data.pdf}}{{reported}} '+\n",
    "        f'{totval:,.0f} initial claims for unemployment '+\n",
    "        f'insurance during the week ending {datelt}. Over the past three months, '+\n",
    "        f'initial claims averaged {latest3m:,.0f} per week. During the same three month period '+\n",
    "        f'three years ago, initial claims averaged {prev3m:,.0f} per week.')\n",
    "\n",
    "write_txt(text_dir / 'icsa.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Department of Labor \\\\href{{https://www.dol.gov/ui/data.pdf}}{{reported}} 252,000 initial claims for unemployment insurance during the week ending December 7, 2019. Over the past three months, initial claims averaged 219,083 per week. During the same three month period three years ago, initial claims averaged 253,000 per week.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'December 7, 2019'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtxt(data.index[-1])['day1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oil Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#series = 'DCOILWTICO'\n",
    "\n",
    "#url = f'http://research.stlouisfed.org/fred2/series/{series}/downloaddata/{series}.csv'\n",
    "\n",
    "#df = pd.read_csv(url, index_col='DATE', parse_dates=True)\n",
    "\n",
    "#data = df.loc['1989':'2018'].query('VALUE != \".\"').astype('float').resample('MS').mean()\n",
    "\n",
    "#data.to_csv(data_dir / 'wti_prev.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir / 'wti_prev.csv', index_col='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = 'DCOILWTICO'\n",
    "start = '2019-01-01'\n",
    "base = 'https://api.stlouisfed.org/fred/series/observations?'\n",
    "param = f'series_id={series}&observation_start={start}&api_key={fred_key}'\n",
    "ftype = '&file_type=json'\n",
    "\n",
    "url = f'{base}{param}{ftype}'\n",
    "r = requests.get(url).json()['observations']\n",
    "df = pd.DataFrame(pd.Series({pd.to_datetime(i['date']): float(i['value']) \n",
    "                             for i in r if i['value'] != '.'}).rename('VALUE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (data['VALUE']\n",
    "     .append(df['VALUE'].resample('MS').mean())\n",
    "     .append(pd.Series([df.iloc[-1][0]], index=[df.index[-1]]).rename('VALUE')))\n",
    "\n",
    "(p.to_csv(data_dir / 'wti.csv', index_label='date', header=True))\n",
    "\n",
    "oneyr = p.pct_change(13).iloc[-1] * 100\n",
    "\n",
    "threeyr = p.pct_change(37).iloc[-1] * 100\n",
    "\n",
    "if oneyr >= 0.1:\n",
    "    oyt = f'increased by {oneyr:.1f} percent'\n",
    "elif oneyr <= -0.1:\n",
    "    oyt = f'decreased by {abs(oneyr):.1f} percent'    \n",
    "else:\n",
    "    oyt = 'been virtually unchanged'\n",
    "    \n",
    "if threeyr >= 0.1:\n",
    "    tyt = f'increased by {threeyr:.1f} percent'\n",
    "elif oneyr <= -0.1:\n",
    "    tyt = f'decreased by {abs(threeyr):.1f} percent'    \n",
    "else:\n",
    "    tyt = 'were virtually unchanged'\n",
    "    \n",
    "ltch = p.loc['2008-06-01'] - p.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'As of {p.index[-1].strftime(\"%B %d, %Y\")}, a barrel of west Texas '+\n",
    "        f'intermediate (WTI) crude oil sells for \\${p.iloc[-1]}. Over the '+\n",
    "        f'past year, this measure of oil prices has {oyt}. Over the past three '+\n",
    "        f'years, the price {tyt}. Currently, the WTI price is \\${ltch:.2f} per barrel '+\n",
    "        'below its June 2008 average.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'wti.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS17200000': 'NILF',\n",
    "          'LNS17100000': 'UNEMP'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1990, 2019)\n",
    "data = bls_api(series, dates, bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data\n",
    "df['TOTAL'] = data.astype('float').sum(axis=1)\n",
    "sh = (df['NILF'] / df['TOTAL']).rename('total') * 100\n",
    "\n",
    "sh.to_csv(data_dir / 'lf_flow.csv', index_label='date', header=True)\n",
    "\n",
    "sh.resample('QS').mean().rename('quarterly').to_csv(data_dir / 'lf_flow_q.csv', index_label='date', header=True)\n",
    "\n",
    "totval = df['TOTAL'].iloc[-1] / 1000\n",
    "nilfval = df['NILF'].iloc[-1] / 1000\n",
    "unval = df['UNEMP'].iloc[-1] / 1000\n",
    "\n",
    "shval = sh.iloc[-1]\n",
    "\n",
    "sh3y = sh.iloc[-37]\n",
    "\n",
    "ltdate = sh.index[-1].strftime('%B %Y')\n",
    "yragodt = sh.index[-37].strftime('%B %Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In {ltdate}, {totval:.1f} million people were newly employed (on a gross basis). '+\n",
    "        f'Of these, {shval:.1f} percent were not looking for work in the prior '+\n",
    "        'month. With low unemployment, new employees are being pulled '+\n",
    "        'from outside of the labor force and bypassing unemployment. '+\n",
    "        f'Three years ago, in {yragodt}, {sh3y:.1f} percent '+\n",
    "        'of the newly employed were not looking for work month prior.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'lf_flow.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wage Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T12:55:25.848260Z",
     "start_time": "2019-11-12T12:55:21.696147Z"
    }
   },
   "outputs": [],
   "source": [
    "data1, data2 = pd.Series(), pd.Series()\n",
    "columns = ['MONTH', 'YEAR', 'AGE', 'PWORWGT', 'WKWAGE', 'HRSUSL1', 'WORKFT']\n",
    "for year in range(1989, 2020):\n",
    "    df = (pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "        .query('WKWAGE > 0 and WORKFT == 1'))\n",
    "    data = df.groupby(['YEAR', 'MONTH']).apply(binned_wage)\n",
    "    data.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data.index]\n",
    "    data1 = data1.append(data)\n",
    "    \n",
    "df = pd.DataFrame({'All': data1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T12:55:52.540152Z",
     "start_time": "2019-11-12T12:55:52.511516Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rolling(3).mean().to_csv(data_dir / 'uwe_bd.csv', index_label='date')\n",
    "(df.pct_change(12).dropna() * 100).rolling(3).mean().to_csv(data_dir / 'uwe_bd_gr.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T02:04:25.735201Z",
     "start_time": "2019-11-12T02:04:24.939999Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LEU0252911200': 'value'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (2000, 2019)\n",
    "df2 = bls_api(series, dates, bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T02:27:19.261429Z",
     "start_time": "2019-11-12T02:27:19.254208Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.to_csv(data_dir / 'uwe_bls.csv', index_label='date')\n",
    "(df2.pct_change(4).dropna() * 100).to_csv(data_dir / 'uwe_bls_gr.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T12:55:34.444380Z",
     "start_time": "2019-11-12T12:55:34.423308Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union Membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_membership_rate = lambda x: np.average(x['UNIONMEM'], weights=x['PWORWGT'])\n",
    "union_coverage_rate = lambda x: np.average(x['UNION'], weights=x['PWORWGT'])\n",
    "\n",
    "unmem, uncov = pd.Series(), pd.Series()\n",
    "\n",
    "untot, nuntot = pd.Series(), pd.Series()\n",
    "\n",
    "columns = ['MONTH', 'YEAR', 'LFS', 'PWORWGT', 'UNION', 'UNIONMEM']\n",
    "for year in range(1989, 2020):\n",
    "    df = (pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "        .query('LFS == \"Employed\" and UNION in [0, 1]'))\n",
    "    data1 = df.groupby(['YEAR', 'MONTH']).apply(union_membership_rate)\n",
    "    data1.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data1.index]\n",
    "    unmem = unmem.append(data1)\n",
    "    data2 = df.groupby(['YEAR', 'MONTH']).apply(union_coverage_rate)\n",
    "    data2.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data2.index]\n",
    "    uncov = uncov.append(data2)\n",
    "    df2 = df.query('UNIONMEM == 1')   \n",
    "    data3 = df2.groupby(['YEAR', 'MONTH']).PWORWGT.sum()\n",
    "    data3.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data3.index]\n",
    "    untot = untot.append(data3)\n",
    "    df3 = df.query('UNIONMEM == 0')\n",
    "    data4 = df3.groupby(['YEAR', 'MONTH']).PWORWGT.sum()\n",
    "    data4.index = [pd.to_datetime(f'{ti[0]}-{ti[1]}-01') for ti in data4.index]\n",
    "    nuntot = nuntot.append(data4)    \n",
    "    \n",
    "data = pd.DataFrame({'Membership': unmem, 'Coverage': uncov})\n",
    "levels = pd.DataFrame({'Union': untot, 'Nonunion': nuntot})\n",
    "data['Diff'] = data['Coverage'] - data['Membership']\n",
    "final = (data.rolling(12).mean().dropna() * 100)\n",
    "final.to_csv(data_dir / 'union.csv', index_label='date')\n",
    "final2 = (levels.rolling(12).mean().dropna()) / 1000000\n",
    "\n",
    "ltdate = final.index[-1].strftime('%B %Y')\n",
    "prevdate = final.index[-13].strftime('%B %Y')\n",
    "prev2date = final.index[-25].strftime('%B %Y')\n",
    "\n",
    "ltval = final['Membership'].iloc[-1]\n",
    "prevval = final['Membership'].iloc[-13]\n",
    "prev2val = final['Membership'].iloc[-25]\n",
    "\n",
    "totvallt = final2['Union'].iloc[-1]\n",
    "totnvallt = final2['Nonunion'].iloc[-1]\n",
    "\n",
    "chlt = final2['Union'].diff(12).iloc[-1] * 1000000\n",
    "chpr = final2['Union'].diff(12).iloc[-13] * 1000000\n",
    "\n",
    "chnlt = final2['Nonunion'].diff(12).iloc[-1] * 1000000\n",
    "chnpr = final2['Nonunion'].diff(12).iloc[-13] * 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if chlt > 10:\n",
    "    chlt_txt = f'increased by {round(chlt, -3):,.0f}'\n",
    "elif chlt <= -10:\n",
    "    chlt_txt = f'decreased by {abs(round(chlt, -3)):,.0f}'\n",
    "else:\n",
    "    chlt_txt = 'were virtually unchanged'\n",
    "    \n",
    "if chnlt > 10:\n",
    "    chnlt_txt = f'increased by {round(chnlt, -3):,.0f}'\n",
    "elif chnlt <= -10:\n",
    "    chnlt_txt = f'decreased by {abs(round(chnlt, -3)):,.0f}'\n",
    "else:\n",
    "    chnlt_txt = 'were virtually unchanged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'Over the 12 months ending {ltdate}, the share of jobs held '+\n",
    "        f'by union and employee association members averaged {ltval:.1f} percent. '+\n",
    "        f'In levels, there were {totvallt:.1f} million union jobs, and '+\n",
    "        f'{totnvallt:.1f} million nonunion jobs, on average over the period. '+\n",
    "        f'This union membership rate averaged {prevval:.1f} percent during the 12 '+\n",
    "        f'months ending {prevdate}, and {prev2val:.1f} percent during the 12 '+\n",
    "        f'months ending {prev2date}. Union jobs {chlt_txt} '+\n",
    "        f'from {prevdate} to {ltdate}, while nonunion jobs {chnlt_txt}.')\n",
    "\n",
    "write_txt(text_dir / 'union.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wealth to GDP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.683462Z",
     "start_time": "2019-10-30T23:45:27.575Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=71f2e13e70c5d96bb5da3a65053d836e&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.684085Z",
     "start_time": "2019-10-30T23:45:27.577Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'LM155035005.Q': 'Real Estate', \n",
    "     'FL892090005.Q': 'Total', \n",
    "     'LM883164105.Q': 'Corporate Equities'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['Other'] = df['Total'] * 2 - df.sum(axis=1)\n",
    "\n",
    "data = (df.div(nipa_df(retrieve_table('T10105')['Data'], ['A191RC']\n",
    "               )['A191RC'], axis=0)).dropna().loc['1989':]\n",
    "data.to_csv(data_dir / 'wealthgdp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.684798Z",
     "start_time": "2019-10-30T23:45:27.580Z"
    }
   },
   "outputs": [],
   "source": [
    "d89 = data.iloc[0].round(2)\n",
    "dlt = data.iloc[-1].round(2)\n",
    "date = f'{data.index[-1].year} Q{data.index[-1].quarter}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.685570Z",
     "start_time": "2019-10-30T23:45:27.584Z"
    }
   },
   "outputs": [],
   "source": [
    "wealthtxt = f\"The ratio of US total wealth, excluding public lands, to GDP increased to {dlt['Total']} in {date} from {d89['Total']} in 1989 Q1. The market value of corporate equities (see\\cbox{{magenta!50!violet}}) increased to a {dlt['Corporate Equities']} multiple of GDP in {date} from {d89['Corporate Equities']} in 1989 Q1. The market value of residential real estate (see\\cbox{{green!80!blue}}) increased to {dlt['Real Estate']} times GDP from {d89['Real Estate']} in 1989. The other category (see\\cbox{{cyan!35!white}}), which includes tangible assets other than residential real estate less US financial obligations to the rest of the world, decreased to {dlt['Other']} from {d89['Other']} in 1989.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.686250Z",
     "start_time": "2019-10-30T23:45:27.587Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print latest date to file\n",
    "f = text_dir.joinpath('wealthgdp.txt')\n",
    "with f.open('w') as wf:\n",
    "    wf.write(wealthtxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.686890Z",
     "start_time": "2019-10-30T23:45:27.589Z"
    }
   },
   "outputs": [],
   "source": [
    "wealthtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:10:35.442122Z",
     "start_time": "2019-11-05T00:10:35.440252Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=d720788442f3511d102b43eee2bddb41&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:10:36.212893Z",
     "start_time": "2019-11-05T00:10:36.207049Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'FL104122005.Q': 'Debt Securities',\n",
    "     'FL143168005.Q': 'Bank Loans',\n",
    "     'FL143165005.Q': 'Mortgages',\n",
    "     'FL143169005.Q': 'Nonbank Loans',\n",
    "     'FL144104005.Q': 'Total',\n",
    "     'FL104104005.Q': 'Total Corporate',\n",
    "     'FL114123005.Q': 'Total Noncorporate',\n",
    "     'FL794122005.Q': 'Financial Debt Securities',\n",
    "     'FL794123005.Q': 'Financial Loans',\n",
    "     'FL794104005.Q': 'Financial Total',\n",
    "     'FL423161705.Q': 'Agency MBS'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:10:55.756953Z",
     "start_time": "2019-11-05T00:10:55.451661Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['Bank Loans and Mortgages'] = df['Bank Loans'] + df['Mortgages']\n",
    "\n",
    "df['Other'] = df['Financial Debt Securities'] - df['Agency MBS']\n",
    "\n",
    "data = (df.div(nipa_df(retrieve_table('T10105')['Data'], ['A191RC']\n",
    "               )['A191RC'], axis=0)).dropna().loc['1989':] * 100\n",
    "data.to_csv(data_dir / 'busdebtgdp2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:10:57.449073Z",
     "start_time": "2019-11-05T00:10:57.442603Z"
    }
   },
   "outputs": [],
   "source": [
    "lt_date = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "total = df['Total'].iloc[-1] / 1_000\n",
    "corp = df['Total Corporate'].iloc[-1] / 1_000\n",
    "corp_sh = corp / total * 100\n",
    "tot_gdp = data['Total'].iloc[-1]\n",
    "tot_gdp_3 = data['Total'].iloc[-13]\n",
    "\n",
    "date_3 = f'{data.index[-13].year} Q{data.index[-13].quarter}'\n",
    "tot_3 = tot_gdp - tot_gdp_3\n",
    "ds_3 = data['Debt Securities'].iloc[-1] - data['Debt Securities'].iloc[-13]\n",
    "nb_3 = data['Nonbank Loans'].iloc[-1] - data['Nonbank Loans'].iloc[-13]\n",
    "\n",
    "if tot_3 >= 1:\n",
    "    tot_text = 'increased faster than'\n",
    "    tot_text2 = 'increased'\n",
    "elif (tot_3 < 1) & (tot_3 >= -1):\n",
    "    tot_text = 'grown at about the same rate as'\n",
    "    tot_text2 = 'grew'\n",
    "else:\n",
    "    tot_text = 'fallen relative to'\n",
    "    tot_text2 = 'fell'\n",
    "    \n",
    "finmax = data['Financial Total'].max()\n",
    "finmaxdt = f'{data[\"Financial Total\"].idxmax().year} Q{data[\"Financial Total\"].idxmax().quarter}'\n",
    "finlt = data['Financial Total'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:11:00.058342Z",
     "start_time": "2019-11-05T00:11:00.055526Z"
    }
   },
   "outputs": [],
   "source": [
    "busdebt = f'As of {lt_date}, nonfinancial business debt--the debt security and loan liabilities of nonfinancial businesses--both corporate and non-corporate--totals \\${total:,.0f} billion, with \\${corp:,.0f} billion ({corp_sh:,.1f}\\%) held by corporate businesses. Over the past three years, nonfinancial business debt has {tot_text} overall economic activity. As a share of GDP, nonfinancial business debt {tot_text2} by {tot_3:.1f} percentage points to {tot_gdp:.1f} percent in {lt_date} from {tot_gdp_3:.1f} percent in {date_3}. The vast majority of the increase, {nb_3:.1f} percentage points, comes from nonbank loans (see\\\\cbox{{blue}}).'\n",
    "# Print text to file\n",
    "f = text_dir.joinpath('busdebtgdp.txt')\n",
    "with f.open('w') as wf:\n",
    "    wf.write(busdebt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:11:02.031460Z",
     "start_time": "2019-11-05T00:11:02.029317Z"
    }
   },
   "outputs": [],
   "source": [
    "fintext = f'Domestic financial sector debt has fallen as a share of GDP to {finlt:.1f} percent in {lt_date} from a housing-bubble peak of {finmax:.1f} percent in {finmaxdt}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-05T00:11:02.786628Z",
     "start_time": "2019-11-05T00:11:02.784019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print text to file\n",
    "f = text_dir.joinpath('findebtgdp.txt')\n",
    "with f.open('w') as wf:\n",
    "    wf.write(fintext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:12:35.984093Z",
     "start_time": "2019-11-14T21:12:35.981994Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=21a69f49792f26a66791418647f75234&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:12:36.820111Z",
     "start_time": "2019-11-14T21:12:36.818073Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'FL153165105.Q': 'Mortgages',\n",
    "     'FL153166000.Q': 'Consumer Credit',\n",
    "     'FL154190005.Q': 'Total'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:12:54.821399Z",
     "start_time": "2019-11-14T21:12:54.564967Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1).divide(1000)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df['Other'] = df['Total'] - df['Consumer Credit'] - df['Mortgages']\n",
    "\n",
    "table_store_fa = df.divide(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:12:55.583612Z",
     "start_time": "2019-11-14T21:12:55.534778Z"
    }
   },
   "outputs": [],
   "source": [
    "dpi = nipa_df(retrieve_table('T20100')['Data'], ['A067RC'])['A067RC']\n",
    "data = (df.div(dpi, axis=0)).dropna().loc['1989':] * 100_000\n",
    "data.to_csv(data_dir / 'hhdebt.csv', index_label='date')\n",
    "\n",
    "table_store_fa_dpi = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:12:56.410395Z",
     "start_time": "2019-11-14T21:12:56.399020Z"
    }
   },
   "outputs": [],
   "source": [
    "date = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "maxdate = f'{data.Total.idxmax().year} Q{data.Total.idxmax().quarter}'\n",
    "\n",
    "totval = (df['Total'].iloc[-1] / 1000)\n",
    "mortval = (df['Mortgages'].iloc[-1] / 1000)\n",
    "mortsh = mortval / totval * 100\n",
    "ccval = (df['Consumer Credit'].iloc[-1] / 1000)\n",
    "ccsh = ccval / totval * 100\n",
    "\n",
    "totrt = data['Total'].iloc[-1]\n",
    "maxrt = data['Total'].max()\n",
    "\n",
    "dpi3 = dpi.pct_change(12).iloc[-1] * 100\n",
    "rt3 = df.Total.pct_change(12).iloc[-1] * 100\n",
    "ch3 = data.Total.diff(12).iloc[-1]\n",
    "\n",
    "if dpi3 > 0.4:\n",
    "    dpi3txt = f'increased {abs(dpi3):.1f} percent'\n",
    "elif dpi3 < -0.4:\n",
    "    dpi3txt = f'decreased {abs(dpi3):.1f} percent'\n",
    "else:\n",
    "    dpi3txt = 'been virtually unchanged'\n",
    "    \n",
    "if rt3 > 0.4:\n",
    "    rt3txt = f'increased {abs(rt3):.1f} percent'\n",
    "elif rt3 < -0.4:\n",
    "    rt3txt = f'decreased {abs(rt3):.1f} percent'\n",
    "else:\n",
    "    rt3txt = 'been virtually unchanged'\n",
    "    \n",
    "if ch3 > 0.4:\n",
    "    ch3txt = f'increased by {abs(ch3):.1f} percentage points'\n",
    "elif ch3 < -0.4:\n",
    "    ch3txt = f'fallen by {abs(ch3):.1f} percentage points'\n",
    "else:\n",
    "    ch3txt = 'been virtually unchanged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:00.262328Z",
     "start_time": "2019-11-14T21:13:00.258535Z"
    }
   },
   "outputs": [],
   "source": [
    "text1 = f'The Federal Reserve \\href{{https://www.federalreserve.gov/releases/z1/current/default.htm}}{{reports}} total liabilities of households and nonprofits of \\${totval:,.2f} trillion in {date}. The vast majority--\\${mortval:,.2f} trillion or {mortsh:.1f} percent of the total--are home mortgages (see\\cbox{{blue!60!violet}}). Consumer credit liabilities (see\\cbox{{magenta}}) which include auto loans, credit card debt, student loans, and other personal loans, total \\${ccval:,.2f} trillion ({ccsh:.1f}\\% of the total). The remaining liabilities (see\\cbox{{orange!80!yellow}}) are primarily attributable to nonprofits.'\n",
    "\n",
    "text2 = f'The ratio of household and nonprofit debt to disposable personal income has fallen to {totrt:.1f} percent in {date} from its housing-bubble peak of {maxrt:.1f} percent in {maxdate}. Over the past three years, nominal household and nonprofit debt has {rt3txt} while nominal disposable personal income has {dpi3txt}. As a result, the ratio of household and nonprofit debt to disposable personal income has {ch3txt}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:00.969195Z",
     "start_time": "2019-11-14T21:13:00.951011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print text to file\n",
    "f = text_dir.joinpath('hhdebt1.txt')\n",
    "with f.open('w') as wf:\n",
    "    wf.write(text1)\n",
    "    \n",
    "f = text_dir.joinpath('hhdebt2.txt')\n",
    "with f.open('w') as wf:\n",
    "    wf.write(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:01.608480Z",
     "start_time": "2019-11-14T21:13:01.602747Z"
    }
   },
   "outputs": [],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:04.066171Z",
     "start_time": "2019-11-14T21:13:04.017640Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'hhdebt2.csv', index_col='Date', parse_dates=True)\n",
    "df['Mortgage Total'] = df['Mortgage'] + df['HE Revolving']\n",
    "dpi = nipa_df(retrieve_table('T20100')['Data'], ['A067RC'])['A067RC']  / 1_000_000\n",
    "data = (df.div(dpi, axis=0)).dropna(how='all') * 100\n",
    "data2 = data\n",
    "data = data.drop(['Other', 'Mortgage Total'], axis=1)\n",
    "data.to_csv(data_dir / 'hhcdebt.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:05.367730Z",
     "start_time": "2019-11-14T21:13:05.360632Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Consumer credit charts\n",
    "d = {'Mortgage': 'gray', 'HE Revolving': 'gray', \n",
    "     'Auto Loan': 'blue!60!cyan', 'Credit Card': 'red', \n",
    "     'Student Loan': 'green!80!blue', 'Total': 'gray'}\n",
    "yr3ch = data.diff(12).iloc[-1].sort_values(ascending=True)\n",
    "ltdate = data.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "ltdate2 = f'`{str(data.index[-1].year)[-2:]} Q{data.index[-1].quarter}'\n",
    "ltdate3 = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "dates = f'{data.index[-13].year} Q{data.index[-13].quarter}--`{str(data.index[-1].year)[-2:]} Q{data.index[-1].quarter}'\n",
    "\n",
    "yticklist = \",\".join(yr3ch.index)\n",
    "\n",
    "col = {}\n",
    "ind = {}\n",
    "coord = {}\n",
    "\n",
    "for i, k in enumerate(yr3ch):\n",
    "    coord[i+1] = round(k, 2)\n",
    "    ind[i+1] = i+1\n",
    "    col[i+1] = d[yr3ch.index[i]]\n",
    "    \n",
    "autocolor = d['Auto Loan']\n",
    "studcolor = d['Student Loan']\n",
    "cccolor = d['Credit Card']\n",
    "\n",
    "autoval = data[\"Auto Loan\"].iloc[-1].round(4)\n",
    "studval = data[\"Student Loan\"].iloc[-1].round(4)\n",
    "ccval = data[\"Credit Card\"].iloc[-1].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:08.180452Z",
     "start_time": "2019-11-14T21:13:08.176987Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Text for charts\n",
    "text = (f'''\\\\noindent \\\\normalsize \\hspace{{5mm}} Total Change, \\small {dates} \\\\normalsize \\hspace{{18mm}} Consumer Debt Trends \\\\footnotesize \n",
    "\\\\vspace{{1mm}}\n",
    "\n",
    "\\hspace{{2.1cm}} \\\\begin{{tikzpicture}}[trim axis left]\n",
    "\t\\\\begin{{axis}}[\\\\barplotnogrid axis y line=left, \\\\barylab{{3.7cm}}{{1.5ex}}\n",
    "\t\twidth=4.6cm, bar width=2.2ex, y=4.0ex, \n",
    "\t\tenlarge y limits={{abs=0.35cm}}, \n",
    "\t\tenlarge x limits=0.33, \\\\bbar{{x}}{{0}},\n",
    "        x tick style={{draw=none}},\n",
    "        ytick={{1,2,3,4,5,6}},\n",
    "\t\tyticklabels={{{yticklist}}},\n",
    "\t\tyticklabel style={{font=\\small, xshift=-4pt}},\n",
    "\t\tevery axis plot/.append style={{bar shift=0pt, fill}},\n",
    "\t\tnodes near coords style={{/pgf/number format/.cd,fixed zerofill,precision=1, assume math mode}}]\n",
    "\t\t\\\\addplot[{col[1]}] coordinates {{{(coord[1], ind[1])}}};\n",
    "\t\t\\\\addplot[{col[2]}] coordinates {{{(coord[2], ind[2])}}};\n",
    "\t\t\\\\addplot[{col[3]}] coordinates {{{(coord[3], ind[3])}}};\n",
    "\t\t\\\\addplot[{col[4]}] coordinates {{{(coord[4], ind[4])}}};\n",
    "\t\t\\\\addplot[{col[5]}] coordinates {{{(coord[5], ind[5])}}};\n",
    "\t\t\\\\addplot[{col[6]}] coordinates {{{(coord[6], ind[6])}}};\n",
    "\t\\end{{axis}}\n",
    "\\end{{tikzpicture}}\n",
    "\\hfill\n",
    "\\\\begin{{tikzpicture}}\n",
    "\t\\\\begin{{axis}}[\\\\bbar{{y}}{{0}}, \\dateaxisticks ytick={{2, 4, 6, 8, 10}}, \n",
    "\t\tclip=false, width=6.7cm, \n",
    "\t\txtick={{{{1999-01-01}}, {{2005-01-01}}, {{2010-01-01}}, {{2015-01-01}}, {{{ltdate}}}}},\n",
    "        minor xtick={{}}, \n",
    "        xticklabels={{`99, `05, `10, `15, {ltdate2}}}, enlarge y limits={{lower, 0.2}}, \n",
    "        enlarge x limits={{0.04}}]\n",
    "\t\\\\rebars\n",
    "\t\\stdline{{{autocolor}}}{{date}}{{Auto Loan}}{{data/hhcdebt.csv}}\n",
    "    \\\\node[label={{0:{{\\scriptsize {autoval:.1f}}}}}, circle, {autocolor}, fill, inner sep=1.5pt] at \n",
    "        (axis cs:{{{ltdate}}},{{{autoval}}}){{}};\n",
    "\t\\stdline{{{studcolor}}}{{date}}{{Student Loan}}{{data/hhcdebt.csv}}\n",
    "    \\\\node[label={{0:{{\\scriptsize {studval:.1f}}}}}, circle, {studcolor}, fill, inner sep=1.5pt] at \n",
    "        (axis cs:{{{ltdate}}},{{{studval}}}){{}};\n",
    "\t\\stdline{{{cccolor}}}{{date}}{{Credit Card}}{{data/hhcdebt.csv}}\n",
    "    \\\\node[label={{0:{{\\scriptsize {ccval:.1f}}}}}, circle, {cccolor}, fill, inner sep=1.5pt] at \n",
    "        (axis cs:{{{ltdate}}},{{{ccval}}}){{}};\n",
    "\t\\stdnode{{4.2cm}}{{1.85cm}}{{\\scriptsize \\color{{{autocolor}}}{{auto}}}}\n",
    "\t\\stdnode{{1.2cm}}{{0.9cm}}{{\\scriptsize \\color{{{studcolor}}}{{student}}}}\n",
    "\t\\stdnode{{3.9cm}}{{0.82cm}}{{\\scriptsize \\color{{{cccolor}}}{{credit card}}}}\n",
    "\t\\end{{axis}}\n",
    "\\end{{tikzpicture}}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:08.975083Z",
     "start_time": "2019-11-14T21:13:08.972832Z"
    }
   },
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'hhcdebt2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:09.986127Z",
     "start_time": "2019-11-14T21:13:09.980897Z"
    },
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Consumer credit text\n",
    "totval = df['Total'].iloc[-1]\n",
    "totval2 = data['Total'].iloc[-1]\n",
    "\n",
    "totvalch = df['Total'].diff(12).iloc[-1]\n",
    "dpich = dpi.diff(12).iloc[-1]\n",
    "\n",
    "if totvalch >= 0.1:\n",
    "    tvdir = f'increased by \\${abs(totvalch):.2f} trillion'\n",
    "elif totvalch <= -0.1:\n",
    "    tvdir = f'decreased by \\${abs(totvalch):.2f} trillion'\n",
    "else:\n",
    "    tvdir = 'was virtually unchanged'\n",
    "    \n",
    "if dpich >= 0.1:\n",
    "    dpidir = f'an increase of \\${abs(dpich):.2f} trillion'\n",
    "elif dpich <= -0.1:\n",
    "    dpidir = f'a decrease of \\${abs(dpich):.2f} trillion'\n",
    "else:\n",
    "    dpidir = 'virtually no change'\n",
    "    \n",
    "totvalch2 = data['Total'].diff(12).iloc[-1]\n",
    "\n",
    "\n",
    "if totvalch2 >= 0.1:\n",
    "    tvdir2 = f'has risen by {abs(totvalch2):.1f} percentage points'\n",
    "elif totvalch2 <= -0.1:\n",
    "    tvdir2 = f'has fallen by {abs(totvalch2):.1f} percentage points'\n",
    "else:\n",
    "    tvdir2 = 'was virtually unchanged'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:10.773671Z",
     "start_time": "2019-11-14T21:13:10.771082Z"
    }
   },
   "outputs": [],
   "source": [
    "cctxt1 = f'Federal Reserve Bank of New York (FRBNY) \\href{{https://www.newyorkfed.org/microeconomics/hhdc/background.html}}{{analysis}} of Equifax data shows \\\\${totval} trillion in total consumer debt in {ltdate3}, which is equivalent to {totval2:.1f} percent of disposable personal income.'\n",
    "\n",
    "cctxt2 = f'Over the past three years, total consumer debt has {tvdir} compared to {dpidir} in disposable personal income. As a result, the ratio of total consumer debt to disposable personal income {tvdir2} over this period.'\n",
    "\n",
    "text2 = f'{cctxt1} {cctxt2}'\n",
    "\n",
    "write_txt(text_dir / 'hhcdebt3.txt', text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:13:12.886862Z",
     "start_time": "2019-11-14T21:13:12.884172Z"
    }
   },
   "outputs": [],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = {}\n",
    "sh = {}\n",
    "gr = {}\n",
    "\n",
    "for series in ['Mortgage Total', 'Auto Loan', 'Student Loan', 'Credit Card']:\n",
    "    tot[series] = df[series].iloc[-1] * 1000\n",
    "    sh[series] = data2[series].iloc[-1]\n",
    "    grtmp = (data2[series].diff(12)).iloc[-1]\n",
    "    if round(grtmp, 1) >= 0.1:\n",
    "        gr[series] = f'an increase of {grtmp:.1f} percentage points'\n",
    "    elif round(grtmp, 1) <= -0.1:\n",
    "        gr[series] = f'a decrease of {abs(grtmp):.1f} percentage points'\n",
    "    else:\n",
    "        gr[series] = 'virtually no change'\n",
    "        \n",
    "mgr = data2['Mortgage Total'].diff(12).iloc[-1]        \n",
    "gr['Mortgage Total'] = f'fell by {abs(mgr):.1f} percentage points'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt3 = ('According to the same FRBNY data, mortgage debt, including home '+\n",
    "        f'equity lines of credit, totalled \\${tot[\"Mortgage Total\"]:,.0f} '+\n",
    "        f'billion in {ltdate3}, equivalent to {sh[\"Mortgage Total\"]:.1f} '+\n",
    "        f'percent of disposable personal income (DPI). Student loans '+\n",
    "        f'totalled \\${tot[\"Student Loan\"]:,.0f} billion, or '+\n",
    "        f'{sh[\"Student Loan\"]:.1f} percent of DPI; auto loans totalled '+\n",
    "        f'\\${tot[\"Auto Loan\"]:,.0f} billion ({sh[\"Auto Loan\"]:.1f} percent '+\n",
    "        f'of DPI); and credit card debt totalled '+\n",
    "        f'\\${tot[\"Credit Card\"]:,.0f} billion ({sh[\"Credit Card\"]:.1f} percent of DPI).' )\n",
    "\n",
    "\n",
    "txt4 = ('Over the past three years, the ratio of total mortgage debt to disposable '+\n",
    "        f'personal income {gr[\"Mortgage Total\"]}, compared to '+\n",
    "        f'{gr[\"Student Loan\"]} for student loans, '+\n",
    "        f'{gr[\"Auto Loan\"]} for auto loans, and '+\n",
    "        f'{gr[\"Credit Card\"]} for credit card debt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'hhcdebt4.txt', txt3)\n",
    "write_txt(text_dir / 'hhcdebt5.txt', txt4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:22:50.803835Z",
     "start_time": "2019-11-14T21:22:50.776360Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Household debt and consumer credit table\n",
    "dtlt = pd.to_datetime(df.index[-1])\n",
    "dt2 = pd.to_datetime(df.index[-2])\n",
    "dt3y = pd.to_datetime(df.index[-13])\n",
    "dt13 = pd.to_datetime('2013-01-01')\n",
    "dt03 = pd.to_datetime('2003-01-01')\n",
    "\n",
    "dts = [dtlt, dt2]\n",
    "\n",
    "dts2 = [dtlt, dt2, dt3y, dt13, dt03]\n",
    "\n",
    "for x in [df, data2]:\n",
    "    x['Mortgage Total'] = x['Mortgage'] + x['HE Revolving']\n",
    "    x['Non-Mortgage Total'] = (x['Auto Loan'] + x['Credit Card'] \n",
    "                               + x['Student Loan'] + x['Other'])\n",
    "\n",
    "    \n",
    "# Attempt to handle CCP coming out first\n",
    "for x in [table_store_fa, table_store_fa_dpi]:\n",
    "    if dtlt not in x.index:\n",
    "        x.at[dtlt, :] = '--'\n",
    "\n",
    "d1 = {'Total': 'Financial Accounts Total*',\n",
    "      'Mortgages': '\\hspace{2mm} \\cbox{blue!60!violet} Mortgage Debt Total',\n",
    "      'Consumer Credit': '\\hspace{2mm} \\cbox{magenta} Consumer Credit',\n",
    "      'Other': '\\hspace{2mm} \\cbox{orange!80!yellow} Other'}\n",
    "\n",
    "d2 = {'Total': 'Consumer Credit Panel Total',\n",
    "      'Mortgage Total': '\\hspace{2mm} Mortgage Debt Total',\n",
    "      'Mortgage': '\\hspace{4mm} Mortgage',\n",
    "      'HE Revolving': '\\hspace{4mm} Home Equity Revolving',\n",
    "      'Non-Mortgage Total': '\\hspace{2mm} Consumer Credit',\n",
    "      'Auto Loan': f'\\hspace{{4mm}} \\cbox{{{autocolor}}} Auto Loan',\n",
    "      'Credit Card': f'\\hspace{{4mm}} \\cbox{{{cccolor}}} Credit Card',\n",
    "      'Student Loan': f'\\hspace{{4mm}} \\cbox{{{studcolor}}} Student Loan',\n",
    "      'Other': '\\hspace{4mm} Other'}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "for dt in dts:\n",
    "    dtmp = f'{dt.year} Q{dt.quarter}'\n",
    "    for srs in [table_store_fa]:\n",
    "        for k, v in d1.items():\n",
    "            if srs.loc[dt, k] != '--':\n",
    "                final.at[v, dtmp] = f'\\${srs.loc[dt, k]:.2f}T'\n",
    "            else: final.at[v, dtmp] = srs.loc[dt, k]\n",
    "    for srs in [df]:\n",
    "        for k, v in d2.items():            \n",
    "            final.at[v, dtmp] = f'\\${srs.loc[dt, k]:.2f}T' \n",
    "            \n",
    "for dt in dts2:\n",
    "    dtmp = f'`{str(dt.year)[2:]} Q{dt.quarter}'\n",
    "    for srs in [table_store_fa_dpi]:\n",
    "        for k, v in d1.items():\n",
    "            if srs.loc[dt, k] != '--':\n",
    "                final.at[v, dtmp] = round(srs.loc[dt, k], 1)\n",
    "            else: \n",
    "                final.at[v, dtmp] = srs.loc[dt, k]\n",
    "    for srs in [data2]:\n",
    "        for k, v in d2.items():\n",
    "            final.at[v, dtmp] = round(srs.loc[dt, k], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-14T21:22:51.470193Z",
     "start_time": "2019-11-14T21:22:51.467011Z"
    }
   },
   "outputs": [],
   "source": [
    "final.to_csv(data_dir / 'hhcdebt.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T19:55:55.127341Z",
     "start_time": "2019-11-10T19:55:55.122619Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Income as return on total HH assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T02:57:58.232781Z",
     "start_time": "2019-11-06T02:57:58.226753Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=906ccd6e7fcae1e4f20ac00b86ade272&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T03:30:26.151028Z",
     "start_time": "2019-11-06T03:30:26.093281Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'LM152010005.Q': 'Nonfinancial',\n",
    "     'FL154090005.Q': 'Financial'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df['Total'] = df['Nonfinancial'] + df['Financial']\n",
    "s = ['A067RC']\n",
    "\n",
    "df['DPI'] = nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "df['DPINF'] = df['Nonfinancial'].divide(df['Total'], axis=0)\n",
    "df['DPIF'] = df['Financial'].divide(df['Total'], axis=0)\n",
    "df['DPIsh'] = df['DPI'].divide(df['Total'], axis=0)\n",
    "df['DPINFsh'] = df['DPINF'] * df['DPIsh']\n",
    "df['DPIFsh'] = df['DPIF'] * df['DPIsh']\n",
    "\n",
    "df = df * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T03:38:37.934798Z",
     "start_time": "2019-11-06T03:38:37.930134Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / 'dpish.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:06:53.360114Z",
     "start_time": "2019-11-11T13:06:53.356245Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic Detail for Housing Wealth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:56:37.149082Z",
     "start_time": "2019-11-11T13:56:37.146810Z"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/releases/efa/state-census-region-housing-wealth.csv'\n",
    "\n",
    "regions = ['Northeast', 'Midwest', 'West', 'South', 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:56:38.141728Z",
     "start_time": "2019-11-11T13:56:37.982446Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(url, index_col=0)\n",
    "data.index = pd.to_datetime([f'{i[:4]}-{int(i[-1]) * 3 - 2}-01' for i in data.index])\n",
    "data = data.rename({'National': 'US'}, axis=1)[regions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T13:55:45.089914Z",
     "start_time": "2019-11-11T13:55:43.276664Z"
    }
   },
   "outputs": [],
   "source": [
    "series = {'EOWNOCCNEQ176N': 'Northeast_Q', \n",
    "          'EOWNOCCMWQ176N': 'Midwest_Q', \n",
    "          'EOWNOCCSOQ176N': 'South_Q', \n",
    "          'EOWNOCCWEQ176N': 'West_Q', \n",
    "          'EOWNOCCUSQ176N': 'US_Q'}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for srs, name in series.items():\n",
    "    url = f'http://research.stlouisfed.org/fred2/series/{srs}/downloaddata/{srs}.csv'\n",
    "    s = pd.read_csv(url, index_col='DATE', parse_dates=True)['VALUE']\n",
    "    df[name] = s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T15:56:13.968019Z",
     "start_time": "2019-11-11T15:56:13.947176Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "for region in regions:\n",
    "    regionq = f'{region}_Q'\n",
    "    regionp = f'{region}_P'\n",
    "    \n",
    "    total_value = data[region]\n",
    "    \n",
    "    quantity = df[regionq]\n",
    "    \n",
    "    unit_price = total_value / quantity\n",
    "    \n",
    "    growth = total_value.pct_change(4) * 100\n",
    "    \n",
    "    price_growth = unit_price.pct_change(4) * 100\n",
    "    \n",
    "    quantity_growth = growth - price_growth\n",
    "    \n",
    "    results[regionq] = quantity_growth \n",
    "    results[regionp] = price_growth \n",
    "\n",
    "results = results.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-11T15:59:04.107502Z",
     "start_time": "2019-11-11T15:59:04.102055Z"
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv(data_dir / 'val_ooh.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household formation estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T22:38:00.434229Z",
     "start_time": "2019-11-02T22:37:59.775137Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "files = ['histtab8.xlsx', 'hist_tab_8a_v2018.xlsx']\n",
    "url = 'https://www.census.gov/housing/hvs/data/'\n",
    "\n",
    "results = {}\n",
    "\n",
    "for file in files:\n",
    "    data = pd.read_excel(data_dir / file).iloc[4:, :5]\n",
    "    data.columns = ['category', 'Q1', 'Q2', 'Q3', 'Q4']\n",
    "    years = []\n",
    "    for h in data[data['Q1'] == '1st Qtr'].index - 1:\n",
    "        year_raw = data.loc[h, 'Q1']\n",
    "        if type(year_raw) == int:\n",
    "            year = year_raw\n",
    "        elif type(year_raw) == str:\n",
    "            year = int(year_raw[:4])\n",
    "        elif type(year) == float:\n",
    "            year = year + 1\n",
    "        years.append(year)\n",
    "    data.loc[data['Q1'] == '1st Qtr', 'category'] = years\n",
    "    data = data.dropna(subset=['category'])\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    levels = pd.DataFrame()\n",
    "    for series in ['Owner', 'Renter']:\n",
    "        srs = data.loc[data['category'].astype('str').str.contains(series)]\n",
    "        srs.index = years\n",
    "        srs = srs[['Q1', 'Q2', 'Q3', 'Q4']].unstack().swaplevel()\n",
    "        srs.index = pd.to_datetime([f'{i[0]}-{i[1]}' for i in srs.index])\n",
    "        srs = srs.sort_index()\n",
    "        df[series] = srs\n",
    "        levels[series] = srs\n",
    "    df = df.dropna()\n",
    "    df['Total'] = df.sum(axis=1)\n",
    "    \n",
    "    # Convert to share of total change\n",
    "    for s in ['Owner', 'Renter']:  \n",
    "        df[s] = ((df[s] - df[s].shift(4))\n",
    "                  /df['Total'].shift(4)) * 100\n",
    "        \n",
    "    df = (df.reset_index()\n",
    "            .drop_duplicates(subset='index', keep='last')\n",
    "            .set_index('index'))\n",
    "    \n",
    "    results[file] = df[['Owner', 'Renter']].dropna().rolling(4).mean().loc['1989':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-02T22:38:01.660808Z",
     "start_time": "2019-11-02T22:38:01.634338Z"
    }
   },
   "outputs": [],
   "source": [
    "final = results['histtab8.xlsx'].loc[:'2001'].append(results['hist_tab_8a_v2018.xlsx'].loc['2002':])\n",
    "final['pop'] = (nipa_df(retrieve_table('T70100')['Data'], ['B230RC'])\n",
    "                .pct_change(4).dropna() * 100)\n",
    "\n",
    "final.to_csv(data_dir / 'hhform.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = levels.dropna()\n",
    "ldate = f'{levels.index[-1].year} Q{levels.index[-1].quarter}'\n",
    "pdate = f'{levels.index[-2].year} Q{levels.index[-2].quarter}'\n",
    "tot = levels.iloc[-1].sum() / 1000\n",
    "rtot = levels['Renter'].iloc[-1] / 1000\n",
    "rsh = rtot / tot * 100\n",
    "otot = levels['Owner'].iloc[-1] / 1000\n",
    "osh = otot / tot * 100\n",
    "\n",
    "ch = levels.diff(4).iloc[-1]\n",
    "incdec = ['increase' if ch.sum() >= 0 else 'decrease']\n",
    "chtot = [f'{abs(ch.sum()) / 1000:.1f} million' if ch.sum() > 1000 else f'{abs(ch.sum()):.0f} thousand'][0]\n",
    "\n",
    "t = {name: [f'{abs(s) / 1000:.1f} million {[\"net new\" if s >= 0 else \"net fewer\"][0]}' \n",
    "            if s > 1000 \n",
    "            else f'{abs(s):.0f} thousand {[\"net new\" if s >= 0 else \"net fewer\"][0]}'][0]\n",
    "     for name, s in [('tot', ch.sum()), ('rent', ch.Renter), ('own', ch.Owner)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'As of {ldate}, there are {tot:.1f} million total occupied '+\n",
    "        f'housing units in the US, of which {rtot:.1f} million ({rsh:.1f} percent) '+\n",
    "        f'are rented, and {otot:.1f} million ({osh:.1f} percent) are '+\n",
    "        'owner-occupied. There was a net total '+\n",
    "        f'{incdec[0]} of {chtot} housing units '+\n",
    "        f'over the year ending {ldate}, the result of {t[\"rent\"]} '+\n",
    "        f'renter households and {t[\"own\"]} '+\n",
    "        f'owner-occupied households. ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totgr = final[['Owner', 'Renter']].sum(axis=1).iloc[-1]\n",
    "ogr = final['Owner'].iloc[-1]\n",
    "rgr = final['Renter'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Total'] = final[['Owner', 'Renter']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = {name: [f\"{['increased' if s >= 0 else 'decreased'][0]} by {abs(s):.1f} percent\"][0] \n",
    "      for name, s in final.iloc[-1].iteritems()}\n",
    "\n",
    "t3 = {name: [f\"{['an increase' if s >= 0 else 'a decreased'][0]} of {abs(s):.1f} percent\"][0] \n",
    "      for name, s in final.iloc[-2].iteritems()}\n",
    "\n",
    "t4 = {name: [f\"{['a contribution' if s >= 0 else 'a reduction'][0]} of {abs(s):.1f} percent\"][0] \n",
    "      for name, s in final.iloc[-2].iteritems()}\n",
    "\n",
    "t5 = {name: [f\"{[f'contributed {abs(s):.1f} percent to' if s >= 0 else f'subtracted {abs(s):.1f} percent from'][0]}\"][0] \n",
    "      for name, s in final.iloc[-1].iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = (f'Over the year ending {ldate}, the total number of occupied housing units '+\n",
    "         f'{t2[\"Total\"]}, compared to {t3[\"Total\"]} percent in {pdate}. Owner-occupied '+\n",
    "         f'units {t5[\"Owner\"]} total household formation on average over the year, compared to a '+\n",
    "         f'{t4[\"Renter\"]} from rented units.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = text + text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'hhform1.txt', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T21:32:21.272688Z",
     "start_time": "2019-11-03T21:32:21.268715Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T20100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporate Profits Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:30:02.269523Z",
     "start_time": "2019-11-01T00:30:02.170587Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A032RC', 'A438RC', 'A054RC', 'B056RC', 'A127RC']\n",
    "cprof = nipa_df(retrieve_table('T11200')['Data'], s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:30:02.999635Z",
     "start_time": "2019-11-01T00:30:02.991875Z"
    }
   },
   "outputs": [],
   "source": [
    "cprof['NNI'] = cprof['A032RC'] - cprof['A438RC']\n",
    "cprof['TAX'] = cprof['A054RC'] / cprof['NNI'] * 100 \n",
    "cprof['DIV'] = cprof['B056RC'] / cprof['NNI'] * 100 \n",
    "cprof['RE'] = cprof['A127RC'] / cprof['NNI'] * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:30:03.695651Z",
     "start_time": "2019-11-01T00:30:03.688037Z"
    }
   },
   "outputs": [],
   "source": [
    "cprof[['TAX', 'DIV', 'RE']].to_csv(data_dir / 'cprof.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporate profits source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:30:06.166913Z",
     "start_time": "2019-11-01T00:30:06.029974Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['W170RC', 'A262RC', 'W986RC', 'A922RC']\n",
    "df1 = nipa_df(retrieve_table('T50100')['Data'], s)\n",
    "\n",
    "s = ['A123RC']\n",
    "df2 = nipa_df(retrieve_table('T40100')['Data'], s)\n",
    "\n",
    "s = ['A001RC']\n",
    "df3 = nipa_df(retrieve_table('T10705')['Data'], s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:30:06.802300Z",
     "start_time": "2019-11-01T00:30:06.789716Z"
    }
   },
   "outputs": [],
   "source": [
    "cprof = pd.DataFrame()\n",
    "cprof['ROW Saving'] = (df2['A123RC'] / df3['A001RC']) * 100\n",
    "cprof['HH Saving'] = (- df1['W986RC'] / df3['A001RC']) * 100\n",
    "cprof['Gov Saving'] = (- df1['A922RC'] / df3['A001RC']) * 100\n",
    "cprof['Investment'] = ((df1['W170RC'] - df1['A262RC']) / df3['A001RC']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-01T00:30:07.462045Z",
     "start_time": "2019-11-01T00:30:07.457372Z"
    }
   },
   "outputs": [],
   "source": [
    "cprof.to_csv(data_dir / 'cprof2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T23:45:29.704755Z",
     "start_time": "2019-10-30T23:45:27.663Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T50100'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T17:22:29.201984Z",
     "start_time": "2019-11-06T17:22:25.977027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'PRS85006092': 'value',\n",
    "          'PRS85006032': 'hours',\n",
    "          'PRS85006042': 'output'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1989, 2019)\n",
    "df = bls_api(series, dates, bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T17:35:01.313905Z",
     "start_time": "2019-11-06T17:35:01.288785Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(data_dir / 'lprod.csv', index_label='date')\n",
    "\n",
    "d = series_info(df['value'])\n",
    "\n",
    "s = {}\n",
    "\n",
    "for srs in list(series.values()):\n",
    "    s[srs] = {}\n",
    "    tmp = series_info(df[srs])\n",
    "    for i in ['val_latest', 'val_prev']:\n",
    "        if tmp[i] > 0:\n",
    "            s[srs][i] = f'increased at an annual rate of {tmp[i]:.1f} percent'\n",
    "            s[srs][i+'2'] = f'an increase of {tmp[i]:.1f} percent'\n",
    "        elif tmp[i] < 0:\n",
    "            s[srs][i] = f'decreased at an annual rate of {abs(d[\"val_latest\"]):.1f} percent'\n",
    "            s[srs][i+'2'] = f'a decrease of {abs(tmp[i]):.1f} percent'\n",
    "        else:\n",
    "            s[srs][i] = 'was unchanged'\n",
    "            s[srs][i+'2'] = 'no change'   \n",
    "    \n",
    "\n",
    "text = (f'In {d[\"date_latest_ft\"]}, labor productivity {s[\"value\"][\"val_latest\"]} '+\n",
    "        f'(see\\cbox{{teal}}), as the result of {s[\"output\"][\"val_latest2\"]} in real ouput and '+\n",
    "        f'{s[\"hours\"][\"val_latest2\"]} in hours worked. In the prior quarter, '+\n",
    "        f'{d[\"date_prev_ft\"]}, labor productivity {s[\"value\"][\"val_prev\"]}, as '+\n",
    "        f'real output {s[\"output\"][\"val_prev\"]} and hours of work {s[\"hours\"][\"val_prev\"]}. '+\n",
    "        f'Over the past five years, '+\n",
    "        f'labor productivity growth has averaged {d[\"five_year_mean\"]:.1f} percent, '+\n",
    "        f'compared to a 1989-onward average of {d[\"mean\"]:.1f} percent.')\n",
    "\n",
    "write_txt(text_dir / 'lprod.txt', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-06T17:35:20.254508Z",
     "start_time": "2019-11-06T17:35:20.246370Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Labor Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T21:33:21.255545Z",
     "start_time": "2019-11-03T21:33:19.143067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'LNS12005054': 'Hours', 'LNS12000000': 'Employment'}\n",
    "\n",
    "# Start year and end year\n",
    "dates = (1989, 2019)\n",
    "emp_hrs = bls_api(series, dates, bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T21:45:10.324640Z",
     "start_time": "2019-11-03T21:45:10.319025Z"
    }
   },
   "outputs": [],
   "source": [
    "emp_hrs['Total'] = emp_hrs['Hours'] * emp_hrs['Employment']\n",
    "emp = emp_hrs['Total'].resample('QS').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T21:45:11.551008Z",
     "start_time": "2019-11-03T21:45:11.506887Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A033RC']\n",
    "coe = nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "\n",
    "s = ['DPCERG']\n",
    "pce = nipa_df(retrieve_table('T20304')['Data'], s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T22:07:24.947241Z",
     "start_time": "2019-11-03T22:07:24.931321Z"
    }
   },
   "outputs": [],
   "source": [
    "data = coe.join(pce).join(emp).dropna()\n",
    "data['real_coe'] = data['A033RC'] / (data['DPCERG'] / data['DPCERG'].iloc[-1])\n",
    "data['coe_inp'] = data['real_coe'] / data['Total']\n",
    "data['wage'] = data['coe_inp'] * data['Total'].iloc[0]\n",
    "data['work'] = data['real_coe'] - data['wage']\n",
    "# Calculate contributions to growth\n",
    "result = growth_contrib(data, 'real_coe')[['work', 'wage']]\n",
    "result.dropna().to_csv(data_dir / 'gli.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T22:10:14.523298Z",
     "start_time": "2019-11-03T22:10:14.520279Z"
    }
   },
   "outputs": [],
   "source": [
    "date = f'{result.index[-1].year} Q{result.index[-1].quarter}'\n",
    "totval = result.iloc[-1].sum()\n",
    "wage = result['wage'].iloc[-1]\n",
    "work = result['work'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T22:20:14.092769Z",
     "start_time": "2019-11-03T22:20:14.088188Z"
    }
   },
   "outputs": [],
   "source": [
    "if totval > 0:\n",
    "    txt1 = f'increased at an annualized and inflation-adjusted rate of {totval:.2f} percent in {date}.'\n",
    "elif totval < 0:\n",
    "    txt1 = f'decreased at an annualized and inflation-adjusted rate of {abs(totval):.2f} percent in {date}.'\n",
    "else:\n",
    "    txt1 = f'was unchanged, after adjusting for inflation, in {date}.'\n",
    "    \n",
    "if wage > 0:\n",
    "    txt2 = f'Changes in wages contributed {wage:.2f} percentage points'\n",
    "elif wage < 0:\n",
    "    txt2 = f'Changes in wages subtracted {abs(wage):.2f} percentage points'\n",
    "else: \n",
    "    txt2 = 'Changes in wages did not contribute'\n",
    "    \n",
    "if work > 0:\n",
    "    txt3 = f', and changes in total hours worked contributed {work:.2f} percentage points.'\n",
    "elif work < 0:\n",
    "    txt3 = f', amd changes in total hours worked subtracted {abs(work):.2f} percentage points.'\n",
    "else: \n",
    "    txt3 = ', and changes in total hours worked did not contribute.'    \n",
    "    \n",
    "text = f'{txt1} {txt2}{txt3}'\n",
    "write_txt(text_dir / 'gli.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average hourly earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = {'CES0500000003': 'ALL', 'CES0500000008': 'PNS'}\n",
    "years = (1988, 2019)\n",
    "df = bls_api(series, years, bls_key)\n",
    "(df.pct_change(12) * 100).loc['1989':].to_csv(data_dir / 'ahe.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average hourly earnings by industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = {'CES3000000008': 'Manufacturing',\n",
    "          'CES1000000008': 'Mining \\& Logging',\n",
    "          'CES4422000008': 'Utilities',\n",
    "          'CES4142000008': 'Wholesale Trade',\n",
    "          'CES5000000008': 'Information',\n",
    "          'CES5500000008': 'Financial Activities',\n",
    "          'CES6000000008': 'Professional \\& Business Services',\n",
    "          'CES6500000008': 'Education \\& Health Services',\n",
    "          'CES0500000008': 'Total Private',\n",
    "          'CES2000000008': 'Construction',\n",
    "          'CES7000000008': 'Leisure \\& Hospitality',\n",
    "          'CES4300000008': 'Transportation \\& Warehousing',\n",
    "          'CES4200000008': 'Retail Trade'}\n",
    "\n",
    "years = (2017, 2019)\n",
    "df = bls_api(series, years, bls_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.pct_change(12).iloc[-1] * 100.0).sort_values(ascending=False).to_csv(data_dir / 'ahe_ind.csv', index_label='name', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'ahe_bar_date.txt', df.index[-1].strftime('%B %Y'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census Population and Age Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T20:08:00.463936Z",
     "start_time": "2019-10-26T20:07:59.801790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries and adjust settings\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.colors import Normalize\n",
    "acsdir = '/home/brian/Documents/ACS/'\n",
    "\n",
    "plt.rc('font', family='Lato')\n",
    "\n",
    "# Match PUMAs to commuter zones (file from Dorn)\n",
    "cz_match = pd.read_stata(acsdir + 'data/cw_puma2010_czone.dta')\n",
    "cz_dict = {cz: [(puma, afactor) \n",
    "                for puma, z, afactor \n",
    "                in cz_match[cz_match['czone'] == cz].values] \n",
    "           for cz in cz_match['czone'].unique()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T20:08:03.968141Z",
     "start_time": "2019-10-26T20:08:01.499457Z"
    }
   },
   "outputs": [],
   "source": [
    "variables = {'DP05_0024E': 'Age 65+',\n",
    "             'DP05_0019E': 'Age 0-17',\n",
    "             'DP03_0114E': 'Other NILF',\n",
    "             'DP05_0001E': 'Total'}\n",
    "srs = ','.join(variables.keys())\n",
    "area = 'for=public%20use%20microdata%20area:*'\n",
    "base = 'https://api.census.gov/data/2018/acs/acs1/profile'\n",
    "url = f'{base}?get={srs}&{area}&key={census_key}'\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-26T20:08:06.633465Z",
     "start_time": "2019-10-26T20:08:06.618334Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(r.json()[1:])\n",
    "df.columns = r.json()[0]\n",
    "df['PUMA'] = [float(f\"{i[-2]}{i[-1]}\") for i in r.json()[1:]]\n",
    "df = df.set_index('PUMA')[variables.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T23:28:35.948402Z",
     "start_time": "2019-10-12T23:28:33.660718Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for cz, puma_list in cz_dict.items(): \n",
    "    pop = 0\n",
    "    u18 = 0\n",
    "    o64 = 0\n",
    "    nlf = 0\n",
    "    for puma, afactor in puma_list:\n",
    "        data = dict(df.loc[puma].astype(int) * afactor)\n",
    "        pop += data['DP05_0001E']\n",
    "        u18 += data['DP05_0019E']\n",
    "        o64 += data['DP05_0024E']\n",
    "        nlf += data['DP03_0114E']\n",
    "    \n",
    "    u18sh = u18 / pop\n",
    "    o64sh = o64 / pop\n",
    "    nlfsh = nlf / pop\n",
    "    results = {'Total': pop, 'Age 0-17': u18sh, 'Age 65+': o64sh, 'NILF': nlfsh}\n",
    "    d[cz] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-12T23:34:00.280363Z",
     "start_time": "2019-10-12T23:34:00.234043Z"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame(d).T\n",
    "result['Sum'] = result[['Age 0-17', 'Age 65+', 'NILF']].sum(axis=1)\n",
    "maxval = result['Age 0-17'].max()\n",
    "minval = result['Age 0-17'].min()\n",
    "\n",
    "maxval2 = result['Age 65+'].max()\n",
    "minval2 = result['Age 65+'].min()\n",
    "\n",
    "maxval3 = result['NILF'].max()\n",
    "minval3 = result['NILF'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T00:55:53.101832Z",
     "start_time": "2019-10-13T00:55:52.692246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map and legend settings\n",
    "m = Basemap(llcrnrlon=-121, llcrnrlat=20, urcrnrlon=-64, urcrnrlat=49,\n",
    "            projection='lcc', lat_1=33, lat_2=45, lon_0=-95)\n",
    "\n",
    "cmap = plt.cm.Blues\n",
    "norm = Normalize(vmin=minval, vmax=maxval)\n",
    "\n",
    "cmap2 = plt.cm.Greens\n",
    "norm2 = Normalize(vmin=minval2, vmax=maxval2)\n",
    "\n",
    "cmap3 = plt.cm.Greens\n",
    "norm3 = Normalize(vmin=minval3, vmax=maxval3)\n",
    "\n",
    "hi_cz = [35600, 34701, 34703, 34702, 34703]\n",
    "ak_cz = [34101, 34114, 34102, 34112, 34104, 34107, 34115, \n",
    "         34109, 34109, 34102, 34111, 34108, 34107, 34102, \n",
    "         34106, 34113, 34105, 34111, 34110, 34109, 34115, \n",
    "         34103, 34112, 34110, 34115]\n",
    "\n",
    "pts = np.arange(1, 101, 1)\n",
    "pct = (np.percentile(\n",
    "    np.repeat(result['Age 0-17'].values, \n",
    "              result.Total.div(1000).astype(int).values), pts))\n",
    "pct2 = (np.percentile(\n",
    "    np.repeat(result['Age 65+'].values, \n",
    "              result.Total.div(1000).astype(int).values), pts))\n",
    "pct3 = (np.percentile(\n",
    "    np.repeat(result['NILF'].values, \n",
    "              result.Total.div(1000).astype(int).values), pts))\n",
    "\n",
    "max_val = f'{maxval * 100:.1f}%'\n",
    "min_val = f'{minval * 100:.1f}%'\n",
    "\n",
    "max_val2 = f'{maxval2 * 100:.1f}%'\n",
    "min_val2 = f'{minval2 * 100:.1f}%'\n",
    "\n",
    "max_val3 = f'{maxval3 * 100:.1f}%'\n",
    "min_val3 = f'{minval3 * 100:.1f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-13T01:45:46.308858Z",
     "start_time": "2019-10-13T01:45:44.477486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Draw map\n",
    "fig = plt.figure(figsize=(5.0,2.5))\n",
    "\n",
    "m.drawmapboundary()\n",
    "m.readshapefile(acsdir + 'shapefiles/cz1990', 'cz', drawbounds=False)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "for info, shape in zip(m.cz_info, m.cz):\n",
    "    fc = cmap(norm(d[info['cz']]['Age 0-17']))\n",
    "    fc2 = cmap2(norm2(d[info['cz']]['Age 65+']))\n",
    "    fc3 = cmap3(norm3(d[info['cz']]['NILF']))\n",
    "    if info['cz'] in hi_cz:\n",
    "        shape = [[x + 5200000, y - 1400000] for x, y in shape]\n",
    "    elif info['cz'] in ak_cz:\n",
    "        shape = [(x * 0.34 + 1280000, \n",
    "                  y * 0.34 - 1300000) for x, y in shape]\n",
    "    #ax.add_patch(Polygon(shape, fc=fc))\n",
    "    ax.add_patch(Polygon(shape, fc=fc2))\n",
    "    #ax.add_patch(Polygon(shape, fc=fc3))\n",
    "\n",
    "ax.axis('off')    \n",
    "\n",
    "ax_inset = inset_axes(ax, width='-10%', height='50%', loc=4, borderpad=1.8) \n",
    "for i, pt in enumerate(pct2):\n",
    "    rect = Rectangle(xy=(pt, i / 100), width=-pt, height=0.1, \n",
    "                     fc=cmap2(norm2(pt)), ec=None)\n",
    "    ax_inset.add_patch(rect)    \n",
    "\n",
    "ax_inset.text(0.6, 1.05, max_val2, fontsize=7)\n",
    "ax_inset.text(0.6, -0.12, min_val2, fontsize=7)\n",
    "ax_inset.axis('off')\n",
    "plt.savefig(data_dir / 'over64pop.pgf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shiller real return trailing 20-year average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-10T04:11:01.151350Z",
     "start_time": "2019-11-10T04:10:59.913176Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('http://www.econ.yale.edu/~shiller/data/ie_data.xls', sheet_name='Data')\n",
    "df = data\n",
    "df = df.iloc[679:1795, np.r_[0, 7, 8]]\n",
    "df.columns = ['Date', 'Price', 'Dividend']\n",
    "df.index = pd.to_datetime(df['Date'].astype('str'))\n",
    "df = df.loc[~df.index.duplicated(keep='first')]\n",
    "df['DY'] = (df['Dividend'] / df['Price']).rolling(240).mean()\n",
    "df['Pch'] = df['Price'].pct_change(240)\n",
    "df['Pch'] = (df['Pch']+1)**(1/20) - 1\n",
    "df = df.dropna()\n",
    "df['Return'] = (df['DY'] + df['Pch']) * 100\n",
    "df.loc['1989':].dropna().to_csv(data_dir / 'sp500rr.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('According to historical stock market return '+\n",
    "        '\\href{www.econ.yale.edu/~shiller/data.htm}{data} from Robert Shiller, '+\n",
    "        'the inflation-adjusted trailing twenty year annual rate of return '+\n",
    "        f'of the S\\&P 500 was {df[\"Return\"].iloc[-1]:.1f} percent as '+\n",
    "        f'of {df.index[-1].strftime(\"%B %Y\")}. Real returns are currently low relative '+\n",
    "        'to the average trailing twenty year real annual return of '+\n",
    "        f'{df[\"Return\"].loc[\"1995\":\"2005\"].mean():.1f} percent during 1995--2005.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'sp500rr.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exchange Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=H10&series=ad1712193ad5bad7b424e3ae5eb101a5&lastobs=&from=01/01/1989&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split(';')[0]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns\n",
    "\n",
    "clean_data['RXI_N.B.EU'] = 1 / clean_data['RXI$US_N.B.EU'] \n",
    "clean_data['RXI_N.B.UK'] = 1 / clean_data['RXI$US_N.B.UK'] \n",
    "clean_data['RXI_N.B.JA'] = clean_data['RXI_N.B.JA'] / 100.0\n",
    "\n",
    "latest = clean_data.iloc[-1]\n",
    "major = ['RXI_N.B.EU', 'RXI_N.B.UK', 'RXI_N.B.CA', 'RXI_N.B.JA']\n",
    "oth = ['RXI_N.B.MX', 'RXI_N.B.BZ', 'RXI_N.B.CH', 'RXI_N.B.SD']\n",
    "idx = ['V0.JRXWTFN_N.B', 'V0.JRXWTFB_N.B']\n",
    "clean_data.resample('MS').mean().append(latest)[major].to_csv(data_dir / 'fx1.csv', index_label='date')\n",
    "clean_data.resample('MS').mean().append(latest)[oth].to_csv(data_dir / 'fx2.csv', index_label='date')\n",
    "clean_data.resample('MS').mean().append(latest)[idx].to_csv(data_dir / 'fx_idx.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=5f48b7338e558e73e11dc78be7354a87&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i.split('; ')[1]) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_col = ['FA156012005.Q', 'FL152000005.Q', 'LM152010005.Q', 'LM155035015.Q', \n",
    "           'FL155035065.Q', 'LM155111005.Q', 'FL154090005.Q', 'FL154000025.Q',\n",
    "           'LM153064475.Q', 'LM152090205.Q']\n",
    "\n",
    "names = ['DPI', 'TOT', 'NFA', 'HRE', 'REQ', 'CDG', 'TFA', 'DEP', 'CEQ', 'NEQ']\n",
    "\n",
    "df = clean_data.loc[:,sel_col]\n",
    "df.columns = names\n",
    "\n",
    "df['NPA'] = clean_data.loc[:,['LM165013765.Q', 'LM165015205.Q', 'LM165035005.Q']].sum(axis=1)\n",
    "df['DSL'] = clean_data.loc[:,['LM154022375.Q', 'FL154023005.Q']].sum(axis=1)\n",
    "df['TEQ'] = df['NEQ'] + df['CEQ']\n",
    "df['OFA'] = df['TFA'] - df['DEP'] - df['DSL'] - df['TEQ']\n",
    "df['OTH'] = df['TOT'] - df['HRE'] - df['DEP'] - df['DSL'] - df['TEQ']\n",
    "\n",
    "pce = nipa_df(retrieve_table('T20304')['Data'], ['DPCERG']).loc[df.index,'DPCERG']\n",
    "pr = (pce / pce.iloc[-1])\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC']).loc[df.index,'A191RC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgdp = df.div(gdp, axis=0).dropna() *100\n",
    "dfgdp.to_csv(data_dir / 'hhassetsgdp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldate = f'{df.index[-1].year} Q{df.index[-1].quarter}'\n",
    "i = df.iloc[-1] / 1000000\n",
    "g = dfgdp.iloc[-1] / 100\n",
    "s = (df.div(df.TOT, axis=0) * 100).iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('Assets '+\n",
    "        f'of households and nonprofits were valued at \\${i.TOT:.1f} trillion in {ldate}, '+\n",
    "        f'equivalent to {g.TOT*100:.0f} percent--or {g.TOT:.2f} years--of GDP. '+\n",
    "        f'Of this, \\${i.NFA:.1f} trillion, or {s.NFA:.1f} percent of the total, '+\n",
    "        f'are tangible assets and \\${i.TFA:.1f} trillion, or {s.TFA:.1f} percent, '+\n",
    "        'are financial assets.')\n",
    "text2 = (\"Tangible, or non-financial, assets include peoples' homes as well \"+\n",
    "         'as consumer durable goods, such as cars, furniture, and appliances. '+\n",
    "         f'The market value of owner-occupied real estate is \\${i.HRE:.1f} trillion in {ldate}, '+\n",
    "         f'equivalent to {g.HRE:.2f} years of GDP (see\\cbox{{green!60!teal}}). Consumer durable goods have a '+\n",
    "         f'replacement value of \\${i.CDG:.1f} trillion, or {g.CDG:.2f} years of GDP. '+\n",
    "         'Tangible assets are reported for the combined household and nonprofit sector '+\n",
    "         'and include real estate and equipment belonging to nonprofits, '+\n",
    "         f'which totals \\${i.NPA:.1f} trillion in {ldate}. ')\n",
    "text3 = ('Financial assets include equity in businesses--corporate and non-coporate--with a market value of '+\n",
    "         f'\\${i.TEQ:.1f} trillion, or {g.TEQ:.2f} years of GDP (see\\cbox{{blue!65!black}}), in {ldate}. Debt '+\n",
    "         f'securities and loan assets total \\${i.DSL:.1f} trillion, or {g.DSL:.2f} '+\n",
    "         'years of GDP (see\\cbox{{blue!55!cyan}}). Cash and deposits, including money market accounts, '+\n",
    "         f'total \\${i.DEP:.1f} trillion, or {g.DEP:.2f} years of GDP (see\\cbox{{cyan!40!white}}). All '+\n",
    "         f'other financial assets total \\${i.OFA:.1f} trillion.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'hhasset1.txt', text)\n",
    "write_txt(text_dir / 'hhasset2.txt', text2)\n",
    "write_txt(text_dir / 'hhasset3.txt', text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data = df.div(pr, axis=0)\n",
    "growth = growth_contrib_ann(real_data, 'TOT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "growth.dropna()[['HRE', 'DEP', 'DSL', 'TEQ', 'OTH']].to_csv(data_dir / 'hh_asset_growth.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = growth.iloc[-1]\n",
    "grtot = [f'grew by {gr.TOT:.1f} percent' if gr.TOT >=0.1 \n",
    "         else f'decreased in value by {abs(gr.TOT):.1f} percent' if gr.TOT <= -0.1\n",
    "         else 'did not change substanatially in value'][0]\n",
    "\n",
    "grhre = [f'contributed {gr.HRE:.1f} percentage points to' if gr.HRE >=0.1\n",
    "         else f'subtracted {abs(gr.HRE):.1f} percentage points from' if gr.HRE <=-0.1\n",
    "         else 'did not contribute significantly to'][0]\n",
    "\n",
    "grteq = [f'contributed {gr.TEQ:.1f} percentage points' if gr.TEQ >=0.1\n",
    "         else f'subtracted {abs(gr.TEQ):.1f} percentage points' if gr.TEQ <=-0.1\n",
    "         else 'did not contribute significantly'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'Household and nonprofit assets {grtot} '+\n",
    "        f'over the year ending {ldate}. Owner-occupied real estate {grhre} '+\n",
    "        'total growth, and business equity '+\n",
    "        f'{grteq}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'hhasset4.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd = {'TOT': '& Total Assets', 'NFA': '& \\hspace{2mm} Non-financial assets', \n",
    "      'HRE': '\\cbox{green!60!teal} & \\hspace{4mm} Owner-occupied real estate', \n",
    "      'CDG': ' & \\hspace{4mm} Consumer durable goods',\n",
    "      'NPA': ' & \\hspace{4mm} Nonprofit assets',\n",
    "      'TFA': ' & \\hspace{2mm} Financial assets',\n",
    "      'DEP': '\\cbox{cyan!40!white} & \\hspace{4mm} Deposits, incl. money market',\n",
    "      'DSL': '\\cbox{blue!55!cyan} & \\hspace{4mm} Debt securities and loans',\n",
    "      'TEQ': '\\cbox{blue!65!black} & \\hspace{4mm} Business equity',\n",
    "      'CEQ': ' & \\hspace{6mm} Corporate equities',\n",
    "      'NEQ': ' & \\hspace{6mm} Noncorporate business equity'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "table['2019 Q2'] = pd.Series({idx: f'\\${val:.1f}' if idx == 'TOT' else f'{val:.1f}' for idx, val in i.iteritems()})\n",
    "table['2019 Q2 '] = dfgdp.iloc[-1]\n",
    "table['2018 Q2 '] = dfgdp.iloc[-5]\n",
    "table['One-year'] = real_data.pct_change(4).iloc[-1] * 100\n",
    "table['Three-year'] = ((real_data.pct_change(12) + 1)**(1/3) - 1).iloc[-1] * 100\n",
    "table['20-year'] = ((real_data.pct_change(80) + 1)**(1/20) - 1).iloc[-1] * 100\n",
    "\n",
    "table.index.name = '& '\n",
    "\n",
    "table.loc[nd.keys()].rename(nd).round(1).to_csv(data_dir / 'hhasset.tex', sep='&', line_terminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=5274f1fc3a4900aba158b78578142b2a&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'FL152090005.Q': 'NW',\n",
    "     'FL152000005.Q': 'ASSETS',\n",
    "     'FL154190005.Q': 'LIAB',\n",
    "     'FA156012005.Q': 'DPI'}\n",
    "\n",
    "df = pd.read_csv(url, skiprows=5, index_col=0)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df = df / 1000000\n",
    "\n",
    "datelt = f'{df.index[-1].year} Q{df.index[-1].quarter}'\n",
    "\n",
    "i = df.iloc[-1]\n",
    "\n",
    "text = (f'In {datelt}, household and nonprofit institution net worth was '+\n",
    "        f'\\${i.NW:.1f} trillion, equivalent to {i.NW / i.DPI:.1f} years of disposable '+\n",
    "        f'personal income; the result of total assets of \\${i.ASSETS:.1f} trillion '+\n",
    "        f'and total liabilities of \\${i.LIAB:.1f} trillion.')\n",
    "\n",
    "write_txt(text_dir / 'nw1.txt', text)\n",
    "\n",
    "pce = nipa_df(retrieve_table('T20304')['Data'], ['DPCERG'])['DPCERG']\n",
    "\n",
    "pr = df.join(pce)['DPCERG'] / df.join(pce)['DPCERG'].iloc[-1]\n",
    "\n",
    "data = df.divide(pr, axis=0)\n",
    "\n",
    "srs = ['NW', 'DPI']\n",
    "\n",
    "result = pd.concat([data[i].dropna().pct_change(4).dropna() * 100 \n",
    "            for i in srs], axis=1)\n",
    "(result.to_csv(data_dir / 'rdpi_nw.csv', index_label='date'))\n",
    "\n",
    "gr = {}\n",
    "gr2 = {}\n",
    "for s in srs:\n",
    "    val = result[s].iloc[-1]\n",
    "    val2 = result[s].iloc[-13:].mean()\n",
    "    if val >= 0.1:\n",
    "        gr[s] = f'increased by {val:.1f} percent'\n",
    "    elif val <= -0.1:\n",
    "        gr[s] = f'decreased by {abs(val):.1f} percent'\n",
    "    else:\n",
    "        gr[s] = 'was virtually unchanged'\n",
    "    if val2 >= 0.1:\n",
    "        gr2[s] = f'grew at an average rate of {val2:.1f} percent'\n",
    "    elif val2 <= -0.1:\n",
    "        gr2[s] = f'decreased at an average rate of {abs(val2):.1f} percent'\n",
    "    else:\n",
    "        gr2[s] = 'was virtually unchanged'\n",
    "        \n",
    "text = (f'In {datelt}, inflation-adjusted net worth {gr[\"NW\"]}, while '+\n",
    "        f'inflation adjusted after-tax income {gr[\"DPI\"]}. Over the past '+\n",
    "        f'three years, real net worth {gr2[\"NW\"]}, while real '+\n",
    "        f'after-tax income {gr2[\"DPI\"]}')\n",
    "\n",
    "write_txt(text_dir / 'nw2.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net worth contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=73021951e1b749df8a5de36975a7926d&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data.loc[:, ['FC152090005.Q', 'FU155060005.Q', 'FV158090005.Q', \n",
    "                 'FU156012005.Q', 'FR158000005.Q']]\n",
    "df.columns = ['NW', 'NI', 'OVC', 'DPI', 'RV']\n",
    "\n",
    "df = df.rolling(4).sum().dropna()\n",
    "rate = (df['NI'] / df['DPI']).mean()\n",
    "rate2 = (df['NI'] / df['DPI']).iloc[-1]\n",
    "\n",
    "df['INC'] = df['DPI'] * rate\n",
    "df['INV'] = df['NI'] - df['INC']\n",
    "df['NWL'] = clean_data['FL152090005.Q']\n",
    "\n",
    "growth = (df[['OVC', 'INC', 'INV', 'RV']]\n",
    "          .div(df['NWL'].shift(4), axis=0).dropna() * 100)\n",
    "\n",
    "growth.to_csv(data_dir / 'nw_gr.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = {1: 'first', 2: 'second', 3: 'third', 4: 'fourth'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldate = f'{growth.index[-1].year} Q{growth.index[-1].quarter}'\n",
    "ltdate = f'{q[growth.index[-1].quarter]} quarter of {growth.index[-1].year}'\n",
    "\n",
    "hg = growth['RV'].iloc[-1]\n",
    "inc = growth['INC'].iloc[-1]\n",
    "inv = growth['INV'].iloc[-1]\n",
    "oth = growth['OVC'].iloc[-1]\n",
    "ni = inc + inv\n",
    "\n",
    "hgtxt = [f'contributed {hg:.1f} percentage points to' if hg >= 0.1 \n",
    "         else f'subtracted {abs(hg):.1f} percentage points from' if hg <= -0.1 \n",
    "         else 'did not contribute significantly to'][0]\n",
    "\n",
    "inctxt = [f'contributed {inc:.1f} percentage points' if inc >= 0.1 \n",
    "         else f'subtracted {abs(inc):.1f} percentage points' if inc <= -0.1 \n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "invtxt = [f'and an additional {inv:.1f} percentage points were added' if inv >= 0.1 \n",
    "         else f'but {abs(inv):.1f} percentage points were subtracted' if inv <= -0.1 \n",
    "         else 'cyclical activity in investment did not seem to play a role'][0]\n",
    "\n",
    "othtxt = [f'contributed {othg:.1f} percentage points' if oth >= 0.1 \n",
    "         else f'subtracted {abs(oth):.1f} percentage points' if oth <= -0.1 \n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "hg3 = growth['RV'].iloc[-13:].mean()\n",
    "inc3 = growth['INC'].iloc[-13:].mean()\n",
    "inv3 = growth['INV'].iloc[-13:].mean()\n",
    "oth3 = growth['OVC'].iloc[-13:].mean()\n",
    "ni3 = inc3 + inv3\n",
    "\n",
    "hg3txt = [f'contributed {hg3:.1f} percentage points' if hg3 >= 0.1 \n",
    "         else f'subtracted {abs(hg3):.1f} percentage points' if hg3 <= -0.1 \n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "oth3txt = [f'contributed {oth3:.1f} percentage points' if oth3 >= 0.1 \n",
    "         else f'subtracted {abs(oth3):.1f} percentage points' if oth3 <= -0.1 \n",
    "         else 'did not contribute significantly'][0]\n",
    "\n",
    "ni3txt = [f'contributed {ni:.1f} percentage points' if ni >= 0.1 \n",
    "         else f'subtracted {abs(ni):.1f} percentage points' if ni <= -0.1 \n",
    "         else 'did not contribute significantly'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (f'In the {ltdate}, holding gains {hgtxt} overall nominal net worth '+\n",
    "        f'growth. Income net invested at the 1989-onward average {rate*100:.1f} percent '+\n",
    "        f'rate {inctxt}; {invtxt} as household net investment was {rate2*100:.1f} '+\n",
    "        f'percent of disposable person income in {ldate}. Other '+\n",
    "        f'volume changes {othtxt}. Over the past three years, holding '+\n",
    "        f'gains have {hg3txt} on average; net investment (combined) has '+\n",
    "        f'{ni3txt}; and other volume changes {oth3txt}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_txt(text_dir / 'nwcontrib.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Money Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=H6&series=fafc1295c552e99d2b907eb62278e4ca&lastobs=&from=01/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final2 = {}\n",
    "data = clean_data[['M2_N.WM', 'MMFIN_N.WM']].sum(axis=1)\n",
    "month_list = clean_data.resample('MS').mean().pct_change(12).dropna().index\n",
    "for date in month_list:\n",
    "    month_len = len(data.loc[date.strftime('%Y-%m')])\n",
    "    prevyr = f'{date.year - 1}-{date.month}'\n",
    "    weeks_in_short_month = 4\n",
    "    end_date = date\n",
    "    if month_len < 4:\n",
    "        end_date = date\n",
    "        short_month = date.strftime('%B %Y')\n",
    "        val = data.loc[date.strftime('%Y-%m')].mean()\n",
    "        prv = data.loc[prevyr].iloc[:month_len]\n",
    "        prev = prv.mean()\n",
    "        weeks_in_short_month = len(prv)\n",
    "    elif month_len >= 4:\n",
    "        val = data.loc[date.strftime('%Y-%m')].mean()\n",
    "        prev = data.loc[prevyr].mean()\n",
    "        end_full = date\n",
    "    final2[date] = (val / prev - 1) * 100\n",
    "    \n",
    "final = pd.Series(final2, name='value')\n",
    "final.to_csv(data_dir / 'm2imf.csv', index_label='date', header='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = series_info(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_conv = {1: f'the first week of {short_month}', \n",
    "             2: f'the first two weeks of {short_month}', \n",
    "             3: f'the first three weeks of {short_month}',\n",
    "             4: end_full.strftime('%B %Y')}\n",
    "\n",
    "if final.iloc[-1] >= 0.1:\n",
    "    txt = f'increased over the equivalent previous year value by {final.iloc[-1]:.1f} percent'\n",
    "elif final.iloc[-1] <= -0.1:\n",
    "    txt = f'decreased over the equivalent previous year value by {abs(final.iloc[-1]):.1f} percent'   \n",
    "else:\n",
    "    txt = 'was virtually unchanged over the previous year value'\n",
    "    \n",
    "if s['days_since_match'] > 300:\n",
    "    txt2 = f\", {s['last_matched'].replace('highest level', 'fastest growth rate')}.\"\n",
    "else:\n",
    "    txt2 = '.'\n",
    "    \n",
    "text = (f'In {week_conv[weeks_in_short_month]}, '+\n",
    "        f'the M2 plus institutional money funds measure {txt}{txt2}')\n",
    "\n",
    "write_txt(text_dir / 'm2imf.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "m2sh = (clean_data['M2_N.WM'].iloc[-1] / (gdp.iloc[-1] / 1000)) * 100\n",
    "imfsh = (clean_data['MMFIN_N.WM'].iloc[-1] / (gdp.iloc[-1] / 1000)) * 100\n",
    "\n",
    "text2 = (f'In the week of {clean_data.index[-1].strftime(\"%B %d, %Y\")}, '+\n",
    "         f'the M2 measure of money averaged \\${clean_data[\"M2_N.WM\"].iloc[-1] / 1000:.1f} '+\n",
    "         f'trillion, equivalent to {m2sh:.1f} percent of GDP. Institution money market '\n",
    "         +f'accounts, which are not included in M2, can be combined with M2 to create a '+\n",
    "         f'slightly-broader-than-M2 measure of the money stock. These funds averaged '+\n",
    "         f'\\${clean_data[\"MMFIN_N.WM\"].iloc[-1] / 1000:.1f} trillion in the same week, '+\n",
    "         f'equivalent to {imfsh:.1f} percent of GDP. ')\n",
    "\n",
    "write_txt(text_dir / 'm2imf2.txt', text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FHFA Housing Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fhfa.gov/HPI_master.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.query('frequency == \"monthly\" and place_name == \"United States\"')[['yr', 'period', 'index_sa']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = [pd.to_datetime(f'{i.yr:.0f}-{i.period:.0f}-01') for idx, i in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['index_sa'].pct_change(12) * 100).to_csv(data_dir / 'hpi.csv', index_label='date', header='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIX "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = pd.read_excel(data_dir/ 'vixarchive.xls', skiprows=1, index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIX = 'http://www.cboe.com/publish/scheduledtask/mktdata/datahouse/vixcurrent.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = pd.read_csv(VIX, skiprows=1, index_col='Date', parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(prev.append(curr)['VIX Close'].resample('MS').mean()\n",
    " .append(curr['VIX Close'].iloc[-1:]).rename('value')\n",
    " .to_csv(data_dir / 'vix.csv', index_label='date', header='True'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equity Payout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.federalreserve.gov/datadownload/Output.aspx?rel=Z1&series=5dbfee986a7636f1bc997a80c313cabc&lastobs=&from=03/01/1988&to=12/31/2019&filetype=csv&label=include&layout=seriescolumn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(url)\n",
    "\n",
    "d = {v: re.sub(\"\\s+[\\(\\[].*?[\\)\\]]\", \"\", i) \n",
    "     for i, v in raw_data.iloc[4, 1:].iteritems()}\n",
    "\n",
    "date_column = raw_data.loc[5:, 'Series Description']\n",
    "date_index = pd.to_datetime(date_column).rename('Date')\n",
    "columns = raw_data.iloc[4, 1:].values\n",
    "    \n",
    "clean_data = raw_data.iloc[5:, 1:].replace('ND', np.nan).astype('float')\n",
    "clean_data.index = date_index\n",
    "clean_data.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srs = {'FA103164103.Q': 'Buybacks',\n",
    "       'FA106121075.Q': 'Dividends'}\n",
    "\n",
    "data = clean_data.rename(srs, axis=1)\n",
    "data['Buybacks'] = -data['Buybacks']\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "results = data.divide(gdp, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(results.dropna() * 100).to_csv(data_dir / 'eq_payout.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
