{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data for Chartbook\n",
    "\n",
    "Brian Dew\n",
    "\n",
    "@bd_econ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T13:37:22.354977Z",
     "start_time": "2023-09-07T13:37:21.420850Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T11500'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-05T02:11:50.599323Z",
     "start_time": "2022-09-05T02:11:50.596520Z"
    }
   },
   "source": [
    "### GDPNow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T21:22:24.406192Z",
     "start_time": "2023-09-07T21:22:23.910049Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = ('https://api.stlouisfed.org/fred/series?series_id=GDPNOW&'+\n",
    "       f'api_key={fred_key}&file_type=json')\n",
    "r = requests.get(url).json()\n",
    "update = r['seriess'][0]['last_updated']\n",
    "url = ('https://api.stlouisfed.org/fred/series/observations?series_id=GDPNOW&'+\n",
    "       f'api_key={fred_key}&file_type=json')\n",
    "r = requests.get(url).json()\n",
    "lv = pd.DataFrame(r['observations']).set_index('date')['value'].sort_index()[-1]\n",
    "lvt = f'{float(lv):.1f}'\n",
    "nowdt = pd.DataFrame(r['observations']).set_index('date')['value'].sort_index().index[-1]\n",
    "ltdt = dtxt(nowdt)['qtr1']\n",
    "\n",
    "# Store GDP now value\n",
    "gdpnow = pd.Series({'date': nowdt, 'value': lv}).to_frame().T.set_index('date')\n",
    "gdpnow.to_csv(data_dir / 'gdpnow.csv', index_label='date')\n",
    "\n",
    "s = ['A191RL']\n",
    "gdp = nipa_df(retrieve_table('T10502')['Data'], s).sort_index()\n",
    "gdpdt = gdp.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T21:22:24.974357Z",
     "start_time": "2023-09-07T21:22:24.966675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latest nowcast for 2023 Q3 is 5.6 percent, as of September 6, 2023 (see \\tikz \\draw[black, fill=red] (2.5pt,2.5pt) circle (2.5pt);).\n"
     ]
    }
   ],
   "source": [
    "# Only add mark to plot if nowcast is available\n",
    "mark = ' (see \\\\tikz \\draw[black, fill=red] (2.5pt,2.5pt) circle (2.5pt);)'\n",
    "if dtxt(gdpdt)['datetime'] < nowdt:\n",
    "    linedt = dtxt(pd.to_datetime(nowdt) - pd.DateOffset(days=46))['datetime']\n",
    "    node = (f'\\\\node[label={{[align=left]90:{{\\scriptsize \\\\textit{{{lvt}}}}}}}, '+\n",
    "            'circle, draw=black, fill=red, inner sep=1.8pt] at '+\n",
    "            f'(axis cs:{nowdt}, {lv}) {{}};'+\n",
    "            f'\\draw [dashed] (axis cs:{{{linedt}}},\\pgfkeysvalueof{{/pgfplots/ymin}})'+\n",
    "            f' -- (axis cs:{{{linedt}}}, \\pgfkeysvalueof{{/pgfplots/ymax}});')\n",
    "    write_txt(text_dir / 'gdpnow_node.txt', node)\n",
    "\n",
    "    node = ('\\\\node[circle, draw=black, fill=red, inner sep=1.0pt] '+\n",
    "            f'at (axis cs:{nowdt}, {lv}) {{}};')\n",
    "    write_txt(text_dir / 'gdpnow_node2.txt', node)\n",
    "    # Nowcast text\n",
    "    write_txt(text_dir / 'nowcast_text.txt', 'nowcast')\n",
    "    latest_txt = 'latest '\n",
    "\n",
    "else:\n",
    "    node = ''\n",
    "    write_txt(text_dir / 'gdpnow_node.txt', node)\n",
    "    write_txt(text_dir / 'gdpnow_node2.txt', node)\n",
    "    write_txt(text_dir / 'nowcast_text.txt', '\\color{white}{.}')\n",
    "    latest_txt = ''\n",
    "    mark = ''\n",
    "            \n",
    "text = (f'The {latest_txt}nowcast for {ltdt} is {lvt} percent, as '+\n",
    "        f'of {dtxt(pd.to_datetime(update))[\"day1\"]}{mark}.')\n",
    "write_txt(text_dir / 'gdpnow.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T02:28:04.781746Z",
     "start_time": "2023-09-05T02:28:04.779721Z"
    }
   },
   "source": [
    "### Monthly nominal GDP measure\n",
    "\n",
    "Does not show meaningful differences within months, basic interpolation. Adds latest quarter from nowcasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T16:51:43.813942Z",
     "start_time": "2023-09-06T16:51:43.806657Z"
    }
   },
   "outputs": [],
   "source": [
    "pce = pd.read_csv(data_dir / 'pce_now.csv', index_col='date', parse_dates=True)\n",
    "gdp = gdpnow.copy().astype('float')\n",
    "gdp.index = pd.to_datetime(gdp.index)\n",
    "data = pd.concat([gdp, pce], axis=1)\n",
    "data['real'] = data[['value', 'pce']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T16:51:44.611284Z",
     "start_time": "2023-09-06T16:51:44.560375Z"
    }
   },
   "outputs": [],
   "source": [
    "df = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "mult = ((data['real'].iloc[0] / 4) / 100) + 1\n",
    "df.loc[data.index[0]] = df.iloc[-1] * mult\n",
    "df.index = (df.index + pd.DateOffset(months=2)).to_period('M')\n",
    "mon = df.resample('M').interpolate()\n",
    "mon.index = mon.index.to_timestamp()\n",
    "mon.to_csv(data_dir / 'gdp_monthly.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate of labor productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T16:51:46.652670Z",
     "start_time": "2023-09-06T16:51:46.621893Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_dir / 'gdpjobslvl.csv', \n",
    "                   index_col='date', parse_dates=True)\n",
    "currdt = data['GDP'].dropna().index[-1]\n",
    "gdpnow = pd.read_csv(data_dir / 'gdpnow.csv', index_col='date', parse_dates=True)\n",
    "\n",
    "qch = ((gdpnow['value'].iloc[0] / 100) + 1) ** (1/4)\n",
    "nowdt = gdpnow.index[0]\n",
    "prdt = nowdt - pd.DateOffset(months=3)\n",
    "\n",
    "if pd.isna(data.loc[nowdt, 'GDP']):\n",
    "    data.loc[nowdt, 'GDP'] = data.loc[prdt, 'GDP'] * qch\n",
    "    data.loc[nowdt, 'LPROD'] = (data.loc[nowdt, 'GDP'] / \n",
    "                                data.loc[nowdt, 'TOT_HRS']) \n",
    "\n",
    "# Convert to indices\n",
    "for i in ['LPROD','TOT_HRS', 'GDP', \n",
    "          'POP', 'EPOP_sa', 'AAH_trend']:\n",
    "    data[f'{i}_ix'] = (data[i] / data.loc['2000-01-01', i]) * 100\n",
    "\n",
    "# Calculate productivity growth rate\n",
    "data['LPROD_gr'] = (((data.LPROD.dropna().pct_change() + 1) ** 4) - 1) * 100\n",
    "    \n",
    "# Create table\n",
    "cl = c_line('cyan!70!white', see=False, paren=False)\n",
    "names = {'LPROD_ix': f'\\hspace{{0.1mm}}{cl} Labor Productivity (index)', \n",
    "         'GDP_ix': '\\hspace{4mm} Real GDP (index)',\n",
    "         'TOT_HRS_ix': '\\hspace{4mm} Total Hours Worked (index)', \n",
    "         'POP': '\\hspace{7mm} Population (millions)', \n",
    "         'EPOP_sa': '\\hspace{7mm} Employment Rate (percent)', \n",
    "         'AAH_trend': '\\hspace{7mm} Average Workweek (hours)',\n",
    "         'LPROD_gr': '\\hspace{0.1mm} Labor Productivity Growth (percent)'}\n",
    "\n",
    "table = data[names.keys()].dropna().iloc[[-1,-2,-3,-5]].T\n",
    "table['2019-10-01'] = data.loc['2019-10-01', names.keys()]\n",
    "table.columns = [dtxt(c)['qtr1'] for c in table.columns]\n",
    "table['2014'] = data.loc['2014', names.keys()].mean()\n",
    "table['1989'] = data.loc['1989', names.keys()].mean()\n",
    "table = table.rename(names)\n",
    "nowqt = dtxt(nowdt)['qtr1']\n",
    "if nowdt > currdt:\n",
    "    table[nowqt] = (table[nowqt].apply('\\\\textit{{{:.1f}}}'.format))\n",
    "    table.iloc[:, 1:] = table.iloc[:, 1:].applymap('{:.1f}'.format)\n",
    "    table.columns = table.columns.str.replace(nowqt, f'\\\\\\\\textit{{{{{nowqt}}} Est.}}')\n",
    "else:\n",
    "    table = table.applymap('{:.1f}'.format)\n",
    "table.to_csv(data_dir / 'gdpjobs.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T16:51:47.425387Z",
     "start_time": "2023-09-06T16:51:47.414968Z"
    }
   },
   "outputs": [],
   "source": [
    "# Only add mark to plot if nowcast is available\n",
    "mark = ' (see \\\\tikz \\draw[black, fill=cyan!70!white] (2.5pt,2.5pt) circle (2.5pt);)'\n",
    "prval = data.loc[currdt, 'LPROD_gr']\n",
    "nowval = data.loc[nowdt, 'LPROD_gr']\n",
    "lv = data.loc[nowdt, 'LPROD_ix']\n",
    "lvt = f'{lv:.1f}'\n",
    "cht = f'{nowval:.1f}'\n",
    "if currdt < nowdt:\n",
    "    node = (f'\\\\node[label={{[align=left]90:{{\\scriptsize \\\\textit{{{lvt}}}}}}}, '+\n",
    "            'circle, draw=black, fill=cyan!70!white, inner sep=1.2pt] at '+\n",
    "            f'(axis cs:{nowdt.date()}, {lv}) {{}};')\n",
    "    node2 = (f'\\\\node[label={{[align=left]90:{{\\scriptsize \\\\textit{{{cht}}}}}}}, '+\n",
    "            'circle, draw=black, fill=cyan!70!white, inner sep=1.2pt] at '+\n",
    "            f'(axis cs:{nowdt.date()}, {nowval}) {{}};')\n",
    "    txt = (f'The estimate for {nowqt}{mark}, based on the Federal Reserve Bank of '+\n",
    "        'Atlanta GDPNow, suggests annualized producivity growth of '+\n",
    "        f'{nowval:.1f} percent.')\n",
    "    write_txt(text_dir / 'gdpjobs_est_node.txt', node)\n",
    "    write_txt(text_dir / 'lprod_rec_node.txt', node2)\n",
    "else:\n",
    "    node = ''\n",
    "    txt = ''\n",
    "    write_txt(text_dir / 'gdpjobs_est_node.txt', node)\n",
    "\n",
    "text = ('More-recent data show annualized total economy productivity '+\n",
    "        f'growth of {prval:.1f} percent in {dtxt(currdt)[\"qtr1\"]}. {txt}')\n",
    "write_txt(text_dir / 'gdpjobs_est.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T16:51:52.885330Z",
     "start_time": "2023-09-06T16:51:52.859644Z"
    }
   },
   "outputs": [],
   "source": [
    "rec = data.loc[:currdt, 'LPROD_gr'].iloc[-8:].to_frame()\n",
    "rec['Quarter'] = [f'Q{i.quarter}\\\\\\\\{i.year}' if i.quarter == 1 \n",
    "                  else dtxt(i)['qtr3'] for i in rec.index]\n",
    "# From GDP Now (cover cases where no nowcast available)\n",
    "if currdt < nowdt:\n",
    "    next_qtr = rec.index[-1] + pd.DateOffset(months=3)\n",
    "    label = (f'Q{next_qtr.quarter}\\\\\\\\{next_qtr.year}' \n",
    "             if next_qtr.quarter == 1 else dtxt(next_qtr)['qtr3'])\n",
    "    frow = pd.DataFrame({'Quarter': label, \n",
    "                         'date': next_qtr}, index={'date': 4})\n",
    "    rec= pd.concat([rec.reset_index(), frow]).set_index('date')\n",
    "    rec.loc[next_qtr, 'LPROD_gr'] = 0\n",
    "rec['zero'] = 0\n",
    "rec.to_csv(data_dir / 'lprod_rec.csv', index_label='date')\n",
    "\n",
    "# Average bar\n",
    "start_date = rec.index[0] - pd.DateOffset(months=2)\n",
    "end_date = rec.index[-1] + pd.DateOffset(months=1)\n",
    "val = data['LPROD_gr'].iloc[:-1].astype('float').mean()\n",
    "color = 'gray!60!white'\n",
    "bar = (f'\\draw [{color}] (axis cs:{{{start_date}}},{val}) -- '+\n",
    "       f'(axis cs:{{{end_date}}},{val});')\n",
    "bardf = pd.Series(index=[start_date, end_date], \n",
    "                data=[val, val], name='Bar')\n",
    "node = end_node(bardf, color, loc='start')\n",
    "write_txt(text_dir / 'lprod_rec_bar_node.txt', bar + '\\n' + node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP Intro Chart and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:58:06.032860Z",
     "start_time": "2023-09-03T04:58:05.978320Z"
    }
   },
   "outputs": [],
   "source": [
    "df = nipa_df(retrieve_table('T10502')['Data'],\n",
    "             ['A191RL'])['A191RL']\n",
    "# Dates for latest quarters chart\n",
    "a = df.iloc[-8:]\n",
    "a['Quarter'] = [f'Q{i.quarter}\\\\\\\\{i.year}' if i.quarter == 1 \n",
    "                else dtxt(i)['qtr3'] for i in a.index]\n",
    "# From GDP Now (cover cases where no nowcast available)\n",
    "if gdpdt < nowdt:\n",
    "    next_qtr = rec.index[-1] + pd.DateOffset(months=3)\n",
    "    label = (f'Q{next_qtr.quarter}\\\\\\\\{next_qtr.year}' \n",
    "             if next_qtr.quarter == 1 else dtxt(next_qtr)['qtr3'])\n",
    "    frow = pd.DataFrame({'Quarter': label, \n",
    "                         'index': next_qtr}, index={'index': 4})\n",
    "    rec= pd.concat([rec.reset_index(), frow]).set_index('index')\n",
    "    rec.loc[next_qtr, 'A191RL'] = 0\n",
    "rec['zero'] = 0\n",
    "a.to_csv(data_dir/'gdp_rec2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:58:06.780893Z",
     "start_time": "2023-09-03T04:58:06.653370Z"
    }
   },
   "outputs": [],
   "source": [
    "df = nipa_df(retrieve_table('T70100')['Data'], ['A939RC', 'A939RX'])\n",
    "df['value'] = (df['A939RX'] / df['A939RX'].iloc[-1]) * df['A939RC'].iloc[-1]\n",
    "df.loc['1989':, 'value'].divide(1000).to_csv(data_dir / 'gdppc.csv', \n",
    "                                             index_label='date')\n",
    "cd = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC'].iloc[-1]\n",
    "rgdp = nipa_df(retrieve_table('T10106')['Data'], ['A191RX'])\n",
    "rgdp_cd = rgdp / rgdp.iloc[-1] * cd\n",
    "\n",
    "ltdate = dtxt(df.index[-1])['qtr2']\n",
    "gdp_val = int(rgdp_cd.iloc[-1].values[0] / 1000)\n",
    "gdp_prv_val = int(rgdp_cd.loc['2019-10-01'] / 1000)\n",
    "gdp_prv_val2 = int(rgdp_cd.iloc[0].values[0] / 1000)\n",
    "gdppc_val = int(df.iloc[-1].loc['value'])\n",
    "gdppc_prv_val = int(df.loc['2019-10-01', 'value'])\n",
    "gdppc_prv_val2 = int(df.iloc[0].loc['value'])\n",
    "qdate = dtxt(df.index[-1])['qtr1']\n",
    "pop = nipa_df(retrieve_table('T20100')['Data'], ['B230RC'])['B230RC']\n",
    "num = numbers[f'{(pop.pct_change(4).iloc[-1] * 1000).round()}']\n",
    "popnum = f'{num}-tenths of' if num != 'five' else 'half'\n",
    "color = 'red!95!black'\n",
    "cl = c_line(color)\n",
    "node = end_node(df['value'] / 1000, color, anchor='south', \n",
    "                dollar='thousands')\n",
    "write_txt(text_dir / 'gdp_pc_node.txt', node)\n",
    "text = (f'\\${gdp_val:,} billion in {ltdate}, compared to an '+\n",
    "        f'inflation-adjusted equivalent of \\${gdp_prv_val:,} '+\n",
    "        f'billion in 2019 Q4, and \\${gdp_prv_val2:,} billion in '+\n",
    "        'the first quarter of 1989.\\n\\nThe US population is growing '+\n",
    "        f'by about {popnum} a percent per year. GDP per capita '+\n",
    "        f'{cl}, adjusted for inflation to {qdate} dollars, had '+\n",
    "        f'increased to \\${gdppc_prv_val:,} in 2019 Q4 from '+\n",
    "        f'\\${gdppc_prv_val2:,} in 1989 Q1, and is currently '+\n",
    "        f'\\${gdppc_val:,}, as of {ltdate}.')\n",
    "write_txt(text_dir / 'gdp1.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:58:10.001135Z",
     "start_time": "2023-09-03T04:58:09.796562Z"
    }
   },
   "outputs": [],
   "source": [
    "pop = nipa_df(retrieve_table('T20100')['Data'], ['B230RC'])['B230RC']\n",
    "\n",
    "srs = {'A191RX': '\\hspace{0.01mm} {\\color{red!95!black}\\\\textbf{---}} Gross Domestic Product', \n",
    "       'DPCERX': '\\hspace{1.0mm} {\\color{yellow!45!orange}\\\\textbf{---}} Consumer Spending', \n",
    "       'A006RX': '\\hspace{1.0mm} {\\color{blue!70!black}\\\\textbf{---}} Gross Private Domestic Investment', \n",
    "       'A822RX': '\\hspace{1.0mm} {\\color{cyan!60!white}\\\\textbf{---}} Government Spending \\& Investment',\n",
    "       'A019RX': '\\hspace{1.0mm} {\\color{green!60!black}\\\\textbf{---}} Net Exports', \n",
    "       'A020RX': '\\hspace{4.5mm} Exports', 'A021RX': '\\hspace{4.5mm} Less: Imports'}\n",
    "s = [key for key, value in srs.items()]\n",
    "s2 = [i[:-1].replace('A02', 'B02') + 'C' for i in s]\n",
    "df = nipa_df(retrieve_table('T10106')['Data'], s).sort_index()\n",
    "df2 = nipa_df(retrieve_table('T10105')['Data'], s2).sort_index()\n",
    "\n",
    "dfpop = df.div(pop, axis=0)\n",
    "real_vals = df2.rename({i: i.replace('RC', 'RX').replace('B02', 'A02') \n",
    "                        for i in s2}, axis=1).iloc[-1]\n",
    "data = ((dfpop / dfpop.iloc[-1]) * (real_vals / pop.iloc[-1])).loc['1989':]\n",
    "\n",
    "sel_cols = ['DPCERX', 'A006RX', 'A019RX', 'A822RX']\n",
    "\n",
    "data[sel_cols].to_csv(data_dir / 'gdp_pc_comp.csv', index_label='date')\n",
    "\n",
    "pce = f'\\${data.DPCERX.iloc[-1] * 1000:,.0f}'\n",
    "inv = f'\\${data.A006RX.iloc[-1] * 1000:,.0f}'\n",
    "gov = f'\\${data.A822RX.iloc[-1] * 1000:,.0f}'\n",
    "exp = f'\\${abs(data.A019RX.iloc[-1]) * 1000:,.0f}'\n",
    "ltdt = dtxt(data.index[-1])['qtr1']\n",
    "pce_diff = f'\\${(data.DPCERX.iloc[-1] - data.DPCERX.iloc[0]) * 1000:,.0f}'\n",
    "\n",
    "text = ('Much of the increase in GDP over the past '+\n",
    "        '30 years comes from consumer spending. Consumer '+\n",
    "        'spending (see {\\color{yellow!45!orange}\\\\textbf{---}}) is '+\n",
    "        f'equivalent to {pce} per person in {ltdt}, a price-adjusted '+\n",
    "        f'increase of {pce_diff} since 1989.\\n\\nGross private domestic '+\n",
    "        'investment (see {\\color{blue!70!black}\\\\textbf{---}}) is '+\n",
    "        f'equivalent to {inv} per person in {ltdt}. Government '+\n",
    "        'spending and investment (see {\\color{cyan!60!white}\\\\textbf{---}}) '+\n",
    "        f'totals {gov} per person. The trade deficit, equivalent to {exp} per '+\n",
    "        'person, is subtracted, to capture only domestic production '+\n",
    "        '(see {\\color{green!60!black}\\\\textbf{---}}).')\n",
    "\n",
    "write_txt(text_dir / 'gdp_pc_comp.txt', text)\n",
    "write_txt(text_dir / 'gdp_ltdt.txt', ltdt)\n",
    "print(text)\n",
    "\n",
    "res = data * 1000\n",
    "lt = res.rename(srs, axis=1).iloc[-1]\n",
    "lt.name = dtxt(lt.name)['qtr1']\n",
    "pr = res.rename(srs, axis=1).iloc[-2]\n",
    "pr.name = dtxt(pr.name)['qtr1']\n",
    "pc = res.rename(srs, axis=1).loc['2019-10-01']\n",
    "pc.name = dtxt(pc.name)['qtr1']\n",
    "p00 = res.rename(srs, axis=1).loc['2000-01-01']\n",
    "p00.name = dtxt(p00.name)['qtr1']\n",
    "fi = res.rename(srs, axis=1).iloc[0]\n",
    "fi.name = dtxt(fi.name)['qtr1']\n",
    "table = pd.concat([lt, pr, pc, p00, fi], axis=1).applymap('{:,.0f}'.format)\n",
    "table.iloc[0, 0] = f'\\${table.iloc[0, 0]}'\n",
    "table.to_csv(data_dir / 'gdppc_levels.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:58:12.602083Z",
     "start_time": "2023-09-03T04:58:12.460726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compensation of employees divided by gross domestic income less \n",
    "# depreciation (net domestic income, as depreciation is income that\n",
    "# does not go to people)\n",
    "s = ['A261RC', 'A4002C', 'A262RC']\n",
    "\n",
    "df = nipa_df(retrieve_table('T11000')['Data'], s).sort_index()\n",
    "df['NDI'] = (df['A261RC'] - df['A262RC'])\n",
    "df['Share'] = (df['A4002C'] / df['NDI']) * 100\n",
    "data = df.loc['1989':, 'Share'].dropna()\n",
    "data.to_csv(data_dir / 'laborshare.csv', \n",
    "            index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "node = end_node(data, 'blue!60!cyan', date='q')\n",
    "write_txt(text_dir / 'laborshare_node.txt', node)\n",
    "\n",
    "s = series_info(data)\n",
    "ltdate = dtxt(s['date_latest'])['qtr2']\n",
    "one_yr = value_text(s['val_latest'] - s['val_year_ago'], ptype='pp')\n",
    "ltmin = s['val_latest'] - s['val_min']\n",
    "ltmax = s['val_max'] - s['val_latest']\n",
    "\n",
    "# Note on value of labor share\n",
    "emp = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                  parse_dates=True)['CES0000000001'] / 1_000\n",
    "emp = emp.resample('QS').mean()\n",
    "tot = ((df['NDI'].dropna()) * 0.01)\n",
    "ltndi = tot.iloc[-1] \n",
    "ltemp = emp.loc[tot.index[-1]]\n",
    "per_emp = (ltndi / ltemp).round(-1)\n",
    "\n",
    "ltdt = dtxt(tot.index[-1])['qtr1']\n",
    "\n",
    "ctxt = ('For context, one percent of annual NDI is equivalent to '+\n",
    "        f'\\${tot.iloc[-1] / 1000:.0f} billion, or '+\n",
    "        f'\\${per_emp:,.0f} per worker. ')\n",
    "\n",
    "text = (f'As of {ltdate}, labor receives {s[\"val_latest\"]:.1f} '+\n",
    "        f\"percent of NDI. Labor's share {one_yr} \"+\n",
    "        f'over the past year. {ctxt}\\n\\nThe labor share is {ltmin:.1f} '+\n",
    "        f'percentage points above its 30-year low of {s[\"val_min\"]:.1f} '+\n",
    "        f'percent in {s[\"date_min_ft\"]}, and {ltmax:.1f} percentage '+\n",
    "        f'points below the 30-year high of {s[\"val_max\"]:.1f} percent '+\n",
    "        f'in {s[\"date_max_ft\"]}. ')\n",
    "write_txt(text_dir / 'laborshare.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:58:14.266710Z",
     "start_time": "2023-09-03T04:58:14.225294Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A191RL']\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s).sort_index()\n",
    "df.loc['1989':].to_csv(data_dir / 'gdp.csv', index_label='date')\n",
    "date = dtxt(df.index[-1])['qtr1']\n",
    "\n",
    "txt = f'{date}: {df[\"A191RL\"].iloc[-1]}\\%'\n",
    "write_txt(data_dir / 'gdp.txt', txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:58:14.963587Z",
     "start_time": "2023-09-03T04:58:14.944711Z"
    }
   },
   "outputs": [],
   "source": [
    "dfa = (nipa_df(retrieve_table('T10101A')['Data'], ['A191RL'])\n",
    "       ['A191RL'])\n",
    "dfa.index = dfa.index + pd.DateOffset(months=6)\n",
    "dfa.loc['1989':].to_csv(data_dir / 'gdp_a.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:58:19.427996Z",
     "start_time": "2023-09-03T04:58:19.359198Z"
    }
   },
   "outputs": [],
   "source": [
    "df = nipa_df(retrieve_table('T10502')['Data'],\n",
    "             ['A191RL'])['A191RL']\n",
    "# Dates for latest quarters chart\n",
    "a = (df.iloc[-4:].to_frame()\n",
    "   .join(pd.Series({i: dtxt(i)['qtr4'].replace(' Q', '\\\\\\Q')\n",
    "                    for i in df.index[-4:]}, \n",
    "                   name='Quarter')))\n",
    "next_qtr = a.index[-1] + pd.DateOffset(months=3)\n",
    "dtxt(next_qtr)['qtr4'].replace(' Q', '\\\\\\Q')\n",
    "frow = pd.DataFrame({'Quarter': dtxt(next_qtr)['qtr4'].replace(' Q', '\\\\\\Q'), \n",
    "                     'index': next_qtr}, index={'index': 4})\n",
    "# From GDP Now (cover cases where no nowcast available)\n",
    "if gdpdt < nowdt:\n",
    "    a = pd.concat([a.reset_index(), frow]).set_index('index')\n",
    "    a.loc[next_qtr, 'A191RL'] = 0\n",
    "a['zero'] = 0\n",
    "a.to_csv(data_dir/'gdp_rec.csv', index_label='date')\n",
    "# Text\n",
    "lty = df.index[-1].year\n",
    "ltdt = dtxt(df.index[-1])['qtr2']\n",
    "ltdt2 = dtxt(df.index[-1])['qtr1']\n",
    "pry = df.index[-2].year\n",
    "pr2y = df.index[-3].year\n",
    "prdt = dtxt(df.index[-2])\n",
    "prdt = prdt['qtr3'] if lty == pry else prdt['qtr1']\n",
    "pr2dt = dtxt(df.index[-3])\n",
    "pr2dt = pr2dt['qtr3'] if lty == pr2y else pr2dt['qtr1']\n",
    "gtot = df.loc['1989':].mean()\n",
    "g9300 = df.loc['1993':'2000'].mean()\n",
    "g0013 = df.loc['2001':'2013'].mean()\n",
    "g1419 = df.loc['2014':'2019'].mean()\n",
    "# expenditure approach data\n",
    "d19 = (nipa_df(retrieve_table('T10106')['Data'], ['A191RX'])\n",
    "       .loc['2019-10-01':, 'A191RX'])\n",
    "g20on = cagr(d19)\n",
    "cov1 = value_text(df.loc['2020-04-01'])\n",
    "cov2 = value_text(df.loc['2020-07-01'], 'increase_by')\n",
    "ltval = value_text(df.iloc[-1], adj='annual')\n",
    "prval = value_text(df.iloc[-2], 'increase_of')\n",
    "prval2 = value_text(df.iloc[-3], 'increase_of')\n",
    "\n",
    "color='red'\n",
    "url = 'https://www.bea.gov/data/gdp/gross-domestic-product'\n",
    "text = ('Real GDP growth \\href{url}{measures} changes in '+\n",
    "        'economic activity. As seen in the previous subsection, '+\n",
    "        'real GDP has increased steadily over the long-term. '+\n",
    "        'Since 1989, growth averaged '+\n",
    "        f'{gtot:.1f} percent per year {c_box(color)}. '+\n",
    "        'Growth rates were relatively high during the mid- '+\n",
    "        f'to late-1990s, averaging {g9300:.1f} percent '+\n",
    "        'from 1993 to 2000.\\n\\nIn the 2000s, the housing '+\n",
    "        'bubble boosted GDP but then collapsed, '+\n",
    "        f'leading to average growth of only {g0013:.1f} '+\n",
    "        'percent from 2001 to 2013. Growth was slightly '+\n",
    "        f'stronger from 2014 to 2019, averaging {g1419:.1f} '+\n",
    "        'percent per year.\\n\\nIn 2020, COVID-19 caused '+\n",
    "        'an economic shutdown, followed by monetary '+\n",
    "        'and fiscal stimulus, resulting in large swings in '+\n",
    "        f'GDP. Annualized real GDP {cov1} in Q2, and {cov2} in Q3, '+\n",
    "        'by far the largest changes in recent history. Since 2019 Q4, '+\n",
    "        f'real GDP has grown at an average annual rate of {g20on:.1f} '+\n",
    "        'percent.')\n",
    "write_txt(text_dir / 'gdp_gr.txt', text)\n",
    "print(text)\n",
    "\n",
    "txt2 = ('The bottom-left chart shows annual growth, to make '+\n",
    "        'trends more visible. The bottom-right chart shows '+\n",
    "        'the most-recent four quarters and the estimate for the '+\n",
    "        'current quarter. In the \\\\textbf{latest data}, '+\n",
    "        f'covering {ltdt}, real GDP {ltval}, compared to {prval} '+\n",
    "        f'in {prdt}, and {prval2} in {pr2dt}.')\n",
    "write_txt(text_dir / 'gdp_gr2.txt', txt2)\n",
    "print('\\n', txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:58:22.081318Z",
     "start_time": "2023-09-03T04:58:22.070067Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dates for latest quarters chart\n",
    "a = df.iloc[-8:].to_frame()\n",
    "a['Quarter'] = [f'Q{i.quarter}\\\\\\\\{i.year}' if i.quarter == 1 \n",
    "                else dtxt(i)['qtr3'] for i in a.index]\n",
    "# From GDP Now (cover cases where no nowcast available)\n",
    "if gdpdt < nowdt:\n",
    "    next_qtr = a.index[-1] + pd.DateOffset(months=3)\n",
    "    label = (f'Q{next_qtr.quarter}\\\\\\\\{next_qtr.year}' \n",
    "             if next_qtr.quarter == 1 else dtxt(next_qtr)['qtr3'])\n",
    "    frow = pd.DataFrame({'Quarter': label, \n",
    "                         'index': next_qtr}, index={'index': 4})\n",
    "    a = pd.concat([a.reset_index(), frow]).set_index('index')\n",
    "    a.loc[next_qtr, 'A191RL'] = 0\n",
    "a['zero'] = 0\n",
    "a.to_csv(data_dir/'gdp_rec2.csv', index_label='date')\n",
    "\n",
    "# Average bar\n",
    "start_date = a.index[0] - pd.DateOffset(months=2)\n",
    "end_date = a.index[-1] + pd.DateOffset(months=1)\n",
    "val = df.mean()\n",
    "color = 'gray!60!white'\n",
    "bar = (f'\\draw [{color}] (axis cs:{{{start_date}}},{val}) -- '+\n",
    "       f'(axis cs:{{{end_date}}},{val});')\n",
    "bardf = pd.Series(index=[start_date, end_date], \n",
    "                data=[val, val], name='Bar')\n",
    "node = end_node(bardf, color, loc='start')\n",
    "write_txt(text_dir / 'gdp_rec2_bar_node.txt', bar + '\\n' + node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-02T04:46:49.344935Z",
     "start_time": "2023-08-02T04:46:49.341939Z"
    }
   },
   "source": [
    "### Nominal GDP decomposed as Real GDP and Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T04:59:02.455819Z",
     "start_time": "2023-09-03T04:59:02.387263Z"
    }
   },
   "outputs": [],
   "source": [
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], ['A191RL'])\n",
    "gdpgr = growth_rate(gdp)\n",
    "df['PR'] = growth_rate(gdp) - df['A191RL']\n",
    "df.loc['1989':].to_csv(data_dir / 'ngdp_gr.csv', index_label='date')\n",
    "(gdp.loc['1989':] / 1_000_000).to_csv(data_dir / 'ngdp.csv', \n",
    "                                      index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T05:28:59.029388Z",
     "start_time": "2023-09-03T05:28:59.008581Z"
    }
   },
   "outputs": [],
   "source": [
    "ltdt = dtxt(gdpgr.index[-1])['qtr2']\n",
    "prdt = dtxt(gdpgr.index[-2])['qtr1']\n",
    "pr2dt = dtxt(gdpgr.index[-3])['qtr1']\n",
    "ltch = value_text(gdpgr.iloc[-1], adj='annual')\n",
    "prch = value_text(gdpgr.iloc[-2], 'increase_of')\n",
    "pr2ch = value_text(gdpgr.iloc[-3], 'increase_of')\n",
    "\n",
    "ann19 = value_text(cagr(gdp.loc['2019-10-01':]), 'plain')\n",
    "ann89 = value_text(cagr(gdp.loc['1989-01-01':'2019-10-01']), adj='annual')\n",
    "    \n",
    "text = (f'In {ltdt}, nominal GDP {ltch}, following {prch} in {prdt}, '+\n",
    "        f'and {pr2ch} in {pr2dt}. From 1989 to 2019 Q4, nominal GDP '+\n",
    "        f'{ann89}. Since 2019 Q4, the annualized growth rate is {ann19}.')\n",
    "write_txt(text_dir / 'ngdp_gr.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-03T13:07:16.875163Z",
     "start_time": "2022-03-03T13:07:16.870308Z"
    }
   },
   "source": [
    "### Recessions Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:39:18.453802Z",
     "start_time": "2023-09-01T12:39:17.933126Z"
    }
   },
   "outputs": [],
   "source": [
    "rec = fred_df('USREC')\n",
    "rec.to_csv(data_dir / 'recessions_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T12:39:18.940367Z",
     "start_time": "2023-09-01T12:39:18.838137Z"
    }
   },
   "outputs": [],
   "source": [
    "rec = pd.read_csv(data_dir / 'recessions_raw.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "first = rec[(rec.VALUE==1) & (rec.VALUE.shift(1) == 0)]\n",
    "post = rec[(rec.VALUE==0) & (rec.VALUE.shift(1) == 1)]\n",
    "names = [' \\ Early `90s Recession', ' \\ Early `00s Recession', \n",
    "         ' \\ Great Recession', ' \\ COVID-19 Recession']\n",
    "recs = (pd.Series(data=first.index, index=names)\n",
    "        .rename('First').to_frame())\n",
    "recs['Last'] = rec[(rec.VALUE==1) & (rec.VALUE.shift(-1) == 0)].index\n",
    "recs['Pre'] = rec[(rec.VALUE==0) & (rec.VALUE.shift(-1) == 1)].index\n",
    "recs['Post'] = post.index\n",
    "dur = [i.n for i in (post.index.to_period('M') - \n",
    "                     first.index.to_period('M'))]\n",
    "recs['Dur'] = pd.Series(data=dur, index=recs.index)\n",
    "recs['PrevEnd'] = recs['Post'].shift(1)\n",
    "recs.loc[' \\ Early `90s Recession', 'PrevEnd'] = pd.to_datetime('1989-01-01')\n",
    "recs['NextStart'] = recs['Pre'].shift(-1)\n",
    "recs.loc[' \\ COVID-19 Recession', 'NextStart'] = cps_date()\n",
    "recs['Start'] = recs.First.apply(lambda x: dtxt(x)['mon2'])\n",
    "recs['End'] = recs.Last.apply(lambda x: dtxt(x)['mon2'])\n",
    "rgdp = nipa_df(retrieve_table('T10106')['Data'], ['A191RX'])['A191RX']\n",
    "unrate = pd.read_csv(data_dir / 'jobs_report_main.csv', index_col='date', \n",
    "                 parse_dates=True)['Total']\n",
    "for row in recs.itertuples():\n",
    "    # Real GDP change\n",
    "    vprev = rgdp.loc[:row.Pre].max()\n",
    "    vmin = rgdp.loc[row.First:row.NextStart].min()\n",
    "    ch = ((vmin / vprev) - 1) * 100\n",
    "    recs.loc[row.Index, 'GDPch'] = ch\n",
    "    # Unemployment rate change and duration\n",
    "    pravg = unrate.loc[row.Pre - pd.DateOffset(years=3): row.Pre].mean()\n",
    "    vmax = unrate.loc[row.First:row.NextStart].max()\n",
    "    uch = vmax - pravg\n",
    "    rdt = (unrate.loc[row.Last:].loc[(unrate <= pravg)].index[0] \n",
    "           if pravg >= unrate.iloc[-1] else '--')\n",
    "    rtime = (int((rdt.to_period('M') - row.Last.to_period('M')).n) \n",
    "             if rdt != '--' else '--')\n",
    "    recs.loc[row.Index, 'Unratech'] = uch    \n",
    "    recs.loc[row.Index, 'RecoDate'] = rdt\n",
    "    recs.loc[row.Index, 'RecoTime'] = str(rtime)\n",
    "recs['GDPcht'] =  recs.GDPch.apply('{:.1f}'.format)\n",
    "recs['Uncht'] =  recs.Unratech.apply('+{:.1f}'.format)\n",
    "tbl = recs[['Start', 'End', 'Dur', 'GDPcht', 'Uncht', 'RecoTime']]\n",
    "tbl.columns = ['Start \\ \\ \\ Month', 'End \\ \\ \\ \\ \\ \\ Month', \n",
    "               'Recession Duration, Months', \n",
    "               'GDP Percent Change', 'Unemp. Rate Change*', \n",
    "               'Unemp. Rate Recovery, Months**']\n",
    "tbl.to_csv(data_dir / 'recession.tex', sep='&', \n",
    "           lineterminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "un3 = unrate.rolling(3).mean()\n",
    "sahm = (un3 - un3.rolling(12).min()).dropna()\n",
    "sahm.to_csv(data_dir / 'sahm.csv', index_label='date', \n",
    "            header=True)\n",
    "bar = pd.Series(index=[sahm.index[0], sahm.index[-1]], \n",
    "                data=[0.5, 0.5], name='Bar')\n",
    "bar.to_csv(data_dir / 'sahm_bar.csv', index_label='date', \n",
    "           header=True)\n",
    "node = end_node(bar, 'gray', loc='start')\n",
    "write_txt(text_dir / 'sahm_bar_node.txt', node)\n",
    "marks = (sahm.loc[(sahm > 0.5) & (sahm.shift(1) < 0.5)]\n",
    "             .rename('Mark').to_frame())\n",
    "marks['Intersect'] = len(marks) * [0.5]\n",
    "marks.to_csv(data_dir / 'sahm_marks.csv', index_label='date')\n",
    "\n",
    "dur90 = numbers[f'{recs.Dur.iloc[0]:.1f}']\n",
    "unrec90 = recs.RecoTime.iloc[0]\n",
    "unrec00 = round(int(recs.RecoTime.iloc[1]) / 12)\n",
    "durgr = recs.Dur.iloc[2]\n",
    "unrecgr = recs.RecoTime.iloc[2]\n",
    "durco = numbers[f'{recs.Dur.iloc[3]:.1f}']\n",
    "gdpco = abs(recs.GDPch.iloc[3])\n",
    "\n",
    "text = ('During the early 1990s recession, output contracted '+\n",
    "        f'for {dur90} months and unemployment was higher '+\n",
    "        f'than its pre-recession average for {unrec90} months. '+\n",
    "        'The drop in output was smaller during the '+\n",
    "        'early 2000s recession, but unemployment rates '+\n",
    "        f'took almost {unrec00} years to recover.\\n\\n'+\n",
    "        'The 2008--2009 great recession, caused by the '+\n",
    "        'collapse of a housing bubble, was very severe. '+\n",
    "        f'The recession lasted {durgr} months, with higher '+\n",
    "        f'rates of unemployment lasting {unrecgr} months. The '+\n",
    "        'most-recent COVID-19 recession was extremely severe '+\n",
    "        f'and also extremely short-lived, lasting only {durco} '+\n",
    "        f'months, but with output reduced {gdpco:.1f} percent.')\n",
    "write_txt(text_dir / 'recessions.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investment overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T14:15:23.362977Z",
     "start_time": "2023-09-06T14:15:23.358683Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T10105'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T21:10:48.715367Z",
     "start_time": "2023-09-07T21:10:48.604679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the second quarter of 2023, annualized US \\textbf{gross fixed investment}, both public and private, totals \\$5.5 trillion, or 20.7 percent of GDP (see {\\color{black}\\textbf{---}}). Gross fixed investment is equivalent to 21.0 percent of GDP one year prior, in 2022 Q2, and also averages 21.0 percent of GDP in 2019.  \n",
      "\n",
      "In 2023 Q2, private nonresidential (business) fixed investment comprises 65 percent of the total and is equivalent to 13.4 percent of GDP (see\\cbox{yellow!70!orange!90!white}). Private residential makes up 18 percent of the total and 3.8 percent of GDP (see\\cbox{blue!60!white}). Public investment is 17 percent of the total and 3.5 percent of GDP (see\\cbox{violet!60!black}).\n"
     ]
    }
   ],
   "source": [
    "d = {'T10105': {'A007RC': 'PrGrossFixed', 'A008RC': 'PrGrossFixedNR', \n",
    "                'A011RC': 'PrGrossFixedRes', 'A191RC': 'GDP', \n",
    "                'A014RC': 'CIPI'},\n",
    "     'T30100': {'A782RC': 'GovGross'}}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for t, s in d.items():\n",
    "    i = nipa_df(retrieve_table(t)['Data'], s.keys()).rename(d, axis=1)\n",
    "    for v, n in s.items():\n",
    "        df[n] = i[v]\n",
    "        \n",
    "# Sum public and private gross investment\n",
    "df['Gross'] = df['PrGrossFixed'] + df['GovGross']\n",
    "df.to_csv(data_dir / 'grossinv_lvl.csv', index_label='date')\n",
    "\n",
    "# Share of GDP\n",
    "sh = df.divide(df.GDP, axis=0) * 100\n",
    "sh.loc['1989':].to_csv(data_dir / 'grossinv_sh.csv', index_label='date')\n",
    "\n",
    "# Text \n",
    "ltdt = dtxt(sh.index[-1])['qtr2']\n",
    "ltval = f'\\${df.Gross.iloc[-1] / 1_000_000:.1f} trillion'\n",
    "ltsh = f'{sh.Gross.iloc[-1]:.1f} percent of GDP'\n",
    "prsh = f'{sh.Gross.iloc[-5]:.1f} percent of GDP'\n",
    "prdt = dtxt(sh.index[-5])['qtr1'] \n",
    "sh19 = f'{sh.loc[\"2019\", \"Gross\"].mean():.1f} percent of GDP'\n",
    "also = 'also ' if prsh == sh19 else ''\n",
    "cl = c_line('black')\n",
    "\n",
    "text = (f'In {ltdt}, annualized US \\\\textbf{{gross fixed investment}}, '+\n",
    "        f'both public and private, totals {ltval}, or {ltsh} '+\n",
    "        f'{cl}. Gross fixed investment is equivalent to {prsh} '+\n",
    "        f'one year prior, in {prdt}, and {also}averages {sh19} '+\n",
    "        'in 2019. ')\n",
    "write_txt(text_dir / 'gross_inv_total.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "# Node for total\n",
    "node = end_node(sh.Gross, 'black', date='qs', offset=0.2)\n",
    "write_txt(text_dir / 'gross_inv_total_node.txt', node)\n",
    "# Nodes for latest values\n",
    "cols = ['GovGross', 'PrGrossFixedRes', 'PrGrossFixedNR']\n",
    "sdf = sh[cols].iloc[-1]\n",
    "height = ((sdf.cumsum() - (sdf / 2) + 1.5)).to_dict()\n",
    "val = sdf.to_dict()\n",
    "dtp = dtxt(sh.index[-1] + pd.DateOffset(months=2))['datetime']\n",
    "nodes = [f'\\\\absnode{{{{{dtp}}}}}{{{height[i]}}}{{\\scriptsize {val[i]:.1f}}}' \n",
    "         for i in cols]\n",
    "nodetext = '\\n'.join(nodes)\n",
    "write_txt(text_dir / 'gross_inv_nodes.txt', nodetext)\n",
    "\n",
    "# Color boxes in text\n",
    "govcb = c_box('violet!60!black').replace('see ', 'see')\n",
    "rescb = c_box('blue!60!white').replace('see ', 'see')\n",
    "nrcb = c_box('yellow!70!orange!90!white').replace('see ', 'see')\n",
    "\n",
    "# Text 2\n",
    "ltdt = dtxt(sh.index[-1])['qtr1']\n",
    "st = sh.iloc[-1].to_frame()\n",
    "st['sh'] = (st / st.loc['Gross']) * 100\n",
    "st['sh_txt'] = st['sh'].apply(value_text, style='plain', digits=0)\n",
    "st['gdp_txt'] = st.iloc[:,0].apply(value_text, style='plain')\n",
    "\n",
    "text = (f'In {ltdt}, private nonresidential (business) fixed investment '+\n",
    "        f'comprises {st.loc[\"PrGrossFixedNR\", \"sh_txt\"]} of the '+\n",
    "        f'total and is equivalent to {st.loc[\"PrGrossFixedNR\", \"gdp_txt\"]} '+\n",
    "        f'of GDP {nrcb}. Private residential makes up '+\n",
    "        f'{st.loc[\"PrGrossFixedRes\", \"sh_txt\"]} of the total and '+\n",
    "        f'{st.loc[\"PrGrossFixedRes\", \"gdp_txt\"]} of GDP {rescb}. Public '+\n",
    "        f'investment is {st.loc[\"GovGross\", \"sh_txt\"]} of the total '+\n",
    "        f'and {st.loc[\"GovGross\", \"gdp_txt\"]} of GDP {govcb}.')\n",
    "print(text)\n",
    "write_txt(text_dir / 'gross_inv_sector.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross fixed investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T14:46:25.495723Z",
     "start_time": "2023-09-07T14:46:25.489136Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T10502'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T21:08:15.752100Z",
     "start_time": "2023-09-07T21:08:15.624207Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For example, from 1996 to 1999, gross domestic fixed investment added an average of 1.75 percentage points to annual real GDP growth. \n",
      "\n",
      "In the second quarter of 2023, gross domestic fixed investment contributed 1.07 percentage points to annualized real GDP growth, following a contribution of 0.09 point in the first quarter. Over the past year, gross fixed investment contributed 0.97 percentage point to real GDP growth.\n",
      "\n",
      "In 2023 Q2, by type of gross fixed investment, private nonresidential contributed 0.80 percentage point to annualized real GDP growth (see\\cbox{yellow!70!orange!90!white}), private residential subtracted 0.14 percentage point (see\\cbox{blue!60!white}), and public contributed 0.41 percentage point (see\\cbox{violet!60!black}). Over the past year, nonresidential or business gross fixed investment contributed 1.21 percentage points, residential subtracted 0.64 point, and public contributed 0.41 point. \n",
      "\n",
      "In 2023 Q2, changes in private inventories subtracted 0.09 percentage point from annualized real GDP growth (see\\cbox{red}), following a subtraction of 2.14 percentage points in 2023 Q1. Over the past year, changes in private inventories subtracted 0.54 percentage point from real GDP growth.\n"
     ]
    }
   ],
   "source": [
    "# Retrieve levels data \n",
    "lvl = pd.read_csv(data_dir / 'grossinv_lvl.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "# Contribution to one-year growth\n",
    "ac = growth_contrib_ann(lvl, 'GDP')\n",
    "act = value_text(ac.Gross.iloc[-1], 'contribution_to', \n",
    "                 ptype='pp', digits=2)\n",
    "\n",
    "# Contribution to annualized quarterly growth\n",
    "s = ['A008RY', 'A011RY', 'A014RY', 'A788RY', 'A798RY', \n",
    "     'A799RY', 'A007RY']\n",
    "gc = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "gc['Gov'] = gc[['A788RY', 'A798RY', 'A799RY']].sum(axis=1)\n",
    "gc['Total'] = gc[['A007RY', 'Gov']].sum(axis=1)\n",
    "gc.loc['1989':].to_csv(data_dir / 'inv.csv', index_label='date')\n",
    "\n",
    "# Example of strong investment growth in late 1990s\n",
    "ex = value_text(gc.loc['1996': '1999', 'Total'].mean(), \n",
    "                    'added_lost', adj='average', digits=2, ptype='pp')\n",
    "\n",
    "# Generate text\n",
    "ltdate = dtxt(gc.index[-1])['qtr2']\n",
    "ltdt = dtxt(gc.index[-1])['qtr1']\n",
    "prdt = dtxt(gc.index[-2])['qtr1']\n",
    "prdate = dtxt(gc.index[-2])['qtr5']\n",
    "pr_dt = prdate if gc.index[-1].year == gc.index[-2].year else prdt\n",
    "tot = value_text(gc.Total.iloc[-1], 'contribution_to', ptype='pp', \n",
    "                 digits=2, threshold=0.01)\n",
    "totpr = value_text(gc.Total.iloc[-2], 'contribution_of', ptype='point',\n",
    "                 digits=2, threshold=0.01)\n",
    "\n",
    "bus = value_text(gc.A008RY.iloc[-1], 'contribution_to', ptype='pp', \n",
    "                 digits=2, threshold=0.01)\n",
    "res = value_text(gc.A011RY.iloc[-1], 'contribution', ptype='pp', \n",
    "                 digits=2, threshold=0.01)\n",
    "pub = value_text(gc.Gov.iloc[-1], 'contribution', ptype='pp', \n",
    "                 digits=2, threshold=0.01)\n",
    "cipi = value_text(gc.A014RY.iloc[-1], 'contribution_to', ptype='pp', \n",
    "                  digits=2, threshold=0.01)\n",
    "cipipr = value_text(gc.A014RY.iloc[-2], 'contribution_of', ptype='pp', \n",
    "                  digits=2, threshold=0.01)\n",
    "cipi_yr = value_text(ac.CIPI.iloc[-1], 'contribution', ptype='pp', \n",
    "                     digits=2, threshold=0.01)\n",
    "nr_yr = value_text(ac.PrGrossFixedNR.iloc[-1], 'contribution', ptype='pp', \n",
    "                     digits=2, threshold=0.01)\n",
    "res_yr = value_text(ac.PrGrossFixedRes.iloc[-1], 'contribution', \n",
    "                    ptype='point', digits=2, threshold=0.01)\n",
    "pub_yr = value_text(ac.GovGross.iloc[-1], 'contribution', ptype='point', \n",
    "                     digits=2, threshold=0.01)\n",
    "\n",
    "# Color boxes in text\n",
    "cbpub = c_box('violet!60!black').replace('see ', 'see')\n",
    "cbres = c_box('blue!60!white').replace('see ', 'see')\n",
    "cbbus = c_box('yellow!70!orange!90!white').replace('see ', 'see')\n",
    "cbcipi = c_box('red').replace('see ', 'see')\n",
    "\n",
    "text = ('For example, from 1996 to 1999, gross domestic fixed '+\n",
    "        f'investment {ex} to annual real GDP growth. \\n\\n'\n",
    "        f'In {ltdate}, gross domestic fixed investment {tot} '+\n",
    "        f'annualized real GDP growth, following {totpr} in {pr_dt}. '+\n",
    "        f'Over the past year, gross fixed investment {act} real '+\n",
    "        'GDP growth.\\n\\n'+\n",
    "        f'In {ltdt}, by type of gross fixed investment, private '+\n",
    "        f'nonresidential {bus} annualized real GDP growth {cbbus}, '+\n",
    "        f'private residential {res} {cbres}, and public {pub} '+\n",
    "        f'{cbpub}. Over the past year, nonresidential or business '+\n",
    "        f'gross fixed investment {nr_yr}, residential {res_yr}, and '+\n",
    "        f'public {pub_yr}.')\n",
    "write_txt(text_dir / 'inv_contrib_text.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "text = (f'In {ltdt}, changes in private inventories {cipi} '+\n",
    "        f'annualized real GDP growth {cbcipi}, following {cipipr} '+\n",
    "        f'in {prdt}. Over the past year, changes in private '+\n",
    "        f'inventories {cipi_yr} from real GDP growth.')\n",
    "write_txt(text_dir / 'cipi_contrib_text.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Fixed Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T05:54:18.411939Z",
     "start_time": "2023-09-08T05:54:18.202730Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'W171RC': 'NetDomInv',  'W790RC': 'NetBusInv', \n",
    "     'W791RC': 'NetHHInv', 'A889RC': 'NetGovInv', \n",
    "     'A928RC': 'GrossInv_NIPA', 'W170RC': 'GrossInv', \n",
    "     'A262RC': 'CFC', 'W276RC': 'CFCBus', 'W279RC': 'CFCHH',\n",
    "     'A264RC': 'CFCGov', 'W987RC': 'GrossBusInv', \n",
    "     'W988RC': 'GrossHHInv', 'A782RC': 'GrossGovInv'}\n",
    "df = nipa_df(retrieve_table('T50100')['Data'], d.keys()).rename(d, axis=1)\n",
    "df['GDP'] = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])\n",
    "sh = df.divide(df['GDP'], axis=0) * 100\n",
    "sh.loc['1989':].to_csv(data_dir / 'bea_nfi.csv', \n",
    "             index_label='date', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Exports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T06:35:35.737927Z",
     "start_time": "2023-09-03T06:35:35.607571Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import and Export share of GDP\n",
    "s = ['B020RC', 'B021RC', 'B648RC', 'LA000006']\n",
    "s2 = ['A191RC']\n",
    "df = nipa_df(retrieve_table('T40205')['Data'], s)\n",
    "df['A191RC'] = nipa_df(retrieve_table('T10105')['Data'], s2)\n",
    "df['EX'] = df['B020RC'] - df['LA000006']\n",
    "df['IM'] = df['B021RC'] - df['B648RC']\n",
    "data = (df.div(df['A191RC'], axis=0) * 100).loc['1989':]\n",
    "data.to_csv(data_dir / 'eximgdp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T06:35:36.650944Z",
     "start_time": "2023-09-03T06:35:36.644660Z"
    }
   },
   "outputs": [],
   "source": [
    "excol = 'green!60!teal!80!black'\n",
    "imcol = 'blue!90!cyan'\n",
    "\n",
    "node = end_node(data.IM, imcol, date='q',\n",
    "                percent=True, offset=-0.1, full_year=True)\n",
    "write_txt(text_dir / 'np_im_node.txt', node)\n",
    "node = end_node(data.EX, excol, percent=True)\n",
    "write_txt(text_dir / 'np_ex_node.txt', node)\n",
    "\n",
    "date = dtxt(data.index[-1])['qtr2']\n",
    "pc_dt = '2019-10-01'\n",
    "pc_date = dtxt(pd.to_datetime(pc_dt))['qtr1']\n",
    "text = ('Nonpetroleum goods and services imports '+\n",
    "        f'{c_line(imcol)} were equivalent to '+\n",
    "        f'{data.IM.iloc[-1]:.1f} percent of GDP '+\n",
    "        f'in {date}, while exports of nonpetroleum '+\n",
    "        f'goods and services {c_line(excol)} were '+\n",
    "        f'equivalent to {data.EX.iloc[-1]:.1f} percent '+\n",
    "        f'of GDP. In {pc_date}, nonpetroleum imports '+\n",
    "        f'were {data.IM.loc[pc_dt]:.1f} percent of GDP, '+\n",
    "        f'and exports were {data.EX.loc[pc_dt]:.1f} percent.')\n",
    "write_txt(text_dir / 'exim.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goods Import Penetration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:15:36.371229Z",
     "start_time": "2023-09-01T00:15:36.206425Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A353RC']\n",
    "\n",
    "G = nipa_df(retrieve_table('T10205')['Data'], s).sort_index()\n",
    "\n",
    "s = ['A253RC', 'A255RC', 'B647RC', 'LA000004', 'A650RC', \n",
    "     'B651RC', 'A652RC', 'A653RC', 'B648RC']\n",
    "\n",
    "MX = nipa_df(retrieve_table('T40205')['Data'], s).sort_index()\n",
    "\n",
    "D = G['A353RC'] - MX['A253RC'] + MX['A255RC']\n",
    "result = (MX['A255RC'] / D)\n",
    "\n",
    "import_categories = ['B647RC', 'LA000004', 'A650RC', 'B651RC', \n",
    "                     'A652RC', 'A653RC', 'B648RC']\n",
    "Msh = MX[import_categories].div(MX['A255RC'], axis=0)\n",
    "\n",
    "Msh['Consumer'] = Msh['B647RC'] + Msh['A652RC'] + Msh['B651RC']\n",
    "Msh['Capital'] = Msh['LA000004'] - Msh['B648RC'] + Msh['A650RC'] + Msh['A653RC']\n",
    "\n",
    "final = Msh[['Consumer', 'Capital', 'B648RC']].multiply(result, axis=0) * 100\n",
    "\n",
    "final.loc['1989':].to_csv(data_dir / 'goodsimpsh.csv', index_label='date')\n",
    "\n",
    "ltdate = final.index[-1]\n",
    "ltdt = dtxt(ltdate)['qtr1']\n",
    "cons, capi = [value_text(final[i].iloc[-1], style='eq') \n",
    "              for i in ['Consumer', 'Capital']]\n",
    "oil = final['B648RC'].iloc[-1]\n",
    "text = (f'As of {ltdt}, imports of consumer goods excluding petroleum '+\n",
    "        f'and petroleum products are {cons} of domestic consumption of '+\n",
    "        'goods (see\\cbox{cyan!40!white}). Petroleum-related imports claim '+\n",
    "        f'{oil:.1f} percent (see\\cbox{{purple}}) and imports of all other '+\n",
    "        f'goods, primarily capital goods, industrial supplies, and materials, '+\n",
    "        f'are {capi} (see\\cbox{{blue!50!cyan}}).')\n",
    "write_txt(text_dir / 'goodsimpsh1.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "ch11 = (final.loc['2011-01-01'] - final.iloc[0])\n",
    "cons11, pet11, oth11 = [value_text(ch11[i], adj='equivalent', threshold=0.1) \n",
    "                        for i in ['Consumer', 'B648RC', 'Capital']]\n",
    "chlt = (final.iloc[-1] - final.loc['2011-01-01'])\n",
    "conslt, petlt, othlt = [value_text(chlt[i], adj='equivalent', threshold=0.1) \n",
    "                        for i in ['Consumer', 'B648RC', 'Capital']]\n",
    "text = ('From 1989 to 2011, imports of consumer goods excluding '+\n",
    "        f'petroleum {cons11} of domestic consumption of goods; petroleum-'+\n",
    "        f'related imports {pet11}; and all other goods imports {oth11}. \\n\\n'+\n",
    "        f'Since 2011, imports of consumer goods {conslt} of domestic goods '+\n",
    "        f'demand; imports of petroleum products {petlt}; and other '+\n",
    "        f'imports {othlt}.')\n",
    "write_txt(text_dir / 'goodsimpsh.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITA - Financial Account Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:15:40.778196Z",
     "start_time": "2023-09-01T00:15:38.011119Z"
    }
   },
   "outputs": [],
   "source": [
    "ind_list = ['FinAssetsExclFinDeriv', 'FinLiabsExclFinDeriv', \n",
    "            'FinDeriv', 'StatDisc']\n",
    "\n",
    "api_results = bea_api_ita(ind_list, bea_key)\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {name: {i['TimePeriod']: i['DataValue'] \n",
    "            for i in json.loads(series)['BEAAPI']['Results']['Data']} \n",
    "     for name, series in api_results})\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = (df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "        .astype('float').rolling(4).sum())\n",
    "df['FAB'] = df['FinLiabsExclFinDeriv'] - df['FinAssetsExclFinDeriv']\n",
    "df['TOT'] = df[['FAB', 'StatDisc', 'FinDeriv']].sum(axis=1)\n",
    "final = (df.divide(gdp, axis=0).dropna(how='all') * 100).fillna(0)\n",
    "keep_cols = ['FinDeriv', 'StatDisc', 'FAB', 'TOT']\n",
    "final.loc['1989':, keep_cols].to_csv(data_dir/'fab.csv', index_label='date')\n",
    "\n",
    "s = final.iloc[-1]\n",
    "liab = value_text(s.FinLiabsExclFinDeriv, style='eq', adj='GDP')\n",
    "assets = value_text(s.FinAssetsExclFinDeriv, style='eq', adj='GDP')\n",
    "ldate = dtxt(final.index[-1])['qtr1']\n",
    "text = (f'Over the year ending {ldate}, net domestic acquisitions of '+\n",
    "        f'foreign assets were {assets}, while net domestic incurrence '+\n",
    "        f'of foreign liabilities was {liab}. As a result, domestic '+\n",
    "        f'net borrowing totals {s.TOT:.1f} percent of GDP over the '+\n",
    "         'one-year period.')\n",
    "write_txt(text_dir / 'fab.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T13:41:23.138507Z",
     "start_time": "2023-08-15T13:41:23.110755Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T10502'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDP Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:15:40.871852Z",
     "start_time": "2023-09-01T00:15:40.779816Z"
    }
   },
   "outputs": [],
   "source": [
    "# Contribution to growth from expenditure approach categories\n",
    "s = ['DPCERY', 'A006RY', 'A822RY', 'A019RY', 'A191RL']\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s).loc['1989':]\n",
    "df.to_csv(data_dir / 'comp.csv', index_label='date')\n",
    "\n",
    "# Text for chart on expenditure approach contributions\n",
    "ltdt = dtxt(df.index[-1])['qtr2']\n",
    "sl = [('DPCERY', 'contribution_to'), ('A006RY', 'contribution_to'), \n",
    "      ('A822RY', 'contribution'), ('A019RY', 'contribution')]\n",
    "d = {s: value_text(df[s].iloc[-1], style=style, ptype='pp', \n",
    "                   digits=2, threshold=0.1) for s, style in sl}\n",
    "text = (f'In {ltdt}, consumer spending (see\\cbox{{yellow!80!orange}}) '+\n",
    "        f'{d[\"DPCERY\"]} overall real GDP growth. Private domestic '+\n",
    "        f'investment (see\\cbox{{blue!70!black}}) {d[\"A006RY\"]} real GDP '+\n",
    "        'growth, government spending and investment (see\\cbox{cyan!50!white}) '+\n",
    "        f'{d[\"A822RY\"]}, and net exports (see\\cbox{{green!60!black}}) '+\n",
    "        f'{d[\"A019RY\"]}.')  \n",
    "write_txt(text_dir / 'gdp_exp_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T02:28:45.189770Z",
     "start_time": "2023-08-16T02:28:45.187787Z"
    }
   },
   "source": [
    "### Contribution to change since 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T05:47:48.203285Z",
     "start_time": "2023-09-03T05:47:48.007646Z"
    }
   },
   "outputs": [],
   "source": [
    "# expenditure approach data\n",
    "ex_s = ['A191RX', 'DPCERX', 'A006RX', 'A019RX', 'A822RX']\n",
    "ex_df = nipa_df(retrieve_table('T10106')['Data'], ex_s).loc['1989':]\n",
    "ex_v = {'A191RX': ['\\\\textbf{Real GDP} \\\\\\\\ \\\\textit{(annual rate)}', \n",
    "                   'red!95!black', 'white', 4.2], \n",
    "        'DPCERX': ['Consumer Spending', 'yellow!80!orange', 'black', 3],\n",
    "        'A006RX': ['Private\\\\\\\\ Investment', 'blue!70!black', 'white', 2],\n",
    "        'A822RX': ['Gov Spending \\& Investment', 'cyan!50!white', 'black', 1],\n",
    "        'A019RX': ['Net Exports', 'green!60!black', 'white', 0]}\n",
    "\n",
    "\n",
    "# income approach data\n",
    "inc_s = ['A261RC', 'A4002C', 'W271RC', 'indirect', 'A262RC']\n",
    "s = ['A261RX', 'W256RX']\n",
    "rgdi = nipa_df(retrieve_table('T11706')['Data'], s).dropna()\n",
    "\n",
    "s = ['A261RC', 'A4002C', 'W056RC', 'A107RC', 'W271RC', 'A262RC',\n",
    "     'A4102C', 'A038RC']\n",
    "\n",
    "df = nipa_df(retrieve_table('T11000')['Data'], s).dropna()\n",
    "\n",
    "# Calculate indirect taxes net of transfers\n",
    "df['indirect'] = df['W056RC'] - df['A107RC']\n",
    "\n",
    "# Calculate GDI deflator from real GDI series\n",
    "deflator = rgdi['A261RX'] / df['A261RC']\n",
    "deflator = deflator / deflator.iloc[-1]\n",
    "inc_df = df.multiply(deflator, axis=0)\n",
    "inc_v = {'A261RC': ['\\\\textbf{Real GDI} \\\\\\\\ \\\\textit{(annual rate)}', \n",
    "                    'blue!95!black', 'white', 4.2], \n",
    "         'A4002C': ['Labor', 'magenta!90!blue', 'white', 3],\n",
    "         'W271RC': ['Capital', 'yellow!60!orange', 'black', 2],\n",
    "         'indirect': ['Indirect Taxes Less Subsidies', 'violet', 'white', 1],\n",
    "         'A262RC': ['Depreciation', 'teal!60!white', 'black', 0]}\n",
    "\n",
    "# houshold inputs data\n",
    "hh_s = ['GDP_idx', 'POP_idx', 'EPOP_sa_idx', 'AAH_trend_idx', 'LPROD_idx']\n",
    "hh_df = pd.read_csv(data_dir / 'gdpjobslvl.csv', index_col='date', \n",
    "                 parse_dates=True).dropna()[hh_s]\n",
    "hh_v = {'GDP_idx': ['\\\\textbf{Real GDP} \\\\\\\\ \\\\textit{(annual rate)}', \n",
    "                    'red!95!black', 'white', 4.2], \n",
    "        'POP_idx': ['Population', 'lime!90!green', 'black', 2],\n",
    "        'EPOP_sa_idx': ['Employment Rate', 'green!30!teal!80!black', 'white', 1],\n",
    "        'AAH_trend_idx': ['Average \\\\\\\\ Workweek', 'blue', 'white', 0],\n",
    "        'LPROD_idx': ['Labor \\\\\\\\ Productivity', 'cyan!55!white', 'black', 3]}\n",
    "\n",
    "# Charts for each approach\n",
    "charts = {'exp': [ex_s, ex_df, ex_v], 'inc': [inc_s, inc_df, inc_v],\n",
    "          'hhinp': [hh_s, hh_df, hh_v]}\n",
    "for n, [s, df, v] in charts.items():\n",
    "    d19 = df.loc['2019-10-01':]\n",
    "    contrib = (((((d19.iloc[-1] - d19.iloc[0])\n",
    "                  / d19[s[0]].iloc[0]) + 1)\n",
    "                ** (1/((len(d19)-1)/4))) - 1) * 100\n",
    "    # Settings for plot\n",
    "    cmax = contrib.max()\n",
    "    cmin = contrib.min()\n",
    "    crng = cmax - cmin\n",
    "    cbuf = max([(cmax - 0), (0 - cmin)]) * 0.68 #Buffer for text labels\n",
    "    thresh = crng * 0.21 #Bigger bars labeled inside\n",
    "    empty_neg = f'\\\\addplot[white!0] coordinates {{(-{cbuf:.2f}, 0)}};'\n",
    "    empty_pos = f'\\\\addplot[white!0] coordinates {{({cbuf:.2f}, 0)}};'\n",
    "    txt = [empty_neg, empty_pos]\n",
    "\n",
    "    for k, [name, color, tcolor, y] in v.items():\n",
    "        x = contrib[k].round(3)\n",
    "        bar = f'\\\\addplot[{color}] coordinates {{({x}, {y})}};'\n",
    "        vtc = 'black'\n",
    "        tx = f'{contrib[k]:.1f}'\n",
    "        if abs(x) > thresh:  # Some value labels inside of bars\n",
    "            vt = f'\\scriptsize \\color{{{tcolor}}} \\\\textbf{{{tx}}}'\n",
    "            inside = True\n",
    "        else:\n",
    "            vt = f'\\scriptsize {tx}'\n",
    "            inside = False\n",
    "        if x > 0:\n",
    "            ytlab = 'left, align=right'\n",
    "            vtlab = 'left, align=right' if inside == True else 'right, align=right'\n",
    "        else:\n",
    "            ytlab = 'right, align=left'\n",
    "            vtlab = 'right, align=left' if inside == True else 'left, align=left'\n",
    "        # Create ylabel and value label\n",
    "        ylabel = f'\\\\node[{ytlab}, text width=2.0cm] at (axis cs:0,{y}) {{{name}}};'\n",
    "        vlabel = f'\\\\node[{vtlab}] at (axis cs:{x},{y}) {{{vt}}};'\n",
    "        txt.append(bar)\n",
    "        txt.append(ylabel)\n",
    "        txt.append(vlabel)\n",
    "    nodes = '\\n'.join(txt)\n",
    "    write_txt(text_dir / f'gdp_{n}_ch19.txt', nodes)\n",
    "\n",
    "    # Store latest date\n",
    "    write_txt(text_dir / f'gdp_{n}_ch19_dt.txt', dtxt(d19.index[-1])['qtr1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Domestic Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T07:37:35.002750Z",
     "start_time": "2023-09-03T07:37:34.844565Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A261RX', 'W256RX']\n",
    "rgdi = nipa_df(retrieve_table('T11706')['Data'], s).dropna()\n",
    "\n",
    "s = ['A261RC', 'A4002C', 'W056RC', 'A107RC', 'W271RC', 'A262RC',\n",
    "     'A4102C', 'A038RC']\n",
    "\n",
    "df = nipa_df(retrieve_table('T11000')['Data'], s).dropna()\n",
    "\n",
    "pop = nipa_df(retrieve_table('T20100')['Data'], ['B230RC'])['B230RC']\n",
    "\n",
    "# Calculate indirect taxes net of transfers\n",
    "df['indirect'] = df['W056RC'] - df['A107RC']\n",
    "\n",
    "# Calculate net domestic income (GDI less depreciation)\n",
    "df['NDI'] = df['A261RC'] - df['A262RC']\n",
    "\n",
    "# Calculate GDI deflator from real GDI series\n",
    "deflator = rgdi['A261RX'] / df['A261RC']\n",
    "deflator = deflator / deflator.iloc[-1]\n",
    "df = df.multiply(deflator, axis=0)\n",
    "\n",
    "# Calculate contributions to growth\n",
    "dft = df.diff()\n",
    "dft = dft.div(dft['A261RC'], axis=0)\n",
    "contr = dft.multiply((((df['A261RC'].pct_change() + 1) ** 4) - 1) * 100, axis=0)\n",
    "\n",
    "cols = ['A261RC', 'W271RC', 'A4002C', 'A262RC', 'indirect']\n",
    "\n",
    "contr.loc['1989':, cols].to_csv(data_dir / 'gdi.csv', index_label='date')\n",
    "\n",
    "dfpop = df.div(pop, axis=0).dropna()\n",
    "\n",
    "ltdt = dtxt(dfpop.index[-1])['qtr1']\n",
    "prdt = dtxt(dfpop.index[-2])['qtr1']\n",
    "write_txt(text_dir / 'gdi_ltdt.txt', ltdt)\n",
    "\n",
    "dfpop[cols].to_csv(data_dir / 'gdi_pc_comp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T07:37:35.878581Z",
     "start_time": "2023-09-03T07:37:35.860131Z"
    }
   },
   "outputs": [],
   "source": [
    "srs = {'A261RC': '\\hspace{0.1mm} Gross Domestic Income', \n",
    "       'A4002C': '\\hspace{-0.2mm} {\\color{magenta!90!blue}\\\\textbf{---}} Labor', \n",
    "       'A4102C': '\\hspace{4mm} Wages and Salaries',\n",
    "       'A038RC': '\\hspace{4mm} Supplements',\n",
    "       'W271RC': '\\hspace{-0.2mm} {\\color{yellow!60!orange}\\\\textbf{---}} Profit', \n",
    "       'indirect': '\\hspace{-0.1mm} {\\color{violet}\\\\textbf{---}} Indirect Taxes', \n",
    "       'W056RC': '\\hspace{4mm} Taxes on Production \\& Imports',\n",
    "       'A107RC': '\\hspace{4mm} Less: Subsidies',\n",
    "       'A262RC': '\\hspace{-0.2mm} {\\color{teal!60!white}\\\\textbf{---}} Depreciation'}\n",
    "\n",
    "res = (dfpop[list(srs.keys())] * 1000).dropna()\n",
    "lt = res.rename(srs, axis=1).iloc[-1]\n",
    "lt.name = dtxt(lt.name)['qtr1']\n",
    "pr = res.rename(srs, axis=1).iloc[-2]\n",
    "pr.name = dtxt(pr.name)['qtr1']\n",
    "pc = res.rename(srs, axis=1).loc['2019-10-01']\n",
    "pc.name = dtxt(pc.name)['qtr1']\n",
    "p12 = res.rename(srs, axis=1).loc['2012-01-01']\n",
    "p12.name = dtxt(p12.name)['qtr1']\n",
    "p00 = res.rename(srs, axis=1).loc['2000-01-01']\n",
    "p00.name = dtxt(p00.name)['qtr1']\n",
    "fi = res.rename(srs, axis=1).loc['1989-01-01']\n",
    "fi.name = dtxt(fi.name)['qtr1']\n",
    "table = pd.concat([lt, pr, pc, p12, p00, fi], axis=1).applymap('{:,.0f}'.format)\n",
    "table.iloc[0, 0] = f'\\${table.iloc[0, 0]}'\n",
    "table.to_csv(data_dir / 'gdipc_levels.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "# GDI text\n",
    "ltval = df['A261RC'].iloc[-1] / 1000\n",
    "ltpc = dfpop['A261RC'].iloc[-1] * 1000\n",
    "text = (f'of \\${ltval:,.0f} billion in {ltdt}, equivalent to '+\n",
    "        f'\\${ltpc:,.0f} per capita. ')\n",
    "write_txt(text_dir / 'gdi_levels.txt', text)\n",
    "print('\\n', text, '\\n')\n",
    "\n",
    "# NDI text\n",
    "ltval = df['NDI'].iloc[-1] / 1000\n",
    "ltpc = dfpop['NDI'].iloc[-1] * 1000\n",
    "text = (f'is \\${ltval:,.0f} billion in {ltdt}, or '+\n",
    "        f'\\${ltpc:,.0f} per capita. ')\n",
    "write_txt(text_dir / 'ndi_levels.txt', text)\n",
    "print('\\n', text, '\\n')\n",
    "\n",
    "# Labor and capital share\n",
    "lsh = (df['A4002C'] / df['NDI']) * 100\n",
    "csh = (df['W271RC'] / df['NDI']) * 100\n",
    "dsh = (df['A262RC'] / df['A261RC']) * 100\n",
    "\n",
    "# Text by income type\n",
    "prdate = '2019-10-01'\n",
    "l_pc = dfpop['A4002C'].iloc[-1] * 1000\n",
    "l_pr = dfpop['A4002C'].loc[prdate] * 1000\n",
    "k_pc = dfpop['W271RC'].iloc[-1] * 1000\n",
    "k_pr = dfpop['W271RC'].loc[prdate] * 1000\n",
    "t_pc = dfpop['indirect'].iloc[-1] * 1000\n",
    "t_pr = dfpop['indirect'].loc[prdate] * 1000\n",
    "d_pc = dfpop['A262RC'].iloc[-1] * 1000\n",
    "d_pr = dfpop['A262RC'].loc[prdate] * 1000\n",
    "\n",
    "text = (f'Labor receives {lsh.iloc[-1]:.1f} percent of NDI in {ltdt}. '+\n",
    "        'Gross labor income per capita is equivalent '+\n",
    "        f'to \\${l_pc:,.0f} in {ltdt} '+\n",
    "        '(see {\\color{magenta!90!blue}\\\\textbf{---}}) '+\n",
    "        f'and \\${l_pr:,.0f} in 2019 Q4, on an annualized, '+\n",
    "        'seasonally-adjusted, and inflation-adjusted basis.\\n\\n '+\n",
    "        f'Profits comprise {csh.iloc[-1]:.1f} percent of NDI in {ltdt}. '+\n",
    "        f'Profits per person total \\${k_pc:,.0f} in {ltdt} '+\n",
    "        '(see {\\color{yellow!60!orange}\\\\textbf{---}}) and '+\n",
    "        f'\\${k_pr:,.0f} in {prdt}, following the same adjustments. '+\n",
    "        f'Indirect taxes less subsidies per capita total \\${t_pc:,.0f} '+\n",
    "        f'in {ltdt} (see {{\\color{{violet}}\\\\textbf{{---}}}}) '+\n",
    "        f'and \\${t_pr:,.0f} in {prdt}.\\n\\nLastly, depreciation per '+\n",
    "        f'capita is \\${d_pc:,.0f} in {ltdt} (see '+\n",
    "        '{\\color{teal!60!white}\\\\textbf{---}}) and '+\n",
    "        f'\\${d_pr:,.0f} in {prdt}. Depreciation makes up '+\n",
    "        f'{dsh.iloc[-1]:.1f} percent of GDI in {ltdt}. ')\n",
    "write_txt(text_dir / 'gdi_levels_pc.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T07:37:39.956294Z",
     "start_time": "2023-09-03T07:37:39.947912Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A261RC', 'A4002C', 'W271RC', 'indirect', 'A262RC']\n",
    "df = contr[s]\n",
    "gdi_lt = value_text(df[\"A261RC\"].iloc[-1], adj='annual')\n",
    "gdi_pr = value_text(df[\"A261RC\"].iloc[-2], style='increase_of')\n",
    "gdi_pr2 = value_text(df[\"A261RC\"].iloc[-3], style='increase_of')\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['qtr2']\n",
    "ltdt2 = dtxt(df.index[-1])['qtr1']\n",
    "prdt = dtxt(df.index[-2])['qtr1']\n",
    "prdt2 = dtxt(df.index[-3])['qtr1']\n",
    "\n",
    "text1 = (f'In {ltdt}, gross domestic income {gdi_lt}, following {gdi_pr} '+\n",
    "         f'in {prdt} and {gdi_pr2} in {prdt2}. ')  \n",
    "\n",
    "l_lt = value_text(df[\"A4002C\"].iloc[-1], style='contribution_to', \n",
    "                  digits=2, ptype='pp')\n",
    "l_pr = value_text(df[\"A4002C\"].iloc[-2], style='contribution_of', \n",
    "                  digits=2, ptype='pp')\n",
    "k_lt = value_text(df[\"W271RC\"].iloc[-1], style='contribution', \n",
    "                  digits=2, ptype='pp')\n",
    "k_pr = value_text(df[\"W271RC\"].iloc[-2], style='contribution', \n",
    "                  digits=2, ptype='pp')\n",
    "t_lt = value_text(df['indirect'].iloc[-1], style='contribution_to', \n",
    "                  digits=2, ptype='pp')\n",
    "t_pr = value_text(df['indirect'].iloc[-2], style='contribution', \n",
    "                  digits=2, ptype='pp')\n",
    "    \n",
    "text = (f'{text1}In the latest quarter, labor income {l_lt} overall growth, '+\n",
    "        f'following {l_pr} in {prdt}. Profit income {k_lt} in '+\n",
    "        f'{ltdt} and {k_pr} in {prdt}. Changes in indirect tax revenue '+\n",
    "        f'and surpluses {t_lt} aggregate income growth in the latest quarter and '+\n",
    "        f'{t_pr} in {prdt}. ')\n",
    "write_txt(text_dir / 'gdi_growth_comp.txt', text)\n",
    "print(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Spending Overview (Levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:16:16.401046Z",
     "start_time": "2023-09-01T00:16:15.901136Z"
    }
   },
   "outputs": [],
   "source": [
    "pop = nipa_df(retrieve_table('T20100')['Data'], ['B230RC'])['B230RC']\n",
    "\n",
    "n = {'DPCERC': 'Total',\n",
    "     'DGDSRC': 'Goods',\n",
    "     'DSERRC': 'Services',\n",
    "     'DHUTRC': 'Housing',\n",
    "     'A011RC': 'ResInv',\n",
    "     'DMOTRC': 'MotorVeh',\n",
    "     'DFDHRC': 'Furn',\n",
    "     'DREQRC': 'RecDG',\n",
    "     'DFXARC': 'Groc',\n",
    "     'DCLORC': 'Cloth',\n",
    "     'DHLCRC': 'Health',\n",
    "     'DTRSRC': 'Transp',\n",
    "     'DRCARC': 'RecSer',\n",
    "     'DFSARC': 'FoodAcc',\n",
    "     'DIFSRC': 'FinIns'}\n",
    "n2 = {k[:-2] + 'RA': v for k, v in n.items()}\n",
    "s = list(n.keys())\n",
    "s2 = list(n2.keys())\n",
    "\n",
    "othserv = lambda x: x['Services'] - x['Housing']\n",
    "shelter = lambda x: x['Housing'] + x['ResInv']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T10505')['Data'], s)\n",
    "      .rename(n, axis=1))\n",
    "df2 = (nipa_df(retrieve_table('T10503')['Data'], s2)\n",
    "       .rename(n2, axis=1))\n",
    "real = ((df2 / df2.iloc[-1]) * df.iloc[-1]).assign(OTHSERV = othserv, SHELTER = shelter)\n",
    "pp = real.divide(pop, axis=0)\n",
    "\n",
    "keep_col = ['Goods', 'Services', 'Housing', 'ResInv', 'OTHSERV', 'SHELTER']\n",
    "pp.loc['1989':, keep_col].to_csv(data_dir / 'pce_levels.csv', index_label='date')\n",
    "\n",
    "lttot = real.Total.iloc[-1] / 1_000_000\n",
    "prtot = real.Total.iloc[-2] / 1_000_000\n",
    "pctot = real.Total.loc['2019-10-01'] / 1_000_000\n",
    "ltdate = dtxt(real.index[-1])['qtr1']\n",
    "prdate = dtxt(real.index[-2])['qtr1']\n",
    "totpp = pp.Total.iloc[-1] * 1_000\n",
    "goodpp = pp.Goods.iloc[-1] * 1_000\n",
    "servpp = pp.Services.iloc[-1] * 1_000\n",
    "goodpppc = pp.Goods.loc['2019-10-01'] * 1_000\n",
    "servpppc = pp.Services.loc['2019-10-01'] * 1_000\n",
    "\n",
    "text = ('Total consumer spending is '+\n",
    "        f'\\${lttot:.1f} trillion in {ltdate}, compared to a price-adjusted '+\n",
    "        f'\\${prtot:.1f} trillion in {prdate} and \\${pctot:.1f} trillion in 2019 Q4. '+\n",
    "        'On a per person basis, consumer spending is '+\n",
    "        f'\\${totpp:,.0f} in {ltdate}, of which \\${goodpp:,.0f} are spent on goods '+\n",
    "        '(see {\\color{red}\\\\textbf{---}}) and '+\n",
    "        f'\\${servpp:,.0f} on services '+\n",
    "        '(see {\\color{orange}\\\\textbf{---}}). In the fourth quarter of 2019, '+\n",
    "        f'before the pandemic, consumer spending on goods was \\${goodpppc:,.0f} '+\n",
    "        f'per person, and spending on services was \\${servpppc:,.0f} per person, '+\n",
    "        'after adjusting for inflation. ')\n",
    "write_txt(text_dir / 'pce_levels.txt', text)\n",
    "print(text)\n",
    "\n",
    "hult = pp['Housing'].iloc[-1] * 1_000\n",
    "hupc = pp['Housing'].loc['2019-10-01'] * 1_000\n",
    "rfilt = pp['ResInv'].iloc[-1] * 1_000\n",
    "rfipc = pp['ResInv'].loc['2019-10-01'] * 1_000\n",
    "\n",
    "text = ('Within consumer spending on services, housing and utilities spending '+\n",
    "        f'totals \\${hult:,.0f} on an annualized and per person basis in {ltdate} '+\n",
    "        '(see {\\color{green!60!blue}\\\\textbf{---}}) '+\n",
    "        f'and \\${hupc:,.0f} in 2019 Q4. Construction or improvement '+\n",
    "        'of housing is considered residential fixed investment, not '+\n",
    "        'consumer spending, but can be combined with spending to analyze '+\n",
    "        'patterns in shelter costs. In '+\n",
    "        f'{ltdate}, residential investment totals \\${rfilt:,.0f} per person '+\n",
    "        '(see {\\color{blue!80!black}\\\\textbf{---}}), '+\n",
    "        f'compared to \\${rfipc:,.0f} in the pre-COVID data covering 2019 Q4. ')\n",
    "write_txt(text_dir / 'pce2_levels.txt', text)\n",
    "print('\\n', text)\n",
    "\n",
    "othlt = pp['OTHSERV'].iloc[-1] * 1_000\n",
    "othpr = pp['OTHSERV'].iloc[-2] * 1_000\n",
    "othpc = pp.loc['2019-10-01', 'OTHSERV'] * 1_000\n",
    "chval = ((othlt / othpc) - 1) * 100\n",
    "chtxt = value_text(chval)\n",
    "shellt = pp['SHELTER'].iloc[-1] * 1_000\n",
    "shelpr = pp['SHELTER'].iloc[-2] * 1_000\n",
    "shelpc = pp.loc['2019-10-01', 'SHELTER'] * 1_000\n",
    "shelmax = pp['SHELTER'].max() * 1_000\n",
    "shelmaxdt = dtxt(pp.SHELTER.idxmax())['qtr2']\n",
    "\n",
    "text = ('Consumer spending on services other than housing and utilities totals \\$'+\n",
    "        f'{othlt:,.0f} per person, on an annualized basis, in {ltdate} '+\n",
    "        '(see {\\color{blue!75!white}\\\\textbf{---}}), '+\n",
    "        f'compared to \\${othpr:,.0f} in {prdate}, and \\${othpc:,.0f} in '+\n",
    "        f'2019 Q4. Spending on non-housing services has {chtxt} since 2019 Q4. '+\n",
    "        '\\n\\nShelter costs, which combine housing, utilities, and residential fixed '+\n",
    "        f'investment, are \\${shellt:,.0f} per person in {ltdate} '+\n",
    "        '(see {\\color{green!85!blue}\\\\textbf{---}})'+\n",
    "        f', \\${shelpr:,.0f} '+\n",
    "        f'in {prdate}, and \\${shelpc:,.0f} in 2019 Q4. Shelter spending peaked at '+\n",
    "        f'\\${shelmax:,.0f} per person in {shelmaxdt}, during the housing bubble.')\n",
    "write_txt(text_dir / 'pce3_levels.txt', text)\n",
    "print('\\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:16:17.845025Z",
     "start_time": "2023-09-01T00:16:17.817241Z"
    }
   },
   "outputs": [],
   "source": [
    "n = {'Total': 'Total',\n",
    "     'Goods': '\\hspace*{-0.6mm} {\\color{red}\\\\textbf{---}} Goods',\n",
    "     'MotorVeh': '\\hspace{4mm} Motor Vehicles \\& Parts',\n",
    "     'Furn': '\\hspace{4mm} Furniture \\& HH Equipment',\n",
    "     'RecDG': '\\hspace{4mm} Recreational Durable Goods',\n",
    "     'Groc': '\\hspace{4mm} Groceries',\n",
    "     'Cloth': '\\hspace{4mm} Clothes \\& Shoes',\n",
    "     'OTHSERV': '\\hspace*{-0.6mm} {\\color{blue!75!white}\\\\textbf{---}} Services ex. Shelter',\n",
    "     'Health': '\\hspace{4mm} Health Care Services',\n",
    "     'Transp': '\\hspace{4mm} Transportation',\n",
    "     'RecSer': '\\hspace{4mm} Recreational',\n",
    "     'FoodAcc': '\\hspace{4mm} Food \\& Accommodations',\n",
    "     'FinIns': '\\hspace{4mm} Financial \\& Insurance',\n",
    "     'SHELTER': '\\hspace*{-0.6mm} {\\color{green!85!blue}\\\\textbf{---}} Shelter ',\n",
    "     'Housing': '\\hspace{4mm} Housing Services \\& Utilities ',\n",
    "     'ResInv': '\\hspace{4mm} Residential Fixed Investment'}\n",
    "\n",
    "res = pp[n.keys()].rename(n, axis=1) * 1_000\n",
    "lt = res.iloc[-1]\n",
    "lt.name = dtxt(lt.name)['qtr1']\n",
    "pr = res.iloc[-2]\n",
    "pr.name = dtxt(pr.name)['qtr1']\n",
    "py = res.iloc[-5]\n",
    "py.name = dtxt(py.name)['qtr1']\n",
    "pc = res.loc['2019-10-01']\n",
    "pc.name = dtxt(pc.name)['qtr1']\n",
    "p00 = res.loc['2000-01-01']\n",
    "p00.name = dtxt(p00.name)['qtr1']\n",
    "fi = res.loc['1989-01-01']\n",
    "fi.name = dtxt(fi.name)['qtr1']\n",
    "table = pd.concat([lt, pr, py, pc, p00, fi], axis=1).applymap('{:,.0f}'.format)\n",
    "table.columns = table.columns.str.replace(' ', '\\n')\n",
    "table.iloc[0, 0] = f'\\${table.iloc[0, 0]}'\n",
    "table.to_csv(data_dir / 'pce_levels.tex', sep='&', lineterminator='\\\\\\ ', quotechar=' ')\n",
    "#table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Spending and Residential Fixed Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:07:40.827029Z",
     "start_time": "2023-08-30T13:07:40.578780Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['DNPIRY', 'DSERRY', 'DPCERY', 'DGDSRY', 'DMOTRY',\n",
    "     'DFDHRY', 'DREQRY', 'DFXARY', 'DCLORY', 'DHLCRY',\n",
    "     'DTRSRY', 'DRCARY', 'DFSARY', 'DIFSRY', 'DHUTRY',\n",
    "     'A011RY']\n",
    "\n",
    "n = {'TOTAL': '& Total',\n",
    "     'DGDSRY': '\\cbox{red} & Goods',\n",
    "     'DMOTRY': '& \\hspace{1mm} Motor Vehicles and Parts',\n",
    "     'DFDHRY': '& \\hspace{1mm} Furniture and HH Equipment',\n",
    "     'DREQRY': '& \\hspace{1mm} Recreational Durable Goods',\n",
    "     'DFXARY': '& \\hspace{1mm} Groceries',\n",
    "     'DCLORY': '& \\hspace{1mm} Clothes and Shoes',\n",
    "     'OTHSERV': '\\cbox{blue!75!white} & Services (ex. Shelter)',\n",
    "     'DHLCRY': '& \\hspace{1mm} Health Care Services',\n",
    "     'DTRSRY': '& \\hspace{1mm} Transportation',\n",
    "     'DRCARY': '& \\hspace{1mm} Recreational',\n",
    "     'DFSARY': '& \\hspace{1mm} Food and Accommodations',\n",
    "     'DIFSRY': '& \\hspace{1mm} Financial and Insurance',\n",
    "     'SHELTER': '\\cbox{green!85!blue} & Shelter ',\n",
    "     'DHUTRY': '& \\hspace{1mm} Housing Services and Utilities ',\n",
    "     'A011RY': '& \\hspace{1mm} Residential Fixed Investment'}\n",
    "\n",
    "total = lambda x: x['DPCERY']\n",
    "othserv = lambda x: x['DSERRY'] - x['DHUTRY']\n",
    "shelter = lambda x: x['DHUTRY'] + x['A011RY']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "      .assign(TOTAL = total, OTHSERV = othserv, SHELTER = shelter)\n",
    "      [list(n.keys())])\n",
    "\n",
    "#(df.loc['1989':, ['DGDSRY', 'OTHSERV', 'SHELTER']]\n",
    "#   .to_csv(data_dir / 'pce.csv', index_label='date', float_format='%g'))\n",
    "\n",
    "(df.loc['1988':, ['DGDSRY', 'OTHSERV', 'SHELTER']]\n",
    " .rolling(4).mean().dropna()\n",
    " .to_csv(data_dir / 'pce_ma.csv', index_label='date', float_format='%g'))\n",
    "\n",
    "data = df.iloc[-5:].iloc[::-1].T\n",
    "\n",
    "cols = [f'& {q.year} Q{q.quarter}' \n",
    "        if i == 0 else f'`{str(q.year)[2:]} Q{q.quarter}'\n",
    "        for i, q in enumerate(data.columns)]\n",
    "\n",
    "data.columns = cols\n",
    "data['3-year'] = df.rolling(13).mean().iloc[-1].round(2)\n",
    "data['10-year'] = df.rolling(41).mean().iloc[-1].round(2)\n",
    "data['30-year'] = df.rolling(121).mean().iloc[-1].round(2)\n",
    "data.index = data.index.map(n)\n",
    "(data.round(2).applymap('{:,.2f}'.format)\n",
    " .to_csv(data_dir / 'pce.tex', sep='&', lineterminator='\\\\\\ ', quotechar=' '))\n",
    "\n",
    "ld = dtxt(df.index[-1])['qtr1']\n",
    "prd = dtxt(df.index[-2])['qtr1']\n",
    "ld2 = dtxt(df.index[-1])['qtr2']\n",
    "\n",
    "totlt = df['TOTAL'].iloc[-1]\n",
    "totltt = value_text(totlt, style='contribution_to', ptype='pp', \n",
    "                    digits=1, threshold=0.1)\n",
    "totpr = df['TOTAL'].iloc[-2]\n",
    "totprt = value_text(totpr, style='contribution', ptype='pp', \n",
    "                    digits=1, threshold=0.1)\n",
    "totpc = df.loc['2019-10-01', 'TOTAL']\n",
    "totpct = value_text(totpc, style='contribution_of', ptype='pp', \n",
    "                    digits=1, casual=True, threshold=0.1)\n",
    "\n",
    "txt1 = (f'These categories {totltt} GDP growth in {ld} and {totprt} in '+\n",
    "        f'{prd}, compared to {totpct} in 2019 Q4, before the pandemic.')\n",
    "write_txt(text_dir / 'pce1.txt', txt1)\n",
    "print(txt1)\n",
    "\n",
    "gdslt = df['DGDSRY'].iloc[-1]\n",
    "gdsltt = value_text(gdslt, style='contribution_to', ptype='pp', \n",
    "                    digits=1, threshold=0.1)\n",
    "serlt = df['OTHSERV'].iloc[-1]\n",
    "serltt = value_text(serlt, style='contribution', ptype='pp', digits=1, \n",
    "                    casual=True, threshold=0.1)\n",
    "shelt = df['SHELTER'].iloc[-1]\n",
    "sheltt = value_text(shelt, style='contribution', ptype='pp', \n",
    "                    digits=1, threshold=0.1)\n",
    "\n",
    "txt2 = (f'In {ld2}, household spending on goods {gdsltt} GDP growth, '+\n",
    "         'household spending on services other than housing and utilities '+\n",
    "        f'{serltt}, and shelter spending and investment {sheltt}.')\n",
    "write_txt(text_dir / 'pce2.txt', txt2)\n",
    "print('\\n', txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade Contribution to GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:07:42.794181Z",
     "start_time": "2023-08-30T13:07:42.692910Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A019RY', 'A253RY', 'A646RY', 'A255RY', 'A656RY']\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "df.loc['1989':].to_csv(data_dir / 'nx.csv', index_label='date')\n",
    "\n",
    "sl = [('A253RY', 'contribution_to'), ('A646RY', 'contribution'), \n",
    "      ('A255RY', 'contribution_to'), ('A656RY', 'contribution')]\n",
    "\n",
    "d = {}\n",
    "for s, style in sl:\n",
    "    d[s] = value_text(df[s].iloc[-1], style, 'pp', digits=2)\n",
    "    \n",
    "ldate = dtxt(df.index[-1])['qtr2']\n",
    "\n",
    "text = (f\"Goods exports {d['A253RY']} GDP growth in {ldate} while \"+\n",
    "        f\"services exports {d['A646RY']}. Good imports {d['A255RY']} \"+\n",
    "        f\"GDP growth and services imports {d['A656RY']}.\")\n",
    "write_txt(text_dir / 'trade.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T06:17:09.249717Z",
     "start_time": "2023-09-03T06:17:09.183045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Contributions to growth\n",
    "s = ['Y001RY', 'A009RY', 'Y033RY']\n",
    "\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], s)\n",
    "df.loc['1989':].to_csv(data_dir / 'businv.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T06:17:10.114436Z",
     "start_time": "2023-09-03T06:17:10.010825Z"
    }
   },
   "outputs": [],
   "source": [
    "# By category/type\n",
    "s = ['Y001RC', 'B009RC', 'Y033RC', 'A008RC']\n",
    "data = nipa_df(retrieve_table('T10105')['Data'], s)\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "df1 = data.divide(gdp, axis=0) * 100\n",
    "(df1.loc['1989':, ['Y001RC', 'B009RC', 'Y033RC']]\n",
    "    .to_csv(data_dir / 'businvsh.csv', index_label='date'))\n",
    "\n",
    "ltdate = dtxt(df1.index[-1])['qtr1']\n",
    "\n",
    "levels = {}\n",
    "shgdp = {}\n",
    "for series in ['Y001RC', 'B009RC', 'Y033RC']:\n",
    "    level_val = data[series].iloc[-1] / 1_000\n",
    "    txt = f\"\\${level_val:,.0f} billion\"\n",
    "    levels[series] = txt\n",
    "    shgdp[series] = f\"{df1[series].iloc[-1]:.1f} percent of GDP\"\n",
    "\n",
    "text = ('Business investments in fixed assets are grouped into three '+\n",
    "        'categories: structures, equipment, and intellectual property '+\n",
    "        '(for example software and R\\&D). Annualized investment in '+\n",
    "        f'structures is {levels[\"B009RC\"]} in {ltdate}, equivalent to '+\n",
    "        f'{shgdp[\"B009RC\"]} '+\n",
    "        '(see {\\color{yellow!50!orange}\\\\textbf{---}}). '+\n",
    "        f'Equipment investment is {levels[\"Y033RC\"]} or {shgdp[\"Y033RC\"]} '+\n",
    "        '(see {\\color{cyan!60!white}\\\\textbf{---}}), '+\n",
    "        'and intellectual property investment '+\n",
    "        f'is {levels[\"Y001RC\"]} or {shgdp[\"Y001RC\"]} '+\n",
    "        '(see {\\color{violet}\\\\textbf{---}}). ')\n",
    "write_txt(text_dir / 'businv_sh.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-03T06:28:31.733102Z",
     "start_time": "2023-09-03T06:28:31.642915Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gross vs Net\n",
    "s = ['W790RC', 'W276RC', 'W987RC']\n",
    "df = nipa_df(retrieve_table('T50100')['Data'], s).join(data['A008RC'])\n",
    "df['NFI'] = (df['A008RC'] - df['W276RC']) # Net Fixed Investment\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "res = (df.div(gdp, axis=0) * 100).dropna()\n",
    "res.loc['1989':].to_csv(data_dir / 'businv_main.csv', index_label='date')\n",
    "\n",
    "ltdate1 = dtxt(df.index[-1])['qtr1']\n",
    "ltdate2 = dtxt(df.index[-1])['qtr2']\n",
    "\n",
    "levels = {}\n",
    "shgdp = {}\n",
    "for series in ['W790RC', 'W276RC', 'W987RC', 'A008RC', 'NFI']:\n",
    "    level_val = df[series].iloc[-1] / 1_000\n",
    "    n = ''\n",
    "    if level_val < 0:\n",
    "        n = 'negative '\n",
    "        level_val = abs(level_val)\n",
    "    txt = f\"{n}\\${level_val:,.0f} billion\"\n",
    "    levels[series] = txt\n",
    "    shgdp[series] = f\"{res[series].iloc[-1]:.1f} percent of GDP\"\n",
    "    \n",
    "diff = cagr(df.loc['2019-10-01':, 'W987RC'])\n",
    "gdt = value_text(diff, adj='annual')\n",
    "diff2 = cagr(df.loc['2019-10-01':, 'NFI'])\n",
    "if diff2 < -95:\n",
    "    ndt = 'but collapsed completely'\n",
    "else:\n",
    "    ndt = 'and ' + value_text(diff2, adj='annual')\n",
    "gpcl = f\"{n}\\${df.loc['2019-10-01', 'W987RC'] / 1_000:,.0f} billion\"\n",
    "npcl = f\"{n}\\${df.loc['2019-10-01', 'NFI'] / 1_000:,.0f} billion\"\n",
    "if diff < 0:\n",
    "    txt = 'as gross investment outpaced depreciation'\n",
    "else:\n",
    "    txt = 'as growth of depreciation costs outpaced the increase in gross investment'\n",
    "    \n",
    "text = (f'In {ltdate2}, gross private business investment totals '+\n",
    "        f'{levels[\"W987RC\"]} on a seasonally-adjusted annualized basis, '+\n",
    "        f'equivalent to {shgdp[\"W987RC\"]} '+\n",
    "        '(see {\\color{blue!60!violet}\\\\textbf{---}}). Private business investment '+\n",
    "        f'in fixed assets totals {levels[\"A008RC\"]}, or {shgdp[\"A008RC\"]} '+\n",
    "        '(see {\\color{cyan!80!white}\\\\textbf{---}}). Private business depreciation '+\n",
    "        f'totals {levels[\"W276RC\"]} in the quarter, or {shgdp[\"W276RC\"]} '+\n",
    "        '(see {\\color{magenta}\\\\textbf{---}}). '+\n",
    "        f'As a result, net fixed investment is {levels[\"NFI\"]}, or {shgdp[\"NFI\"]} '+\n",
    "        '(see {\\color{green!80!blue}\\\\textbf{---}}). \\n\\n '+\n",
    "        'In 2019 Q4, prior to the COVID-19 pandemic, private business gross '+\n",
    "        f'investment was {gpcl}. Since 2019 Q4, gross investment {gdt}. '+\n",
    "        f'Net fixed investment was {npcl} in 2019 Q4, {ndt} from 2019 Q4 to {ltdate1}, '+\n",
    "        f'{txt}. ')\n",
    "write_txt(text_dir / 'businv_levels.txt', text)\n",
    "print(text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Durable goods new orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:16:26.421699Z",
     "start_time": "2023-09-01T00:16:24.300877Z"
    }
   },
   "outputs": [],
   "source": [
    "# New orders for capital goods excluding defense or aircraft\n",
    "url = ('https://api.census.gov/data/timeseries/eits/advm3?'+\n",
    "       f'get=cell_value,time_slot_id&key={census_key}&'+\n",
    "       'category_code=NXA&data_type_code=NO&time=from+1992&'+\n",
    "       'for=us&seasonally_adj=yes')\n",
    "r = requests.get(url).json()\n",
    "date = lambda x: pd.to_datetime(x.time)\n",
    "df = (pd.DataFrame(r[1:], columns=r[0]).assign(date = date)\n",
    "        .set_index('date')['cell_value'].astype('float')).sort_index()\n",
    "df.to_csv(data_dir / 'dgno_raw.csv', index_label='date', \n",
    "          header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:16:26.484541Z",
     "start_time": "2023-09-01T00:16:26.428832Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'dgno_raw.csv', index_col='date', \n",
    "                 parse_dates=True)['cell_value']\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])\n",
    "res = ((df.resample('QS').sum() * 4  / \n",
    "        gdp['A191RC']).dropna() * 100).iloc[1:]\n",
    "(res.rename('value').to_csv(data_dir / 'dgno.csv', \n",
    "                            index_label='date',  header=True))\n",
    "color = 'purple!50!violet'\n",
    "node = end_node(res, color, date='q', percent=True)\n",
    "write_txt(text_dir / 'dgno_node.txt', node)\n",
    "ltval = f'\\${df.iloc[-1] / 1000:,.0f} billion'\n",
    "ldate = dtxt(df.index[-1])['mon1']\n",
    "comp = pd.to_datetime('2020-02-01')\n",
    "compdt = dtxt(pd.to_datetime(comp))['mon1']\n",
    "val = value_text(df.pct_change(12).iloc[-1] * 100)\n",
    "pcv = ((df.iloc[-1] / df.loc[comp]) - 1) * 100\n",
    "pcval = value_text(pcv, 'increase_by')\n",
    "text = ('New orders for manufactured core capital goods excluding '+\n",
    "        f'aircraft total {ltval} in {ldate}, equivalent to '+\n",
    "        f'{res.iloc[-1]:.1f} percent of GDP {c_line(color)}. New '+\n",
    "        f'orders {val} over the past year, and {pcval} since '+\n",
    "        f'{compdt}.')\n",
    "write_txt(text_dir / 'dgno.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government spending and investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:04.416151Z",
     "start_time": "2023-08-30T13:08:04.229898Z"
    }
   },
   "outputs": [],
   "source": [
    "n = {'A822RY': 'Total',\n",
    "     'A823RY': '\\hspace{1mm}Federal total',\n",
    "     'A824RY': '\\hspace{1mm}\\cbox{blue!60!black}National defense',\n",
    "     'A997RY': '\\hspace{7mm}Consumption expenditures',\n",
    "     'A788RY': '\\hspace{7mm}Gross investment',\n",
    "     'A825RY': '\\hspace{1mm}\\cbox{green!85!black}Nondefense',\n",
    "     'A542RY': '\\hspace{7mm}Consumption expenditures',\n",
    "     'A798RY': '\\hspace{7mm}Gross investment',\n",
    "     'A829RY': '\\hspace{-2mm}\\cbox{purple!70!magenta}State \\& local total',\n",
    "     'A991RY': '\\hspace{5mm}Consumption expenditures',\n",
    "     'A799RY': '\\hspace{5mm}Gross investment'}\n",
    "\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], \n",
    "             list(n.keys()) + ['A191RL'])\n",
    "df.rolling(4).mean().loc['1989':].to_csv(data_dir / 'gov.csv', \n",
    "                                         index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:04.929139Z",
     "start_time": "2023-08-30T13:08:04.916504Z"
    }
   },
   "outputs": [],
   "source": [
    "ltdt = dtxt(df.index[-1])['qtr2']\n",
    "ltdt2 = dtxt(df.index[-1])['qtr1']\n",
    "tot = df.A822RY\n",
    "gdp = df['A191RL'].iloc[-1]\n",
    "oneyr = value_text(tot.iloc[-4:].mean(), 'contribution', 'pp', \n",
    "                   threshold=0.01, digits=2)\n",
    "v89 = tot.loc['1989':].mean()\n",
    "totval = value_text(tot.iloc[-1], 'contribution_to', 'pp', \n",
    "                    threshold=0.01, digits=2)\n",
    "defval = value_text(df['A824RY'].iloc[-4:].mean(), 'contribution', 'pp', \n",
    "                   threshold=0.01, digits=2)\n",
    "defcb = c_box('blue!60!black')\n",
    "fedval = value_text(df['A825RY'].iloc[-4:].mean(), 'contribution', 'pp', \n",
    "                   threshold=0.01, digits=2)\n",
    "fedcb = c_box('green!85!black')\n",
    "slgval = value_text(df['A829RY'].iloc[-4:].mean(), 'contribution', 'pp', \n",
    "                   threshold=0.01, digits=2)\n",
    "slgcb = c_box('purple!70!magenta')\n",
    "text = ('Government consumption and investment directly affect economic '+\n",
    "        f'growth in the short-term. In {ltdt}, government consumption spending '+\n",
    "        f'and investment {totval} the real GDP growth rate of {gdp:.1f} '+\n",
    "        'percent. Over the latest four quarters, government consumption '+\n",
    "        f'and investment {oneyr} to economic growth, on average. '+\n",
    "        f'Since 1989, the average contribution has been {v89:.2f} '+\n",
    "        f'percentage points.\\n\\nOver the four quarters ending {ltdt2}, '+\n",
    "        f'by level of government, national defense {defval} {defcb}, '+\n",
    "        f'other federal government {fedval} {fedcb}, and state and '+\n",
    "        f'local government {slgval} {slgcb}.')\n",
    "write_txt(text_dir / 'gov.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:06.402620Z",
     "start_time": "2023-08-30T13:08:06.383339Z"
    }
   },
   "outputs": [],
   "source": [
    "result = df[n.keys()]\n",
    "data = result.iloc[-5:].iloc[::-1].T\n",
    "\n",
    "cols = [f' {q.year} Q{q.quarter}' \n",
    "        if i == 0 else f'`{str(q.year)[2:]} Q{q.quarter}'\n",
    "        for i, q in enumerate(data.columns)]\n",
    "\n",
    "data.columns = cols\n",
    "data['3-year'] = result.rolling(13).mean().iloc[-1].round(2)\n",
    "data['10-year'] = result.rolling(41).mean().iloc[-1].round(2)\n",
    "data['30-year'] = result.rolling(121).mean().iloc[-1].round(2)\n",
    "data.index = data.index.map(n)\n",
    "data = data.applymap('{:.2f}'.format)\n",
    "data.to_csv(data_dir / 'gov.tex', sep='&', lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government Net Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:08.643578Z",
     "start_time": "2023-08-30T13:08:08.551162Z"
    }
   },
   "outputs": [],
   "source": [
    "cofc = nipa_df(retrieve_table('T11000')['Data'], ['A264RC'])['A264RC']\n",
    "ginv = nipa_df(retrieve_table('T30100')['Data'], ['A782RC'])['A782RC']\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "data = (((ginv - cofc) / gdp) * 100).loc['1989':]\n",
    "data.name = 'Value'\n",
    "data.to_csv(data_dir / 'govnetinv.csv', index_label='date')\n",
    "\n",
    "color = 'red'\n",
    "node = end_node(data, color, percent=True, date='q', digits=2, \n",
    "                full_year=True)\n",
    "write_txt(text_dir / 'govnetinv_node.txt', node)\n",
    "\n",
    "ltdt = dtxt(data.index[-1])['qtr1']\n",
    "yrdt = dtxt(data.index[-5])['qtr1']\n",
    "yr2dt = dtxt(data.index[-9])['qtr1']\n",
    "gni = f'\\${(ginv - cofc).iloc[-1] / 1_000:.1f} billion'\n",
    "gnish = f'{data.iloc[-1]:.2f} percent'\n",
    "gnishyr = f'{data.iloc[-5]:.2f} percent'\n",
    "gnishyr2 = f'{data.iloc[-9]:.2f} percent'\n",
    "\n",
    "text = (\"Government gross investment, less depreciation, is the government's \"+\n",
    "        \"net investment in the tangible assets that make the economy more \"+\n",
    "        \"productive. Government investment includes infrastructure, \"+\n",
    "        \"buildings, equipment, intellectual property, and other capital goods. \"+\n",
    "        f\"In the latest data, covering {ltdt}, government net investment is \"+\n",
    "        f\"{gni}. Government net investment is equivalent to {gnish} \"+\n",
    "        f\"of GDP in {ltdt} {c_line(color)}, compared \"+\n",
    "        f\"to {gnishyr} in {yrdt}, and {gnishyr2} in {yr2dt}. \")\n",
    "write_txt(text_dir / f'govnetinv.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government receipts and expenditures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:10.643852Z",
     "start_time": "2023-08-30T13:08:10.512499Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "\n",
    "d = {'slggdp': {'name': 'combined state and local government', \n",
    "                'table': 'T30300', 'series': \n",
    "                {'W024RC': 'SLG_EXP', 'W023RC': 'SLG_REC'}},\n",
    "     'fedgdp': {'name': 'federal government', \n",
    "                'table': 'T30200', 'series':\n",
    "                {'W005RC': 'FED_REC', 'W013RC': 'FED_EXP'}}}\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "ltdate = dtxt(gdp.index[-1])['qtr1']\n",
    "\n",
    "for group, details in d.items():\n",
    "    df = nipa_df(retrieve_table(details['table'])['Data'], details['series'].keys())\n",
    "    (df.div(gdp, axis=0) * 100).loc['1989':].to_csv(data_dir / f'{group}.csv', \n",
    "                                                    index_label='date', float_format='%g')\n",
    "    \n",
    "    grp = group[:3].upper()\n",
    "    df.columns = [details['series'][i] for i in df.columns]\n",
    "    bal = df[f'{grp}_REC'] - df[f'{grp}_EXP']\n",
    "    bal_lt = bal.dropna().iloc[-1]\n",
    "    bal_lt_dt = dtxt(bal.dropna().index[-1])['qtr1']\n",
    "    def_sur = 'deficit' if bal_lt < 0 else 'surplus'\n",
    "    df[f'{grp}_BAL'] = bal\n",
    "    \n",
    "    for col in df.columns:\n",
    "        data[col] = df[col]\n",
    "        data[col+'_GDP'] = df[col].div(gdp, axis=0) * 100\n",
    "        \n",
    "    bal_gdp = data[f'{grp}_BAL_GDP'].dropna().iloc[-1]\n",
    "    bal_txt = (f'In {bal_lt_dt}, the {d[group][\"name\"]} {def_sur} was '+\n",
    "               f'\\${abs(bal_lt) / 1000:,.0f} billion or {abs(bal_gdp):.1f} percent of GDP. ')\n",
    "    \n",
    "    exp_txt = (f'{d[group][\"name\"].capitalize()} expenditures total '+\n",
    "               f'\\${data[grp+\"_EXP\"].iloc[-1] / 1000000:.1f} trillion, '+\n",
    "               f'or {data[grp+\"_EXP_GDP\"].iloc[-1]:.1f} percent of GDP, in {ltdate}. ')\n",
    "    \n",
    "    if pd.isna(df[[i for i in df.columns if i[4:] == 'REC'][0]].iloc[-1]) == True:\n",
    "        rec_txt = (f'BEA has not yet released receipts data for {ltdate}, however, '+\n",
    "                   f'in {bal_lt_dt}, {d[group][\"name\"]} receipts total '+\n",
    "                   f'\\${data[grp+\"_REC\"].dropna().iloc[-1] / 1000000:.1f} trillion, '+\n",
    "                   f'or {data[grp+\"_REC_GDP\"].dropna().iloc[-1]:.1f} percent of GDP. ')\n",
    "    else:\n",
    "        rec_txt = ('Receipts for the same period total '+\n",
    "                   f'\\${data[grp+\"_REC\"].dropna().iloc[-1] / 1000000:.1f} trillion '+\n",
    "                   f'or {data[grp+\"_REC_GDP\"].dropna().iloc[-1]:.1f} percent of GDP. ')\n",
    "    \n",
    "    text = exp_txt + rec_txt + bal_txt\n",
    "    write_txt(text_dir / f'{group}.txt', text)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public Debt by Holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T20:56:26.706637Z",
     "start_time": "2023-09-05T20:56:25.136229Z"
    }
   },
   "outputs": [],
   "source": [
    "series = ['FDHBATN', 'GFDEBTN', 'FDHBFRBN', 'FDHBPIN', 'FDHBFIN']\n",
    "start = '1988-01-01'\n",
    "ftype = '&file_type=json'\n",
    "base = 'https://api.stlouisfed.org/fred/series/observations?'\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for srs in series:\n",
    "    param = f'series_id={srs}&observation_start={start}&api_key={fred_key}'\n",
    "    url = f'{base}{param}{ftype}'\n",
    "    r = requests.get(url).json()['observations']\n",
    "    s = pd.Series({pd.to_datetime(i['date']): (float(i['value']) / 1000.0) \n",
    "                   if srs in series[:2] else float(i['value']) for i in r})\n",
    "    data[srs] = s\n",
    "    \n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:09:08.906058Z",
     "start_time": "2023-09-05T21:09:08.898444Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add dot for latest value of total debt to GDP\n",
    "totgdp = (data['GFDEBTN'] / (gdp / 1000)).dropna() * 100\n",
    "ldtot = totgdp.index[-1]\n",
    "ld = pd.to_datetime(data.dropna().index[-1])\n",
    "ldt = dtxt(ldtot + pd.DateOffset(days=45))['datetime']\n",
    "ltval = totgdp.iloc[-1]\n",
    "lvt = f'{ltval:.1f}'\n",
    "dt = dtxt(totgdp.index[-1])['qtr4']\n",
    "\n",
    "# Only add mark to plot if necessary \n",
    "mark = ' (see \\\\tikz \\draw[black, fill=black!20!white] (2.5pt,4pt) circle (2pt);)'\n",
    "if ldtot > ld:\n",
    "    node = (f'\\\\node[label={{[align=left]90:{{\\scriptsize{dt}: '+\n",
    "            f'\\\\\\\\ \\scriptsize \\ {lvt}}}}}, '+\n",
    "            'circle, draw=black, fill=black!20!white, inner sep=1.4pt] at '+\n",
    "            f'(axis cs:{ldt}, {ltval}) {{}};')\n",
    "    write_txt(text_dir / 'pdebt_node.txt', node)\n",
    "else:\n",
    "    node = ''\n",
    "    mark = ''\n",
    "    write_txt(text_dir / 'pdebt_node.txt', node)\n",
    "\n",
    "# Add text\n",
    "lvls = data['GFDEBTN'].dropna().divide(1000).apply('\\${:.1f} trillion'.format)\n",
    "ltdt = dtxt(lvls.index[-1])['qtr1']\n",
    "ltlvl = lvls.iloc[-1]\n",
    "url = 'https://www.fiscal.treasury.gov/reports-statements/treasury-bulletin/current.html'\n",
    "text = (f'Federal government public debt \\href{{{url}}}{{totals}} '+\n",
    "        f'{ltlvl} in {ltdt}, equivalent to {lvt} '+\n",
    "        f'percent of GDP{mark}.')    \n",
    "write_txt(text_dir / 'pdebt_ltval.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T21:03:47.218813Z",
     "start_time": "2023-09-05T21:03:47.199850Z"
    }
   },
   "outputs": [],
   "source": [
    "df = data.copy().dropna()\n",
    "df['PD'] = df['FDHBPIN'] - df['FDHBFIN']\n",
    "df['IG'] = df['GFDEBTN'] - (df['FDHBFRBN'] + df['FDHBPIN'])\n",
    "dgdp = df.loc['1989':].div(gdp / 1000.0, axis=0).dropna()\n",
    "(dgdp * 100).to_csv(data_dir / 'pubdebt.csv', index_label='date')\n",
    "\n",
    "# Text \n",
    "ldate = dtxt(ld)['qtr2']\n",
    "ltgdp = dgdp['GFDEBTN'].iloc[-1] * 100\n",
    "txt = 'Breaking down federal debt by holder, '\n",
    "if ldtot > ld:\n",
    "    txt = (f'In {ldate}, federal government public debt totals '+\n",
    "           f'{lvls[df.index[-1]]}, equivalent to {ltgdp:.1f} '+\n",
    "           'percent of GDP. Of this, ')\n",
    "sh = df.div(df['GFDEBTN'], axis=0).iloc[-1] * 100\n",
    "lv = df.iloc[-1] / 1000\n",
    "text = (f'{txt}\\${lv.PD:.1f} trillion, or {sh.PD:.1f} percent of '+\n",
    "        'the total, is held by private domestic investors (see\\cbox{green!60!black}). '+\n",
    "        f'An additional \\${lv.FDHBFIN:.1f} trillion, or {sh.FDHBFIN:.1f} percent '+\n",
    "        'of the total, is held by foreign investors (see\\cbox{orange!70!white}). '+\n",
    "        'The remainder is held by the Federal Reserve (see\\cbox{blue}) '+\n",
    "        'and various government agencies and trusts (see\\cbox{cyan!50!white}), '+\n",
    "        'such as the Social Security Trust Fund. ')\n",
    "write_txt(text_dir / 'pubdebt.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personal Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:18.582777Z",
     "start_time": "2023-08-30T13:08:18.427500Z"
    }
   },
   "outputs": [],
   "source": [
    "# deflator\n",
    "d = nipa_df(retrieve_table('T20304')['Data'], ['DPCERG'])['DPCERG']\n",
    "deflator = d.iloc[-1] / d\n",
    "\n",
    "# collect and combine series\n",
    "s = ['A065RC', 'A033RC', 'A041RC', 'A048RC', 'W210RC', 'A577RC', 'A061RC']\n",
    "df = (nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "      .assign(CAPITAL = lambda x: x['A041RC'] + x['A048RC'] + x['W210RC'],\n",
    "              TRANSFER = lambda x: x['A577RC'] - x['A061RC'])\n",
    "      .drop(['A061RC', 'A041RC', 'A048RC', 'W210RC', 'A577RC'], axis=1)\n",
    "      .multiply(deflator, axis=0))\n",
    "growth_contrib(df, 'A065RC').loc['1989':].to_csv(data_dir / 'pi.csv', index_label='date')\n",
    "\n",
    "data = growth_contrib(df, 'A065RC').rename({'A065RC': 'TOTAL', 'A033RC': 'LABOR'}, axis=1)\n",
    "\n",
    "ltdate = dtxt(data.index[-1])['qtr1']\n",
    "tot = value_text(data['TOTAL'].iloc[-1], adj='annualized', digits=2)\n",
    "slist = ['LABOR', 'CAPITAL', 'TRANSFER']\n",
    "style = {k: 'contribution' for k in slist}\n",
    "style['LABOR'] = 'contribution_to'\n",
    "d = {}\n",
    "for i in slist:\n",
    "    d[i] = value_text(data[i].iloc[-1], style=style[i], \n",
    "                      ptype='pp', digits=2)\n",
    "text = (f'Aggregate real personal income {tot} in {ltdate}. '+\n",
    "        f'Labor income {d[\"LABOR\"]} overall growth, capital '+\n",
    "        f'income {d[\"CAPITAL\"]}, and welfare income {d[\"TRANSFER\"]}. ')\n",
    "write_txt(text_dir / 'pi.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T06:23:18.467227Z",
     "start_time": "2020-10-14T06:23:18.460090Z"
    }
   },
   "source": [
    "### Government Personal Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:20.903611Z",
     "start_time": "2023-08-30T13:08:20.763899Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['DPCERG']\n",
    "\n",
    "d = nipa_df(retrieve_table('T20304')['Data'], s)['DPCERG']\n",
    "deflator = d.iloc[-1] / d\n",
    "\n",
    "s = ['B230RC']\n",
    "\n",
    "population = nipa_df(retrieve_table('T20100')['Data'], s)['B230RC']\n",
    "\n",
    "s = ['A063RC', 'B202RC', 'A061RC', 'W055RC']\n",
    "df = nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "\n",
    "n = {'A063RC': 'Welfare',\n",
    "     'B202RC': 'WandS'}\n",
    "result = df.multiply(deflator, axis=0).divide(population, axis=0)\n",
    "result['TaxSI'] = result['A061RC'] + result['W055RC']\n",
    "result = result.drop(['A061RC', 'W055RC'], axis=1).rename(n, axis=1)\n",
    "result.loc['1989':].to_csv(data_dir / 'govpi.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(result.index[-1])['qtr1']\n",
    "prdt = '2019-10-01'\n",
    "prdate = dtxt(pd.to_datetime(prdt))['qtr1']\n",
    "wsltval = result['WandS'].iloc[-1] * 1_000\n",
    "wsprval = result.loc[prdt, 'WandS'] * 1_000\n",
    "wltval = result['Welfare'].iloc[-1] * 1_000\n",
    "wprval = result.loc[prdt, 'Welfare'] * 1_000\n",
    "w89val = result.loc['1989-01-01', 'Welfare'] * 1_000\n",
    "tltval = result['TaxSI'].iloc[-1] * 1_000\n",
    "tprval = result.loc[prdt, 'TaxSI'] * 1_000\n",
    "t89val = result.loc['1989-01-01', 'TaxSI'] * 1_000\n",
    "\n",
    "text = (f'In {ltdate}, government worker wages and salaries, not including '+\n",
    "        f'benefits, were equivalent to \\${wsltval:,.0f} per capita, following a '+\n",
    "        f'price-adjusted \\${wsprval:,.0f} in {prdate} '+\n",
    "        '(see {\\color{orange}\\\\textbf{---}}). Welfare payments were equivalent '+\n",
    "        f'to \\${wltval:,.0f} per capita in {ltdate}, compared to \\${wprval:,.0f} '+\n",
    "        f'per capita in {prdate} '+\n",
    "        '(see {\\color{violet}\\\\textbf{---}}). In 1989 Q1, welfare payments were '+\n",
    "        f'equivalent to \\${w89val:,.0f} per person.  \\n\\n Personal current taxes '+\n",
    "        f'and social insurance contributions total \\${tltval:,.0f} per capita '+\n",
    "        f'in {ltdate}, \\${tprval:,.0f} in {prdate}, and \\${t89val:,.0f} in 1989 '+\n",
    "        '(see {\\color{cyan!80!blue}\\\\textbf{---}}).')\n",
    "write_txt(text_dir / 'govpi.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-14T15:23:11.647340Z",
     "start_time": "2020-10-14T15:23:11.645438Z"
    }
   },
   "source": [
    "### Government Consumption and Investment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:22.533081Z",
     "start_time": "2023-08-30T13:08:22.461824Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A823RC', 'A829RC', 'A191RC', 'A824RC', 'A825RC']\n",
    "df = nipa_df(retrieve_table('T10105')['Data'], s).sort_index()\n",
    "result = df.drop('A191RC', axis=1).divide(df['A191RC'], axis=0) * 100\n",
    "result.loc['1989':].to_csv(data_dir / 'govci.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(result.index[-1])['qtr1']\n",
    "prdt = pd.to_datetime('2019-10-01')\n",
    "prdate = dtxt(prdt)['qtr1']\n",
    "fndnom = df['A825RC'].iloc[-1] / 1_000\n",
    "fndlt = result['A825RC'].iloc[-1]\n",
    "fndpr = result.loc[prdt, 'A825RC']\n",
    "dlt = result['A824RC'].iloc[-1]\n",
    "dpr = result.loc[prdt, 'A824RC']\n",
    "d89 = result.loc['1989-01-01', 'A824RC']\n",
    "slt = result['A829RC'].iloc[-1]\n",
    "spr = result.loc[prdt, 'A829RC']\n",
    "\n",
    "text = (f'In {ltdate}, federal non-defense spending and investment '+\n",
    "        f'was \\${fndnom:,.1f} billion, equivalent to {fndlt:.1f} percent '+\n",
    "        'of GDP (see {\\color{green!85!black}\\\\textbf{---}}), compared '+\n",
    "        f'to {fndpr:.1f} percent of GDP in {prdate}. Federal spending '+\n",
    "        f'on national defense was equivalent to {dlt:.1f} percent of '+\n",
    "        f'GDP in the latest quarter and {dpr:.1f} percent in {prdate} '+\n",
    "        '(see {\\color{blue!60!black}\\\\textbf{---}}). National defense '\n",
    "        f'spending was {d89:.1f} percent of GDP in 1989 Q1. \\n\\n In '+\n",
    "        f'{ltdate}, state and local government spending and investment '+\n",
    "        f'was equivalent to {slt:.1f} percent of GDP, compared to '+\n",
    "        f'{spr:.1f} percent in {prdate} '+\n",
    "        '(see {\\color{purple!70!magenta}\\\\textbf{---}}).')\n",
    "write_txt(text_dir / 'govci.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Spending Growth Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:24.760569Z",
     "start_time": "2023-08-30T13:08:24.619100Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['B230RC']\n",
    "population = nipa_df(retrieve_table('T20100')['Data'], s)['B230RC']\n",
    "s = ['DPCERG']\n",
    "d = nipa_df(retrieve_table('T20304')['Data'], s)['DPCERG']\n",
    "deflator = d.iloc[-1] / d\n",
    "\n",
    "s = ['A067RC', 'A068RC', 'A071RC', 'DPCERC']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T20100')['Data'], s)\n",
    "      .assign(OTHER = lambda x: -(x['A068RC'] - x['DPCERC']),\n",
    "              SAVING = lambda x: -x['A071RC'])\n",
    "      .drop(['A068RC'], axis=1)\n",
    "      .divide(population, axis=0)\n",
    "      .multiply(deflator, axis=0))\n",
    "\n",
    "data = growth_contrib(df, 'DPCERC').rolling(4).mean()\n",
    "data3y = growth_contrib(df, 'DPCERC').rolling(12).mean()\n",
    "data.loc['1989':].to_csv(data_dir / 'pcedecomp.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:25.504573Z",
     "start_time": "2023-08-30T13:08:25.488821Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date = f'{data.index[-1].year} Q{data.index[-1].quarter}'\n",
    "pcetext = value_text(data['DPCERC'].iloc[-1], adj='average')\n",
    "\n",
    "slist = ['A067RC', 'SAVING', 'OTHER']\n",
    "d = {}\n",
    "for i in slist:\n",
    "    val = data[i].iloc[-1]\n",
    "    vt = value_text(data[i].iloc[-1], style='contribution', \n",
    "           ptype='pp', casual=True)\n",
    "    if f'{abs(val):.1f}' == '0.0':\n",
    "        vt = \"didn't affect the total\"\n",
    "    d[i] = vt\n",
    "pce19 = value_text(data.loc['2019', 'DPCERC'].mean(), adj='average')\n",
    "dpi19 = value_text(data.loc['2019', 'A067RC'].mean(), style='contribution', \n",
    "           ptype='pp')\n",
    "save19 = value_text(data.loc['2019', 'SAVING'].mean(), style='contribution', \n",
    "           ptype='pp')\n",
    "ltsv = data['SAVING'].iloc[-1].round(2)\n",
    "svid = 'decreased' if ltsv > 0 else '' if ltsv == 0 else 'increased'\n",
    "ltot = data['OTHER'].iloc[-1].round(2)\n",
    "otid = 'decreases in' if ltsv > 0 else '' if ltsv == 0 else 'increases in'\n",
    "pcetxt = (f'Real per capita consumer spending {pcetext} over the '+\n",
    "          f'four quarters ending {date}. Changes to disposable income '+\n",
    "          f'{d[\"A067RC\"]}, {svid} saving {d[\"SAVING\"]}, and '+\n",
    "          f'{otid} other outlays {d[\"OTHER\"]}. '+\n",
    "          f'During 2019, real per capita consumer spending {pce19}. '+\n",
    "          f'Increased income {dpi19}, and a slight increase in saving {save19}.')\n",
    "write_txt(text_dir / 'pcedecomp.txt', pcetxt)\n",
    "print(pcetxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sectoral Accounts\n",
    "\n",
    "**NOTE:** Need to convert \"deficit\", \"borrower\" etc to parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:27.700356Z",
     "start_time": "2023-08-30T13:08:27.693156Z"
    }
   },
   "outputs": [],
   "source": [
    "def sect_txt(val):\n",
    "    lb = ('borrower', 'deficit') if val < 0 else ('lender', 'surplus')\n",
    "    d = {'v': val,\n",
    "         'vt': f'{val:.1f}',\n",
    "         'avt': f'{abs(val):.1f}',\n",
    "         'vg': f'the equivalent of {abs(val):.1f} percent of GDP',\n",
    "         'lb': lb[0],\n",
    "         'ds': lb[1]}\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:28.572051Z",
     "start_time": "2023-08-30T13:08:28.431956Z"
    }
   },
   "outputs": [],
   "source": [
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "s = ['W162RC', 'W994RC', 'AD01RC', 'W995RC', 'W996RC', 'AD03RC']\n",
    "sb = nipa_df(retrieve_table('T50100')['Data'], s)\n",
    "df = (sb.div(gdp, axis=0) * 100).dropna()\n",
    "res = df[['W995RC', 'W996RC', 'AD03RC']].loc['1989':]\n",
    "res.to_csv(data_dir / 'sectbal2.csv', index_label='date')\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['PRIV'] = df['W994RC']\n",
    "data['GOV'] = df['AD01RC']\n",
    "data['ROW'] = -df['W162RC'] # Negative in raw data\n",
    "data = data.dropna().loc['1989':]\n",
    "data.to_csv(data_dir / 'sectbal.csv', index_label='date')\n",
    "\n",
    "date = dtxt(data.index[-1])['qtr1']\n",
    "pcdt = '2019-10-01'\n",
    "\n",
    "priv = sect_txt(data.PRIV.iloc[-1])\n",
    "privpr = sect_txt(data.loc['2019', 'PRIV'].mean())\n",
    "row = sect_txt(data.ROW.iloc[-1])\n",
    "rowpr = sect_txt(data.loc['2019', 'ROW'].mean())\n",
    "gov = sect_txt(data.GOV.iloc[-1])\n",
    "govpr = sect_txt(data.loc['2019', 'GOV'].mean())\n",
    "\n",
    "compare = compare_text(priv['v'], privpr['v'], [0.4, 1.0, 3.5])\n",
    "\n",
    "txt = (f\"In {date}, the US private sector was a net {priv['lb']} \"+\n",
    "       f\"(running a {priv['ds']}) of {priv['vg']}, {compare} the \"+\n",
    "       f\"{privpr['avt']} percent surplus in 2019. The rest of the world \"+\n",
    "       f\"was a net {row['lb']} to the US to {row['vg']} in {date}, compared \"+\n",
    "       f\"to {rowpr['avt']} percent in 2019. Balancing these transactions, \"+\n",
    "       \"the government (federal, state, and local combined) was a net \"+\n",
    "       f\"{gov['lb']} (running a {gov['ds']}) of {gov['vg']} in {date}, \"+\n",
    "       f\"compared to {govpr['avt']} percent in 2019. \")\n",
    "write_txt(text_dir / 'sectbal.txt', txt)\n",
    "print(txt, '\\n')\n",
    "\n",
    "date = dtxt(df.index[-1])['qtr1']\n",
    "hh = sect_txt(df.W996RC.iloc[-1])\n",
    "hhpr = sect_txt(df.loc['2019', 'W996RC'].mean())\n",
    "pb = sect_txt(df.W995RC.iloc[-1])\n",
    "pbpr = sect_txt(df.loc['2019', 'W995RC'].mean())   \n",
    "text = ('Breaking out the two main categories in the private sector, households '+\n",
    "       f'were net {hh[\"lb\"]}s (ran a {hh[\"ds\"]}) of {hh[\"vg\"]} in {date} '+\n",
    "        '(see\\cbox{orange!90!yellow}), while private businesses--corporate '+\n",
    "       f'and noncorporate--were net {pb[\"lb\"]}s of {pb[\"vg\"]} '+\n",
    "       '(see\\cbox{purple!50!red}). In 2019, households were net '+\n",
    "       f'{hhpr[\"lb\"]}s of {hhpr[\"avt\"]} percent, and private businesses were net '+\n",
    "       f'{pbpr[\"lb\"]}s of {pbpr[\"avt\"]} percent.') \n",
    "write_txt(text_dir / 'sectbal2.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Account Balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:31.081360Z",
     "start_time": "2023-08-30T13:08:30.801356Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "s = ['A191RC']\n",
    "\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], s)\n",
    "\n",
    "n = {'A124RC': 'Current Account Balance',\n",
    "     'A1073C': 'Current Receipts',\n",
    "     'B020RC': '\\hspace{1mm}Exports',\n",
    "     'A253RC': '\\hspace{3mm}Goods',\n",
    "     'A332RC': '\\hspace{5mm}Durable',\n",
    "     'A339RC': '\\hspace{5mm}Non-Durable',\n",
    "     'A646RC': '\\hspace{3mm}Services',\n",
    "     'B645RC': '\\hspace{1mm}Income Receipts',\n",
    "     'LA000035': '\\hspace{1mm}Transfer Receipts',\n",
    "     'W163RC': 'Current payments',\n",
    "     'B021RC': '\\hspace{1mm}Imports',\n",
    "     'A255RC': '\\hspace{3mm}Goods',\n",
    "     'A333RC': '\\hspace{5mm}Durable',\n",
    "     'A340RC': '\\hspace{5mm}Non-Durable',\n",
    "     'B656RC': '\\hspace{3mm}Services',\n",
    "     'A655RC': '\\hspace{1mm}Income Payments',\n",
    "     'A123RC': '\\hspace{1mm}Transfer Payments'}\n",
    "\n",
    "s = ['A124RC', 'GOODS', 'SERVICES', 'INCOME', 'TRANSFERS']\n",
    "\n",
    "df = (nipa_df(retrieve_table('T40100')['Data'], n.keys())\n",
    "      .assign(GOODS = lambda x: x['A253RC'] - x['A255RC'],\n",
    "              SERVICES = lambda x: x['A646RC'] - x['B656RC'],\n",
    "              INCOME = lambda x: x['B645RC'] - x['A655RC'],\n",
    "              TRANSFERS = lambda x: - x['A123RC']))\n",
    "\n",
    "data = (df.div(nipa_df(retrieve_table('T10105')['Data'], ['A191RC']\n",
    "               )['A191RC'], axis=0).loc['1989':].multiply(100).round(2))\n",
    "\n",
    "data.loc['1989':, s].dropna().to_csv(data_dir / 'cab.csv', index_label='date')\n",
    "\n",
    "node = end_node(data['A124RC'].dropna(), 'black', date='q', \n",
    "                full_year=True, percent=True)\n",
    "write_txt(text_dir / 'cab_node.txt', node)  \n",
    "\n",
    "cab = abs(data.dropna()['A124RC'].iloc[-1])\n",
    "tb = abs(data.dropna()['GOODS'].iloc[-1])\n",
    "ld = dtxt(data.dropna().index[-1])['qtr1']\n",
    "ltdate = dtxt(data.index[-1])['qtr1']\n",
    "prdate = dtxt(data.index[-2])['qtr1']\n",
    "lttbval = abs(data['GOODS'].iloc[-1])\n",
    "tbprval = abs(data['GOODS'].iloc[-2])\n",
    "prval = abs(data['A124RC'].iloc[-2])\n",
    "\n",
    "if pd.isna(data['A124RC'].iloc[-1]) == True:\n",
    "    mtxt = (f'The initial GDP report for {ltdate} does not include the '+\n",
    "            'data needed to calculate the current account balance, however, '+\n",
    "            f'the goods trade deficit for {ltdate} is equivalent to '+\n",
    "            f'{lttbval:.1f} percent of GDP. ')\n",
    "else:\n",
    "    mtxt = (f'In {prdate}, the current account deficit was equivalent to '\n",
    "            f'{prval:.1f}, and the trade deficit was equivalent to '+\n",
    "            f'{tbprval:.1f} percent of GDP.')\n",
    "\n",
    "text = (f'As of {ld}, the US runs a current account deficit of {cab:.1f} '+\n",
    "        'percent of GDP, primarily as the result of a trade deficit on '+\n",
    "        f'goods of {tb:.1f} percent of GDP. {mtxt}')\n",
    "write_txt(text_dir / 'cab.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:34.300069Z",
     "start_time": "2023-08-30T13:08:34.287180Z"
    }
   },
   "outputs": [],
   "source": [
    "result = data[n.keys()]\n",
    "data2 = result.iloc[-6:].iloc[::-1].T\n",
    "\n",
    "cols = [f' {q.year} Q{q.quarter}' \n",
    "        if i == 0 else f'`{str(q.year)[2:]} Q{q.quarter}'\n",
    "        for i, q in enumerate(data2.columns)]\n",
    "\n",
    "data2.columns = cols\n",
    "data2['3-year'] = result.rolling(13).mean().iloc[-1].round(2)\n",
    "data2['10-year'] = result.rolling(41).mean().iloc[-1].round(2)\n",
    "data2.index = data2.index.map(n)\n",
    "data2 = data2.applymap('{:.2f}'.format).replace('nan', '--')\n",
    "data2.to_csv(data_dir / 'cab.tex', sep='&', lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federal Interest Outlays share of GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:16:42.127250Z",
     "start_time": "2023-09-01T00:16:41.530097Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])\n",
    "gdp.index = gdp.index + pd.DateOffset(months=3)\n",
    "gdp = gdp.A191RC.rolling(4).mean()\n",
    "tot = fred_df('FYOINT')['VALUE']\n",
    "tot.index = tot.index + pd.DateOffset(days=1)\n",
    "df = (tot / gdp).dropna() * 100\n",
    "fedadj = pd.read_csv(data_dir / 'fedintadj.csv', index_col='date', \n",
    "                     parse_dates=True)['RESPPLLOP_N.WW']\n",
    "res = pd.DataFrame({'Tot': tot, 'FedAdj': fedadj}).fillna(0.0)\n",
    "adj = res['Tot'] - res['FedAdj']\n",
    "df2 = (adj / gdp).dropna() * 100\n",
    "final = pd.DataFrame({'Tot': df, 'Adj': df2})\n",
    "\n",
    "final.to_csv(data_dir / 'fedintexp.csv', index_label='date')\n",
    "node = end_node(df, 'magenta', digits=2, percent=True, date='fy', offset=0.15)\n",
    "node2 = end_node(df2, 'orange', digits=2, percent=True)\n",
    "write_txt(text_dir / 'fedintexp_nodes.txt', '\\n'.join([node, node2]))\n",
    "val90s = df.loc['1990':'1999'].mean()\n",
    "\n",
    "text = ('The Office of Management and Budget '+\n",
    "        '\\href{https://www.whitehouse.gov/omb/historical-tables/}{report} '+\n",
    "        f'\\\\textbf{{federal interest outlays}} of \\${tot.iloc[-1] / 1000:.0f} '+\n",
    "        f'billion in fiscal year {tot.index[-1].year}, compared to '+\n",
    "        f'\\${tot.iloc[-2] / 1000:.0f} billion in fiscal year '+\n",
    "        f'{tot.index[-2].year}. Put into the context of the size of '+\n",
    "        f'the economy, federal interest outlays in fiscal year '+\n",
    "        f'{df.index[-1].year} were equivalent to {df.iloc[-1]:.2f} '+\n",
    "        'percent of GDP (see {\\color{magenta}\\\\textbf{---}}), following '+\n",
    "        f'{df.iloc[-2]:.2f} percent of GDP in FY{df.index[-2].year} '+\n",
    "        f'and {df.iloc[-3]:.2f} percent in FY{df.index[-3].year}, '+\n",
    "        f'and compared to an average of {val90s:.1f} percent in '+\n",
    "        'the 1990s, when interest rates were substantially higher. ')\n",
    "write_txt(text_dir / 'fedintexp.txt', text)\n",
    "print(text)\n",
    "\n",
    "val = (fedadj / 1_000).iloc[-1].round(-1)\n",
    "adjval = df2.iloc[-1]\n",
    "cl = c_line('orange')\n",
    "text = ('The actual interest expense is slightly lower than the reported '+\n",
    "        'figure, because interest paid to the Federal Reserve gets returned '+\n",
    "        f'to the Treasury. In FY{df.index[-1].year}, '+\n",
    "        f'the Fed returned more than \\${val:.0f} billion to the Treasury. '+\n",
    "        f'Adjusting for these remittances, the interest expense was '+\n",
    "        f'{adjval:.2f} percent of GDP in FY{df.index[-1].year} {cl}. ')\n",
    "write_txt(text_dir / 'fedintexp2.txt', text)\n",
    "print('\\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T15:02:08.075876Z",
     "start_time": "2023-06-07T15:02:08.072075Z"
    }
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T20100'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporate Profits Destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:39.249140Z",
     "start_time": "2023-08-30T13:08:39.136560Z"
    }
   },
   "outputs": [],
   "source": [
    "s = ['A032RC', 'A438RC', 'A054RC', 'B056RC', 'A127RC']\n",
    "df = (nipa_df(retrieve_table('T11200')['Data'], s)\n",
    "         / 1_000_000).dropna().rename({})\n",
    "df['NNI'] = df['A032RC'] - df['A438RC']\n",
    "df['TOT'] = df[['A054RC', 'B056RC', 'A127RC']].sum(axis=1)\n",
    "dt = df.index[-1]\n",
    "ltdate = dtxt(df.index[-1])['qtr2']\n",
    "sh = df.div(df.NNI, axis=0) * 100\n",
    "(sh.loc['1989':, ['A054RC', 'B056RC', 'A127RC']]\n",
    "   .to_csv(data_dir / 'cprof.csv', index_label='date'))\n",
    "taxrt = ((df.A054RC / df.TOT) * 100).loc['1989':]\n",
    "taxrt.to_csv(data_dir / 'cprof_taxrt.csv', index_label='date')\n",
    "totsh19 = sh.loc['2019', 'TOT'].mean()\n",
    "divsh19 = sh.loc['2019', 'B056RC'].mean()\n",
    "resh19 = sh.loc['2019', 'A127RC'].mean()\n",
    "taxsh19 = sh.loc['2019', 'A054RC'].mean()\n",
    "taxrt19 = taxrt.loc['2019'].mean()\n",
    "text = (f'In {ltdate}, corporate profits were '+\n",
    "        f'\\${df.TOT.iloc[-1]:.2f} trillion, equivalent to '+\n",
    "        f'{sh.TOT.iloc[-1]:.1f} percent of the income paid '+\n",
    "        'to US nationals after depreciation costs (net national '+\n",
    "        f'income). Of this, \\${df.B056RC.iloc[-1]:.2f} trillion, '+\n",
    "        f'equivalent to {sh.B056RC.iloc[-1]:.1f} percent of '+\n",
    "        'net national income, were paid out as dividends '+\n",
    "        '(see\\cbox{blue!70!purple}), '+\n",
    "        f'\\${df.A127RC.iloc[-1] * 1000:,.0f} billion were '+\n",
    "        'retained (corporate saving, see\\cbox{cyan!50!white}), '+\n",
    "        f'and \\${df.A054RC.iloc[-1] * 1000:.0f} billion, '+\n",
    "        f'{taxrt.iloc[-1]:.1f} percent of corporate profits, '+\n",
    "        'went to corporate income tax (see\\cbox{red!80!orange}). \\n\\n'+\n",
    "        f'In 2019, corporate profits were {totsh19:.1f} percent '+\n",
    "        'of net national income. Dividends were equivalent to '+\n",
    "        f'{divsh19:.1f} percent, corporate savings were '+\n",
    "        f'{resh19:.1f} percent, and corporate income taxes were '+\n",
    "        f'{taxsh19:.1f} percent of net national income '+\n",
    "        f'and {taxrt19:.1f} percent of corporate profits.')\n",
    "write_txt(text_dir / 'cprof.txt', text)\n",
    "print(text)\n",
    "\n",
    "cols = ['B056RC', 'A127RC', 'A054RC']\n",
    "sdf = sh[cols].iloc[-1]\n",
    "height = ((sdf.cumsum() - (sdf / 2) + 1.0)).to_dict()\n",
    "val = sdf.to_dict()\n",
    "dtp = dtxt(sh.index[-1] + pd.DateOffset(months=3))['datetime']\n",
    "nodes = [f'\\\\absnode{{{{{dtp}}}}}{{{height[i]}}}{{\\scriptsize {val[i]:.1f}\\%}}' \n",
    "         for i in cols]\n",
    "dtv = dtxt(sh.index[-1])['qtr1'].replace(' ', '\\\\\\\\ \\scriptsize ')\n",
    "dtn = f'\\\\absnode{{{{{dtp}}}}}{{{sdf.cumsum().iloc[-1] + 3.0}}}{{\\scriptsize{dtv}:}}'\n",
    "nodes.append(dtn)\n",
    "nodetext = '\\n'.join(nodes)\n",
    "write_txt(text_dir / 'cprof_nodes.txt', nodetext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corporate profits source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:08:41.745817Z",
     "start_time": "2023-08-30T13:08:41.622255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Based loosely on Levy's Where do Profits Come From?\n",
    "s = ['W170RC', 'A262RC', 'W986RC', 'A922RC']\n",
    "df1 = nipa_df(retrieve_table('T50100')['Data'], s)\n",
    "\n",
    "s = ['A123RC']\n",
    "df2 = nipa_df(retrieve_table('T40100')['Data'], s)\n",
    "\n",
    "s = ['A001RC']\n",
    "df3 = nipa_df(retrieve_table('T10705')['Data'], s)\n",
    "\n",
    "cprof = pd.DataFrame()\n",
    "cprof['ROW Saving'] = (df2['A123RC'] / df3['A001RC']) * 100\n",
    "cprof['HH Saving'] = (- df1['W986RC'] / df3['A001RC']) * 100\n",
    "cprof['Gov Saving'] = (- df1['A922RC'] / df3['A001RC']) * 100\n",
    "cprof['Investment'] = ((df1['W170RC'] - df1['A262RC']) / df3['A001RC']) * 100\n",
    "\n",
    "cprof.loc['1989':].to_csv(data_dir / 'cprof2.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T15:02:08.314707Z",
     "start_time": "2023-06-07T15:02:08.312655Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#nipa_series_codes(retrieve_table('T50100'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Productivity ST / LT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T21:23:40.802267Z",
     "start_time": "2023-09-07T21:23:40.392204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over this same period, which features a sharp increase in education in the US, labor productivity increased by 89.8 percent.\n",
      "Over the longer-term, US labor productivity growth has averaged two percent per year. The trailing 20-year average growth rate was 1.6 percent in 2023 Q2 (see {\\color{orange!80!yellow}\\textbf{---}}). During the 1990s and early 2000s, labor productivity growth was above its long-term average. In contrast, from 2010 to 2017, productivity growth was below average. Over the year ending 2023 Q2, productivity growth averaged 1.3 percent (see {\\color{blue!80!black}\\textbf{---}}). \n"
     ]
    }
   ],
   "source": [
    "# Sentence for comparison with median wage growth\n",
    "df = fred_df('OPHNFB', start='1968')['VALUE']\n",
    "lpch = ((df.iloc[-1] / df.loc['1989-01-01']) - 1) * 100\n",
    "lpcht = value_text(lpch, 'increase_by')\n",
    "text = ('Over this same period, which features a sharp increase '+\n",
    "        f'in education in the US, labor productivity {lpcht}.')\n",
    "write_txt(text_dir / 'lprod_rw_educ.txt', text)\n",
    "print(text)\n",
    "\n",
    "# Long-term and short-term growth rates\n",
    "df = growth_rate(df)\n",
    "lt = df.rolling(80).mean().dropna()\n",
    "st = df.rolling(4).mean().dropna()\n",
    "data = pd.DataFrame({'ST': st, 'LT': lt})\n",
    "data.loc['1989':].to_csv(data_dir / 'prod_st_lt.csv', index_label='date')\n",
    "ltdt = dtxt(data.index[-1])['qtr1']\n",
    "ltavg = value_text(data['LT'].mean(), 'plain')\n",
    "tty = value_text(data['LT'].iloc[-1], 'plain')\n",
    "ltv = value_text(data['ST'].iloc[-1], 'plain')\n",
    "colors = {'LT': 'orange!80!yellow', 'ST': 'blue!80!black'}\n",
    "cl = {name: c_line(col) for name, col in colors.items()}\n",
    "text = ('Over the longer-term, US labor productivity growth '+\n",
    "        f'has averaged {ltavg} per year. The trailing 20-'+\n",
    "        f'year average growth rate was {tty} in {ltdt} '+\n",
    "        f'{cl[\"LT\"]}. During the 1990s and early 2000s, labor '+\n",
    "        'productivity growth was above its long-term average. '+\n",
    "        'In contrast, from 2010 to 2017, productivity growth '+\n",
    "        f'was below average. Over the year ending {ltdt}, productivity '+\n",
    "        f'growth averaged {ltv} {cl[\"ST\"]}. ')\n",
    "write_txt(text_dir / 'prod_st_lt.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T12:30:00.496531Z",
     "start_time": "2023-09-07T12:30:00.491385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'PRS85006092': 'value',\n",
    "          'PRS85006032': 'hours',\n",
    "          'PRS85006042': 'output',\n",
    "          'PRS85006033': 'hours_index'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T12:30:04.860685Z",
     "start_time": "2023-09-07T12:30:01.583270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start year and end year\n",
    "dates = (1989, 2023)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "\n",
    "df.to_csv(data_dir / 'lprod.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T12:30:04.877929Z",
     "start_time": "2023-09-07T12:30:04.862962Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'lprod.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "ltdt = dtxt(df.index[-1])['qtr1']\n",
    "prdt = dtxt(df.index[-2])['qtr1']\n",
    "d = series_info(df['value'])\n",
    "s = {srs: {'lt': value_text(df[srs].iloc[-1], adj='annual'), \n",
    "           'pr': value_text(df[srs].iloc[-2], adj='annual'), \n",
    "           'lt2': value_text(df[srs].iloc[-1], style='increase_of'), \n",
    "           'pr2': value_text(df[srs].iloc[-2]),\n",
    "           'pr3': value_text(df[srs].iloc[-2], style='increase_of')} \n",
    "     for srs in series.values()}\n",
    "compare = compare_text(d['five_year_mean'], d['mean'], [0.1, 0.5, 2.0])\n",
    "\n",
    "text = (f'In {ltdt}, nonfarm business labor productivity {s[\"value\"][\"lt\"]} '+\n",
    "        f'(see\\cbox{{teal}}), as the result of {s[\"output\"][\"lt2\"]} in '+\n",
    "        f'real output and {s[\"hours\"][\"lt2\"]} in hours worked. In the '+\n",
    "        f'prior quarter, {prdt}, labor productivity {s[\"value\"][\"pr\"]}, '+\n",
    "        f'as real output {s[\"output\"][\"pr2\"]} and hours of work '+\n",
    "        f'{s[\"hours\"][\"pr2\"]}. Over the past five years, labor productivity '+\n",
    "        f'growth has averaged {d[\"five_year_mean\"]:.1f} percent, '+\n",
    "        f'{compare} the 1989-onward average of {d[\"mean\"]:.1f} percent.')\n",
    "write_txt(text_dir / 'lprod.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "hr19 = value_text(df.loc['2017': '2019', 'hours'].mean(), adj='average')\n",
    "ch19 = (df['hours_index'].iloc[-1] / \n",
    "        df.loc['2019-10-01', 'hours_index'] - 1) * 100\n",
    "ch19txt = value_text(ch19, 'increase_by', adj='total')\n",
    "text = (f'Total hours worked in nonfarm businesses {s[\"hours\"][\"lt\"]} '+\n",
    "        f'in {ltdt}, following {s[\"hours\"][\"pr3\"]} in {prdt}. From '+\n",
    "        f'2017 through 2019, total hours worked {hr19}. Since 2019, '+\n",
    "        f'hours worked have {ch19txt}.')\n",
    "write_txt(text_dir / 'tot_hours.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Labor Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T12:30:07.647030Z",
     "start_time": "2023-09-07T12:30:07.586671Z"
    }
   },
   "outputs": [],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=[0])\n",
    "         .set_index('date')[['avghrstot', 'EMPsa']])\n",
    "emp = (df['avghrstot'] * df['EMPsa']).rename('Total')\n",
    "coe = nipa_df(retrieve_table('T20100')['Data'], ['A033RC'])\n",
    "data = coe.join(emp.resample('QS').mean()).dropna()\n",
    "data['coe_inp'] = data['A033RC'] / data['Total']\n",
    "data['wage'] = data['coe_inp'] * data['Total'].iloc[0]\n",
    "data['work'] = data['A033RC'] - data['wage']\n",
    "\n",
    "# Calculate contributions to growth\n",
    "result = (growth_contrib(data, 'A033RC')[['work', 'wage']]\n",
    "          .rolling(4).mean().dropna())\n",
    "result['sum'] = result.sum(axis=1)\n",
    "result.to_csv(data_dir / 'gli.csv', index_label='date')\n",
    "\n",
    "# Horizontal bar at 5\n",
    "start = dtxt(result.index[0] - pd.DateOffset(months=1))['datetime']\n",
    "end = dtxt(result.index[-1] + pd.DateOffset(months=3))['datetime']\n",
    "hbar = (f'\\draw [dotted, thick] (axis cs:{{{start}}}, 5) -- '+\n",
    "        f'(axis cs:{{{end}}}, 5);')\n",
    "write_txt(text_dir / 'gli_hbar2.txt', hbar) \n",
    "\n",
    "# Text\n",
    "ltdate = dtxt(result.index[-1])['qtr1']\n",
    "totch = value_text(result['sum'].iloc[-1], adj='avg_ann', \n",
    "                   threshold=0.1)\n",
    "wage = result['wage'].iloc[-1]\n",
    "work = result['work'].iloc[-1]\n",
    "    \n",
    "txt2 = value_text(wage, 'contribution', 'pp')\n",
    "txt3 = value_text(work, 'contribution', 'pp')\n",
    "\n",
    "text = (f'{totch} over the year ending {ltdate}. Changes in wages {txt2}, '+\n",
    "        f'and changes in total hours worked {txt3}.')\n",
    "write_txt(text_dir / 'gli.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Obligations Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-01T00:16:52.829956Z",
     "start_time": "2023-09-01T00:16:52.603180Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=FOR&series=1dc13603606b1a2cf3c07004eeb7f026&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2023&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, clean_data = clean_fed_data(url)\n",
    "\n",
    "d = {k: v.replace(', seasonally adjusted', '') for k, v in d.items()}\n",
    "\n",
    "data = clean_data.rename(d, axis=1)\n",
    "data.to_csv(data_dir / 'for.csv', index_label='date')\n",
    "col1 = 'blue!80!black'\n",
    "node = end_node(data['Financial obligations ratio'], col1, \n",
    "                percent=True, date='q', full_year=True)\n",
    "write_txt(text_dir / 'for_node.txt', node)\n",
    "\n",
    "ltdate = dtxt(data.index[-1])['qtr1']\n",
    "ltval = data['Financial obligations ratio'].iloc[-1]\n",
    "col2 = 'red'\n",
    "node2 = end_node(data['Debt service ratio'], col2, percent=True)\n",
    "write_txt(text_dir / 'dsr_node.txt', node2)\n",
    "\n",
    "dsrval = data['Debt service ratio'].iloc[-1]\n",
    "\n",
    "text = (f'As of {ltdate}, the \\\\textbf{{financial obligations ratio}} '+\n",
    "        f'is {ltval:.1f} percent {c_line(col1)}, and the '+\n",
    "        f'\\\\textbf{{debt service ratio}} is {dsrval:.1f} percent '+\n",
    "        f'{c_line(col2)}.')\n",
    "write_txt(text_dir / 'for.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shiller real return trailing 20-year average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:32:52.662990Z",
     "start_time": "2023-09-08T14:32:50.811134Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In July 2023, the Shiller total return CAPE ratio was 33.3, compared to 32.5 in June 2023 and 31.5 in July 2022 (see {\\color{blue!80!cyan}\\textbf{---}}). In 2019, the Shiller CAPE ratio was 32.1, on average. In 2000, during the stock market bubble, the ratio averaged 45.1. \n",
      "Three conflicting nodes\n",
      "According to historical stock market \\href{http://www.econ.yale.edu/~shiller/data.htm}{data} from Robert Shiller, the \\textbf{inflation-adjusted trailing twenty-year annual rate of return} of the S\\&P 500 is 7.3 percent as of March 2023 (see {\\color{green!80!blue}\\textbf{---}}). Ultra-long-term real returns are currently low relative to the average trailing twenty-year real annual return of 10.1 percent during 1995--2005. The trailing ten-year real return was 8.9 percent, as of March 2023, and 10.7 percent during 1995--2005 (see {\\color{blue}\\textbf{---}}). \n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.econ.yale.edu/~shiller/data/ie_data.xls'\n",
    "data = pd.read_excel(url, sheet_name='Data', header=7, \n",
    "                     index_col='Date').dropna(subset=['TR CAPE'])\n",
    "data.index = pd.to_datetime(data.index.format())\n",
    "data.loc['1989':, 'TR CAPE'].to_csv(data_dir / 'catrpe.csv', \n",
    "                                    index_label='date')\n",
    "color = 'blue!80!cyan'\n",
    "cl = c_line(color)\n",
    "pe = data.loc['1989':, 'TR CAPE']\n",
    "ltdt = dtxt(pe.index[-1])['mon1']\n",
    "prdt = dtxt(pe.index[-2])['mon1']\n",
    "yrdt = dtxt(pe.index[-13])['mon1']\n",
    "ltval = pe.iloc[-1]\n",
    "prval = pe.iloc[-2]\n",
    "yrval = pe.iloc[-13]\n",
    "val19 = pe.loc['2019'].mean()\n",
    "val00 = pe.loc['2000'].mean()\n",
    "\n",
    "text = (f'In {ltdt}, the Shiller total return CAPE ratio was '+\n",
    "        f'{ltval:.1f}, compared to {prval:.1f} in {prdt} and '+\n",
    "        f'{yrval:.1f} in {yrdt} {cl}. In 2019, the Shiller CAPE ratio '+\n",
    "        f'was {val19:.1f}, on average. In 2000, during the stock market '+\n",
    "        f'bubble, the ratio averaged {val00:.1f}. ')\n",
    "write_txt(text_dir / 'cape.txt', text)\n",
    "print(text)\n",
    "node = end_node(data['TR CAPE'], color, date='m')\n",
    "write_txt(text_dir / 'cape_node.txt', node)\n",
    "col = ['Price', 'Dividend']\n",
    "df = data.loc['1960':, col].dropna()\n",
    "for yrs in [10, 15, 20]:\n",
    "    mos = yrs * 12\n",
    "    dy = (df.Dividend / df.Price).rolling(mos).mean()\n",
    "    pch = (df.Price.pct_change(mos)+1)**(1/yrs) - 1\n",
    "    df[f'r{yrs}'] = (dy + pch) * 100\n",
    "    \n",
    "res = df.loc['1989':, ~df.columns.isin(col)]\n",
    "res.to_csv(data_dir / f'sp500rr.csv', index_label='date', \n",
    "           float_format='%g')\n",
    "adj = node_adj(res)\n",
    "smax = res.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'r20': 'green!80!blue', \n",
    "          'r15': 'orange',\n",
    "          'r10': 'blue'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(res[series], color, \n",
    "                            date=date[series], \n",
    "                            percent=True, full_year=True, \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'sp500rr_nodes.txt', nodes)  \n",
    "url = 'http://www.econ.yale.edu/~shiller/data.htm'\n",
    "lt20 = df['r20'].iloc[-1]\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "pr = df['r20'].loc['1995':'2005'].mean()\n",
    "lt10 = df['r10'].iloc[-1]\n",
    "pr10 = df['r10'].loc['1995':'2005'].mean()\n",
    "cl = c_line(colors['r20'])\n",
    "text = (f'According to historical stock market \\href{{{url}}}'+\n",
    "        '{data} from Robert Shiller, the \\\\textbf{inflation-adjusted '+\n",
    "        'trailing twenty-year annual rate of return} of the S\\&P '+\n",
    "        f'500 is {lt20:.1f} percent as of {ltdt} {cl}. Ultra-long-'+\n",
    "        'term real returns are currently low relative to the '+\n",
    "        'average trailing twenty-year real annual return of '+\n",
    "        f'{pr:.1f} percent during 1995--2005. The trailing ten-'+\n",
    "        f'year real return was {lt10:.1f} percent, as of {ltdt}, '+\n",
    "        f'and {pr10:.1f} percent during 1995--2005 '+\n",
    "        f'{c_line(colors[\"r10\"])}. ')\n",
    "write_txt(text_dir / 'sp500rr.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:32:53.241821Z",
     "start_time": "2023-09-08T14:32:53.218287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In March 2023, the dividend yield for the S\\&P 500 is 1.72 percent (see {\\color{green!80!black}\\textbf{---}}), compared to 1.66 percent in February 2023, and 1.41 percent in March 2022. From 1990 to 2015, the dividend yield averaged 2.09 percent.\n"
     ]
    }
   ],
   "source": [
    "dy = ((data.D / data.P).dropna() * 100).loc['1989':].rename('DY')\n",
    "dy.to_csv(data_dir / 'sp500dy.csv', index_label='date')\n",
    "color = 'green!80!black'\n",
    "\n",
    "node = end_node(dy, color, date='m', full_year=True, percent=True, \n",
    "                digits=2, offset=0.3)\n",
    "write_txt(text_dir / 'sp500dy_node.txt', node)\n",
    "\n",
    "ltdt = dtxt(dy.index[-1])['mon1']\n",
    "prdt = dtxt(dy.index[-2])['mon1']\n",
    "yrdt = dtxt(dy.index[-13])['mon1']\n",
    "ltval = dy.iloc[-1]\n",
    "prval = dy.iloc[-2]\n",
    "yrval = dy.iloc[-13]\n",
    "cl = c_line(color)\n",
    "avg = dy.loc['1990': '2015'].mean()\n",
    "text = (f'In {ltdt}, the dividend yield for the S\\&P 500 is '+\n",
    "        f'{ltval:.2f} percent {cl}, compared to {prval:.2f} percent '+\n",
    "        f'in {prdt}, and {yrval:.2f} percent in {yrdt}. From 1990 to '+\n",
    "        f'2015, the dividend yield averaged {avg:.2f} percent.')\n",
    "write_txt(text_dir / 'sp500div.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S&P 500 Quarterly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-07T15:02:17.178135Z",
     "start_time": "2023-06-07T15:02:17.171360Z"
    }
   },
   "outputs": [],
   "source": [
    "#url = ('https://us.spindices.com/documents/'+\n",
    "#       'additional-material/sp-500-eps-est.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Quality Corporate Bond Yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T16:18:23.341956Z",
     "start_time": "2023-09-06T16:18:22.653501Z"
    }
   },
   "outputs": [],
   "source": [
    "df = fred_df('HQMCB10YR')\n",
    "df.to_csv(data_dir / 'hqcb.csv', index_label='date')\n",
    "\n",
    "color = 'violet!80!black'\n",
    "node = end_node(df['VALUE'], color, date='m', percent=True, \n",
    "                full_year=True, digits=2)\n",
    "write_txt(text_dir / 'hqcb_node.txt', node)\n",
    "\n",
    "data = df.VALUE.apply('{:.2f} percent'.format).values\n",
    "idx = [dtxt(i)['mon1'] for i in df.index]\n",
    "cl = c_line(color)\n",
    "\n",
    "text = (f'The yield on high-quality corporate bonds with a maturity '+\n",
    "        f'of 10 years is {data[-1]} in {idx[-1]}, following '+\n",
    "        f'{data[-2]} in {idx[-2]} {cl}. One year prior, in '+\n",
    "        f'{idx[-13]}, this spot rate was {data[-13]}, and '+\n",
    "        f'four years prior, in {idx[-49]}, it was {data[-49]}.')\n",
    "write_txt(text_dir / 'hqcb.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treasury Monthly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:08.187704Z",
     "start_time": "2023-09-08T14:33:07.616826Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['record_date', 'classification_desc', \n",
    "        'current_month_rcpt_outly_amt']\n",
    "fields = ','.join(cols)\n",
    "lines = ','.join(['2', '3', '5', '6', '7', '12'])\n",
    "url = ('https://api.fiscaldata.treasury.gov/services/api/'+\n",
    "       'fiscal_service/v1/accounting/mts/mts_table_9'+\n",
    "       f'?filter=src_line_nbr:in:({lines})&format=csv&'+\n",
    "       f'fields={fields}&page[size]=700')\n",
    "\n",
    "other = lambda x: x['Total'] - x['Individual Income Taxes']\n",
    "si_cols = ['Employment and General Retirement', 'Other Retirement', \n",
    "           'Unemployment Insurance']\n",
    "si = lambda x: x[si_cols].sum(axis=1)\n",
    "df = (pd.read_csv(url, index_col=cols[:2], parse_dates=True)\n",
    "        ['current_month_rcpt_outly_amt']\n",
    "        .unstack().astype('float').divide(1_000_000_000_000)\n",
    "        .assign(Other = other, SI = si).rolling(12).sum().dropna())\n",
    "df.to_csv(data_dir / 'tmb_rec.csv', float_format='%g', \n",
    "          index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:09.685332Z",
     "start_time": "2023-09-08T14:33:09.669492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States Treasury \\href{https://fiscal.treasury.gov/reports-statements/mts/current.html}{report} federal government receipts and outlays in the Monthly Treasury Statement. Over the 12 months ending July 2023, \\textbf{federal government receipts} total \\$4.5 trillion, of which \\$2.2 trillion are from individual income taxes (see {\\color{blue!70!black}\\textbf{---}}). The remaining receipts (see {\\color{blue!40!cyan}\\textbf{---}}) are largely social insurance contributions (\\$1.6 trillion) and corporate income taxes (\\$0.4 trillion).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'tmb_rec.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "col_iit = 'blue!70!black'\n",
    "write_txt(text_dir / 'tmb_rec_iit.txt', \n",
    "          end_node(df['Individual Income Taxes'], col_iit))\n",
    "cl_iit = c_line(col_iit)\n",
    "col_oth = 'blue!40!cyan'\n",
    "write_txt(text_dir / 'tmb_rec_oth.txt', \n",
    "          end_node(df['Other'], col_oth))\n",
    "cl_oth = c_line(col_oth)\n",
    "\n",
    "# Text \n",
    "url = 'https://fiscal.treasury.gov/reports-statements/mts/current.html'\n",
    "tval = df.iloc[-1].apply(lambda x: f'\\${x:.1f} trillion')\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "text = (f'The United States Treasury \\href{{{url}}}{{report}} '+\n",
    "        'federal government receipts and outlays in the Monthly '+\n",
    "        f'Treasury Statement. 'f'Over the 12 months ending {ltdt}, '+\n",
    "        f'\\\\textbf{{federal government receipts}} total {tval[\"Total\"]}, '+\n",
    "        f'of which {tval[\"Individual Income Taxes\"]} are from '+\n",
    "        f'individual income taxes {cl_iit}. The remaining receipts '+\n",
    "        f'{cl_oth} are largely social insurance contributions '+\n",
    "        f'({tval[\"SI\"]}) and corporate income taxes '+\n",
    "        f'({tval[\"Corporation Income Taxes\"]}).')\n",
    "write_txt(text_dir / 'tmb_rec.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Size of Treasury Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T06:51:07.379392Z",
     "start_time": "2023-09-08T06:51:06.821905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of August 2023, the public holds \\$25.5 trillion in marketable treasuries. \n"
     ]
    }
   ],
   "source": [
    "url = ('https://api.fiscaldata.treasury.gov/services/api/fiscal_service/'+\n",
    "       'v1/debt/mspd/mspd_table_1?sort=-record_date&fields=record_date,'+\n",
    "       'security_type_desc,security_class_desc,total_mil_amt')\n",
    "\n",
    "r = requests.get(url).json()\n",
    "\n",
    "df = pd.DataFrame(r['data']).set_index('record_date')\n",
    "ltdt = df.index[0]\n",
    "ltval = df.query('security_type_desc == \"Total Marketable\"')['total_mil_amt'].iloc[0]\n",
    "tdt = dtxt(ltdt)['mon1']\n",
    "tval = f'\\${float(ltval) / 1_000_000:.1f} trillion'\n",
    "\n",
    "text = (f'As of {tdt}, the public holds {tval} in marketable treasuries. ')\n",
    "write_txt(text_dir / 'treas_market.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### International Investment Position (IIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:09:30.347976Z",
     "start_time": "2023-08-30T13:09:25.143874Z"
    }
   },
   "outputs": [],
   "source": [
    "# Annual GDP for 1988-2005\n",
    "s = 'A191RC'\n",
    "r = bea_api_nipa([f'T10105'], bea_key, freq='A')\n",
    "data = json.loads(r[0][2])['BEAAPI']['Results']\n",
    "date = lambda x: (pd.to_datetime(x.TimePeriod) + \n",
    "                  pd.DateOffset(months=6))\n",
    "value = lambda x: x.DataValue.str.replace(',','')\n",
    "gdpa = (pd.DataFrame(data['Data']).query('SeriesCode == @s')\n",
    "          .assign(date = date, value=value).set_index('date')\n",
    "          .loc[:'2005', 'value'].astype(int))\n",
    "gdpq = nipa_df(retrieve_table('T10105')['Data'], [s])[s]\n",
    "gdp = pd.concat([gdpa, gdpq.loc['2006':]])\n",
    "\n",
    "srs = ['FinAssets', 'FinLiabs', 'Net']\n",
    "years = ','.join(map(str, range(1988, 2024)))\n",
    "res = pd.DataFrame()\n",
    "for s in srs:\n",
    "    url = (f'https://apps.bea.gov/api/data/?&UserID={bea_key}'+\n",
    "           f'&method=GetData&datasetname=IIP&TypeOfInvestment={s}'+\n",
    "           f'&Component=Pos&Frequency=A,QNSA&Year={years}')\n",
    "    r = requests.get(url)\n",
    "    t = pd.DataFrame(r.json()['BEAAPI']['Data'])\n",
    "    a = t.query('Frequency == \"A\"')[['TimePeriod', 'DataValue']]\n",
    "    a = a.set_index(pd.to_datetime(a['TimePeriod']) + \n",
    "                    pd.DateOffset(months=6)).loc[:'2005', 'DataValue']\n",
    "    q = t.query('Frequency == \"QNSA\"')[['TimePeriod', 'DataValue']]\n",
    "    q = q.set_index(pd.to_datetime(q['TimePeriod']))['DataValue']\n",
    "    res[s] = pd.concat([a, q]).astype('float')\n",
    "\n",
    "sh = res.divide(gdp, axis=0).multiply(100).dropna()\n",
    "sh.to_csv(data_dir / 'iip.csv', index_label='date')\n",
    "\n",
    "tot = res.iloc[-1] / 1_000_000\n",
    "lt = sh.iloc[-1]\n",
    "ltdt = dtxt(sh.index[-1])['qtr1']\n",
    "pr = sh.iloc[-2]\n",
    "prdt = dtxt(sh.index[-2])['qtr1']\n",
    "pr19 = sh.loc['2019'].mean()\n",
    "col_a, col_l, col_n = 'blue!95!violet', 'red', 'cyan!25!white'\n",
    "\n",
    "text = (f'In {ltdt}, domestic holdings of foreign assets total '+\n",
    "        f'\\${tot.FinAssets:.1f} trillion, equivalent to {lt.FinAssets:.1f} '+\n",
    "        f'percent of GDP {c_line(col_a)}. In {prdt}, these assets were '+\n",
    "        f'equivalent to {pr.FinAssets:.1f} percent of GDP, and in '+\n",
    "        f'2019, they were equivalent to {pr19.FinAssets:.1f} percent. '+\n",
    "        'Domestic liabilities to the foreign sector total '+\n",
    "        f'\\${tot.FinLiabs:.1f} trillion, or {lt.FinLiabs:.1f} percent of '+\n",
    "        f'GDP, in {ltdt}, following {pr.FinLiabs:.1f} percent in {prdt}, '+\n",
    "        f'and {pr19.FinLiabs:.1f} percent in 2019 {c_line(col_l)}.\\n\\n'+\n",
    "        f'The overall result of these financial positions, net IIP, or '+\n",
    "        'holdings of foreign assets minus liabilities, identifies the '+\n",
    "        'US as a net debtor to the rest of the world, to the equivalent '+\n",
    "        f'of {abs(lt.Net):.1f} percent of GDP in {ltdt}, following '\n",
    "        f'{abs(pr.Net):.1f} percent in {prdt}, and {abs(pr19.Net):.1f} '+\n",
    "        f'percent in 2019 {c_box(col_n)}.')\n",
    "write_txt(text_dir / 'niip.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H.6 Money Stock - M2 (Monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:09:30.557686Z",
     "start_time": "2023-08-30T13:09:30.350550Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.federalreserve.gov/datadownload/Output.aspx?'+\n",
    "       'rel=H6&series=411c4c269dc600450339f8d4809d80eb&lastobs=&'+\n",
    "       'from=01/01/1987&to=12/31/2023&filetype=csv&label=include&'+\n",
    "       'layout=seriescolumn')\n",
    "d, df = clean_fed_data(url)\n",
    "df.rename(d, axis=1).to_csv(data_dir / 'h6raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-30T13:09:31.162713Z",
     "start_time": "2023-08-30T13:09:31.100783Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'h6raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "prmodt = dtxt(df.index[-2])['mon1']\n",
    "ltval = df['M2'].iloc[-1] / 1000.0\n",
    "one_yr = value_text(df['M2'].pct_change(12).iloc[-1] * 100, threshold=0.1)\n",
    "pr_mo = value_text(df['M2'].pct_change(12).iloc[-2] * 100, \n",
    "                   style='increase_of')\n",
    "four_yr = value_text(df['M2'].pct_change(48).iloc[-1] * 100)\n",
    "\n",
    "# M2 share of GDP\n",
    "m2q = df.M2.resample('QS').mean() * 1_000\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "m2gdp = ((m2q / gdp) * 100).dropna()\n",
    "m2gi = (m2gdp / m2gdp.iloc[0]).rename('value')\n",
    "m2gi.to_csv(data_dir / 'm2gdp.csv', index_label='date',\n",
    "         float_format='%g')\n",
    "ltqtr = dtxt(m2gi.index[-1])['qtr2']\n",
    "lt = m2gdp.iloc[-1]\n",
    "totch = (m2gi.iloc[-1] - 1) * 100\n",
    "\n",
    "txt1 = (f'In {ltdate}, the M2 money stock totals \\${ltval:.1f} '+\n",
    "        'trillion. Put into the context of overall economic activity, '+\n",
    "        f'M2 is equivalent to {lt:.1f} percent of GDP in {ltqtr}. During '+\n",
    "        'the 1990s, the ratio of money to economic activity was falling '+\n",
    "        f'{c_line(\"magenta\")}. Following the great recession, the money '+\n",
    "        'supply has expanded relative to activity. Since 1989, the ratio '+\n",
    "        f'has increased by a total of {totch:.1f} percent.')\n",
    "write_txt(text_dir / 'm2lvl.txt', txt1)\n",
    "col = 'green!80!blue'\n",
    "\n",
    "mo_ch = value_text((df.M2.pct_change()*100).iloc[-1], threshold=0.1)\n",
    "pc_mo_ch = value_text((df.M2.pct_change()*100).iloc[-2], \n",
    "                      'increase_of', threshold=0.1)\n",
    "prdt = dtxt(df.index[-2])['mon1']\n",
    "txt2 = (f'The M2 money stock {mo_ch} in {ltdate}, over the previous '+\n",
    "        f'month, following {pc_mo_ch} in {prdt}. Over the past 12 '+\n",
    "        f'months, the money stock {one_yr} {c_line(col)}. The M2 money '+\n",
    "        f'stock has {four_yr}, in total, over the past four years. ')\n",
    "write_txt(text_dir / 'm2chg.txt', txt2)\n",
    "print(txt1, '\\n', txt2)\n",
    "\n",
    "r = pd.DataFrame({'value': df['M2'].pct_change(12) * 100,\n",
    "                  '3M': m3rate(df['M2']),\n",
    "                  '1M': (((df.M2.pct_change() + 1) ** 12) - 1) * 100}\n",
    "                ).loc['1989':]\n",
    "r.value.to_csv(data_dir / 'm2.csv', index_label='date', header=True,\n",
    "         float_format='%g')\n",
    "\n",
    "node = end_node(r.value, col, percent=True, offset=True,\n",
    "                date='m', full_year=True)\n",
    "write_txt(text_dir / 'm2_node.txt', node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consumer Credit (G.19)\n",
    "\n",
    "The same chart also includes a line from the Z.1 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T16:18:40.964728Z",
     "start_time": "2023-09-06T16:18:40.745641Z"
    }
   },
   "outputs": [],
   "source": [
    "base = 'https://www.federalreserve.gov/datadownload/Output.aspx?'\n",
    "srs = 'rel=G19&series=8c7511a37e4aea678be81e7a61df57db&lastobs=&'\n",
    "dt = 'from=01/01/1989&to=12/31/2023&'\n",
    "oth = 'filetype=csv&label=include&layout=seriescolumn'\n",
    "url = base + srs + dt + oth\n",
    "\n",
    "d, df = clean_fed_data(url)\n",
    "cc = df['DTCTL.M']\n",
    "\n",
    "dpi = (pd.read_csv(data_dir / 'nipa20600.csv', index_col='date', \n",
    "                   parse_dates=True).loc['1989':, 'A067RC'])\n",
    "rate = ((cc / dpi) * 100).rename('value').dropna()\n",
    "rate.to_csv(data_dir / 'cc_dpi_monthly.csv', index_label='date')\n",
    "\n",
    "node_color = 'green!60!blue!80!black'\n",
    "node = end_node(rate, node_color, date='m', percent=True, full_year=True)\n",
    "write_txt(text_dir / 'cc_dpi_monthly_node.txt', node)\n",
    "\n",
    "ltdate = dtxt(cc.index[-1])['mon1']\n",
    "ltval = cc.iloc[-1] / 1_000_000\n",
    "ltrate = rate.iloc[-1]\n",
    "one_yr = value_text(cc.pct_change(12).iloc[-1] * 100, style='increase_by')\n",
    "one_yr_dpi = value_text(dpi.pct_change(12).iloc[-1] * 100, style='increase_by')\n",
    "one_yr_rate = value_text(rate.diff(12).iloc[-1], adj='total', \n",
    "                         ptype='pp', threshold=0.1)\n",
    "cline = c_line(node_color)\n",
    "also = 'also ' if one_yr == one_yr_dpi else ''    \n",
    "text = ('In the monthly measure, consumer credit totals '+\n",
    "        f'\\${ltval:.2f} trillion US dollars on a '+\n",
    "        f'seasonally-adjusted and annualized basis in {ltdate}. '+\n",
    "        f'Over the past year, consumer credit {one_yr}, while '+\n",
    "        f'after-tax income {also}{one_yr_dpi}. As a result, the ratio '+\n",
    "        f'of consumer credit to disposable income {one_yr_rate}. '+\n",
    "        f'In {ltdate}, total consumer credit is equivalent to '+\n",
    "        f'{ltrate:.1f} percent of annualized {ltdate} disposable '+\n",
    "        f'income {cline}. ')\n",
    "write_txt(text_dir / 'cc_dpi.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Employment Cost Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-28T12:55:30.820025Z",
     "start_time": "2023-07-28T12:55:29.392227Z"
    }
   },
   "outputs": [],
   "source": [
    "series = {'CIU2020000000000A': 'WS',\n",
    "          'CIU2030000000000A': 'Be'}\n",
    "\n",
    "dates = (2001, 2023)\n",
    "df = bls_api(series, dates, bls_key)\n",
    "df.to_csv(data_dir/ 'eci.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T21:44:06.211962Z",
     "start_time": "2023-08-17T21:44:06.188980Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'eci.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "adj = node_adj(df)\n",
    "smax = df.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'WS': 'green!80!blue', \n",
    "          'Be': 'cyan!40!blue'}\n",
    "date = {series: 'q' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(df[series], color, \n",
    "                            date=date[series], \n",
    "                            percent=True, colon=False,\n",
    "                            size=1.1, offset=adj[series])\n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'eci_nodes.txt', nodes)\n",
    "\n",
    "obs = [(-1, 'lt'), (-2, 'pr'), (-3, 'pr2')]\n",
    "sty = [('increase', '1'), ('increase_of', '2'), \n",
    "       ('increase_by', '3')]\n",
    "dt = {n: dtxt(df.index[i]) for i, n in obs}\n",
    "v = {f'{name}_{n}_{s}': value_text(val, style=style) \n",
    "     for i, n in obs for name, val \n",
    "     in df.iloc[i].to_dict().items() \n",
    "     for style, s in sty}\n",
    "\n",
    "val19 = {s: value_text(df.loc['2019', s].mean(), 'increase_by') \n",
    "         for s in ['WS', 'Be']}\n",
    "text = (f'In {dt[\"lt\"][\"qtr2\"]}, private industry wage and '+\n",
    "        f'salary costs {v[\"WS_lt_3\"]} (one-year percent '+\n",
    "        f'change, {c_line(colors[\"WS\"]).replace(\"(\", \"\")}, '+\n",
    "        f'following {v[\"WS_pr_2\"]} in {dt[\"pr\"][\"qtr1\"]}, '+\n",
    "        f'and {v[\"WS_pr2_2\"]} in {dt[\"pr2\"][\"qtr1\"]}. In '+\n",
    "        f'2019, private wages and salaries costs {val19[\"WS\"]}, '+\n",
    "        'on average.\\n\\nThe cost of private sector benefits '+\n",
    "        f'{v[\"Be_lt_3\"]} {c_line(colors[\"Be\"])} over the year '+\n",
    "        f'ending {dt[\"lt\"][\"qtr1\"]}, following {v[\"Be_pr_2\"]} '+\n",
    "        f'in {dt[\"pr\"][\"qtr1\"]}. In 2019, private-sector '+\n",
    "        f'benefits costs {val19[\"Be\"]}, on average.')\n",
    "write_txt(text_dir / 'eci.txt', text)\n",
    "print(text, '\\n')\n",
    "\n",
    "# Calculate Gross Labor Income\n",
    "start = '2017-01-01'\n",
    "eci = pd.read_csv(data_dir / 'eci.csv', index_col='date', \n",
    "                  parse_dates=True)['WS']\n",
    "epop = (pd.read_csv(data_dir / 'jobs_report_main.csv', index_col='date', \n",
    "                   parse_dates=True)['PA_EPOP'].pct_change(12)\n",
    "        .resample('QS').mean()) * 100\n",
    "ece = (eci + epop).rename('ECI_EPOP').dropna()\n",
    "# Shift dates to center quarter on chart\n",
    "ds = ece.loc[start:]\n",
    "ds.index = ds.index + pd.DateOffset(days=45)\n",
    "ds.to_csv(data_dir / 'gli_qtr.csv', index_label='date')\n",
    "\n",
    "#text\n",
    "cline = c_line('violet!80!black')\n",
    "ltdt = dtxt(ece.index[-1])['qtr1']\n",
    "text = ('Calculating gross labor income from the employment cost index '+\n",
    "        f'for private industries and the prime age employment rate {cline}, '+\n",
    "        f'one-year growth is {ece.iloc[-1]:.1f} percent in {ltdt}, '+\n",
    "        f'following {ece.iloc[-5]:.1f} percent one year prior. ')\n",
    "write_txt(text_dir / 'gli_eci.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T00:25:27.133068Z",
     "start_time": "2022-02-16T00:25:27.131119Z"
    }
   },
   "source": [
    "### Treasury International Capital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:54.799315Z",
     "start_time": "2023-09-08T14:33:34.662069Z"
    }
   },
   "outputs": [],
   "source": [
    "# URL \n",
    "file = ('https://treasury.gov/resource-center/data-chart-center/tic/'+\n",
    "        'Documents/npr_history.csv')\n",
    "#file = ('/home/brian/Downloads/npr_history.csv')\n",
    "# Match names with numbers of columns in report\n",
    "names = {10: 'Treasuries_official', 5: 'Treasuries_private', \n",
    "         11: 'Agencies_official', 6: 'Agencies_private', \n",
    "         12: 'Corporate_official', 7: 'Corporate_private',\n",
    "         13: 'Equities_official', 8: 'Equities_private'}\n",
    "\n",
    "df = pd.read_csv(file, header=12, index_col=0, parse_dates=True).iloc[1:].dropna()\n",
    "df.index.name = 'date'\n",
    "df.index = pd.to_datetime(df.index)\n",
    "rn = {f'[{k}]': v for k, v in names.items()}\n",
    "res = df[rn.keys()].rename(rn, axis=1).sort_index().loc['1988':]\n",
    "# Categories to combine\n",
    "c = {'Treasury_Bonds': ['Treasuries_official',\n",
    "                        'Treasuries_private'],\n",
    "     'Agency_Bonds': ['Agencies_official', \n",
    "                      'Agencies_private'],\n",
    "     'Corporate_Bonds': ['Corporate_official',\n",
    "                         'Corporate_private'],\n",
    "     'Equities': ['Equities_official', 'Equities_private']}\n",
    "\n",
    "final = pd.DataFrame()\n",
    "for name, grp in c.items():\n",
    "    final[name] = (res[grp].astype('int').sum(axis=1).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:54.814283Z",
     "start_time": "2023-09-08T14:33:54.800874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "June 2023\n"
     ]
    }
   ],
   "source": [
    "s = ['Treasury_Bonds', 'Agency_Bonds', 'Corporate_Bonds']\n",
    "pce = pd.read_csv(data_dir / 'nipa20804.csv', index_col='date', \n",
    "                  parse_dates=True).loc[final.index, 'DPCERG']\n",
    "pr = pce / pce.iloc[-1]\n",
    "data = (final[s].rolling(12).sum().loc['1989':]\n",
    "        .divide(1000).dropna())\n",
    "adj = (final[s].divide(pr, axis=0).rolling(12).sum().loc['1989':]\n",
    "        .divide(1000).dropna())\n",
    "adj.to_csv(data_dir/ 'tic_bond.csv', index_label='date')\n",
    "date = dtxt(adj.index[-1])['mon1']\n",
    "write_txt(text_dir / 'tic_date.txt', date)\n",
    "print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:54.845444Z",
     "start_time": "2023-09-08T14:33:54.815515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the year ending June 2023, the rest of the world was a net buyer of \\$802 billion of US treasury bonds, equivalent to 3.0 percent of US GDP (see \\cbox{black!25!white}). Over the same period, the rest of the world was a net buyer of \\$215 billion of US agency bonds, (see \\cbox{orange!30!yellow!90!white}), and a net buyer of \\$185 billion of US corporate bonds, (see \\cbox{blue!70!white}).\n"
     ]
    }
   ],
   "source": [
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "gdp = nipa_df(retrieve_table('T10105')['Data'], ['A191RC'])['A191RC']\n",
    "tbgdp = ((data.iloc[-1].loc['Treasury_Bonds'] * 1_000) / \n",
    "         gdp.iloc[-1]) * 100\n",
    "\n",
    "colors = {'Treasury_Bonds': 'black!25!white', \n",
    "          'Corporate_Bonds': 'blue!70!white',\n",
    "          'Agency_Bonds': 'orange!30!yellow!90!white'}\n",
    "\n",
    "cb = {k: c_box(v) for k,v in colors.items()}\n",
    "\n",
    "d = {}\n",
    "for i in s:\n",
    "    item = i.replace('_', ' ').lower()\n",
    "    val = data.iloc[-1].loc[i]\n",
    "    buysell = 'buyer' if val > 0 else 'seller'\n",
    "    txt = (f'a net {buysell} of \\${val:,.0f} billion of US {item}' \n",
    "           if abs(val) >= 5 else \n",
    "           f'about unchanged in holdings of US {item}')\n",
    "    d[i] = txt\n",
    "\n",
    "text = (f'Over the year ending {ltdt}, the rest of the world was '+\n",
    "        f'{d[\"Treasury_Bonds\"]}, equivalent to {tbgdp:.1f} percent '+\n",
    "        f'of US GDP {cb[\"Treasury_Bonds\"]}. Over the same period, '+\n",
    "        f'the rest of the world was {d[\"Agency_Bonds\"]}, '+\n",
    "        f'{cb[\"Agency_Bonds\"]}, and {d[\"Corporate_Bonds\"]}, '+\n",
    "        f'{cb[\"Corporate_Bonds\"]}.')\n",
    "write_txt(text_dir / 'tic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FRBNY Survey of Consumer Expectations Job Separation Expectation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:55.572277Z",
     "start_time": "2023-09-08T14:33:54.847341Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.newyorkfed.org/medialibrary/interactives/'+\n",
    "       'sce/sce/downloads/data/frbny-sce-data.xlsx')\n",
    "df = pd.read_excel(url, sheet_name='Job separation expectation', \n",
    "                   skiprows=3, index_col=0)\n",
    "df.index = pd.to_datetime([f'{str(i)[:4]}-{str(i)[-2:]}-01' \n",
    "                          for i in df.index])\n",
    "df.columns = ['Losing', 'Leaving']\n",
    "df.to_csv(data_dir / 'sce_job_separation.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:55.583494Z",
     "start_time": "2023-09-08T14:33:55.573783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In July 2023, the perceived likelihood of leaving one's job voluntarily in the next 12 months averages 17.0 percent, compared to 21.0 percent in 2019 (see {\\color{violet!50!blue}\\textbf{---}}). In the latest month, the perceived probability losing one's job is 11.8 percent, compared to 14.3 percent in 2019 (see {\\color{cyan}\\textbf{---}}).\n",
      "\n",
      "During the pandemic, in April 2020, job loss expectations exceeded job leaving expectations. In July 2023, job leaving expectations exceed job loss expectations by 5.3 percentage points, compared to 6.8 percentage points in 2019. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'sce_job_separation.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "\n",
    "lcol = 'cyan'\n",
    "vcol = 'violet!50!blue'\n",
    "vnode = end_node(df.Leaving, vcol, date='m', percent=True, \n",
    "                 full_year=True, colon=False, offset=0.35)\n",
    "lnode = end_node(df.Losing, lcol, percent=True)\n",
    "nodes = '\\n'.join([vnode, lnode])\n",
    "write_txt(text_dir / 'sce_job_sep_nodes.txt', nodes)\n",
    "\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "ltv = df.Leaving.iloc[-1]\n",
    "prv = df.Leaving.loc['2019'].mean()\n",
    "ltl = df.Losing.iloc[-1]\n",
    "prl = df.Losing.loc['2019'].mean()\n",
    "diff = ltv - ltl\n",
    "diffpr = prv - prl\n",
    "exfb = 'exceed' if diff > 0 else 'false below'\n",
    "text = (f'In {ltdt}, the perceived likelihood of leaving '+\n",
    "        \"one's job voluntarily in the next 12 months \"+\n",
    "        f'averages {ltv:.1f} percent, compared to {prv:.1f} '+\n",
    "        f'percent in 2019 {c_line(vcol)}. In the latest month, '+\n",
    "        f\"the perceived probability losing one's job is {ltl:.1f} \"+\n",
    "        f'percent, compared to {prl:.1f} percent in 2019 '+\n",
    "        f'{c_line(lcol)}.\\n\\nDuring the pandemic, in April 2020, '+\n",
    "        'job loss expectations exceeded job leaving expectations. '+\n",
    "        f'In {ltdt}, job leaving expectations {exfb} job loss '+\n",
    "        f'expectations by {diff:.1f} percentage points, compared '+\n",
    "        f'to {diffpr:.1f} percentage points in 2019. ')\n",
    "write_txt(text_dir / 'sce_job_sep.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-10T16:51:48.241151Z",
     "start_time": "2022-03-10T16:51:48.238778Z"
    }
   },
   "source": [
    "### Real Effective Exchange Rate\n",
    "\n",
    "From BIS\n",
    "\n",
    "Index 2010 = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:55.996146Z",
     "start_time": "2023-09-08T14:33:55.585078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bank for International Settlements (BIS) \\href{https://www.bis.org/statistics/eer.htm}{calculates} \\textbf{real effective exchange rates} for many countries, on a monthly basis. As of July 2023, the US dollar real effective exchange rate has increased 6.2 percent since 2010. In 2019, the index average was 98.6. Over the past three months, the index average value was 106.7.\n"
     ]
    }
   ],
   "source": [
    "df = fred_df('RBUSBIS')\n",
    "df.to_csv(data_dir / 'reer.csv', index_label='date')\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "ltval = value_text(df.VALUE.iloc[-1] - 100)\n",
    "val19 = df.loc['2019', 'VALUE'].mean()\n",
    "lt3m = df.VALUE.iloc[-3:].mean()\n",
    "url = 'https://www.bis.org/statistics/eer.htm'\n",
    "text = (f'The Bank for International Settlements (BIS) \\href{{{url}}}{{calculates}} '+\n",
    "        '\\\\textbf{real effective exchange rates} for many countries, on a monthly '+\n",
    "        f'basis. As of {ltdt}, the US dollar real effective exchange rate has '+\n",
    "        f'{ltval} since 2010. In 2019, the index average was {val19:.1f}. Over the '+\n",
    "        f'past three months, the index average value was {lt3m:.1f}.')\n",
    "write_txt(text_dir / 'reer.txt', text)\n",
    "print(text)\n",
    "node = end_node(df.VALUE, 'red', date='m', full_year=True, offset=-0.35)\n",
    "write_txt(text_dir / 'reer_node.txt', node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposition of US Public Debt Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T18:23:17.273967Z",
     "start_time": "2023-08-27T18:23:17.094336Z"
    }
   },
   "outputs": [],
   "source": [
    "url = ('https://www.federalreserve.gov/datadownload/Output.aspx?'+\n",
    "       'rel=Z1&series=005f835d2ffea228372c2cc838173fa5&lastobs=&'+\n",
    "       'from=01/01/1988&to=12/31/2023&filetype=csv&label=include&'+\n",
    "       'layout=seriescolumn')\n",
    "d, df = clean_fed_data(url)\n",
    "n = {'FA316006005.A': 'Fiscal balance',\n",
    "     'FA316130001.A': 'Interest paid',\n",
    "     'FL314104005.A': 'DSL',\n",
    "     'FL314190005.A': 'Liab',\n",
    "     'FA315000905.A': 'Borrowing'}\n",
    "data = df[n.keys()].rename(n, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T18:23:18.016219Z",
     "start_time": "2023-08-27T18:23:17.960733Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Primary balance'] = data['Fiscal balance'] + data['Interest paid']\n",
    "gdpa = (nipa_df(retrieve_table('T10105A')['Data'], ['A191RC'])\n",
    "        ['A191RC'])\n",
    "data['GDP'] = gdpa\n",
    "data['pi_'] = (nipa_df(retrieve_table('T10104A')['Data'], ['A191RG'])\n",
    "               ['A191RG'])\n",
    "data['defl'] = data['pi_'].iloc[-1] / data['pi_']\n",
    "data['Real GDP'] = data['defl'] * data['GDP']\n",
    "\n",
    "pb = -data['Primary balance']\n",
    "i = data['Interest paid'] / data['DSL'].shift()\n",
    "pi = data['pi_'].pct_change()\n",
    "g = data['Real GDP'].pct_change()\n",
    "lmbda = data['GDP'].pct_change()\n",
    "d = data['DSL'] / data['GDP']\n",
    "p = pb / data['GDP']\n",
    "\n",
    "res = (((i / (1 + lmbda)) * d.shift()) - \n",
    "       ((pi / (1 + lmbda)) * d.shift()) - \n",
    "       ((g / (1 + g)) * d.shift()) +\n",
    "       p)\n",
    "\n",
    "data['calc'] = res\n",
    "\n",
    "g2 = 0\n",
    "res3 = (((i / (1 + lmbda - g)) * d.shift()) - \n",
    "       ((pi / (1 + lmbda - g)) * d.shift()) - \n",
    "       ((g2 / (1 + g2)) * d.shift()) +\n",
    "       p)\n",
    "\n",
    "res4 = (((pi / (1 + lmbda)) * d.shift()) - \n",
    "       ((pi / (1 + lmbda)) * d.shift()) - \n",
    "       ((g / (1 + g)) * d.shift()) +\n",
    "       p)\n",
    "\n",
    "res5 = (((i / (1 + lmbda)) * d.shift()) - \n",
    "       ((pi / (1 + lmbda)) * d.shift()) - \n",
    "       ((g / (1 + g)) * d.shift()))\n",
    "\n",
    "data['e_gdp'] = (res - res3)\n",
    "data['e_p'] = (res - res5)\n",
    "data['e_r'] = (res - res4)\n",
    "data['calc2'] = data['e_gdp'] + data['e_p'] + data['e_r']\n",
    "data['sfa'] = d.diff() - data['calc2']\n",
    "data['total'] = d.diff()\n",
    "final = data[['e_gdp', 'e_p', 'e_r', 'sfa', 'total']] * 100\n",
    "final = final.dropna()\n",
    "final.index = final.index + pd.DateOffset(months=6)\n",
    "final.to_csv(data_dir / 'debt_dynamics.csv', index_label='date')\n",
    "\n",
    "col = {'p': 'orange!60!yellow!86!white',\n",
    "       'gdp': 'violet!80!white', 'r': 'green!80!yellow!68!black', \n",
    "       'sfa': 'blue!90!cyan!78!white'}\n",
    "\n",
    "lt = final.iloc[-1]\n",
    "ltdt = final.index[-1].year\n",
    "totch = value_text(lt['total'], 'increase_by', 'pp', threshold=0.1)\n",
    "pbch = value_text(lt['e_p'], 'contribution_to', 'pp', casual=True, threshold=0.1)\n",
    "rch = value_text(lt['e_r'], 'contribution', 'pp', casual=True, threshold=0.1)\n",
    "gdpch = value_text(lt['e_gdp'], 'contribution', 'pp', casual=True, threshold=0.1)\n",
    "sfach = value_text(lt['sfa'], 'contribution', 'pp', casual=True, threshold=0.1)\n",
    "cmb = lt[['e_gdp', 'e_p', 'e_r']].sum()\n",
    "cmbtxt = 'greater' if cmb > d.diff().iloc[-1] else 'less'\n",
    "text = (f'In {ltdt}, the debt to GDP ratio {totch} (see '+\n",
    "        '\\\\begin{tikzpicture} \\\\node[line width=0.3mm, circle, '+\n",
    "        'draw=black, scale=0.4, aspect=0.8] (d) at (0,0) {}; '+\n",
    "        '\\end{tikzpicture}). The primary balance '+\n",
    "        f'{pbch} the debt to GDP ratio {c_box(col[\"p\"])}, economic '+\n",
    "        f'growth {gdpch} {c_box(col[\"gdp\"])}, and real interest rates '+\n",
    "        f'{rch} {c_box(col[\"r\"])}. These combined factors were '+\n",
    "        f'{cmbtxt} than the actual change in liabilities; '+\n",
    "        'the adjustment to reconcile stocks and flows '+\n",
    "        f'{sfach} {c_box(col[\"sfa\"])}.')\n",
    "write_txt(text_dir / 'debt_dynamics.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Government Expenditures by Type\n",
    "\n",
    "Longer-term data from OMB Historical Data Table 8.3\n",
    "\n",
    "Shorter-term data from Treasury Monthly Statement Table 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:56.286695Z",
     "start_time": "2023-09-08T14:33:56.000558Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/miniconda3/lib/python3.8/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# Retrieve long-term data\n",
    "url = 'https://www.whitehouse.gov/wp-content/uploads/2023/03/hist08z3_fy2024.xlsx'\n",
    "data = pd.read_excel(url, header=[2,3,4], skipfooter=2, index_col=0)\n",
    "data = data.rename(columns=lambda x: x if not 'Unnamed' in str(x) else '')\n",
    "data.columns = [' '.join(col).strip() for col in data.columns.values]\n",
    "data['Mandatory'] = data.loc[:,data.columns.duplicated()]\n",
    "data = data.loc[:,~data.columns.duplicated()]\n",
    "data = data.rename({'Total': 'Discretionary', '': 'Total'}, axis=1).loc['1989':]\n",
    "data.columns = [i.replace('\\n', ' ').replace('Mandatory Programmatic', 'MP') \n",
    "                for i in data.columns]\n",
    "data.to_csv(data_dir / 'gov_exp_omb_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:56.306125Z",
     "start_time": "2023-09-08T14:33:56.288324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "national defense spending fell to 15.2 percent of outlays in 2019 from 26.6 percent in 1989 (see \\cbox{green!80!blue!68!black}). Discretionary non-defense spending maintained a relative stable share of spending over the period (see \\cbox{green!78!black}). Net interest expense, the cost of federal borrowing, fell along with long-term interest rates, to 8.4 percent of outlays in 2019 from 14.8 percent in 1989 (see \\cbox{orange!80!yellow}). \n",
      "\n",
      " Offsetting the reduction in spending on interest and national defense, Medicare and Social Security now make up a larger share of federal spending, as a larger share of people are retirement age. Likewise, spending on the social safety net (means-tested benefits and Medicaid) increased as employment-to-population ratios fell and Medicaid was expanded. Medicare (see \\cbox{blue!65!black}), Social Security (see \\cbox{cyan!50!blue!95!white}), and the social safety net (see \\cbox{cyan!95!white}) combine to comprise 54.8 percent of federal spending in 2019, compared to 34.7 percent in 1989. \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_dir / 'gov_exp_omb_raw.csv', index_col='date')\n",
    "res = data[['Net Interest', 'Non- defense', 'National Defense', \n",
    "            'MP Social Security', 'MP Medicare']].copy()\n",
    "res['Social Safety Net'] = (data['MP Medicaid'] + \n",
    "                            data['MP Other Means  Tested Entitlements (1)'])\n",
    "res['Other'] = 100 - res.sum(axis=1)\n",
    "res = res.loc[~res.index.str.contains('estimate')]\n",
    "res.index = pd.to_datetime(res.index) + pd.DateOffset(months=6)\n",
    "res.to_csv(data_dir / 'gov_exp_omb.csv', index_label='date')\n",
    "\n",
    "cols = ['National Defense', 'Non- defense', 'MP Medicare', 'MP Social Security', \n",
    "        'Social Safety Net', 'Other', 'Net Interest']\n",
    "sdf = res[cols].iloc[-1]\n",
    "height = ((sdf.cumsum() - (sdf / 2) + 4)).to_dict()\n",
    "val = sdf.to_dict()\n",
    "dt = dtxt(res.index[-1] + pd.DateOffset(weeks=2))['datetime']\n",
    "nodes = [f'\\\\absnode{{{dt}}}{{{height[i]}}}{{\\scriptsize {val[i]:.1f}\\%}}' for i in cols]\n",
    "dt2 = dtxt(final.index[-1] - pd.DateOffset(months=24))['datetime']\n",
    "dv = dtxt(res.index[-1])['year']\n",
    "dtnode = f'\\\\absnode{{{dt2}}}{{{108}}}{{\\\\footnotesize {dv}}}'\n",
    "nodetext = '\\n'.join([dtnode] + nodes)\n",
    "write_txt(text_dir / 'gov_exp_nodes.txt', nodetext)\n",
    "\n",
    "val19 = res.loc['2019-07-01']\n",
    "val89 = res.loc['1989-07-01']\n",
    "def19 = val19['National Defense']\n",
    "def89 = val89['National Defense']\n",
    "ni19 = val19['Net Interest']\n",
    "ni89 = val89['Net Interest']\n",
    "combcat = ['MP Medicare', 'MP Social Security', 'Social Safety Net']\n",
    "comb19 = val19.loc[combcat].sum()\n",
    "comb89 = val89.loc[combcat].sum()\n",
    "colors = {'Defense': 'green!80!blue!68!black',\n",
    "          'NonDef': 'green!78!black',\n",
    "          'NI': 'orange!80!yellow',\n",
    "          'SS': 'cyan!50!blue!95!white',\n",
    "          'Medicare': 'blue!65!black',\n",
    "          'SSN': 'cyan!95!white'}\n",
    "\n",
    "text = (f'national defense spending fell to {def19:.1f} percent '+\n",
    "        f'of outlays in 2019 from {def89:.1f} percent in 1989 '+\n",
    "        f'{c_box(colors[\"Defense\"])}. Discretionary non-defense '+\n",
    "        'spending maintained a relative stable share of spending '+\n",
    "        f'over the period {c_box(colors[\"NonDef\"])}. Net interest '+\n",
    "        'expense, the cost of federal borrowing, fell along with '+\n",
    "        f'long-term interest rates, to {ni19:.1f} percent of outlays '+\n",
    "        f'in 2019 from {ni89:.1f} percent in 1989 '+\n",
    "        f'{c_box(colors[\"NI\"])}. \\n\\n Offsetting the reduction in '+\n",
    "        'spending on interest and national defense, Medicare and '+\n",
    "        'Social Security now make up a larger share of federal '+\n",
    "        'spending, as a larger share of people are retirement age. '+\n",
    "        'Likewise, spending on the social safety net (means-tested '+\n",
    "        'benefits and Medicaid) increased as employment-to-population '+\n",
    "        'ratios fell and Medicaid was expanded. Medicare '+\n",
    "        f'{c_box(colors[\"Medicare\"])}, Social Security '+\n",
    "        f'{c_box(colors[\"SS\"])}, and the social safety net '+\n",
    "        f'{c_box(colors[\"SSN\"])} combine to comprise {comb19:.1f} '+\n",
    "        'percent of federal spending in 2019, compared to '+\n",
    "        f'{comb89:.1f} percent in 1989. ')\n",
    "write_txt(text_dir / 'gov_exp_comp1.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:57.096758Z",
     "start_time": "2023-09-08T14:33:56.307485Z"
    }
   },
   "outputs": [],
   "source": [
    "#Retrieve short-term data\n",
    "cols = ['record_date', 'classification_desc', \n",
    "        'current_month_rcpt_outly_amt']\n",
    "fields = ','.join(cols)\n",
    "lines = ','.join([str(i) for i in list(range(14, 34))])\n",
    "url = ('https://api.fiscaldata.treasury.gov/services/api/'+\n",
    "       'fiscal_service/v1/accounting/mts/mts_table_9'+\n",
    "       f'?filter=src_line_nbr:in:({lines})&format=csv&'+\n",
    "       f'fields={fields}&page[size]=6000')\n",
    "df = (pd.read_csv(url, index_col=cols[:2], parse_dates=True)\n",
    "        ['current_month_rcpt_outly_amt']\n",
    "        .unstack().astype('float').divide(1_000_000))\n",
    "df.to_csv(data_dir / 'gov_exp_mts_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-08T14:33:57.158308Z",
     "start_time": "2023-09-08T14:33:57.101237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Income security, which includes economic impact payments, the child tax credit, unemployment compensation, food and nutrition assistance, federal employee retirement and disability, and housing assistance, was 11.9 percent of federal spending over the 12 months ending July 2023 (see \\cbox{brown}). At its peak, over the 12 months ending March 2021, income security comprised 24.7 percent of federal spending. Pre-pandemic, in 2019, the category comprised 11.3 percent. \n",
      "\n",
      " The category labeled ``other'' in the above-right chart includes several subcategories worth examining. The category increased to 21.9 percent of federal spending during the 12 months ending July 2023, from 24.2 percent during the 12 months ending March 2021 (see \\cbox{yellow!50!brown!55!white}). Prior to the pandemic, in 2019, the category was 12.8 percent of spending. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'gov_exp_mts_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "oth = ['Administration of Justice', 'Agriculture',\n",
    "       'Commerce and Housing Credit', \n",
    "       'Community and Regional Development',\n",
    "       'Education, Training, Employment, and Social Services', \n",
    "       'Energy', 'General Government', \n",
    "       'General Science, Space, and Technology',\n",
    "       'International Affairs', 'Natural Resources and Environment', \n",
    "       'Transportation', 'Undistributed Offsetting Receipts', \n",
    "       'Veterans Benefits and Services']\n",
    "df['Other'] = df[oth].sum(axis=1)\n",
    "res = df[['Income Security', 'Social Security', 'Health', \n",
    "          'National Defense', 'Medicare', 'Net Interest', 'Other']].copy()\n",
    "final = ((res.divide(res.sum(axis=1), axis=0) * 100)\n",
    "             .rolling(12).mean().dropna())\n",
    "final.loc['2016-12-01':].to_csv(data_dir / 'gov_exp_mts.csv', \n",
    "                                index_label='date')\n",
    "\n",
    "cols = ['National Defense', 'Health', 'Medicare', 'Social Security', \n",
    "        'Income Security', 'Other', 'Net Interest']\n",
    "sdf = final[cols].iloc[-1]\n",
    "height = ((sdf.cumsum() - (sdf / 2) + 4)).to_dict()\n",
    "val = sdf.to_dict()\n",
    "dt = dtxt(final.index[-1] + pd.DateOffset(weeks=1))['datetime']\n",
    "nodes = [f'\\\\absnode{{{dt}}}{{{height[i]}}}{{\\scriptsize {val[i]:.1f}\\%}}' \n",
    "         for i in cols]\n",
    "dt2 = dtxt(final.index[-1] - pd.DateOffset(months=3))['datetime']\n",
    "dv = dtxt(final.index[-1])['mon6']\n",
    "dtnode = f'\\\\absnode{{{dt2}}}{{{108}}}{{\\\\footnotesize {dv}}}'\n",
    "nodetext = '\\n'.join([dtnode] + nodes)\n",
    "write_txt(text_dir / 'gov_exp_nodes2.txt', nodetext)\n",
    "\n",
    "ltdt = dtxt(final.index[-1])['mon1']\n",
    "lt = final.iloc[-1]\n",
    "incseclt = lt['Income Security']\n",
    "maxdt = dtxt(final[['Income Security', 'Other']].sum(axis=1).idxmax())\n",
    "maxmon = maxdt['mon1']\n",
    "mx = final.loc[maxdt['datetime']]\n",
    "pc = final.loc['2019-12-31']\n",
    "incsecmx = mx['Income Security']\n",
    "incsecpc = pc['Income Security']\n",
    "text = ('Income security, which includes economic impact payments, the '+\n",
    "        'child tax credit, unemployment compensation, food and nutrition '+\n",
    "        'assistance, federal employee retirement and disability, and '+\n",
    "        f'housing assistance, was {incseclt:.1f} percent of federal spending '+\n",
    "        f'over the 12 months ending {ltdt} {c_box(\"brown\")}. At its peak, '+\n",
    "        f'over the 12 months ending {maxmon}, income security comprised '+\n",
    "        f'{incsecmx:.1f} percent of federal spending. Pre-pandemic, in 2019, '+\n",
    "        f'the category comprised {incsecpc:.1f} percent. ')\n",
    "write_txt(text_dir / 'gov_exp_comp2.txt', text)\n",
    "print(text)\n",
    "\n",
    "cols2 = {'Income Security': 'brown', 'Health': 'violet!50!black', \n",
    "         'Medicare': 'blue!65!black', \n",
    "         'Social Security': 'cyan!50!blue!95!white', \n",
    "         'National Defense': 'green!80!blue!68!black',  \n",
    "         'Net Interest': 'orange!80!yellow', \n",
    "         'Other: ': 'yellow!50!brown!55!white'}\n",
    "col_names = {k: f'\\hspace{{-1mm}}\\cbox{{{v}}}{k}' for k, v in cols2.items()}\n",
    "col_names2 = {i: f'\\hspace{{6mm}}{i}' for i in oth}\n",
    "\n",
    "data = df.rolling(12).sum()\n",
    "data = data.divide(data.Total, axis=0) * 100\n",
    "data = data.rename({'Other': 'Other: '}, axis=1)\n",
    "data = data[list(cols2.keys()) + oth]\n",
    "tbl = data.iloc[-3:].iloc[::-1].T\n",
    "dmax = data.loc[maxdt['datetime']]\n",
    "d19 = data.loc['2019'].mean().rename('2019')\n",
    "d17 = data.loc['2017'].mean().rename('2017')\n",
    "tbl = tbl.join(dmax)\n",
    "tbl.columns = [dtxt(i)['mon2'] for i in tbl.columns]\n",
    "tbl = tbl.join(d19).join(d17)\n",
    "tbl = tbl.rename(col_names).rename(col_names2)\n",
    "tbl.index = tbl.index.str.replace('and', '\\&')\n",
    "tbl = tbl.round(1).applymap('{:.1f}'.format)\n",
    "tbl = tbl.rename({'\\hspace{6mm}Education, Training, Employment, \\& Social Services': \n",
    "            '\\hspace{6mm}Educ., Training, Employment, \\& Social Serv.'})\n",
    "(tbl.to_csv(data_dir / 'gov_exp_comp.tex', sep='&', \n",
    "            lineterminator='\\\\\\ ', quotechar=' '))\n",
    "\n",
    "ltval = data['Other: '].iloc[-1]\n",
    "maxval = data.loc[maxdt['datetime'], 'Other: ']\n",
    "val19 = data.loc['2019', 'Other: '].mean()\n",
    "text = (f\"The category labeled ``other'' in the above-right chart \"+\n",
    "        f'includes several subcategories worth examining. The '+\n",
    "        f'category increased to {ltval:.1f} percent of federal '+\n",
    "        f'spending during the 12 months ending {ltdt}, from '+\n",
    "        f'{maxval:.1f} percent during the 12 months ending {maxmon} '+\n",
    "        f'{c_box(cols2[\"Other: \"])}. Prior to the pandemic, in 2019, '+\n",
    "        f'the category was {val19:.1f} percent of spending. ')\n",
    "write_txt(text_dir / 'gov_exp_comp3.txt', text)\n",
    "print('\\n', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 1.15 Prices and Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T10:44:48.638585Z",
     "start_time": "2023-09-02T10:44:48.541588Z"
    }
   },
   "outputs": [],
   "source": [
    "d = nipa_series_codes(retrieve_table('T11500'))\n",
    "df = nipa_df(retrieve_table('T11500')['Data'], d.keys())\n",
    "res = growth_contrib_ann(df, 'A455RD')[['A460RD', 'A467RD', 'A463RD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-02T10:44:50.915794Z",
     "start_time": "2023-09-02T10:44:50.906140Z"
    }
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Spending\n",
    "\n",
    "Census data on the value of construction put-in-place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T21:11:17.909902Z",
     "start_time": "2023-09-06T21:11:10.641740Z"
    }
   },
   "outputs": [],
   "source": [
    "# Category codes and data type codes\n",
    "d = {'PrRes': ['A00XX', 'V'], 'PrNR': ['ANRXX', 'V'], \n",
    "     'Pub': ['AXXXX', 'P'], 'Total': ['AXXXX', 'T'],\n",
    "     'PrMan': ['A20IX', 'V']}\n",
    "date = lambda x: pd.to_datetime(x.time)\n",
    "df = pd.DataFrame()\n",
    "for name, (cc, dtc) in d.items():\n",
    "    url = ('https://api.census.gov/data/timeseries/eits/vip?'+\n",
    "           f'get=cell_value,time_slot_id&key={census_key}&time=from+2002&'+\n",
    "           f'category_code={cc}&data_type_code={dtc}&'+\n",
    "           'for=us&seasonally_adj=yes')\n",
    "    r = requests.get(url).json()\n",
    "    df[name] = (pd.DataFrame(r[1:], columns=r[0]).assign(date = date)\n",
    "                .set_index('date')['cell_value'].astype('float')).sort_index()\n",
    "df.to_csv(data_dir / 'construction_spending.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-06T23:55:30.556866Z",
     "start_time": "2023-09-06T23:55:30.534196Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'construction_spending.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "\n",
    "gdp = pd.read_csv(data_dir / 'gdp_monthly.csv', index_col='date', \n",
    "                  parse_dates=True)['A191RC']\n",
    "\n",
    "sh = (df.divide(gdp, axis=0).dropna() * 100)\n",
    "sh.to_csv(data_dir / 'construction_spending_sh.csv', index_label='date')\n",
    "\n",
    "# Text for total\n",
    "ltdt = dtxt(sh.index[-1])['mon1']\n",
    "ltval = f'\\${(df.Total.iloc[-1] / 1_000_000):.1f} trillion'\n",
    "ltsh = value_text(sh.Total.iloc[-1], 'eq', adj='GDP')\n",
    "\n",
    "text = (f'In {ltdt}, the annualized value of construction put-in-place '+\n",
    "        f'is {ltval}, {ltsh}.')\n",
    "write_txt(text_dir / 'construction_spending_total.txt', text)\n",
    "print(text)\n",
    "\n",
    "# End nodes\n",
    "colors = {'PrRes': 'blue!60!white', 'PrNR': 'yellow!60!orange', \n",
    "          'Pub': 'violet!60!black'}\n",
    "res = sh[colors.keys()]\n",
    "adj = node_adj(res)\n",
    "smax = res.iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(res[series], color, \n",
    "                            date=date[series], full_year=True, \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'construction_spending_nodes.txt', nodes)  \n",
    "\n",
    "# Share of GDP by sector\n",
    "shd = {i: value_text(sh[i].iloc[-1], 'plain') \n",
    "       for i in ['PrRes', 'PrNR', 'Pub']}\n",
    "cl = {i: c_line(c) for i, c in colors.items()}\n",
    "\n",
    "# Growth contribution\n",
    "df['GDP'] = gdp\n",
    "gc = growth_contrib_ann(df, 'GDP', freq='M')\n",
    "gcd = {i: value_text(gc[i].iloc[-1], 'contribution', \n",
    "                     ptype='pp', digits=2) \n",
    "       for i in ['PrRes', 'PrNR', 'Pub', 'Total']}\n",
    "gcnr = value_text(gc['PrNR'].iloc[-1], 'contribution', \n",
    "                   ptype=None, digits=2) + ' point'\n",
    "gcpub = value_text(gc['Pub'].iloc[-1], 'contribution', casual=True,\n",
    "                   ptype=None, digits=2) + ' point'\n",
    "\n",
    "text = (f'By sector, private residential construction is '+\n",
    "        f'{shd[\"PrRes\"]} of GDP {cl[\"PrRes\"]} in {ltdt}, '+\n",
    "        f'private nonresidential construction is {shd[\"PrNR\"]} '+\n",
    "        f'{cl[\"PrNR\"]}, and government construction is '+\n",
    "        f'{shd[\"Pub\"]} {cl[\"Pub\"]}.\\n\\n'+\n",
    "        'Over the past year, construction spending '+\n",
    "        f'{gcd[\"Total\"]} to nominal GDP growth. Private residential '+\n",
    "        f'construction {gcd[\"PrRes\"]}, private '+\n",
    "        f'nonresidential {gcnr}, and '+\n",
    "        f'public construction {gcpub}.')\n",
    "write_txt(text_dir / 'construction_spending_sector.txt', text)  \n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
