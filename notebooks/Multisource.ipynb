{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c6ae962",
   "metadata": {},
   "source": [
    "### Handle Charts Driven by Multiple Sources\n",
    "\n",
    "This notebook contains the codeblocks that pull from multiple sources. For example, if a chart uses both CES and CPS data, it would be run twice if located in either of those notebooks. \n",
    "\n",
    "Run this notebook after running the jobs report, CPI, ECI, GDP, CPS update, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac37884",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.266601Z",
     "start_time": "2023-11-30T16:24:37.269635Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0d5ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c9fb89",
   "metadata": {},
   "source": [
    "### References Formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e1f4b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.270844Z",
     "start_time": "2023-11-30T16:24:38.268553Z"
    }
   },
   "outputs": [],
   "source": [
    "# ref = lambda x: '\\\\bibitem{{{name}}} {author}. \\\\textit{{{title}}}. Available at: \\\\url{{{url}}}.'.format(**x)\n",
    "# df = pd.read_csv('/home/brian/Documents/uschartbook/chartbook/references.csv')\n",
    "# df = df.assign(REF = df.apply(ref, 1)).sort_values(['author', 'title']).REF\n",
    "# group_size = 15\n",
    "# for i in range(0, len(df), group_size):\n",
    "#     group = '\\n'.join(df.iloc[i:i+group_size])\n",
    "#     fname = f'reference_group_{(i/group_size)+1:.0f}.txt'\n",
    "#     write_txt(text_dir / fname, group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43003978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21db620",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2af475e",
   "metadata": {},
   "source": [
    "### Wage Growth Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1c5b23",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.350374Z",
     "start_time": "2023-11-30T16:24:38.272036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average Hourly Earnings\n",
    "s = {'CES0500000003': 'AHE', 'CES0500000008': 'PNS', \n",
    "     'CES0600000008': 'Goods', 'CES0800000008': 'Serv'}\n",
    "# AHE series\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)[s.keys()].rename(s, axis=1)\n",
    "dfg = df['Goods']\n",
    "ch = df.pct_change(12) * 100\n",
    "\n",
    "# Median wage from CPS\n",
    "ch['UWE_P50'] = pd.read_csv(data_dir / 'uwe_cps.csv', index_col='date', \n",
    "                            parse_dates=True)['p50_gr']\n",
    "# Wage Growth Tracker\n",
    "ch['WGT'] = pd.read_csv(data_dir / 'atl_wgt.csv', \n",
    "                        index_col='date', parse_dates=True)['bd_cps']\n",
    "\n",
    "# NIPA Wages and Salaries / NFP\n",
    "df = pd.read_csv(data_dir / 'pi_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "# Nonfarm payrolls\n",
    "nfp = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)['CES0000000001']\n",
    "ch['NIPA'] = (df['A034RC'] / nfp).dropna().pct_change(12) * 100\n",
    "\n",
    "# 3 Month Moving average for volatile series\n",
    "for i in ['UWE_P50', 'WGT', 'NIPA']:\n",
    "    ch[f'{i}_3m'] = ch[i].rolling(3).mean()\n",
    "    \n",
    "ch.loc['1989':].to_csv(data_dir / 'wages_yy_monthly.csv', \n",
    "                      index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5871633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.364396Z",
     "start_time": "2023-11-30T16:24:38.352168Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rename for table\n",
    "d = {'AHE': 'Average Hourly Earnings (AHE), Private',\n",
    "     'PNS': '\\hspace{2mm} Production \\& Nonsupervisory',\n",
    "     'Goods': '\\hspace{4mm} Goods-Producing Industries',\n",
    "     'Serv': '\\hspace{4mm} Service-Providing Industries',\n",
    "     'UWE_P50': 'Usual Weekly Earnings, Median',\n",
    "     'UWE_P50_3m': 'Usual Weekly Earnings, Median (3M Avg)',\n",
    "     'WGT': 'Wage Growth Tracker, Median',\n",
    "     'WGT_3m': 'Wage Growth Tracker, Median (3M Avg)',\n",
    "     'NIPA': 'Wages \\& Salaries, Average (NIPA)',\n",
    "     'NIPA_3m': 'Wages \\& Salaries, Average (3M Avg)'}\n",
    "\n",
    "dfm = pd.read_csv(data_dir / 'wages_yy_monthly.csv', index_col='date', \n",
    "                 parse_dates=True)[d.keys()].rename(d, axis=1)\n",
    "\n",
    "# Latest 6 months\n",
    "res = dfm.iloc[-6:].iloc[::-1].T\n",
    "# Same month, prior two years\n",
    "for i in [-13, -25]:\n",
    "    res[dfm.index[i]] = dfm.iloc[i]\n",
    "    \n",
    "res.columns = [dtxt(dt)['mon6'] for dt in res.columns]\n",
    "res = res.applymap('{:.1f}'.format).replace('nan', '--')\n",
    "(res.to_csv(data_dir / 'wages_yy_monthly.tex', sep='&', lineterminator='\\\\\\ ', \n",
    "           quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9cf6851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.394157Z",
     "start_time": "2023-11-30T16:24:38.365787Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Quarterly measures of wages \n",
    "# Median wage from BLS \n",
    "d = {'IndexWS': 'Wages \\& Salaries (ECI)',\n",
    "     'P50_tot': 'Usual Weekly Earnings, Median',\n",
    "     'nfbus_ulc': 'Unit Labor Cost'}\n",
    "df = (pd.read_csv(data_dir / 'uwe_main.csv', index_col='date', \n",
    "                            parse_dates=True)) \n",
    "\n",
    "# Wages and Salaries from Employment Cost Index\n",
    "eci = pd.read_csv(data_dir / 'eci.csv', index_col='date', \n",
    "                 parse_dates=True)[['IndexWS','IndexWSGoods']]\n",
    "\n",
    "# Unit Labor Costs\n",
    "ulc = pd.read_csv(data_dir / 'lprod.csv', index_col='date', \n",
    "                 parse_dates=True)[['business_ulc', 'manuf_ulc', 'nfbus_ulc']]\n",
    "\n",
    "df = pd.concat([df, eci, ulc], axis=1)\n",
    "\n",
    "# Average Hourly Earnings PNS, Goods\n",
    "df['AHEGoods'] = dfg.resample('QS').mean()\n",
    "\n",
    "dfy = df.pct_change(4, fill_method=None) * 100 \n",
    "dfy.loc['1989':].to_csv(data_dir / 'wages_yy_quarterly.csv', \n",
    "                      index_label='date')\n",
    "dfq = df.pct_change(fill_method=None) * 400 \n",
    "\n",
    "# Gender Wage Gap\n",
    "gwg = (df['P50_women'] / df['P50_men']).rolling(4).mean()\n",
    "gwg.name = 'GWG'\n",
    "gwg.loc['1989':].multiply(100).to_csv(data_dir / 'gwg.csv', \n",
    "                      index_label='date')\n",
    "node = end_node(gwg * 100, 'red', date='qs', offset=0.1,\n",
    "                anchor='south', align='center', colon=False)\n",
    "write_txt(text_dir / 'gwg_node.txt', node)\n",
    "\n",
    "# Sumary Table\n",
    "# Latest 5 quarters\n",
    "res = dfy.iloc[-5:].iloc[::-1].T\n",
    "# Same quarter, prior two years\n",
    "for i in [-9, -13, -17]:\n",
    "    res[dfy.index[i]] = dfy.iloc[i]\n",
    "    \n",
    "res = res.loc[d.keys()].rename(d)\n",
    "res.columns = [dtxt(dt)['qtr4'] for dt in res.columns]\n",
    "res = res.applymap('{:.1f}'.format).replace('nan', '--')\n",
    "(res.to_csv(data_dir / 'wages_yy_quarterly.tex', sep='&', lineterminator='\\\\\\ ', \n",
    "           quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f052f861",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.401298Z",
     "start_time": "2023-11-30T16:24:38.395319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1989, the gender wage gap was 30 percent; women were paid 70 cents for each dollar men were paid. From 1989 to 2006, the gap closed at a rate of 0.74 percentage point per year. From 2006 to 2019 Q4, the gap closed at a rate of only 0.03 percentage point per year.\n",
      "\n",
      "Over the year ending 2023 Q3, the gender wage gap is 16.4 percent; women are paid 83.6 cents on the dollar. Pre-pandemic, in 2019 Q4, the gap was 18.4 percent.\n"
     ]
    }
   ],
   "source": [
    "# Gender Wage Gap Text\n",
    "ltdt = dtxt(gwg.index[-1])['qtr1']\n",
    "gap = gwg.iloc[-1] * 100\n",
    "gap2 = 100 - gap\n",
    "cmp = '2019-10-01'\n",
    "cmpdt = dtxt(cmp)['qtr1']\n",
    "gapcmp = (1.0 - gwg.loc['2019-10-01']) * 100\n",
    "dt1 = '1989-01-01'\n",
    "dt2 = '2006-01-01'\n",
    "dt3 = '2006-01-01'\n",
    "dt4 = cmp\n",
    "\n",
    "# Annualize rates (divide by 59 quarters)\n",
    "hgap1 = value_text((gwg.loc[dt2] - gwg.loc[dt1]) * (100 / (59 / 4)), \n",
    "                   'plain', 'pp', digits=2)\n",
    "hgap2 = value_text((gwg.loc[dt4] - gwg.loc[dt3]) * (100 / (59 / 4)), \n",
    "                   'plain', 'pp', digits=2)\n",
    "\n",
    "text = ('In 1989, the gender wage gap was 30 percent; women were paid '+\n",
    "        '70 cents for each dollar men were paid. From 1989 to 2006, '+\n",
    "        f'the gap closed at a rate of {hgap1} per year. '+\n",
    "        'From 2006 to 2019 Q4, the gap closed at a '+\n",
    "        f'rate of only {hgap2} per year.\\n\\n'+\n",
    "        f'Over the year ending {ltdt}, the gender wage gap is {gap2:.1f} '+\n",
    "        f'percent; women are paid {gap:.1f} cents on the dollar. '+\n",
    "        f'Pre-pandemic, in 2019 Q4, the gap was {gapcmp:.1f} percent.')\n",
    "write_txt(text_dir / 'gwg.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b59ee922",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.423786Z",
     "start_time": "2023-11-30T16:24:38.402456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nearly all measures show one-year nominal wage growth that is falling but still above the pre-pandemic rate.\n"
     ]
    }
   ],
   "source": [
    "# Summary text \n",
    "d, d2 = {}, {} # One-year change and change since 2019\n",
    "# Monthly series\n",
    "for s in ['AHE', 'PNS', 'Goods', 'WGT', 'WGT_3m']:\n",
    "    d[s] = ch[s].dropna().diff(12).iloc[-1]\n",
    "    d2[s] = ch[s].dropna().iloc[-1] - ch.loc['2019', s].mean()\n",
    "    \n",
    "# Quarterly Series    \n",
    "for s in ['IndexWS', 'IndexWSGoods', 'p50uwe']:\n",
    "    d[s] = dfy[s].dropna().diff(4).iloc[-1]\n",
    "    d2[s] = dfy[s].dropna().iloc[-1] - dfy.loc['2019', s].mean()\n",
    "    \n",
    "chlt = pd.DataFrame({'One-year': d, 'Since 2019': d2})\n",
    "keych = chlt.loc[['IndexWS', 'WGT_3m']].mean()\n",
    "chlt.loc['keych'] = keych\n",
    "chdf = pd.concat([pd.cut(chlt[c], [-50, -0.49, 0.49, 50], \n",
    "                         labels=['below', 'same', 'above']) \n",
    "           for c in chlt.columns], axis=1)\n",
    "\n",
    "ref = chdf.drop('keych')\n",
    "keym = chdf.loc['keych']\n",
    "\n",
    "# What percent of the series match the key series?\n",
    "pct = pd.DataFrame(map(lambda k: ref[k]==keym[k], ref)).all().mean()\n",
    "\n",
    "keydir1 = ('falling' if keych['One-year'] <= -0.49 else 'rising' \n",
    "           if keych['One-year'] >=0.49 else 'stable')\n",
    "keydir2 = ('below' if keych['Since 2019'] <= -0.49 else 'above' \n",
    "           if keych['Since 2019'] >=0.49 else 'in line with')\n",
    "\n",
    "keyt = 'key'\n",
    "if pct > 0.8:\n",
    "    keyt = 'nearly all'\n",
    "elif pct > 0.5:\n",
    "    keyt = 'most'\n",
    "    \n",
    "but = 'but still' if ((keydir1 == 'falling') & (keydir2 == 'above') | \n",
    "                (keydir1 == 'rising') & (keydir2 == 'below')) else 'and'    \n",
    "\n",
    "text = (f'{keyt} measures show one-year nominal wage growth that is {keydir1} '+\n",
    "        f'{but} {keydir2} the pre-pandemic rate.')\n",
    "write_txt(text_dir / 'wage_rec_summary.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c512bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498a12ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12bc512b",
   "metadata": {},
   "source": [
    "### Recessions Table / Sahm Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cd8b602",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.431494Z",
     "start_time": "2023-11-30T16:24:38.425011Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve recession info from FRED\n",
    "#rec = fred_df('USREC')\n",
    "#rec.to_csv(data_dir / 'recessions_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c6c2eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.520657Z",
     "start_time": "2023-11-30T16:24:38.433070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the early 1990s recession, output contracted for eight months and unemployment was higher than its pre-recession average for 63 months. The drop in output was smaller during the early 2000s recession, but unemployment rates took almost 16 years to recover.\n",
      "\n",
      "The 2008--2009 great recession, caused by the collapse of a housing bubble, was very severe. The recession lasted 18 months, with higher rates of unemployment lasting 89 months. The most-recent COVID-19 recession was extremely severe and also extremely short-lived, lasting only two months, but with output reduced 9.1 percent.\n"
     ]
    }
   ],
   "source": [
    "rec = pd.read_csv(data_dir / 'recessions_raw.csv', \n",
    "                  index_col='date', parse_dates=True)\n",
    "first = rec[(rec.VALUE==1) & (rec.VALUE.shift(1) == 0)]\n",
    "post = rec[(rec.VALUE==0) & (rec.VALUE.shift(1) == 1)]\n",
    "names = [' \\ Early `90s Recession', ' \\ Early `00s Recession', \n",
    "         ' \\ Great Recession', ' \\ COVID-19 Recession']\n",
    "recs = (pd.Series(data=first.index, index=names)\n",
    "        .rename('First').to_frame())\n",
    "recs['Last'] = rec[(rec.VALUE==1) & (rec.VALUE.shift(-1) == 0)].index\n",
    "recs['Pre'] = rec[(rec.VALUE==0) & (rec.VALUE.shift(-1) == 1)].index\n",
    "recs['Post'] = post.index\n",
    "dur = [i.n for i in (post.index.to_period('M') - \n",
    "                     first.index.to_period('M'))]\n",
    "recs['Dur'] = pd.Series(data=dur, index=recs.index)\n",
    "recs['PrevEnd'] = recs['Post'].shift(1)\n",
    "recs.loc[' \\ Early `90s Recession', 'PrevEnd'] = pd.to_datetime('1989-01-01')\n",
    "recs['NextStart'] = recs['Pre'].shift(-1)\n",
    "recs.loc[' \\ COVID-19 Recession', 'NextStart'] = cps_date()\n",
    "recs['Start'] = recs.First.apply(lambda x: dtxt(x)['mon2'])\n",
    "recs['End'] = recs.Last.apply(lambda x: dtxt(x)['mon2'])\n",
    "rgdp = nipa_df(retrieve_table('T10106')['Data'], ['A191RX'])['A191RX']\n",
    "unrate = pd.read_csv(data_dir / 'jobs_report_main.csv', index_col='date', \n",
    "                 parse_dates=True)['Total']\n",
    "for row in recs.itertuples():\n",
    "    # Real GDP change\n",
    "    vprev = rgdp.loc[:row.Pre].max()\n",
    "    vmin = rgdp.loc[row.First:row.NextStart].min()\n",
    "    ch = ((vmin / vprev) - 1) * 100\n",
    "    recs.loc[row.Index, 'GDPch'] = ch\n",
    "    # Unemployment rate change and duration\n",
    "    pravg = unrate.loc[row.Pre - pd.DateOffset(years=3): row.Pre].mean()\n",
    "    vmax = unrate.loc[row.First:row.NextStart].max()\n",
    "    uch = vmax - pravg\n",
    "    rdt = (unrate.loc[row.Last:].loc[(unrate <= pravg)].index[0] \n",
    "           if pravg >= unrate.iloc[-1] else '--')\n",
    "    rtime = (int((rdt.to_period('M') - row.Last.to_period('M')).n) \n",
    "             if rdt != '--' else '--')\n",
    "    recs.loc[row.Index, 'Unratech'] = uch    \n",
    "    recs.loc[row.Index, 'RecoDate'] = rdt\n",
    "    recs.loc[row.Index, 'RecoTime'] = str(rtime)\n",
    "recs['GDPcht'] =  recs.GDPch.apply('{:.1f}'.format)\n",
    "recs['Uncht'] =  recs.Unratech.apply('+{:.1f}'.format)\n",
    "tbl = recs[['Start', 'End', 'Dur', 'GDPcht', 'Uncht', 'RecoTime']]\n",
    "tbl.columns = ['Start \\ \\ \\ Month', 'End \\ \\ \\ \\ \\ \\ Month', \n",
    "               'Recession Duration, Months', \n",
    "               'GDP Percent Change', 'Unemp. Rate Change*', \n",
    "               'Unemp. Rate Recovery, Months**']\n",
    "tbl.to_csv(data_dir / 'recession.tex', sep='&', \n",
    "           lineterminator='\\\\\\ ', quotechar=' ')\n",
    "\n",
    "un3 = unrate.rolling(3).mean()\n",
    "sahm = (un3 - un3.rolling(12).min()).dropna()\n",
    "sahm.to_csv(data_dir / 'sahm.csv', index_label='date', \n",
    "            header=True)\n",
    "\n",
    "# End Node\n",
    "node = end_node(sahm, 'blue!60!black', digits=2, date='m', offset=0.35)\n",
    "write_txt(text_dir / 'sahm_node.txt', node)\n",
    "\n",
    "bar = pd.Series(index=[sahm.index[0], sahm.index[-1]], \n",
    "                data=[0.5, 0.5], name='Bar')\n",
    "bar.to_csv(data_dir / 'sahm_bar.csv', index_label='date', \n",
    "           header=True)\n",
    "node = end_node(bar, 'gray', loc='start')\n",
    "write_txt(text_dir / 'sahm_bar_node.txt', node)\n",
    "marks = (sahm.loc[(sahm > 0.5) & (sahm.shift(1) < 0.5)]\n",
    "             .rename('Mark').to_frame())\n",
    "marks['Intersect'] = len(marks) * [0.5]\n",
    "marks.to_csv(data_dir / 'sahm_marks.csv', index_label='date')\n",
    "\n",
    "dur90 = numbers[f'{recs.Dur.iloc[0]:.1f}']\n",
    "unrec90 = recs.RecoTime.iloc[0]\n",
    "unrec00 = round(int(recs.RecoTime.iloc[1]) / 12)\n",
    "durgr = recs.Dur.iloc[2]\n",
    "unrecgr = recs.RecoTime.iloc[2]\n",
    "durco = numbers[f'{recs.Dur.iloc[3]:.1f}']\n",
    "gdpco = abs(recs.GDPch.iloc[3])\n",
    "\n",
    "text = ('During the early 1990s recession, output contracted '+\n",
    "        f'for {dur90} months and unemployment was higher '+\n",
    "        f'than its pre-recession average for {unrec90} months. '+\n",
    "        'The drop in output was smaller during the '+\n",
    "        'early 2000s recession, but unemployment rates '+\n",
    "        f'took almost {unrec00} years to recover.\\n\\n'+\n",
    "        'The 2008--2009 great recession, caused by the '+\n",
    "        'collapse of a housing bubble, was very severe. '+\n",
    "        f'The recession lasted {durgr} months, with higher '+\n",
    "        f'rates of unemployment lasting {unrecgr} months. The '+\n",
    "        'most-recent COVID-19 recession was extremely severe '+\n",
    "        f'and also extremely short-lived, lasting only {durco} '+\n",
    "        f'months, but with output reduced {gdpco:.1f} percent.')\n",
    "write_txt(text_dir / 'recessions.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a7d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecccace1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b02ca191",
   "metadata": {},
   "source": [
    "### Gross Labor Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c8631d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.571998Z",
     "start_time": "2023-11-30T16:24:38.523525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increased at an average annualized rate of 5.5 percent over the year ending 2023 Q3. Changes in wages contributed three percentage points, and changes in total hours worked contributed 2.5 percentage points.\n"
     ]
    }
   ],
   "source": [
    "df = (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=[0])\n",
    "         .set_index('date')[['avghrstot', 'EMPsa']])\n",
    "emp = (df['avghrstot'] * df['EMPsa']).rename('Total')\n",
    "coe = nipa_df(retrieve_table('T20100')['Data'], ['A033RC'])\n",
    "data = coe.join(emp.resample('QS').mean()).dropna()\n",
    "data['coe_inp'] = data['A033RC'] / data['Total']\n",
    "data['wage'] = data['coe_inp'] * data['Total'].iloc[0]\n",
    "data['work'] = data['A033RC'] - data['wage']\n",
    "\n",
    "# Calculate contributions to growth\n",
    "result = (growth_contrib(data, 'A033RC')[['work', 'wage']]\n",
    "          .rolling(4).mean().dropna())\n",
    "result['sum'] = result.sum(axis=1)\n",
    "result.to_csv(data_dir / 'gli.csv', index_label='date')\n",
    "\n",
    "# Horizontal bar at 5\n",
    "start = dtxt(result.index[0] - pd.DateOffset(months=1))['datetime']\n",
    "end = dtxt(result.index[-1] + pd.DateOffset(months=3))['datetime']\n",
    "hbar = (f'\\draw [dotted, thick] (axis cs:{{{start}}}, 5) -- '+\n",
    "        f'(axis cs:{{{end}}}, 5);')\n",
    "write_txt(text_dir / 'gli_hbar2.txt', hbar) \n",
    "\n",
    "# Text\n",
    "ltdate = dtxt(result.index[-1])['qtr1']\n",
    "totch = value_text(result['sum'].iloc[-1], adj='avg_ann', \n",
    "                   threshold=0.1)\n",
    "wage = result['wage'].iloc[-1]\n",
    "work = result['work'].iloc[-1]\n",
    "    \n",
    "txt2 = value_text(wage, 'contribution', 'pp')\n",
    "txt3 = value_text(work, 'contribution', 'pp')\n",
    "\n",
    "text = (f'{totch} over the year ending {ltdate}. Changes in wages {txt2}, '+\n",
    "        f'and changes in total hours worked {txt3}.')\n",
    "write_txt(text_dir / 'gli.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39514a35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983f522d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19456aef",
   "metadata": {},
   "source": [
    "### Employment rate - disability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e848461a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.575342Z",
     "start_time": "2023-11-30T16:24:38.573272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve series from FRED for comparison\n",
    "#bls = fred_df('LNU02374597')\n",
    "#bls = bls.rename({'VALUE': 'BLS'}, axis=1)\n",
    "#pd.concat([bls, data], axis=1).plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23ed2c76",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:38.586808Z",
     "start_time": "2023-11-30T16:24:38.576659Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of October 2023, BLS reports a 22.6 percent employment rate for individuals aged 16 and over with at least one disability (see {\\color{red}\\textbf{---}}). This marks a 0.6 percentage point increase over the past year, and a jump of 3.5 percentage points since October 2019.\n"
     ]
    }
   ],
   "source": [
    "# BLS data on age 16+\n",
    "df = pd.read_csv(data_dir / 'jobs_report_main2.csv', index_col='date', \n",
    "                 parse_dates=True)['empdis'].dropna().rename('BLS')\n",
    "df.to_csv(data_dir / 'dis_emp_rate_bls.csv', index_label='date', \n",
    "         header=True)\n",
    "node = end_node(df, 'red', date='m', \n",
    "                size=1.1, offset=-0.2) \n",
    "write_txt(text_dir / 'dis_emp_node_bls.txt', node)\n",
    "\n",
    "bdt = dtxt(df.index[-1])['mon1']\n",
    "prdt = dtxt(df.index[-49])['mon1']\n",
    "prdt2 = dtxt(df.index[-13])['mon1']\n",
    "ltval = df.iloc[-1]\n",
    "prch = ltval - df.iloc[-49]\n",
    "vch = value_text(prch, 'increase_of', \n",
    "                 ptype='pp', threshold=0.1)\n",
    "if prch > 3:\n",
    "    vch = vch.replace('an increase of ', 'a jump of ')\n",
    "\n",
    "vch2 = value_text(ltval - df.iloc[-13], 'increase_end', \n",
    "                  ptype='pp', threshold=0.1)\n",
    "\n",
    "text = (f'As of {bdt}, BLS reports a {ltval:.1f} percent employment '+\n",
    "        'rate for individuals aged 16 and over with at least one '+\n",
    "        f'disability {c_line(\"red\")}. This marks '+\n",
    "        f'{vch2} over the past year, and {vch} since {prdt}.')\n",
    "write_txt(text_dir / 'dis_rate_bls.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc719a30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.178844Z",
     "start_time": "2023-11-30T16:24:38.588059Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In October 2023, 33.6 million people age 16 and older report at least one such disability, of which 16.9 million are under age 65. \n",
      "For those age 16 to 64 with disabilities, the employment rate is 37.3 percent in October 2023 (see {\\color{blue}\\textbf{---}}), a one-year increase of 1.7 percentage points, and a 6.5 percentage point increase since 2019.\n",
      "\n",
      "In 2013, during the sluggish recovery from the great recession, the employment rate for those age 16 to 64 with a disability averaged 26.8 percent. \n"
     ]
    }
   ],
   "source": [
    "# CPS data on more narrow age groups\n",
    "columns = ['MONTH', 'YEAR', 'LFS', 'DISABILITY', 'BASICWGT', 'AGE', 'NILFREASON', 'FEMALE']\n",
    "raw = (pd.concat([pd.read_feather(cps_dir / f'cps{year}.ft', columns=columns)\n",
    "                 for year in range(2008, 2024)]))\n",
    "\n",
    "d = {'Age2554': '25 <= AGE <= 54 and DISABILITY == 1',\n",
    "     'Age1664': '16 <= AGE <= 64 and DISABILITY == 1',\n",
    "     'Age55plus': 'AGE >= 55 and DISABILITY == 1'}\n",
    "data = pd.DataFrame()\n",
    "\n",
    "# Employment rate for each age group\n",
    "for name, query in d.items():\n",
    "    df = raw.query(query)\n",
    "    data[name] = ((df.groupby(['YEAR', 'MONTH', 'LFS']).BASICWGT.sum() / \n",
    "                   df.groupby(['YEAR', 'MONTH']).BASICWGT.sum() * 100)\n",
    "                  .unstack()['Employed'].dropna())\n",
    "data.index = [pd.to_datetime(f'{i[0]}-{i[1]}-01') for i in data.index]\n",
    "\n",
    "# End nodes \n",
    "s = {#'Age2554': 'orange', \n",
    "     'Age1664': 'blue'}\n",
    "nodes  ='\\n'.join([end_node(data[series], color, \n",
    "                            date='m', size=1.1, offset=-0.1) \n",
    "                   for series, color in s.items()])\n",
    "write_txt(text_dir / 'dis_emp_nodes_cps.txt', nodes)\n",
    "\n",
    "data.applymap('{:.1f}'.format).to_csv(data_dir / 'dis_emp_rate_cps.csv', \n",
    "            index_label='date', header=True)\n",
    "\n",
    "# Count with disability\n",
    "ltdt = dtxt(cps_date())['mon1']\n",
    "cps_mo = cps_date().month\n",
    "cps_yr = cps_date().year\n",
    "tmp = raw.query('MONTH == @cps_mo and YEAR == @cps_yr')\n",
    "td = tmp.query('DISABILITY == 1').BASICWGT.sum() / 1_000_000\n",
    "td2 = tmp.query('DISABILITY == 1 and AGE < 65').BASICWGT.sum() / 1_000_000\n",
    "\n",
    "text = (f'In {ltdt}, {td:.1f} million people age 16 and older '+\n",
    "        f'report at least one such disability, of which {td2:.1f} '\n",
    "        f'million are under age 65. ')\n",
    "write_txt(text_dir / 'dis_rate.txt', text)\n",
    "print(text)\n",
    "\n",
    "dft = data['Age1664']\n",
    "ltval = dft.iloc[-1]\n",
    "ltdt = dtxt(dft.index[-1])['mon1']\n",
    "prdt = dtxt(dft.index[-49])['year']\n",
    "ch = dft.iloc[-1] - dft.iloc[-49]\n",
    "valch = value_text(ch, 'increase_end', ptype='pp')\n",
    "ch2 = dft.iloc[-1] - dft.iloc[-13]\n",
    "valch2 = value_text(ch2, 'increase_of', ptype='pp', time_str='one-year ')\n",
    "val13 = dft.loc['2013'].mean()\n",
    "cl = c_line('blue')\n",
    "\n",
    "text = ('For those age 16 to 64 with disabilities, the '+\n",
    "        f'employment rate is {ltval:.1f} percent in {ltdt} {cl}, '+\n",
    "        f'{valch2}, and {valch} since {prdt}.\\n\\n'+\n",
    "        'In 2013, during the sluggish recovery from the great recession, '+\n",
    "        'the employment rate for those age 16 to 64 with a disability '+\n",
    "        f'averaged {val13:.1f} percent. ')\n",
    "write_txt(text_dir / 'dis_rate_cps.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c666ccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4b7c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e864644f",
   "metadata": {},
   "source": [
    "### Average Weekly Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa126e58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.710221Z",
     "start_time": "2023-11-30T16:24:40.180241Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/miniconda3/lib/python3.8/site-packages/statsmodels/tsa/x13.py:203: X13Warning: WARNING: At least one visually significant trading day peak has been\n",
      "          found in the estimated spectrum of the regARIMA residuals.\n",
      "  warn(errors, X13Warning)\n"
     ]
    }
   ],
   "source": [
    "hrs = {'CES0500000002': 'ceshrstot',\n",
    "       'CES0600000002': 'ceshrsgoods',\n",
    "       'CES0800000002': 'ceshrsserv',\n",
    "       'CES0500000007': 'ceshrspns'}\n",
    "\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                   parse_dates=True)\n",
    "df = df[hrs.keys()].rename(hrs, axis=1)\n",
    "\n",
    "df2 = pd.concat([df, (pd.read_csv(data_dir / 'jobs_report_main2.csv', parse_dates=['date'])\n",
    "        .set_index('date'))], axis=1)\n",
    "cps = pd.read_csv(data_dir / 'uslhrs.csv', \n",
    "                  index_col='name', parse_dates=True)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['TOTCES'] = df2['ceshrstot']\n",
    "data['TOTLFS'] = df2['avghrstot']\n",
    "data['SERVNSA'] = df2['avghrsserv']\n",
    "data['SERVSA'] = x13_arima_analysis(df2['avghrsserv'].dropna()).seasadj\n",
    "data['PNS'] = df2['ceshrspns']\n",
    "data['PTECONNSA'] = df2['avghrsptecon']\n",
    "data['PTECONSA'] = x13_arima_analysis(df2['avghrsptecon'].dropna()).seasadj\n",
    "data['TOTCPS'] = cps['Total']\n",
    "data['PA_CPSFT'] = cps['Age2554FT']\n",
    "data['FT_CPS'] = cps['FT']\n",
    "data['PA_CPSPT'] = cps['Age2554PT']\n",
    "data['PT_CPS'] = cps['PT']\n",
    "\n",
    "data.loc['1989':].to_csv(data_dir / 'hours.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "828473f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.721831Z",
     "start_time": "2023-11-30T16:24:40.711977Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve data\n",
    "data = pd.read_csv(data_dir / 'hours.csv', index_col='date', \n",
    "                   parse_dates=True)\n",
    "ltval = data['TOTLFS'].iloc[-1]\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "feb20val = data.loc['2020-02-01', 'TOTLFS']\n",
    "compare = compare_text(ltval, feb20val, [0.2, 1.5, 3.0])\n",
    "avg90 = data.loc['1998':'2000', 'TOTLFS'].mean()\n",
    "gfclow = data.loc['2005': '2012', 'TOTLFS'].min()\n",
    "gfclowdt = dtxt(data.loc['2005': '2012', 'TOTLFS'].idxmin())['mon1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0be213a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.732378Z",
     "start_time": "2023-11-30T16:24:40.723084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual hours worked by people at work in all industries during the survey reference week average 38.4 in October 2023 (see {\\color{blue}\\textbf{---}}), slightly below the 38.8 average actual hours worked in February 2020. Average actual hours for this group average 39.6 from 1998 through 2000, and fell to a great recession low of 37.4 in February 2010.\n",
      "Those in service occupations work fewer hours on average, with 34.8 average weekly hours in October 2023, slightly below the 35.2 average in February 2020. Those part-time for economic reasons (see {\\color{red!90!black}\\textbf{---}}) work an average of 23.3 hours per week in October 2023. \n",
      "In October 2023, production and non-supervisory workers (see {\\color{orange}\\textbf{---}}), about four of every five employees, worked 33.7 hours per week on average, in line with the 33.6 average weekly hours in February 2020 and substantially below the 1998--2000 average of 34.4 hours.\n"
     ]
    }
   ],
   "source": [
    "text = ('Actual hours worked by people at work in all industries '+\n",
    "        f'during the survey reference week average {ltval:.1f} in {ltdate} '+\n",
    "        '(see {\\color{blue}\\\\textbf{---}}), '+\n",
    "        f'{compare} the {feb20val:.1f} average actual hours worked in February '+\n",
    "        f'2020. Average actual hours for this group average {avg90:.1f} from '+\n",
    "        '1998 through 2000, and fell to a great recession low of '+\n",
    "        f'{gfclow:.1f} in {gfclowdt}.')\n",
    "write_txt(text_dir / 'hours_tot.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval2 = data.SERVSA.iloc[-1]\n",
    "feb20val2 = data.loc['2020-02-01', 'SERVSA']\n",
    "compare2 = compare_text(ltval2, feb20val2, [0.2, 0.6, 2.5])\n",
    "pteval = data.PTECONSA.iloc[-1]\n",
    "text = ('Those in service occupations work '+\n",
    "        f'fewer hours on average, with {ltval2:.1f} average '+\n",
    "        f'weekly hours in {ltdate}, {compare2} the {feb20val2:.1f} '+\n",
    "        'average in February 2020. Those part-time '+\n",
    "        'for economic reasons (see {\\color{red!90!black}\\\\textbf{---}}) '+\n",
    "        f'work an average of {pteval:.1f} hours per week in {ltdate}. ')\n",
    "write_txt(text_dir / 'hours_lfs2.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval3 = data.PNS.iloc[-1]\n",
    "feb20val3 = data.loc['2020-02-01', 'PNS']\n",
    "compare3 = compare_text(ltval3, feb20val3, [0.2, 0.6, 2.5])\n",
    "val98 = data.loc['1998':'2000', 'PNS'].mean()\n",
    "compare4 = compare_text(ltval3, val98, [0.2, 0.6, 2.5])\n",
    "text = (f'In {ltdate}, '+\n",
    "        'production and non-supervisory workers (see {\\color{orange}\\\\textbf{---}})'+\n",
    "        ', about four of every five employees, '+\n",
    "        f'worked {ltval3:.1f} hours per week on average, '+\n",
    "        f'{compare3} the {feb20val3:.1f} average weekly hours in February 2020 and '+\n",
    "        f'{compare4} the 1998--2000 average of {val98:.1f} hours.')\n",
    "write_txt(text_dir / 'hours_ces.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "207ee812",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.745557Z",
     "start_time": "2023-11-30T16:24:40.734461Z"
    }
   },
   "outputs": [],
   "source": [
    "d = {'TOTCES': 'Total Actual, CES',\n",
    "     'PNS': '\\hspace{2mm} Production \\& Non-Supervisory, CES ({\\color{orange}\\\\textbf{---}} )',\n",
    "     'TOTLFS': 'Total Actual, LFS ({\\color{blue}\\\\textbf{---}})',\n",
    "     'PTECONSA': '\\hspace{2mm} Part-Time for Economic Reasons, LFS ({\\color{red!90!black}\\\\textbf{---}})',\n",
    "     'SERVSA': '\\hspace{2mm} Services Occupations, LFS',\n",
    "     'TOTCPS': 'Total Usual, CPS',\n",
    "     'FT_CPS': '\\hspace{2mm} Full-Time, All Ages, CPS',\n",
    "     'PA_CPSFT': '\\hspace{4mm} Full-Time, Age 25 to 54, CPS',\n",
    "     'PT_CPS': '\\hspace{2mm} Part-Time, All Ages, CPS',\n",
    "     'PA_CPSPT': '\\hspace{4mm} Part-Time, Age 25 to 54, CPS'}\n",
    "\n",
    "dft = data[d.keys()].rename(d, axis=1)\n",
    "tbl = dft.iloc[[-1, -2, -3, -13]].T\n",
    "tbl.columns = [dtxt(c)['mon8'] for c in tbl.columns]\n",
    "tbl['2019'] = dft.loc['2019'].mean()\n",
    "tbl['2015'] = dft.loc['2015'].mean()\n",
    "tbl['2010'] = dft.loc['2010'].mean()\n",
    "\n",
    "tbl.round(1).to_csv(data_dir / 'hoursworked_table.tex', sep='&', \n",
    "             lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba203f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047b1f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07f39597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T12:39:43.731164Z",
     "start_time": "2023-11-10T12:39:43.728241Z"
    }
   },
   "source": [
    "### Pay - Productivity Gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ad32559",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.917452Z",
     "start_time": "2023-11-30T16:24:40.747028Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gather data\n",
    "# Productivity\n",
    "ndp = nipa_df(retrieve_table('T11706')['Data'], ['A362RX'])['A362RX']\n",
    "hrs = pd.read_csv(data_dir / 'gdpjobslvl.csv', \n",
    "                   index_col='date', parse_dates=True)['TOT_HRS']\n",
    "lprod = (ndp / hrs).rolling(4).mean().loc['1989':].dropna()\n",
    "nprod = lprod / lprod.iloc[0]\n",
    "nprod.name = 'Productivity'\n",
    "\n",
    "# Wages - ECI\n",
    "df = pd.read_csv(data_dir / 'eci.csv', index_col='date', \n",
    "                 parse_dates=True)[['IndexWS_All_SA_SIC', 'IndexWS']]\n",
    "df0 = df.loc[:'2000-10-01', 'IndexWS_All_SA_SIC']\n",
    "df1 = df.dropna().mean(axis=1) # Average of SIC and NAICs during overlap\n",
    "df2 = df.loc['2006-01-01':, 'IndexWS']\n",
    "res = pd.concat([df0, df1, df2])\n",
    "\n",
    "defl = nipa_df(retrieve_table('T20304')['Data'], ['DPCERG'])['DPCERG']\n",
    "rw = (res / defl)\n",
    "rw = rw.rolling(4).mean().dropna().loc['1989':]\n",
    "eci = rw / rw.loc['1989-10-01']\n",
    "eci.name = 'Average'\n",
    "\n",
    "# Wages - Median\n",
    "nw = pd.read_csv(data_dir / 'uwe_cps.csv', index_col='date', \n",
    "                 parse_dates=True)['p50']\n",
    "cpi = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                 index_col='date', parse_dates=True)['All items']\n",
    "rw = x13_arima_analysis((nw / cpi).dropna().resample('QS').mean()).seasadj\n",
    "rw = rw.rolling(4).mean().dropna()\n",
    "rmw = rw / rw.iloc[0]\n",
    "rmw.name = 'Median'\n",
    "\n",
    "# Combine data\n",
    "res = pd.concat([rmw, eci, nprod], axis=1) * 100\n",
    "res.loc['1989-10-01':].to_csv(data_dir / 'payprod.csv', index_label='date')\n",
    "resa = cagr(res.loc['1989-10-01':].dropna()) # Annual growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ab69fad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.953432Z",
     "start_time": "2023-11-30T16:24:40.919147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since 1989, annualized net output growth is 2.3 percent, net productivity growth is 1.3 percent, and population growth is 0.9 percent.\n",
      "\n",
      "While the US has modest labor productivity growth over the past few decades, wages have not kept pace. The average wage has grown by nan percent per year since 1989, and the median wage has increased by 0.4 percent per year. \n"
     ]
    }
   ],
   "source": [
    "# Text\n",
    "ndpgr = value_text(cagr(ndp.loc['1989-10-01':]), 'plain')\n",
    "prodgr = value_text(cagr(nprod.loc['1989-10-01':]), 'plain')\n",
    "pop = nipa_df(retrieve_table('T20100')['Data'], ['B230RC'])['B230RC']\n",
    "popgr = value_text(cagr(pop.loc['1989-10-01':]), 'plain')\n",
    "wmdgr = value_text(cagr(res.Median.loc['1989-10-01':]), 'increase_by')\n",
    "wmngr = value_text(cagr(res.Average.loc['1989-10-01':]), 'increase_by', \n",
    "                   casual=True).replace('grew', 'grown')\n",
    "\n",
    "text = (f'Since 1989, annualized net output growth is {ndpgr}, net '+\n",
    "        f'productivity growth is {prodgr}, and population growth is {popgr}.\\n\\n'+\n",
    "        f'While the US has modest labor productivity growth over the past few '+\n",
    "        'decades, wages have not kept pace. The average wage has '+\n",
    "        f'{wmngr} per year since 1989, and the median wage has '+\n",
    "        f'{wmdgr} per year. ')\n",
    "write_txt(text_dir / 'payprod.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "067dce3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.960127Z",
     "start_time": "2023-11-30T16:24:40.954625Z"
    }
   },
   "outputs": [],
   "source": [
    "# Settings for plot\n",
    "cmax, cmin = resa.max(), resa.min()\n",
    "thresh = (cmax - cmin) * 0.5 #Bigger bars labeled inside\n",
    "\n",
    "v = {'Median': ['\\\\footnotesize Median (CPS)', 'green!90!blue', 'black', 0], \n",
    "    'Average': ['\\\\footnotesize Average (ECI)', 'blue!80!black', 'white', 1],\n",
    "    'Productivity': ['\\\\footnotesize Net Labor \\\\ \\\\footnotesize Productivity', \n",
    "                     'cyan!90!white', 'black', 2.4]}\n",
    "txt = []\n",
    "for k, [name, color, tcolor, y] in v.items():\n",
    "    x = resa[k].round(3)\n",
    "    bar = f'\\\\addplot[{color}] coordinates {{({x}, {y})}};'\n",
    "    vtc = 'black'\n",
    "    tx = f'{resa[k]:.1f}\\%'\n",
    "    if abs(x) > thresh:  # Some value labels inside of bars\n",
    "        vt = f'\\scriptsize \\color{{{tcolor}}} \\\\textbf{{{tx}}}'\n",
    "        inside = True\n",
    "    else:\n",
    "        vt = f'\\scriptsize {tx}'\n",
    "        inside = False\n",
    "    if x > 0:\n",
    "        ytlab = 'left, align=right'\n",
    "        vtlab = 'left, align=right' if inside == True else 'right, align=right'\n",
    "    else:\n",
    "        ytlab = 'right, align=left'\n",
    "        vtlab = 'right, align=left' if inside == True else 'left, align=left'\n",
    "    # Create ylabel and value label\n",
    "    ylabel = f'\\\\node[{ytlab}, text width=2.0cm] at (axis cs:0,{y}) {{{name}}};'\n",
    "    vlabel = f'\\\\node[{vtlab}] at (axis cs:{x},{y}) {{{vt}}};'\n",
    "    txt.append(bar)\n",
    "    txt.append(ylabel)\n",
    "    txt.append(vlabel)\n",
    "nodes = '\\n'.join(txt)\n",
    "write_txt(text_dir / f'payprod_bars.txt', nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf37b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e52417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ed74c65",
   "metadata": {},
   "source": [
    "### Aggregate Hours Worked\n",
    "\n",
    "BLS series (private sector) CES0500000016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc217d6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:40.990794Z",
     "start_time": "2023-11-30T16:24:40.961240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine data and save monthly and quarterly separately\n",
    "s = {'CES0500000016': 'CES',\n",
    "     'CES0500000006': 'PNS_payrolls',\n",
    "     'CES0500000007': 'PNS_hrs'}\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)[s.keys()].rename(s, axis=1)\n",
    "df['CES_PNS'] = df['PNS_payrolls'] * df['PNS_hrs']\n",
    "df2 = pd.read_csv(data_dir / 'lprod.csv', \n",
    "                  index_col='date', parse_dates=True)['hours_index']\n",
    "df['CPS'] = pd.read_csv(data_dir / 'gdpjobslvl_mo.csv', index_col='date', \n",
    "                  parse_dates=True)['TOT_HRS']\n",
    "\n",
    "resm = (df / df.loc['2010-01-01']) * 100\n",
    "resm.loc['1989':].to_csv(data_dir / 'agg_hrs_m.csv', index_label='date')\n",
    "resq = (((df2 / df2.loc['2010-01-01']) * 100).to_frame()\n",
    "        .rename({'hours_index': 'LPC'}, axis=1))\n",
    "resq.to_csv(data_dir / 'agg_hrs_q.csv', index_label='date')\n",
    "\n",
    "# Text1 - LPC\n",
    "chval1 = value_text(cagr(resq.LPC), 'increase_end', adj='annualized')\n",
    "txt1 = (f'which shows {chval1} in aggregate hours since 1989.')\n",
    "write_txt(text_dir / f'agg_hrs_lpc.txt', txt1)\n",
    "\n",
    "# CES\n",
    "chval2 = value_text(cagr(resm.CES_PNS.dropna(), freq='M'), 'increase')\n",
    "txt2 = (f'have {chval2} per year since 1989')\n",
    "write_txt(text_dir / f'agg_hrs_ces.txt', txt2)\n",
    "\n",
    "# CPS\n",
    "chval3 = value_text(cagr(resm.CPS.dropna(), freq='M'), 'increase')\n",
    "txt3 = (f'{chval3} per year since 1989')\n",
    "write_txt(text_dir / f'agg_hrs_cps.txt', txt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070b31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dee586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e13d9549",
   "metadata": {},
   "source": [
    "### Average Hourly Earnings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "825a6bb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.010629Z",
     "start_time": "2023-11-30T16:24:40.992087Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average hourly earnings\n",
    "s = {'CES0500000003': 'AHE'}\n",
    "# CES series from flat/text files\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)[s.keys()].rename(s, axis=1)\n",
    "ch = df.pct_change(12) * 100\n",
    "\n",
    "cpi = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "cpidt = cpi.index[-73]\n",
    "ch.loc[cpidt:].to_csv(data_dir / 'ahe_growth_recent.csv', \n",
    "                      index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb42e430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5531a76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c062af1",
   "metadata": {},
   "source": [
    "### Average Hourly Earnings Growth\n",
    "\n",
    "From CES Flat File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ba0e849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.053716Z",
     "start_time": "2023-11-30T16:24:41.011931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the year ending October 2023, nominal average hourly earnings increased 4.4 percent for production and non-supervisory workers (see {\\color{violet!80!blue}\\textbf{---}}), following increases of 4.5 percent in both September and August. Comparing the latest three months to the previous three months, nominal earnings increased at an annual rate of 3.8 percent. \n",
      "\n",
      "Real average hourly earnings increased 1.1 percent in October 2023 (see {\\color{green!80!blue}\\textbf{---}}), following increases of 0.7 percent in September and 0.8 percent in August. Real wages decreased at an annual rate of 0.6 percent over the latest three months, compared to the previous three months.\n"
     ]
    }
   ],
   "source": [
    "# Average hourly earnings recent monthly change\n",
    "s = {'CES0500000003': 'ALL', 'CES0500000008': 'PNS'}\n",
    "# CES series from flat/text files\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)[s.keys()].rename(s, axis=1)\n",
    "data = (df.pct_change(12) * 100)\n",
    "\n",
    "# Latest 3 months compared to previous 3, annualized\n",
    "data['PNS_3'] = m3rate(df.PNS)\n",
    "\n",
    "# Adjust for inflation \n",
    "cpi = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                  parse_dates=True)['All items (SA)']\n",
    "cpia = cpi.iloc[-1] / cpi\n",
    "df['PNS_Real'] = df['PNS'].multiply(cpia)\n",
    "\n",
    "data['PNS_Real'] = df.PNS_Real.dropna().pct_change(12) * 100\n",
    "data['PNS_Real_3'] = m3rate(df.PNS_Real)\n",
    "\n",
    "# Latest 3 months compared to previous 3, annualized\n",
    "data['PNS_3'] = m3rate(df.PNS)\n",
    "\n",
    "# Adjust for inflation \n",
    "cpi = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                  parse_dates=True)['All items (SA)']\n",
    "cpia = cpi.iloc[-1] / cpi\n",
    "df['PNS_Real'] = df['PNS'].multiply(cpia)\n",
    "data['PNS_Real'] = df.PNS_Real.pct_change(12) * 100\n",
    "data['PNS_Real_3'] = m3rate(df.PNS_Real)\n",
    "\n",
    "# Handle cases with estimated real wage\n",
    "cpi_dt = cpi.index[-1]\n",
    "ahe_dt = data.PNS.dropna().index[-1]\n",
    "if ahe_dt > cpi_dt:\n",
    "    # Nowcast inflation rate\n",
    "    cn = pd.read_csv(data_dir / 'cpinow.csv', \n",
    "                 index_col='date', parse_dates=True)['All items (SA)']\n",
    "    cpia = cn.iloc[-1] / cn\n",
    "    rahe = df['PNS'].multiply(cpia)\n",
    "    cval = (rahe.pct_change(12) * 100).iloc[-1]\n",
    "    c3val = m3rate(rahe).iloc[-1]\n",
    "    data.loc[ahe_dt, 'PNS_Real_e'] = cval\n",
    "    data.loc[ahe_dt, 'PNS_Real_3e'] = c3val\n",
    "data.to_csv(data_dir / 'ahe.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "# Nominal line end node\n",
    "colors = {'PNS': 'violet!80!blue', 'PNS_Real': 'green!80!blue'}\n",
    "node = end_node(data['PNS'], colors['PNS'], date='m', offset=0.35)\n",
    "write_txt(text_dir / f'ahe_growth_node.txt', node)\n",
    "\n",
    "# Text\n",
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "lt = data.iloc[-1]\n",
    "real_lt = value_text(lt.PNS_Real, style='increase')\n",
    "nom_lt = value_text(lt.PNS)\n",
    "prval = prval_comp(data.PNS)\n",
    "rprval = prval_comp(data.PNS_Real)\n",
    "nom_3m = value_text(lt.PNS_3, style='increase', adj='annual')\n",
    "rl_3m = value_text(lt.PNS_Real_3, style='increase', adj='annual')\n",
    "clr = c_line(colors['PNS_Real'])\n",
    "cln = c_line(colors['PNS'])\n",
    "text = (f'Over the year ending {ltdt}, nominal average hourly earnings '+\n",
    "        f'{nom_lt} for production and non-supervisory workers {cln}, '+\n",
    "        f'following {prval}. Comparing the latest '+\n",
    "        f'three months to the previous three months, nominal earnings '+\n",
    "        f'{nom_3m}.')\n",
    "write_txt(text_dir / 'ahe_summary1.txt', text)        \n",
    "print(text, '\\n')      \n",
    "        \n",
    "if ahe_dt == cpi_dt:\n",
    "    nowsrc = ' '\n",
    "    write_txt(text_dir / f'real_ahe_nowsrc.txt', nowsrc)\n",
    "    text = (f'Real average hourly earnings {real_lt} in {ltdt} '+\n",
    "            f'{clr}, following {rprval}. Real wages {rl_3m} '+\n",
    "            f'over the latest three months, compared to the previous three '+\n",
    "             'months.')\n",
    "    print(text)\n",
    "    write_txt(text_dir / 'ahe_summary2.txt', text)\n",
    "    # End node real\n",
    "    node = end_node(data['PNS_Real'], colors['PNS_Real'])\n",
    "    write_txt(text_dir / f'ahe_growth_node_real.txt', node)\n",
    "    \n",
    "# Handle cases where latest CPI not yet published\n",
    "if ahe_dt > cpi_dt:\n",
    "    nowsrc = ', FRB Cleveland'\n",
    "    write_txt(text_dir / f'real_ahe_nowsrc.txt', nowsrc)\n",
    "    col = colors['PNS_Real']\n",
    "    mark = f'(see \\\\tikz \\draw[{col}, fill=white] (0pt,0pt) circle (2.0pt);)'\n",
    "    lv = data['PNS_Real_e'].iloc[-1]\n",
    "    lvt = f'{lv:.1f}'\n",
    "    dt = dtxt(ahe_dt)['datetime']\n",
    "    # End node real\n",
    "    node = (f'\\\\node[label={{[align=left]0:{{\\scriptsize \\\\textit{{{lvt}}}}}}}, '+\n",
    "            f'circle, draw={col}, fill=white, inner sep=1.4pt] at '+\n",
    "            f'(axis cs:{dt}, {lv}) {{}};') \n",
    "    write_txt(text_dir / f'ahe_growth_node_real.txt', node)\n",
    "    real_lt = value_text(lt.PNS_Real_e, 'plain')\n",
    "    real_pr = value_text(data.iloc[-2].PNS_Real, 'plain')\n",
    "    rl_3m = value_text(lt.PNS_Real_3e, style='plain')\n",
    "    cpi_month = dtxt(ahe_dt)['mon3']\n",
    "    pr_month = dtxt(data.index[-2])['mon3']\n",
    "    text = (f'The {cpi_month} CPI is not yet published, but the one-year '+\n",
    "            'real wage growth estimate based on the CPI nowcast is '+\n",
    "            f'{real_lt} {mark}. The real rate for {pr_month} is {real_pr} {clr}. '+\n",
    "            'Using the nowcast, the annualized real growth rate for the '+\n",
    "            'latest three months compared to the previous three months is '\n",
    "            f'{rl_3m}.')\n",
    "    write_txt(text_dir / 'ahe_summary2.txt', text)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685371b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a40f7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c76add8",
   "metadata": {},
   "source": [
    "### Real AHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8a39ec2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.060092Z",
     "start_time": "2023-11-30T16:24:41.055039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Handle cases with missing CPI\n",
    "cdt = pd.read_csv(data_dir / 'cpi.csv', index_col='date', \n",
    "            parse_dates=True).index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53cbd7a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.083350Z",
     "start_time": "2023-11-30T16:24:41.061224Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average hourly earnings recent monthly change\n",
    "s = {'CES0600000008': 'Goods', 'CES0800000008': 'Serv'}\n",
    "# CES series from flat/text files\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)[s.keys()].rename(s, axis=1)\n",
    "cpi = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                  parse_dates=True)['All items (SA)']\n",
    "cpi = cpi.iloc[-1] / cpi\n",
    "real = df.multiply(cpi, axis=0).dropna()\n",
    "real.loc['1989':].to_csv(data_dir / 'real_ahe.csv', index_label='date')\n",
    "\n",
    "# Store latest date\n",
    "ltdt = dtxt(real.index[-1])['mon1']\n",
    "write_txt(text_dir / 'real_ahe_ltdate.txt', ltdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fdbe323c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.108517Z",
     "start_time": "2023-11-30T16:24:41.088762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hourly wages for production and non-supervisory workers in private goods-producing sectors average \\$29.95 in October 2023 (see {\\color{cyan!80!green!92!blue}\\textbf{---}}). In October 2019, the average hourly wage for the sector is \\$29.84, after adjusting for inflation.\n",
      "\n",
      "Private service-providing industry wages average \\$29.03 for production and non-supervisory workers in October 2023. The inflation-adjusted equivalent is \\$28.10 in October 2019 (see {\\color{blue!70!violet}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "fmtval = real.applymap('\\${:.2f}'.format)\n",
    "fmtval.Goods.iloc[-1]\n",
    "colors = {'Serv': 'blue!70!violet',\n",
    "          'Goods': 'cyan!80!green!92!blue'}\n",
    "cl = {n: c_line(c) for n, c in colors.items()}\n",
    "dt19 = '2019' + dtxt(real.index[-1])['datetime'][4:]\n",
    "dt19t = dtxt(pd.to_datetime(dt19))['mon1']\n",
    "gval19 = fmtval.loc[dt19, 'Goods']\n",
    "sval19 = fmtval.loc[dt19, 'Serv']\n",
    "text = ('Hourly wages for production and non-supervisory workers in '+\n",
    "        f'private goods-producing sectors average {fmtval.Goods.iloc[-1]} '+\n",
    "        f'in {ltdt} {cl[\"Goods\"]}. In {dt19t}, the average hourly wage '+\n",
    "        f'for the sector is {gval19}, after adjusting for inflation.\\n\\n'+\n",
    "        'Private service-providing industry wages average '+\n",
    "        f'{fmtval.Serv.iloc[-1]} for production and non-supervisory workers '+\n",
    "        f'in {ltdt}. The inflation-adjusted equivalent is {sval19} '+\n",
    "        f'in {dt19t} {cl[\"Serv\"]}.')\n",
    "write_txt(text_dir / 'real_ahe_summary.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026785f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b1531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "184be291",
   "metadata": {},
   "source": [
    "### AHE Growth by Industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "081db787",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.152600Z",
     "start_time": "2023-11-30T16:24:41.112867Z"
    }
   },
   "outputs": [],
   "source": [
    "s = {'CES3000000008': 'Manufacturing',\n",
    "     'CES1000000008': 'Mining \\& Logging',\n",
    "     'CES4422000008': 'Utilities',\n",
    "     'CES4142000008': 'Wholesale Trade',\n",
    "     'CES5000000008': 'Information',\n",
    "     'CES5500000008': 'Financial Activities',\n",
    "     'CES6000000008': 'Professional \\& \\\\\\\\[-0.6ex] Business Services',\n",
    "     'CES6500000008': 'Education \\& \\\\\\\\[-0.6ex] Health Services',\n",
    "     'CES0500000008': 'Total Private',\n",
    "     'CES2000000008': 'Construction',\n",
    "     'CES7000000008': 'Leisure \\& \\\\\\\\[-0.6ex] Hospitality',\n",
    "     'CES4300000008': 'Transportation \\\\\\\\[-0.6ex] \\& Warehousing',\n",
    "     'CES4200000008': 'Retail Trade'}\n",
    "\n",
    "data = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                   parse_dates=True)[s.keys()].rename(s, axis=1)\n",
    "df = data.loc['2017':]\n",
    "df.to_csv(data_dir / 'ahe_industry_raw.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "821719e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.163726Z",
     "start_time": "2023-11-30T16:24:41.157221Z"
    }
   },
   "outputs": [],
   "source": [
    "# Major sector categories\n",
    "c = {'Manufacturing': 'Goods',\n",
    "     'Mining \\& Logging': 'Goods',\n",
    "     'Utilities': 'Serv',\n",
    "     'Wholesale Trade': 'Serv',\n",
    "     'Information': 'Serv',\n",
    "     'Financial Activities': 'Serv',\n",
    "     'Professional \\& \\\\\\\\[-0.6ex] Business Services': 'Serv',\n",
    "     'Education \\& \\\\\\\\[-0.6ex] Health Services': 'Serv',\n",
    "     'Total Private': 'Total',\n",
    "     'Construction': 'Goods',\n",
    "     'Leisure \\& \\\\\\\\[-0.6ex] Hospitality': 'Serv',\n",
    "     'Transportation \\\\\\\\[-0.6ex] \\& Warehousing': 'Serv',\n",
    "     'Retail Trade': 'Serv'}\n",
    "\n",
    "colors = {'Goods': 'cyan!80!green!92!blue', 'Serv': 'blue!70!violet',\n",
    "          'Total': 'gray'}\n",
    "s = df.iloc[-1].sort_values()\n",
    "txt = []\n",
    "for i, (val, name) in enumerate(list(zip(s, s.index))):\n",
    "    # X Bar\n",
    "    color = colors[c[name]]\n",
    "    bar = (f'\\\\addplot[{color}, xbar, bar width=2.4ex, '+\n",
    "           f'bar shift=0pt, fill] coordinates {{({val}, {i})}};')\n",
    "    txt.append(bar)    \n",
    "    # Y Label\n",
    "    label = name\n",
    "    if name == 'Total Private':\n",
    "        label = '\\\\textbf{Total Private}'\n",
    "    ylab = (f'\\\\node[left, align=right, text width=2.6cm] '+\n",
    "            f'at (axis cs:0,{i}) {{\\\\footnotesize{{{label}}}}};')\n",
    "    txt.append(ylab)    \n",
    "    # Value Label\n",
    "    vtx = f'\\scriptsize {val:.2f}'\n",
    "    if name == s.index[-1]:\n",
    "        vtx = vtx.replace('\\scriptsize ', '\\scriptsize \\$')\n",
    "    vt = f'\\scriptsize \\color{{white}} \\\\textbf{{{vtx}}}'\n",
    "    vlab = f'\\\\node[left, align=right] at (axis cs:{val},{i}) {{{vt}}};'\n",
    "    txt.append(vlab)\n",
    "nodes = '\\n'.join(txt)\n",
    "write_txt(text_dir / 'ahe_ind_levels.txt', nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a09c139",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.175155Z",
     "start_time": "2023-11-30T16:24:41.165193Z"
    }
   },
   "outputs": [],
   "source": [
    "# Chart for growth rates\n",
    "p = pd.read_csv(data_dir / 'cpi.csv')\n",
    "allitems = p['ALL'].iloc[-1]\n",
    "s2 = (df.pct_change(12).iloc[-1] * 100.0).loc[s.index]\n",
    "txt1, txt2 = [], []\n",
    "for i, (val, name) in enumerate(list(zip(s2, s2.index))):\n",
    "    # X Bar\n",
    "    color = colors[c[name]]\n",
    "    bar = (f'\\\\addplot[{color}, xbar, bar width=2.3ex, '+\n",
    "           f'bar shift=0pt, fill] coordinates {{({val}, {i})}};')\n",
    "    txt1.append(bar)       \n",
    "    # Value Label    \n",
    "    vtx = f'\\scriptsize {val:.1f}'\n",
    "    if name == s.index[-1]:\n",
    "        vtx = vtx + '\\%'\n",
    "    vt = f'\\scriptsize \\color{{black!90}} \\\\textbf{{{vtx}}}'\n",
    "    vlab = (f'\\\\node[right, align=left, fill=white, inner sep=0.2, '+\n",
    "            f'xshift=1.0mm] at (axis cs:{val},{i}) {{{vt}}};')\n",
    "    txt2.append(vlab)\n",
    "nodes1 = '\\n'.join(txt1)\n",
    "write_txt(text_dir / 'ahe_ind_growth.txt', nodes1)\n",
    "nodes2 = '\\n'.join(txt2)\n",
    "write_txt(text_dir / 'ahe_ind_growth2.txt', nodes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef64abcd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.193549Z",
     "start_time": "2023-11-30T16:24:41.176803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For production and nonsupervisory workers, the highest average hourly earnings in October 2023 are in the utilities industry (\\$44.84), followed by the information industry (\\$39.21), and the mining and logging industry (\\$34.72). The lowest wage industries in the latest data, by average hourly earnings, are leisure and hospitality (\\$19.00) and retail trade (\\$20.62). \n",
      "\n",
      "Over the past year, 10 of the 12 industry groups have wage growth above the increase in prices indicated by the consumer price index (see {\\color{orange!50!yellow}\\textbf{---}}). The transportation and warehousing industry had the fastest nominal growth rate, at 7.2 percent, followed by 5.8 percent in financial activities and 5.4 percent in mining and logging. \n"
     ]
    }
   ],
   "source": [
    "# Data in Levels\n",
    "df = (pd.read_csv(data_dir / 'ahe_industry_raw.csv', \n",
    "                  parse_dates=['date'])\n",
    "        .set_index('date'))\n",
    "lev = df.iloc[-1].sort_values(ascending=False)\n",
    "lev.to_csv(data_dir / 'ahe_ind_levels.csv', \n",
    "           index_label='name', header=True)\n",
    "\n",
    "# Text\n",
    "ltd = {i: (lev.index[i].lower().replace ('\\&', 'and')\n",
    "           .replace('\\\\\\\\[-0.6ex] ', ''), lev.iloc[i]) \n",
    "       for i in [0, 1, 2, -1, -2]}\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "text = ('For production and nonsupervisory workers, the highest '+\n",
    "        f'average hourly earnings in {ltdt} are in the {ltd[0][0]} '+\n",
    "        f'industry (\\${ltd[0][1]:.2f}), followed by the {ltd[1][0]} '+\n",
    "        f'industry (\\${ltd[1][1]:.2f}), and the {ltd[2][0]} '+\n",
    "        f'industry (\\${ltd[2][1]:.2f}). The lowest wage industries in '+\n",
    "        f'the latest data, by average hourly earnings, are {ltd[-1][0]} '+\n",
    "        f'(\\${ltd[-1][1]:.2f}) and {ltd[-2][0]} (\\${ltd[-2][1]:.2f}).')\n",
    "print(text, '\\n')\n",
    "\n",
    "# Growth Rate\n",
    "p = pd.read_csv(data_dir / 'cpi.csv')\n",
    "allitems = p['ALL'].iloc[-1]\n",
    "data = (df.pct_change(12).iloc[-1] * 100.0).loc[lev.index]\n",
    "data.to_csv(data_dir / 'ahe_ind.csv', index_label='name', \n",
    "            header=True)\n",
    "# Date for bar\n",
    "write_txt(text_dir / 'ahe_bar_date.txt', df.index[-1].strftime('%B %Y'))\n",
    "\n",
    "data = data.sort_values(ascending=False)\n",
    "real = (data - allitems).drop('Total Private')\n",
    "ltd = {i: (data.index[i].lower().replace ('\\&', 'and')\n",
    "           .replace('\\\\\\\\[-0.6ex] ', ''), data.iloc[i]) \n",
    "       for i in [0, 1, 2]}\n",
    "rwn = len(real.loc[real > 0])\n",
    "rwg = numbers2[rwn] if rwn < 10 else rwn\n",
    "if rwn == 0:\n",
    "    rwg = 'none'\n",
    "alltxt = 'all ' if rwg == 12 else ''\n",
    "clcpi = c_line('orange!50!yellow')\n",
    "\n",
    "#Text\n",
    "txt1 = (f'Over the past year, {alltxt}{rwg} of the {len(real)} industry '+\n",
    "         'groups have wage growth above the increase in prices '+\n",
    "        f'indicated by the consumer price index {clcpi}. The {ltd[0][0]} '+\n",
    "        f'industry had the fastest nominal growth rate, at {ltd[0][1]:.1f} '+\n",
    "        f'percent, followed by {ltd[1][1]:.1f} percent in {ltd[1][0]} and '+\n",
    "        f'{ltd[2][1]:.1f} percent in {ltd[2][0]}. ')\n",
    "write_txt(text_dir / 'ahe_comp.txt', text+'\\n\\n'+txt1)\n",
    "print(txt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5373fc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227a6844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0847565b",
   "metadata": {},
   "source": [
    "### AHE Monthly Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a17b782f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.233352Z",
     "start_time": "2023-11-30T16:24:41.195055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average hourly earnings recent monthly change\n",
    "s = {'CES0500000003': 'ALL', 'CES0500000008': 'PNS'}\n",
    "# CES series from flat/text files\n",
    "df = pd.read_csv(data_dir / 'ces_raw.csv', index_col='date', \n",
    "                 parse_dates=True)[s.keys()].rename(s, axis=1)\n",
    "res = (df.pct_change() * 100).dropna(how='all')\n",
    "#res['FILL'] = 0\n",
    "res['label'] = [dt.strftime('%b\\\\\\%Y') if dt.month == 1 \n",
    "                else dt.strftime('%b') if dt.month in [4, 7, 10]\n",
    "                else '' for dt in res.index]\n",
    "res['label2'] = [dt.strftime('%b\\\\\\%Y') if (dt.month == 1) | (dt == res.index[-19]) \n",
    "                else dt.strftime('%b') for dt in res.index]\n",
    "\n",
    "# Axis from CPI chart\n",
    "cpi = pd.read_csv(data_dir / 'cpi_monthly.csv', index_col='date', \n",
    "                  parse_dates=True)\n",
    "d = (pd.concat([cpi[['ALL_S', 'FILL']], res.iloc[-19:]], axis=1)\n",
    "       .dropna(subset=['ALL']))\n",
    "d['REAL'] = d['ALL'] - d['ALL_S']\n",
    "d.to_csv(data_dir / 'ahe_monthly.csv', index_label='date', float_format='%g')\n",
    "\n",
    "# Nodes with latest values\n",
    "ltdate = d.index[-1]\n",
    "rv = d.loc[ltdate, 'REAL']\n",
    "rn = ''\n",
    "rn2 = end_node(d['REAL'].dropna(), 'magenta', italic=True)\n",
    "ltdtime = dtxt(ltdate)['datetime']\n",
    "adj = {'ALL': 0.12, 'REAL': 0}\n",
    "mon = {'ALL': '', 'REAL': ''}\n",
    "date = f\"\\scriptsize {dtxt(ltdate)['mon6'][:3]} \\\\\\\\[-2pt] \\ \"\n",
    "if pd.isnull(rv) == False:\n",
    "    adj = node_adj(d[['REAL', 'ALL']])\n",
    "    smax = d[['REAL', 'ALL']].iloc[-1].idxmax()\n",
    "    adj[smax] += 0.12\n",
    "    mon[smax] = date\n",
    "    rn = (f'\\\\node[label={{[yshift={adj[\"REAL\"]}cm, xshift=0.05cm, align=left]0:'+\n",
    "          f'{{{mon[\"REAL\"]}\\scriptsize {rv:.1f}}}}}, circle, white, fill, inner '+\n",
    "          f'sep=0pt] at (axis cs:{ltdtime}, {rv:.3f}) {{}};')\n",
    "    rn2 = end_node(d['REAL'], 'white!0', xoffset=0.08)\n",
    "else: \n",
    "    mon['ALL'] = date\n",
    "v = d.loc[ltdate, 'ALL']\n",
    "node = (f'\\\\node[label={{[yshift={adj[\"ALL\"]}cm, align=left]0:'+\n",
    "        f'{{{mon[\"ALL\"]}\\scriptsize {v:.1f}}}}}, circle, '+\n",
    "        f'white, fill, inner sep=0pt] at (axis cs:{ltdtime}, {v:.3f}) '+\n",
    "        '{};')\n",
    "text = rn + '\\n' + node\n",
    "write_txt(text_dir / 'ahe_summary_nodes.txt', text)\n",
    "write_txt(text_dir / 'ahe_mo_real_node.txt', rn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8ef63574",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.256462Z",
     "start_time": "2023-11-30T16:24:41.237563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in October 2023, nominal average hourly earnings for all private sector employees increased by 0.2 percent, following increases of 0.3 percent in both September and August (see\\cbox{violet!90!black}).\n",
      "\n",
      " Adjusting for inflation shows one-month growth of 0.2 percent in October, virtually no change in September, and a decrease of 0.4 percent in August (see \\tikz[magenta,scale=1.5]\\pgfuseplotmark{diamond};).\n"
     ]
    }
   ],
   "source": [
    "ltdt = dtxt(d.index[-1])['mon1']\n",
    "prval = prval_comp(d.ALL)\n",
    "rprval = prval_comp(d.REAL.dropna())\n",
    "nlt = value_text(d.ALL.iloc[-1], 'increase_by')\n",
    "\n",
    "# Handle cases with estimated real wage\n",
    "cpi = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                  parse_dates=True)['All items (SA)']\n",
    "cpi_dt = cpi.index[-1]\n",
    "ahe_dt = d.ALL.dropna().index[-1]\n",
    "estimated = ''\n",
    "following = ''\n",
    "#if ahe_dt > cpi_dt:\n",
    "#    estimated = 'estimated '\n",
    "#    following = 'following '\n",
    "rltmo = dtxt(d.REAL.dropna().index[-1])['mon3']\n",
    "rlt = f'{d.REAL.dropna().iloc[-1]:.1f} percent'\n",
    "cb = c_box('violet!90!black')\n",
    "text = (f'in {ltdt}, nominal average hourly earnings for all private sector '+\n",
    "        f'employees {nlt}, following {prval} {cb}.\\n\\n '+\n",
    "        f'Adjusting for inflation shows {estimated}one-month growth of {rlt} '+\n",
    "        f'in {rltmo}, {following}{rprval} '+\n",
    "        '(see \\\\tikz[magenta,scale=1.5]\\pgfuseplotmark{diamond};).')\n",
    "write_txt(text_dir / 'ahe_monthly_growth.txt', text)\n",
    "print(text)\n",
    "\n",
    "# Real AHE end node\n",
    "write_txt(text_dir / 'ahe_mo_real_node.txt', rn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d93b59a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f9b89f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cee1349",
   "metadata": {},
   "source": [
    "### GDP Growth Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9694344c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.623159Z",
     "start_time": "2023-11-30T16:24:41.258144Z"
    }
   },
   "outputs": [],
   "source": [
    "# Row Names\n",
    "n = {'A191RL': '\\\\textbf{Gross Domestic Product}',\n",
    "     'DPCERY': '\\hspace{2mm} Consumer Spending',\n",
    "     'DDURRY': '\\hspace{4mm} Durable Goods',\n",
    "     'DNDGRY': '\\hspace{4mm} Non-Durable Goods ',\n",
    "     'DSERRY': '\\hspace{4mm} Services ',\n",
    "     'A006RY': '\\hspace{2mm} Gross Investment',\n",
    "     'A011RY': '\\hspace{4mm} Residential ',\n",
    "     'A008RY': '\\hspace{4mm} Non-Residential ',\n",
    "     'A014RY': '\\hspace{4mm} Change in Inventories ',\n",
    "     'A019RY': '\\hspace{2mm} Net Exports ',\n",
    "     'A020RY': '\\hspace{4mm} Exports ',\n",
    "     'A021RY': '\\hspace{4mm} Imports ',\n",
    "     'A822RY': '\\hspace{2mm} Government ',\n",
    "     'A823RY': '\\hspace{4mm} Federal ',\n",
    "     'A829RY': '\\hspace{4mm} State and Local '}\n",
    "n2 = {'GoodsTTU': '\\hspace{2mm} Goods and TTU ',\n",
    "      'Manufacturing': '\\hspace{4mm} Manufacturing ',\n",
    "      'Construction': '\\hspace{4mm} Construction ',\n",
    "      'Retail trade': '\\hspace{4mm} Retail Trade ',\n",
    "      'FIRE': '\\hspace{2mm} FIRE+ ',\n",
    "      'Information': '\\hspace{4mm} Information ',\n",
    "      'Oth_Serv': '\\hspace{2mm} Other Services ',\n",
    "      'Educational services, health care, and social assistance': '\\hspace{4mm} Education \\& Healthcare ',\n",
    "      'Professional and business services': '\\hspace{4mm} Professional \\& Business',\n",
    "      'Government': '\\hspace{2mm} Government '}\n",
    "n3 = {'pop_contr': '\\hspace{2mm} Population ',\n",
    "      'epop_contr': '\\hspace{2mm} Employment Rate ',\n",
    "      'hours_contr': '\\hspace{2mm} Average Hours',\n",
    "      'prod': '\\hspace{2mm} Productivity '}\n",
    "n4 = {'A261RC': '\\\\textbf{Gross Domestic Income} ',\n",
    "      'A4002C': '\\hspace{2mm} Labor ',\n",
    "      'W271RC': '\\hspace{2mm} Profit ',\n",
    "      'A262RC': '\\hspace{2mm} Depreciation ',\n",
    "      'indirect': '\\hspace{2mm} Indirect Taxes '}\n",
    "\n",
    "# Color boxes\n",
    "c = {'A191RL': 'red!95!black',\n",
    "     'DPCERY': 'yellow!80!orange',\n",
    "     'A006RY': 'blue!70!black',\n",
    "     'A019RY': 'green!60!black',\n",
    "     'A822RY': 'cyan!50!white',\n",
    "     'GoodsTTU': 'purple!70!blue',\n",
    "     'FIRE': 'red!90!white',\n",
    "     'Oth_Serv': 'blue!90!white',\n",
    "     'Government': 'orange!80!white',\n",
    "     'pop_contr': 'lime!90!green',\n",
    "     'epop_contr': 'green!30!teal!80!black',\n",
    "     'hours_contr': 'blue',\n",
    "     'prod': 'cyan!55!white',\n",
    "     'A4002C': 'magenta!90!blue',\n",
    "     'W271RC': 'yellow!60!orange',\n",
    "     'A262RC': 'teal!60!white',\n",
    "     'indirect': 'violet'}\n",
    "\n",
    "# Main GDP Report\n",
    "df = nipa_df(retrieve_table('T10502')['Data'], n.keys())\n",
    "\n",
    "# GDP By Industry\n",
    "va = pd.read_csv(data_dir / 'gdpvafull.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "\n",
    "# GDP and Jobs Report\n",
    "jb = pd.read_csv(data_dir / 'gdpjobs.csv', index_col='date', \n",
    "                 parse_dates=True) \n",
    "\n",
    "# Gross Domestic Income\n",
    "gd = pd.read_csv(data_dir / 'gdi.csv', index_col='date',\n",
    "                 parse_dates=True)\n",
    "\n",
    "# Combined\n",
    "res = pd.concat([df, va, jb, gd], axis=1)\n",
    "tbl = res.iloc[-5:].iloc[::-1].T\n",
    "tbl.columns = [dtxt(i)['qtr1'] for i in tbl.columns]\n",
    "for p in [12, 40, 120]:\n",
    "    name = f'\\ \\ \\ {p/4:.0f}-  year'\n",
    "    tbl[name] = (pd.Series({i: res[i].dropna().rolling(p)\n",
    "                                     .mean().iloc[-1] \n",
    "                            for i in res.columns}))\n",
    "    \n",
    "# GDP and GDI get one decimal otherwise 2\n",
    "digit1 = ['A191RL', 'A261RC']\n",
    "row_fmt = (lambda x: x.apply('{:.1f}'.format) if x.name in digit1 \n",
    "           else x.apply('{:.2f}'.format))\n",
    "\n",
    "# Formatting and blank rows\n",
    "tbl = tbl.apply(row_fmt, axis=1).replace('nan', '--')\n",
    "tbl['CBOX'] = [f'\\cbox{{{c[i]}}}' if i in c else '' for i in tbl.index]\n",
    "tbl.index.name = '  '\n",
    "blank_row = pd.Series({col: '' for col in tbl.reset_index().columns}).to_frame().T\n",
    "fnl = pd.concat([pd.concat([tbl.loc[g.keys()].rename(g).reset_index(), blank_row], axis=0) \n",
    "                 for g in [n, n2, n3, n4]])\n",
    "fnl = fnl[['CBOX'] + [col for col in fnl.columns if col != 'CBOX']]\n",
    "fnl = fnl.rename({'CBOX': ' '}, axis=1)\n",
    "\n",
    "fnl.iloc[:-1].to_csv(data_dir / 'gdptable.tex', sep='&', index=False,\n",
    "           lineterminator='\\\\\\ ', quotechar=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9705fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471fe4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "319641b1",
   "metadata": {},
   "source": [
    "### Atlanta Fed Wage Growth Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8cda224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.673249Z",
     "start_time": "2023-11-30T16:24:41.624586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication of the wage growth tracker shows matched-observation nominal median wage growth of 5.2 percent over the three months ending October 2023, on an hourly basis, and 5.4 percent on a weekly basis (see {\\color{blue!65!violet}\\textbf{---}}). One year prior, in October 2022, three-month moving average nominal median wage growth was 6.7 percent, on an hourly basis, and 6.5 percent on a weekly basis.\n",
      "In October 2023, 12.1 percent of individuals had no hourly wage growth, compared to 12.2 in September 2023 (see {\\color{red}\\textbf{---}}). One year prior, in October 2022, 11.8 percent of individuals had no wage growth.\n",
      "In October 2023, the real median wage growth is 1.9 percent on an hourly basis, and two percent on a weekly basis. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'atl_wgt.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "ltdt = dtxt(df.index[-1])['mon1']\n",
    "ltval = df['bd_cps'].iloc[-1]\n",
    "lt3m = value_text(df['3ma'].iloc[-1], 'plain')\n",
    "ltwk3m = value_text(df.wk3ma.iloc[-1], 'plain')\n",
    "yrdt = dtxt(df.index[-13])['mon1']\n",
    "pr3m = value_text(df['3ma'].iloc[-13], 'plain')\n",
    "prwk3m = value_text(df['wk3ma'].iloc[-13], 'plain')\n",
    "also = 'also ' if lt3m == ltwk3m else ''\n",
    "alsopr = 'also ' if pr3m == prwk3m else ''\n",
    "\n",
    "col = 'purple!80!magenta!80!white'\n",
    "col3 = 'blue!65!violet'\n",
    "node = end_node(df['3ma'], col3, date='m', offset=0.35)\n",
    "write_txt(text_dir/ 'wgt_h_node.txt', node)\n",
    "node = end_node(df['wk3ma'], col3, date='m', offset=0.35)\n",
    "write_txt(text_dir/ 'wgt_w_node.txt', node)\n",
    "wval = value_text(df.wk3ma.iloc[-1])\n",
    "text = ('Replication of the wage growth tracker shows '+\n",
    "        'matched-observation nominal median wage growth of '+\n",
    "        f'{lt3m} over the three months ending {ltdt}, '+\n",
    "        f'on an hourly basis, and {also}{ltwk3m} on a weekly '+\n",
    "        f'basis {c_line(col3)}. One year prior, in {yrdt}, '+\n",
    "        f'three-month moving average nominal median '+\n",
    "        f'wage growth was {pr3m}, on an hourly '+\n",
    "        f'basis, and {alsopr}{prwk3m} on a weekly basis.')\n",
    "write_txt(text_dir / 'atl_wgt.txt', text)\n",
    "print(text)\n",
    "\n",
    "ltval = df['zwc'].iloc[-1]\n",
    "prval = df['zwc'].iloc[-2]\n",
    "prdate = dtxt(df.index[-2])['mon1']\n",
    "yrval = df['zwc'].iloc[-13]\n",
    "\n",
    "zcol = 'red'\n",
    "node = end_node(df['zwc'], zcol, date='m')\n",
    "write_txt(text_dir/ 'zwc_node.txt', node)\n",
    "\n",
    "text = (f'In {ltdt}, {ltval:.1f} '+\n",
    "        'percent of individuals had no hourly wage growth, '+\n",
    "        f'compared to {prval:.1f} in {prdate} {c_line(zcol)}. '+\n",
    "        f'One year prior, in {yrdt}, {yrval:.1f} percent of '+\n",
    "        'individuals had no wage growth.')\n",
    "write_txt(text_dir / 'atl_zwc.txt', text)\n",
    "print(text)\n",
    "\n",
    "# Text for real wages lines\n",
    "cpi_dt = pd.read_csv(data_dir / 'cpi.csv', index_col='date', \n",
    "                     parse_dates=True).index[-1]\n",
    "cps_dt = cps_date()\n",
    "cps_month = dtxt(cps_dt)['mon3']\n",
    "cps_month2 = dtxt(cps_dt)['mon1']\n",
    "dt = dtxt(cps_dt)['datetime']\n",
    "if cps_dt > cpi_dt:\n",
    "    nowsrc = ', FRB Cleveland'\n",
    "    write_txt(text_dir / f'atl_wgt_nowsrc.txt', nowsrc)\n",
    "    mark = f'(see \\\\tikz \\draw[{col}, fill=white] (0pt,0pt) circle (2.0pt);)'\n",
    "    for s in ['RHR3', 'RWK3']:\n",
    "        lv = df[s+'e'].iloc[-1]\n",
    "        lvt = f'{lv:.1f}'\n",
    "        node = (f'\\\\node[label={{[align=left]0:{{\\scriptsize \\\\textit{{{lvt}}}}}}}, '+\n",
    "                f'circle, draw={col}, fill=white, inner sep=1.4pt] at '+\n",
    "                f'(axis cs:{dt}, {lv}) {{}};') \n",
    "        write_txt(text_dir / f'atl_wgt_{s}.txt', node)\n",
    "    hrt = value_text(df['RHR3e'].iloc[-1], 'plain')\n",
    "    wkt = value_text(df['RWK3e'].iloc[-1], 'plain')\n",
    "    also = 'also ' if hrt == wkt else ''\n",
    "    cpit = (f'The {cps_month} CPI is not yet published, but the '+\n",
    "            'real median wage growth estimate based on the CPI nowcast '+\n",
    "            f'is {hrt} on an hourly basis, and {also}{wkt} on a weekly basis '+\n",
    "            f'{mark}.')\n",
    "        \n",
    "if cps_dt == cpi_dt:\n",
    "    nowsrc = ''\n",
    "    write_txt(text_dir / f'atl_wgt_nowsrc.txt', nowsrc)\n",
    "    for s in ['RHR3', 'RWK3']:\n",
    "        write_txt(text_dir / f'atl_wgt_{s}.txt', end_node(df[s], col))\n",
    "    hrt = value_text(df['RHR3'].iloc[-1], 'plain')\n",
    "    wkt = value_text(df['RWK3'].iloc[-1], 'plain')\n",
    "    cpit = (f'In {cps_month2}, the real median wage growth is {hrt} '+\n",
    "            f'on an hourly basis, and {wkt} on a weekly basis. ')    \n",
    "    \n",
    "write_txt(text_dir / 'atl_wgt_cpi.txt', cpit)\n",
    "print(cpit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c31cd9d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-30T16:24:41.685916Z",
     "start_time": "2023-11-30T16:24:41.674582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Recent Data for wage growth chart\n",
    "df = pd.read_csv(data_dir / 'atl_wgt.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "\n",
    "cpi = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "cpidt = cpi.index[-73]\n",
    "data = (df.loc[cpidt:, '3ma'].to_frame()\n",
    "        .rename({'3ma': 'WGT'}, axis=1))\n",
    "data.loc[cpidt:].to_csv(data_dir / 'wgt_growth_recent.csv', \n",
    "                        index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e60668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c4308",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
