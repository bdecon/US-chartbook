{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:07.120053Z",
     "start_time": "2023-04-14T20:08:05.721785Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:12:04.798017Z",
     "start_time": "2022-02-28T03:12:04.792427Z"
    }
   },
   "source": [
    "### Consumer Price Index: Collect Information\n",
    "\n",
    "#### Relative importance\n",
    "\n",
    "https://www.bls.gov/cpi/tables/relative-importance/home.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:09.904007Z",
     "start_time": "2023-04-14T20:08:08.471223Z"
    }
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m wgt_dt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2022-12-01\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.bls.gov/cpi/tables/relative-importance/2022.htm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_html\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m t[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m t[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mU.S. City Average, \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m                                         regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m t[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mto_csv(data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpi_rel_wgts_raw.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     10\u001b[0m                      index_label\u001b[38;5;241m=\u001b[39mwgt_dt)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[1;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[1;32m   1203\u001b[0m io \u001b[38;5;241m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflavor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskiprows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskiprows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthousands\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthousands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mna_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_na\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisplayed_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisplayed_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextract_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextract_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/html.py:986\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[1;32m    985\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/html.py:262\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/html.py:821\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 821\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    823\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_content\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/html.py:802\u001b[0m, in \u001b[0;36m_LxmlFrameParser._build_doc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_url(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio):\n\u001b[0;32m--> 802\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    803\u001b[0m             r \u001b[38;5;241m=\u001b[39m parse(f, parser\u001b[38;5;241m=\u001b[39mparser)\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;66;03m# try to parse the input in the simplest way\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    530\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 640\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:569\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    568\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:649\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# Retrieve and store latest relative weights\n",
    "# URL should be updated every two years:\n",
    "# https://www.bls.gov/cpi/tables/relative-importance/home.htm\n",
    "wgt_dt = '2022-12-01'\n",
    "url = 'https://www.bls.gov/cpi/tables/relative-importance/2022.htm'\n",
    "t = pd.read_html(url,header=0, index_col=0)\n",
    "t[0].columns = t[0].columns.str.replace('U.S. City Average, ', '', \n",
    "                                        regex=True)\n",
    "t[0].dropna().to_csv(data_dir / 'cpi_rel_wgts_raw.csv', \n",
    "                     index_label=wgt_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series names and display level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:40:23.208835Z",
     "start_time": "2023-04-12T12:40:22.652183Z"
    }
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve item names and codes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://download.bls.gov/pub/time.series/cu/cu.item\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m codes \u001b[38;5;241m=\u001b[39m (\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m            \u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay_level\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m      5\u001b[0m codes\u001b[38;5;241m.\u001b[39mto_csv(data_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpi_codes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1289\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m   1274\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1275\u001b[0m     dialect,\n\u001b[1;32m   1276\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1285\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m   1286\u001b[0m )\n\u001b[1;32m   1287\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    710\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    721\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    722\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/common.py:363\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[1;32m    362\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[1;32m    364\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    366\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pandas/io/common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:222\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:531\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[1;32m    530\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[0;32m--> 531\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:640\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[0;32m--> 640\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:569\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[1;32m    568\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:502\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    501\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 502\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/urllib/request.py:649\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# Retrieve item names and codes\n",
    "url = 'https://download.bls.gov/pub/time.series/cu/cu.item'\n",
    "codes = (pd.read_table(url, index_col=0)\n",
    "           .loc[:, ['item_name', 'display_level']])\n",
    "codes.to_csv(data_dir / 'cpi_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:07.357108Z",
     "start_time": "2023-04-12T12:40:51.424364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Selected series to retrieve from API\n",
    "nsa = 'CUUR0000'\n",
    "sa = 'CUSR0000'\n",
    "lt = ['SA0', 'SAF1', 'SAH1', 'SACL1E', 'SASLE', 'SEHA', \n",
    "      'SA0E', 'SA0L1E', 'SETB01', 'SETA01', 'SETA02', 'SAE1',\n",
    "      'SAM']\n",
    "lts = ['SA0', 'SA0L1E']\n",
    "st = ['SAH', 'SEFV', 'SAF11', 'SAR',  'SAT', 'SAA', 'SAE2', \n",
    "      'SAG1', 'SEHC', 'SAH3', 'SEMD', 'SEMC', 'SEME',\n",
    "      'SETB', 'SETG', 'SAH21', 'SEHB', 'SEFV01', 'SEFV02',\n",
    "      'SEEB01', 'SEEB03', 'SEED03', 'SEEE03', ]\n",
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "code_names = codes['item_name'].to_dict().items()\n",
    "\n",
    "# Retrieve recent data from API \n",
    "dst = {nsa + code: name for code, name in code_names \n",
    "       if code in st}\n",
    "years = (2014, 2023)\n",
    "dfs = bls_api(dst, years, bls_key)\n",
    "\n",
    "# Retrieve recent data from API (SA)\n",
    "dst2 = {sa + code: name + ' (SA)' for code, name in code_names \n",
    "       if code in st}\n",
    "years = (2014, 2023)\n",
    "dfs2 = bls_api(dst2, years, bls_key)\n",
    "\n",
    "# Retrieve recent data from API (SA)\n",
    "dst3 = {sa + code: name + ' (SA)' for code, name in code_names \n",
    "       if code in lt and code not in lts}\n",
    "years = (2014, 2023)\n",
    "dfs3 = bls_api(dst3, years, bls_key)\n",
    "\n",
    "# Retrieve long-term data from API \n",
    "dlt = {nsa + code: name for code, name in code_names \n",
    "       if code in lt}\n",
    "dlts = {sa + code: name + ' (SA)' for code, name in code_names \n",
    "        if code in lts}\n",
    "years = (1988, 2023)\n",
    "dfl = bls_api({**dlt, **dlts}, years, bls_key)\n",
    "\n",
    "dfl.join(dfs).join(dfs2).join(dfs3).to_csv(data_dir / 'cpi_raw.csv', \n",
    "                     index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly CPI Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:08.984800Z",
     "start_time": "2023-04-12T12:41:08.951508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In March 2023, the one-month change in the consumer price index (CPI) was 0.1 percent (see \\cbox{blue}), following 0.4 percent in February 2023. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                parse_dates=True)\n",
    "s = df.rename({'All items (SA)': 'ALL_S'}, axis=1)[['ALL_S']]\n",
    "data = s.pct_change() * 100\n",
    "\n",
    "# Last row is empty for nowcast\n",
    "next_mo = data.index[-1] + pd.DateOffset(months=1)\n",
    "data.loc[next_mo, 'ALL_S'] = ''\n",
    "data['label'] = [dt.strftime('%b\\\\\\`%y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') for dt in data.index]\n",
    "data['FILL'] = 0\n",
    "data.iloc[-20:].to_csv(data_dir / 'cpi_monthly.csv', \n",
    "                         index_label='date', float_format='%g')\n",
    "ltdate = dtxt(data.index[-2])['mon1']\n",
    "prdate = dtxt(data.index[-3])['mon1']\n",
    "ltval = float(data.ALL_S.iloc[-2])\n",
    "prval = float(data.ALL_S.iloc[-3])\n",
    "text = (f'In {ltdate}, the one-month change '+\n",
    "        f'in the consumer price index (CPI) was {ltval:.1f} '+\n",
    "        f'percent {c_box(\"blue\")}, following '+\n",
    "        f'{prval:.1f} percent in {prdate}. ')\n",
    "write_txt(text_dir / 'cpi_monthly.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Line Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:13.226123Z",
     "start_time": "2023-04-12T12:41:13.197611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\href{https://www.bls.gov/cpi/}{Consumer prices} increased five percent over the year ending March 2023 (see {\\color{blue!60!cyan}\\textbf{---}}), according to the Consumer Price Index for all urban consumers (CPI-U). The core CPI, which does not include the more-volatile food and energy prices, increased 5.6 percent over the same one-year period (see {\\color{gray}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                parse_dates=True)\n",
    "rn = {'All items': 'ALL', 'All items less food and energy': 'CORE',\n",
    "      'All items (SA)': 'ALL_S', 'All items less food and energy (SA)': \n",
    "      'CORE_S'}\n",
    "df = df.rename(rn, axis=1)[rn.values()].pct_change(12).dropna() * 100\n",
    "df.to_csv(data_dir / 'cpi.csv', index_label='date', \n",
    "           float_format='%g')\n",
    "\n",
    "node_color = 'blue!60!cyan'\n",
    "node = end_node(df.ALL, node_color, offset=True, percent=True,\n",
    "                date='m', full_year=True)\n",
    "write_txt(text_dir / 'cpi_node.txt', node)\n",
    "\n",
    "date = dtxt(df.index[-1])['mon1']\n",
    "allitems = value_text(df['ALL'].iloc[-1])\n",
    "core = value_text(df['CORE'].iloc[-1])\n",
    "text = ('\\href{https://www.bls.gov/cpi/}{Consumer prices} '+\n",
    "        f'{allitems} over the year ending {date} '+\n",
    "        f'{c_line(node_color)}, according to the Consumer '+\n",
    "        'Price Index for all urban consumers (CPI-U). '+\n",
    "        'The core CPI, which does not include the more-'+\n",
    "        f'volatile food and energy prices, {core} over '+\n",
    "        f'the same one-year period {c_line(\"gray\")}.')\n",
    "write_txt(text_dir / 'cpi_main.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:13.997783Z",
     "start_time": "2023-04-12T12:41:13.979687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Line for AHE chart\n",
    "s = pd.read_csv(data_dir / 'cpi.csv', index_col='date', parse_dates=True)\n",
    "cpival = s['ALL_S'].iloc[-1].round(3)\n",
    "cpi_txt = f'{cpival:.1f} percent'\n",
    "text = ('\\\\addplot[dashed, ultra thick, red, sharp plot, update limits=false] '+\n",
    "        f'coordinates {{({cpival},-12.5) ({cpival}, 0.5)}} node[right] at '+\n",
    "        f'(axis cs:{cpival},-12.5) {{\\\\textbf{{CPI}} ({cpi_txt})}};')\n",
    "write_txt(text_dir / 'cpi_lt_line.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI: components contribution to total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:16.625923Z",
     "start_time": "2023-04-12T12:41:16.579080Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "# Weights and weight date\n",
    "rw = (pd.read_csv(data_dir / 'cpi_rel_wgts_raw.csv', \n",
    "                  index_col=0))\n",
    "wgt_date = pd.to_datetime(rw.index.name)\n",
    "wgts = rw['CPI-U'].drop_duplicates()\n",
    "\n",
    "# Calculate contribution to annual growth rate\n",
    "uwt = (((df.divide(df.loc[wgt_date])).multiply(wgts))\n",
    "       .divide((df['All items'].divide(df.loc[wgt_date, 'All items'])), \n",
    "               axis=0)).dropna(how='all', axis=1)\n",
    "cols = ['All items', 'Medical care', 'Housing', 'Food', \n",
    "        'Recreation', 'Education', 'Transportation', \n",
    "        'Apparel', 'Energy', 'Communication', 'Personal care']\n",
    "cont = uwt.multiply(df.pct_change(12)).loc['2019':, cols]\n",
    "\n",
    "res = cont.iloc[[-1, -13]].T\n",
    "dates = res.columns\n",
    "res.columns = ['Latest', 'Previous']\n",
    "res = res.sort_values('Latest', ascending=False)\n",
    "res.drop('All items').to_csv(data_dir / 'cpi_comp.csv', \n",
    "                             index_label='name')\n",
    "\n",
    "write_txt(text_dir / 'cpi_mo1.txt', dtxt(dates[0])['mon2'])\n",
    "write_txt(text_dir / 'cpi_mo2.txt', dtxt(dates[1])['mon2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:17.356079Z",
     "start_time": "2023-04-12T12:41:17.292193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In March 2023, housing prices contributed 3.5 percentage points to the CPI one-year inflation rate of 5.0 percent, substantially above the category's March 2022 contribution of 2.8 percentage points. Food prices added 1.1 percentage points to March 2023 inflation, in line with the year-prior contribution of 1.1 percentage points. Energy prices reduced the inflation rate by 0.4 percentage point in the latest data, compared to a contribution of 2.5 percentage points in March 2022.\n",
      "\n",
      "Recreation prices increased the inflation rate by 0.3 percentage point in March 2023, in line with the year-prior contribution of 0.3 percentage point. Transportation prices make up 16.7 percent of the CPI basket and subtracted 0.2 percentage point from overall inflation in the latest data, far below a contribution of four percentage points one year prior. \n"
     ]
    }
   ],
   "source": [
    "final = res.join(wgts)\n",
    "final['AtWgt'] = ((final['CPI-U'] / 100) * \n",
    "                  final.loc['All items', 'Latest'])\n",
    "final['Share'] = ((final['Latest'] / \n",
    "                   final.loc['All items', 'Latest'])) * 100\n",
    "final = final.drop('All items')\n",
    "final['Ratio'] = abs(final['Latest'] / final['AtWgt'])\n",
    "final['ltabs'] = abs(final['Latest'])\n",
    "final['Points'] = final['CPI-U'] * final['Ratio'] * final['ltabs']\n",
    "\n",
    "# Generate text\n",
    "styles = [('c', 'contribution'), ('to', 'contribution_to'), \n",
    "          ('of', 'contribution_of')]\n",
    "groups = [('lt', 'Latest'), ('pr', 'Previous')]\n",
    "final = final.join(pd.DataFrame({f'{name}_{cname}': final[col].apply(\n",
    "    lambda x: value_text(x, style, 'pp')) for (name, style), (cname, col) \n",
    "                              in itertools.product(styles, groups)}))\n",
    "compare = lambda x: compare_text(x.Latest, x.Previous, \n",
    "                                 cutoffs=[0.05, 0.3, 1])\n",
    "final['Compare'] = final.apply(compare, axis=1)\n",
    "casual = lambda x: value_text(x, 'contribution_to', 'pp', casual=True)\n",
    "final['to_lt_cas'] = final.Latest.apply(casual)\n",
    "increase = lambda x: value_text(x, 'increase_by', 'pp', adj='inflation')\n",
    "final['inc_lt'] = final.Latest.apply(increase)\n",
    "final['same_sign'] = final.apply(lambda x: np.where(\n",
    "    np.sign(x.Latest) == np.sign(x.Previous), \n",
    "    value_text(x.Previous, 'plain', 'pp'), \n",
    "    value_text(x.Previous, 'contribution_of', 'pp')), axis=1)\n",
    "t = final.sort_values('Points', ascending=False)\n",
    "t['of_lt'] = t.of_lt.str.replace(\"a \", \"\")\n",
    "t['of_pr'] = t.of_pr.str.replace(\"a \", \"\")\n",
    "t['overweight'] = ''\n",
    "ltdt = dtxt(dates[0])['mon1']\n",
    "prdt = dtxt(dates[1])['mon1']\n",
    "if t.Ratio.max() > 2:\n",
    "    ocat = t.Ratio.idxmax()\n",
    "    otxt = (f'The {ocat.lower()} category makes up '+\n",
    "            f'{t.loc[ocat, \"CPI-U\"]:.1f} percent of the CPI '+\n",
    "            f'basket, but accounts for {t.loc[ocat, \"Share\"]:.1f} '+\n",
    "            f'percent of {ltdt} inflation. ')\n",
    "    t.at[ocat, 'overweight'] = otxt\n",
    "    \n",
    "cat1 = t.index[0]\n",
    "ltall = res.loc['All items', 'Latest']\n",
    "cat2 = t.index[1]\n",
    "cat3 = t.index[2]\n",
    "cat4 = t.index[3]\n",
    "cat5 = t.drop([cat1, cat2, cat3, cat4]).sort_values('CPI-U').index[-1]\n",
    "text = (f'In {ltdt}, {cat1.lower()} prices {t.loc[cat1, \"to_lt\"]} '+\n",
    "        f'the CPI one-year inflation rate of {ltall:.1f} percent, '+\n",
    "        f\"{t.loc[cat1, 'Compare']} the category's {prdt} \"+\n",
    "        f'{t.loc[cat1, \"of_pr\"]}. {t.loc[cat2, \"overweight\"]}{cat2} '+\n",
    "        f'prices {t.loc[cat2, \"to_lt_cas\"]} {ltdt} inflation, '+\n",
    "        f'{t.loc[cat2, \"Compare\"]} the year-prior {t.loc[cat2, \"of_pr\"]}. '+\n",
    "        f'{t.loc[cat3, \"overweight\"]}{cat3} prices {t.loc[cat3, \"inc_lt\"]} '+\n",
    "        f'in the latest data, compared to {t.loc[cat3, \"same_sign\"]} '+\n",
    "        f'in {prdt}.\\n\\n{cat4} prices '+\n",
    "        f'{t.loc[cat4, \"inc_lt\"]} in {ltdt}, {t.loc[cat4, \"Compare\"]} '+\n",
    "        f'the year-prior {t.loc[cat4, \"of_pr\"]}. {t.loc[cat4, \"overweight\"]}'+\n",
    "        f'{cat5} prices make up {t.loc[cat5, \"CPI-U\"]:.1f} percent of the '+\n",
    "        f'CPI basket and {t.loc[cat5, \"to_lt\"]} overall inflation in the '+\n",
    "        f'latest data, {t.loc[cat5, \"Compare\"]} a {t.loc[cat5, \"of_pr\"]} '+\n",
    "        f'one year prior. {t.loc[cat5, \"overweight\"]}')\n",
    "write_txt(text_dir / 'cpicomp.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Relative Prices Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:20.214762Z",
     "start_time": "2023-04-12T12:41:20.178178Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPI data and calculate percent change\n",
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "dfc = df.pct_change(12) * 100\n",
    "\n",
    "# Create table\n",
    "tbl = dfc.iloc[[-1, -2, -3, -13]]\n",
    "tbl.index = [dtxt(i)['mon6'] for i in tbl.index]\n",
    "t19 = dfc.loc['2019'].mean().rename('2019')\n",
    "tpc = ((df.iloc[-1] / df.loc['2020-02-01']) - 1) * 100\n",
    "tbl = (pd.concat([tbl, t19.to_frame().T, tpc.rename('Since Feb `20')\n",
    "                  .to_frame().T]).applymap('{:,.1f}'.format))\n",
    "wgt_col = f'Weight, {dtxt(uwt.index[-1])[\"mon6\"]}'\n",
    "tbl = pd.concat([tbl, uwt.iloc[-1].apply('{:.3f}'.format).rename(wgt_col).to_frame().T])\n",
    "tbl.loc[wgt_col, 'All items'] = '100.0'\n",
    "\n",
    "order = ['All items', 'All items less food and energy',\n",
    "         'Housing', \"Owners' equivalent rent of residences\",\n",
    "         'Rent of primary residence', 'Lodging away from home', \n",
    "         'Household furnishings and operations', 'Household energy', \n",
    "         'Transportation', 'New vehicles',\n",
    "         'Used cars and trucks', 'Gasoline (all types)', \n",
    "         'Public transportation', 'Medical care', 'Professional services',\n",
    "         'Hospital and related services', 'Health insurance', 'Food',\n",
    "         'Food at home', 'Food away from home',\n",
    "         'Full service meals and snacks', \n",
    "         'Limited service meals and snacks', 'Recreation',\n",
    "         'Communication', 'Wireless telephone services',\n",
    "         'Internet services and electronic information providers', \n",
    "         'Education', 'College tuition and fees', \n",
    "         'Day care and preschool',\n",
    "         'Apparel', 'Personal care']\n",
    "final = tbl[order].T\n",
    "\n",
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "levels = codes.set_index('item_name')['display_level'].to_dict()\n",
    "final.index = [f'\\hspace{{2mm}} {c}' if levels[c] in [2, 3, 4] else c \n",
    "               for c in final.index]\n",
    "rn = {\"\\hspace{2mm} Owners' equivalent rent of residences\": \n",
    "      \"\\hspace{2mm} Owners' equivalent rent\",\n",
    "      'Household furnishings and operations':\n",
    "      '\\hspace{2mm} Household furnishings \\& ops.',\n",
    "      'Public transportation':\n",
    "      '\\hspace{2mm} Public transportation',\n",
    "      '\\hspace{2mm} Full service meals and snacks':\n",
    "      '\\hspace{4mm} Full-service',\n",
    "      '\\hspace{2mm} Limited service meals and snacks':\n",
    "      '\\hspace{4mm} Limited-service',\n",
    "      '\\hspace{2mm} Internet services and electronic information providers':\n",
    "      '\\hspace{2mm} Internet services'}\n",
    "final = (final.rename(rn))\n",
    "(final.to_csv(data_dir / 'cpi_comp.tex', sep='&', \n",
    "              lineterminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:21.000802Z",
     "start_time": "2023-04-12T12:41:20.982963Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing prices increased 7.8 percent over the year ending March 2023, far above the pre-COVID rate of 2.9 percent (the average monthly rate during 2019). Medical care prices increased 1.5 percent, these prices grew at an average rate of 2.8 percent during 2019. In contrast, prices of food consumed at home (groceries) increased 8.4 percent in the year ending March 2023 compared to 0.9 percent during 2019.\n",
      "\n",
      "Transportation prices decreased one percent over the year ending March 2023, slightly below the pre-COVID 0.3 percent decrease. Energy prices decreased 6.4 percent over the year, compared to an average 2.1 percent decrease on average in 2019. Energy prices are historically more volatile than other categories. \n"
     ]
    }
   ],
   "source": [
    "ltdt = dfc.index[-1]\n",
    "cdt = '2019'\n",
    "ltdate = dtxt(ltdt)['mon1']\n",
    "dfc = dfc.dropna()\n",
    "res = pd.DataFrame({ltdt: dfc.iloc[-1], \n",
    "                    cdt: dfc.loc[cdt].mean()})\n",
    "\n",
    "hc = res.loc['Housing', ltdt]\n",
    "h1 = value_text(res.loc['Housing', ltdt])\n",
    "hp = res.loc['Housing', cdt]\n",
    "hch = compare_text(hc, hp, [0.3, 1.0, 3.0])\n",
    "m1 = value_text(res.loc['Medical care', ltdt])\n",
    "mpr = value_text(res.loc['Medical care', cdt], casual=True, \n",
    "                 adj='average')\n",
    "fah1 = value_text(res.loc['Food at home', ltdt])\n",
    "fahpr = res.loc['Food at home', cdt]\n",
    "tc = res.loc['Transportation', ltdt]\n",
    "t1 = value_text(tc)\n",
    "tp = res.loc['Transportation', cdt]\n",
    "tpr = (value_text(tp, style='increase_end')\n",
    "       .replace('a ', '').replace('an ', ''))\n",
    "tch = compare_text(tc, tp, [0.3, 1.0, 3.0])\n",
    "e1 = value_text(res.loc['Energy', ltdt])\n",
    "epr = value_text(res.loc['Energy', cdt], style='increase_end', \n",
    "                 adj='average')\n",
    "\n",
    "text = (f'Housing prices {h1} over the year ending {ltdate}, '+\n",
    "        f'{hch} the pre-COVID rate of {hp:.1f} percent (the average '+\n",
    "        f'monthly rate during 2019). Medical care prices {m1}, '+\n",
    "        f'these prices {mpr} during 2019. '+\n",
    "        'In contrast, prices of food consumed at home '+\n",
    "        f'(groceries) {fah1} in the year ending {ltdate} '+\n",
    "        f'compared to {fahpr:.1f} percent during 2019.\\n\\n'+\n",
    "        f'Transportation prices {t1} over the year ending '+\n",
    "        f'{ltdate}, {tch} the pre-COVID {tpr}. Energy prices '+\n",
    "        f'{e1} over the year, compared to {epr} on average in '+\n",
    "        f'2019. Energy prices are historically more '+\n",
    "        'volatile than other categories. ')\n",
    "write_txt(text_dir / 'cpicomp2.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:24.204626Z",
     "start_time": "2023-04-12T12:41:24.186736Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPI data and calculate percent change\n",
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "dfy = df.pct_change(12) * 100\n",
    "dfc = df.pct_change() * 100\n",
    "dfa = (((dfc / 100) + 1)**(12) - 1) * 100\n",
    "# Create table\n",
    "tbl = dfc.iloc[[-1, -2, -3, -4, -5, -6, -12, -13]]\n",
    "tbl.index = [dtxt(i)['mon6'].replace(' ', '\\n\\n') for i in tbl.index]\n",
    "order = ['All items', 'All items less food and energy',\n",
    "         'Housing', \"Owners' equivalent rent of residences\",\n",
    "         'Rent of primary residence', 'Lodging away from home', \n",
    "         'Household furnishings and operations', 'Household energy', \n",
    "         'Transportation', 'New vehicles',\n",
    "         'Used cars and trucks', 'Gasoline (all types)', \n",
    "         'Public transportation', 'Medical care', 'Professional services',\n",
    "         'Hospital and related services', 'Health insurance', 'Food',\n",
    "         'Food at home', 'Food away from home',\n",
    "         'Full service meals and snacks', \n",
    "         'Limited service meals and snacks', 'Recreation',\n",
    "         'Communication', 'Wireless telephone services',\n",
    "         'Internet services and electronic information providers', \n",
    "         'Education', 'College tuition and fees', \n",
    "         'Day care and preschool',\n",
    "         'Apparel', 'Personal care']\n",
    "\n",
    "nsa = ['Health insurance', 'Limited service meals and snacks', \n",
    "       'Wireless telephone services']\n",
    "\n",
    "order = [i + ' (SA)' if i not in nsa else i for i in order]\n",
    "final = tbl[order].T.applymap('{:,.1f}'.format)\n",
    "final.index = final.index.str.replace(' (SA)', '', regex=False)\n",
    "\n",
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "levels = codes.set_index('item_name')['display_level'].to_dict()\n",
    "final.index = [f'\\hspace{{2mm}} {c}' if levels[c] in [2, 3, 4] else c \n",
    "               for c in final.index]\n",
    "rn = {\"\\hspace{2mm} Owners' equivalent rent of residences\": \n",
    "      \"\\hspace{2mm} Owners' equivalent rent\",\n",
    "      'Household furnishings and operations':\n",
    "      '\\hspace{2mm} Household furnishings \\& ops.',\n",
    "      '\\hspace{2mm} Full service meals and snacks':\n",
    "      '\\hspace{4mm} Full-service',\n",
    "      '\\hspace{2mm} Limited service meals and snacks':\n",
    "      '\\hspace{4mm} Limited-service*',\n",
    "      '\\hspace{2mm} Wireless telephone services':\n",
    "      '\\hspace{2mm} Wireless telephone services*',\n",
    "      '\\hspace{2mm} Health insurance':\n",
    "      '\\hspace{2mm} Health insurance*',\n",
    "      '\\hspace{2mm} Internet services and electronic information providers':\n",
    "      '\\hspace{2mm} Internet services'}\n",
    "final = (final.rename(rn))\n",
    "(final.to_csv(data_dir / 'cpi_comp_mo.tex', sep='&', \n",
    "              lineterminator='\\\\\\ ', quotechar=' '))\n",
    "#final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:25.097149Z",
     "start_time": "2023-04-12T12:41:25.084300Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Work in progress\n",
    "def month_comp(s):\n",
    "    '''Return text to describe the data from three consecutive months '''\n",
    "    '''from series with length of three and a monthly datetime index.'''\n",
    "    if len(s) != 3:\n",
    "        print('Series must be three consecutive months (length == 3)')\n",
    "        pass\n",
    "    \n",
    "    if isinstance(s, pd.DataFrame):\n",
    "        if len(s.columns == 1):\n",
    "            s = s.squeeze()\n",
    "        else:\n",
    "            print('Input must be series (one column)')\n",
    "            pass\n",
    "    \n",
    "    # Store date, month, and year\n",
    "    dt1 = s.index[-1]\n",
    "    mo1 = dt1.month\n",
    "    yr1 = dt1.year\n",
    "    dt2 = s.index[-2]\n",
    "    mo2 = dt2.month\n",
    "    yr2 = dt2.year\n",
    "    dt3 = s.index[-3]\n",
    "    mo3 = dt3.month\n",
    "    yr3 = dt3.year\n",
    "    \n",
    "    # Create date text for each month\n",
    "    date1 = dtxt(dt1)['mon1']\n",
    "    date2 = dtxt(dt2)['mon1']# if yr1 != yr2 else dtxt(dt2)['mon3']\n",
    "    date3 = dtxt(dt3)['mon1']# if yr1 != yr3 else dtxt(dt3)['mon3']\n",
    "    \n",
    "    # Store the values\n",
    "    val1 = round(s.iloc[-1],1)\n",
    "    vt1 = value_text(val1, threshold=0.1)\n",
    "    val2 = round(s.iloc[-2],1)\n",
    "    vt2 = value_text(val2, threshold=0.1)\n",
    "    val3 = round(s.iloc[-3],1)\n",
    "    vt3 = value_text(val3, threshold=0.1)\n",
    "    \n",
    "    # Check if values are the same\n",
    "    same_all = False\n",
    "    allt = ''\n",
    "    if val1 == val2 == val3:\n",
    "        same_all = True\n",
    "        allt = 'also '\n",
    "        \n",
    "    same1_2 = False\n",
    "    t12 = ''\n",
    "    if val1 == val2:\n",
    "        same1_2 = True\n",
    "        t12 = f'in both {date1} and {date2}'\n",
    "    t23 = ''\n",
    "    same2_3 = False\n",
    "    if val2 == val3:\n",
    "        same2_3 = True\n",
    "        t23 = f'in both {date2} and in {date3}'\n",
    "        \n",
    "    # Value text\n",
    "    txt1 = value_text(val1, 'plain')\n",
    "    txt2 = value_text(val1, 'plain')\n",
    "    txt3 = value_text(val1, 'plain')\n",
    "    \n",
    "    t1 = f'{vt1} in {date1}'\n",
    "    t2 = f'{vt2} in {date2}, and {vt3} in {date3}'\n",
    "    if same2_3 == True:\n",
    "        t2 = f'{vt2} {t23}'\n",
    "        \n",
    "    return([t1, t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:25.810188Z",
     "start_time": "2023-04-12T12:41:25.798105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The core CPI, which excludes food and energy, increased 0.4 percent in March 2023, or 4.7 percent annualized, substantially below the one-year core CPI inflation rate of 5.6 percent. The core CPI increased 0.5 percent in February 2023, and increased 0.4 percent in January 2023.\n",
      "\n",
      "In March, housing prices increased 0.3 percent, (3.6 percent annualized). Over the past three months, housing prices increased at an average annualized rate of 6.7 percent, substantially above the 12-month rate of 5.6 percent. Food prices was virtually unchanged in March, or 0.2 percent, annualized, compared to a three-month average of 3.7 percent.\n",
      "\n",
      "Transportation prices decreased at an annualized rate of 6.4 percent in March, and increased at an average annualized rate of 0.2 percent over the past three months. Energy prices decreased at an annualized rate of 35.0 percent in March, and decreased at an average annualized rate of five percent over the past three months.\n"
     ]
    }
   ],
   "source": [
    "# Core CPI\n",
    "s = 'All items less food and energy (SA)'\n",
    "s1 = dfc[s].iloc[-3:]\n",
    "vt = month_comp(s1) # Returns text describing changes\n",
    "\n",
    "# Compare monthly value to one-year (12-month) value\n",
    "chy = dfy[s].iloc[-1]\n",
    "cha = dfa[s].iloc[-1]\n",
    "chat = f'{cha:.1f} percent'\n",
    "ct = compare_text(cha, chy, [0.1, 0.5, 2.0])\n",
    "ctt = f'{ct} the one-year core CPI inflation rate of {chy:.1f} percent'\n",
    "\n",
    "txt1 = ('The core CPI, which excludes food and energy, '+\n",
    "        f'{vt[0]}, or {chat} annualized, '+\n",
    "        f'{ctt}. The core CPI {vt[1]}.\\n\\n')\n",
    "\n",
    "# Text for different categories\n",
    "ltdt = dtxt(dfc.index[-1])['mon1']\n",
    "ltmo = dtxt(dfc.index[-1])['mon3']\n",
    "\n",
    "cats = ['Housing (SA)', 'Transportation (SA)', 'Food (SA)', 'Energy (SA)']\n",
    "d = {c: {} for c in cats}\n",
    "for c in cats:\n",
    "    t = c[:-4].lower() + 'prices'\n",
    "    s1 = dfc[c].iloc[-3:]\n",
    "    vt = month_comp(s1)\n",
    "    ltv = dfc[c].iloc[-1]\n",
    "    ltvt = value_text(ltv, threshold=0.1)\n",
    "    ltvalmo = f'{ltvt} in {ltmo}'\n",
    "    lta = dfa[c].iloc[-1]\n",
    "    ltat = value_text(lta, 'plain', threshold=0.1)\n",
    "    ltat2 = value_text(lta, threshold=0.1, adj='annualized') + f' in {ltmo}'\n",
    "    lt3m = dfa[c].iloc[-3:].mean()\n",
    "    lt3mt = value_text(lt3m, threshold=0.1, adj='avg_ann')\n",
    "    chy = dfy[s].iloc[-1]\n",
    "    ct = compare_text(lt3m, chy, [0.1, 0.5, 2.0])\n",
    "    ctt = f'{ct} the 12-month rate of {chy:.1f} percent'\n",
    "    eqt = f'equivalent to an annualized rate of {ltat}'\n",
    "    eqt2 = f'an annualized rate of {ltat}'\n",
    "    eqt3 = f'or {ltat}, annualized'\n",
    "    eqt4 = f'({ltat} annualized)'\n",
    "    t3m = f'a three-month average of {lt3m:.1f} percent'\n",
    "    d[c]['t1'] = (f'In {ltmo}, {t} {ltvt}, {eqt4}. '+\n",
    "                  f'Over the past three months, {t} '+\n",
    "                  f'{lt3mt}, {ctt}.')\n",
    "    d[c]['t2'] = vt\n",
    "    d[c]['t3'] = ctt\n",
    "    d[c]['t4'] = eqt2\n",
    "    d[c]['t5'] = t3m\n",
    "    d[c]['t6'] = ltvalmo\n",
    "    d[c]['t7'] = ltat2\n",
    "    d[c]['t8'] = f'{lt3mt} over the past three months'\n",
    "    d[c]['t9'] = eqt3\n",
    "    d[c]['t0'] = eqt4\n",
    "    \n",
    "txt2 = (f'{d[\"Housing (SA)\"][\"t1\"]} Food prices {d[\"Food (SA)\"][\"t6\"]}'+\n",
    "       f', {d[\"Food (SA)\"][\"t9\"]}, compared to '+\n",
    "       f'{d[\"Food (SA)\"][\"t5\"]}.\\n\\nTransportation prices '+\n",
    "       f'{d[\"Transportation (SA)\"][\"t7\"]}, and '+\n",
    "       f'{d[\"Transportation (SA)\"][\"t8\"]}. Energy prices '+\n",
    "       f'{d[\"Energy (SA)\"][\"t7\"]}, and '+\n",
    "       f'{d[\"Energy (SA)\"][\"t8\"]}.')\n",
    "\n",
    "text = txt1 + txt2\n",
    "write_txt(text_dir / 'cpi_monthly_rel.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ('The one-month percent change in CPI categories provides a '+\n",
    "        'more-volatile but more-timely look into changes in relative prices. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Decomposition (ROUGH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:30.405361Z",
     "start_time": "2023-04-12T12:41:30.390604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Relative weights for series of interest, from here: \n",
    "# https://www.bls.gov/cpi/tables/relative-importance/home.htm\n",
    "rel_wgt = {'CUUR0000SAF1': [(('2009-12-01', '2011-12-01'), 13.738),\n",
    "                           (('2011-12-01', '2013-12-01'), 14.308),\n",
    "                           (('2013-12-01', '2015-12-01'), 13.891), \n",
    "                           (('2015-12-01', '2017-12-01'), 14.015), \n",
    "                           (('2017-12-01', '2019-12-01'), 13.384),\n",
    "                           (('2019-12-01', '2021-12-01'), 13.771),\n",
    "                           (('2021-12-01', '2023-12-01'), 13.370)],\n",
    "           'CUUR0000SA0': [(('2009-12-01', '2011-12-01'), 100.0),\n",
    "                           (('2011-12-01', '2013-12-01'), 100.0),\n",
    "                           (('2013-12-01', '2015-12-01'), 100.0), \n",
    "                           (('2015-12-01', '2017-12-01'), 100.0), \n",
    "                           (('2017-12-01', '2019-12-01'), 100.0),\n",
    "                           (('2019-12-01', '2021-12-01'), 100.0),\n",
    "                           (('2021-12-01', '2023-12-01'), 100.0)],\n",
    "           'CUUR0000SA0E': [(('2009-12-01', '2011-12-01'), 8.553),\n",
    "                            (('2011-12-01', '2013-12-01'), 9.679),\n",
    "                            (('2013-12-01', '2015-12-01'), 9.046), \n",
    "                            (('2015-12-01', '2017-12-01'), 6.816), \n",
    "                            (('2017-12-01', '2019-12-01'), 7.513),\n",
    "                            (('2019-12-01', '2021-12-01'), 6.706),\n",
    "                            (('2021-12-01', '2023-12-01'), 7.348)],\n",
    "           'CUUR0000SAH1': [(('2009-12-01', '2011-12-01'), 32.289),\n",
    "                            (('2011-12-01', '2013-12-01'), 31.539),\n",
    "                            (('2013-12-01', '2015-12-01'), 32.029), \n",
    "                            (('2015-12-01', '2017-12-01'), 33.15), \n",
    "                            (('2017-12-01', '2019-12-01'), 32.843),\n",
    "                            (('2019-12-01', '2021-12-01'), 33.158),\n",
    "                            (('2021-12-01', '2023-12-01'), 32.946)],\n",
    "           'CUUR0000SACL1E': [(('2009-12-01', '2011-12-01'), 21.276),\n",
    "                              (('2011-12-01', '2013-12-01'), 19.852),\n",
    "                              (('2013-12-01', '2015-12-01'), 19.71), \n",
    "                              (('2015-12-01', '2017-12-01'), 19.613), \n",
    "                              (('2017-12-01', '2019-12-01'), 19.849),\n",
    "                              (('2019-12-01', '2021-12-01'), 20.137),\n",
    "                              (('2021-12-01', '2023-12-01'), 21.699)],\n",
    "           'CUUR0000SASLE': [(('2009-12-01', '2011-12-01'), 56.432),\n",
    "                             (('2011-12-01', '2013-12-01'), 56.161),\n",
    "                             (('2013-12-01', '2015-12-01'), 57.353), \n",
    "                             (('2015-12-01', '2017-12-01'), 59.556), \n",
    "                             (('2017-12-01', '2019-12-01'), 59.254),\n",
    "                             (('2019-12-01', '2021-12-01'), 59.387),\n",
    "                             (('2021-12-01', '2023-12-01'), 57.583)]}\n",
    "series = {key: key for key, value in rel_wgt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:31.234671Z",
     "start_time": "2023-04-12T12:41:31.103801Z"
    }
   },
   "outputs": [],
   "source": [
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "ids = (codes.reset_index().set_index('item_name')\n",
    "       .item_code.apply(lambda x: 'CUUR0000' + x).to_dict())\n",
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                 parse_dates=True).rename(ids, axis=1)\n",
    "\n",
    "# Dictionary combining all the info for each series\n",
    "d = {i: {'name': i,\n",
    "         'values': df[i],\n",
    "         'rel_wgt': rel_wgt[i]} for i in list(rel_wgt.keys())}\n",
    "\n",
    "# Adjust for changes to relative importance\n",
    "df1, df2, df3, df4, df5, df6, df7 = (pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame())\n",
    "for i, v in d.items():\n",
    "    start, end = v['rel_wgt'][0][0][0], v['rel_wgt'][0][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][0][1], v['rel_wgt'][1][1]\n",
    "    df1.at[start: end, i] = (v['values'].loc[start: end])\n",
    "    df1[i] = (df1[i].diff().cumsum() / df1.loc[start, i] + 1)\n",
    "    df1.at[start, i] = 1.0\n",
    "    df1[i] = (df1[i] * rwc)\n",
    "    link = (df1.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][1][0][0], v['rel_wgt'][1][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][1][1], v['rel_wgt'][2][1]\n",
    "    df2[i] = (v['values'].loc[start: end])\n",
    "    df2[i] = df2[i].diff().cumsum() / df2.loc[start, i] + 1\n",
    "    df2.at[start, i] = 1.0\n",
    "    df2[i] = (df2[i] * rwc) * link\n",
    "    link = (df2.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][2][0][0], v['rel_wgt'][2][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][2][1], v['rel_wgt'][3][1]\n",
    "    df3[i] = (v['values'].loc[start: end])\n",
    "    df3[i] = df3[i].diff().cumsum() / df3.loc[start, i] + 1\n",
    "    df3.at[start, i] = 1.0\n",
    "    df3[i] = (df3[i] * rwc) * link\n",
    "    link = (df3.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][3][0][0], v['rel_wgt'][3][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][3][1], v['rel_wgt'][4][1]\n",
    "    df4[i] = (v['values'].loc[start: end])\n",
    "    df4[i] = df4[i].diff().cumsum() / df4.loc[start, i] + 1\n",
    "    df4.at[start, i] = 1.0\n",
    "    df4[i] = (df4[i] * rwc) * link\n",
    "    link = (df4.loc[end, i] / rwn)\n",
    "\n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][4][0][0], v['rel_wgt'][4][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][4][1], v['rel_wgt'][5][1]\n",
    "    df5[i] = (v['values'].loc[start: end])\n",
    "    df5[i] = df5[i].diff().cumsum() / df5.loc[start, i] + 1\n",
    "    df5.at[start, i] = 1.0\n",
    "    df5[i] = (df5[i] * rwc) * link\n",
    "    link = (df5.loc[end, i] / rwn)    \n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][5][0][0], v['rel_wgt'][5][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][5][1], v['rel_wgt'][6][1]\n",
    "    df6[i] = (v['values'].loc[start: end])\n",
    "    df6[i] = df6[i].diff().cumsum() / df6.loc[start, i] + 1\n",
    "    df6.at[start, i] = 1.0\n",
    "    df6[i] = (df6[i] * rwc) * link\n",
    "    link = (df6.loc[end, i] / rwn)   \n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][6][0][0], v['rel_wgt'][6][0][1]\n",
    "    rwc = v['rel_wgt'][6][1]\n",
    "    df7[i] = (v['values'].loc[start: end])\n",
    "    df7[i] = df7[i].diff().cumsum() / df7.loc[start, i] + 1\n",
    "    df7.at[start, i] = 1.0\n",
    "    df7[i] = (df7[i] * rwc) * link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-12T12:41:33.520914Z",
     "start_time": "2023-04-12T12:41:33.473743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In March 2023, core goods contributed 0.3 percentage point to the one-year non-seasonally-adjusted CPI inflation rate of 5.0 percent (see \\cbox{blue!85!black}), while core services excluding shelter contributed 1.4 percentage points (see \\cbox{green!60!black}). Shelter added 2.8 percentage points (see \\cbox{cyan!50!white}), and food \\& energy added 0.6 percentage point (see \\cbox{orange!80!red}).\n",
      "\n",
      " One year prior, in March 2022, the corresponding CPI inflation rate was 8.5 percent; core goods contributed 2.1 percentage points, core services excluding shelter contributed 1.1 percentage points, shelter contributed 1.8 percentage points, and food and energy added 3.7 percentage points.\n"
     ]
    }
   ],
   "source": [
    "res = pd.concat([df1, df2, df3, df4, df5, df6, df7])  \n",
    "# Drop duplicate pivot year data\n",
    "res = res[~res.index.duplicated(keep='first')] \n",
    "final = ((res.diff(12).divide(res['CUUR0000SA0'].diff(12), axis=0))\n",
    "         .multiply(res['CUUR0000SA0'].pct_change(12) * 100, axis=0))\n",
    "# Core services is services less food, energy, and shelter\n",
    "final['core_services'] = final['CUUR0000SASLE'] - final['CUUR0000SAH1']\n",
    "# Combine food and energy\n",
    "final['food_energy'] = final['CUUR0000SAF1'] + final['CUUR0000SA0E']\n",
    "final = final.dropna().round(2)\n",
    "d2 = (final[['CUUR0000SACL1E', 'core_services', 'CUUR0000SAH1', 'food_energy']]\n",
    "      .loc['2011-01-01':])\n",
    "col_names = ['core_goods', 'core_services', 'shelter', 'food_energy']\n",
    "d2.columns = col_names\n",
    "d2['total'] = final['CUUR0000SA0'].loc['2011-01-01':]\n",
    "\n",
    "d2.to_csv(data_dir / 'cpi_decomp.csv', index_label='date', \n",
    "           float_format='%g')\n",
    "\n",
    "ltdate = dtxt(d2.index[-1])['mon1']\n",
    "prdate = dtxt(d2.index[-13])['mon1']\n",
    "cg = value_text(d2.core_goods.iloc[-1], 'contribution_to', 'pp')\n",
    "cs = value_text(d2.core_services.iloc[-1], 'contribution', 'pp')\n",
    "sh = value_text(d2.shelter.iloc[-1], 'contribution', 'pp', \n",
    "                casual=True)\n",
    "fe = value_text(d2.food_energy.iloc[-1], 'contribution', 'pp', \n",
    "                casual=True)\n",
    "tot = d2.total.iloc[-1]\n",
    "cgpr = value_text(d2.core_goods.iloc[-13], 'contribution', 'pp')\n",
    "cspr = value_text(d2.core_services.iloc[-13], 'contribution', 'pp')\n",
    "shpr = value_text(d2.shelter.iloc[-13], 'contribution', 'pp')\n",
    "fepr = value_text(d2.food_energy.iloc[-13], 'contribution', 'pp', \n",
    "                  casual=True)\n",
    "totpr = d2.total.iloc[-13]\n",
    "colors = {'cg': 'blue!85!black', 'cs': 'green!60!black', \n",
    "          'sh': 'cyan!50!white', 'fe': 'orange!80!red'}\n",
    "cbs = {name: c_box(color) for name, color in colors.items()}\n",
    "text = (f'In {ltdate}, core goods {cg} the one-year non-seasonally-'+\n",
    "        f'adjusted CPI inflation rate of {tot:.1f} percent '+\n",
    "        f'{cbs[\"cg\"]}, while core services excluding shelter {cs} '+\n",
    "        f'{cbs[\"cs\"]}. Shelter {sh} {cbs[\"sh\"]}, and food \\& energy '+\n",
    "        f'{fe} {cbs[\"fe\"]}.\\n\\n One year prior, in {prdate}, the '+\n",
    "        f'corresponding CPI inflation rate was {totpr:.1f} percent; '\n",
    "        f'core goods {cgpr}, core services excluding shelter {cspr}, '+\n",
    "        f'shelter {shpr}, and food and energy {fepr}.')\n",
    "write_txt(text_dir / 'cpi_decomp.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T12:24:31.075479Z",
     "start_time": "2022-05-11T12:24:31.075469Z"
    }
   },
   "outputs": [],
   "source": [
    "# cols = list(rel_wgt.keys())\n",
    "# d = {c: {} for c in cols}\n",
    "# data = {c: {} for c in cols}\n",
    "# dates = [f'{i}-12-01' for i in range(2009, 2023, 2)]\n",
    "# for s, i in itertools.product(cols, dates):\n",
    "#     start, end, prev = (i, dtxt(pd.to_datetime(i) + \n",
    "#                          pd.DateOffset(years=2))['datetime'],\n",
    "#                         dtxt(pd.to_datetime(i) - \n",
    "#                          pd.DateOffset(years=2))['datetime'])\n",
    "#     ri = [w[1] for w in rel_wgt[s] if w[0][0] == start][0]\n",
    "#     base = df.loc[start, s]\n",
    "#     print(s)\n",
    "#     dt = pd.to_datetime(i)\n",
    "#     d10 = pd.to_datetime('2010-01-01')\n",
    "#     prev_link = d[s][prev] if dt > d10 else df.loc[start, s]\n",
    "#     print(prev_link)\n",
    "#     val = (ri * df.loc[start:end, s]) / prev_link\n",
    "#     d[s][start] = (val[-1] / val[0]) * df.loc[:end, s].iloc[-1]\n",
    "#     data[s].update(val.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:31.714212Z",
     "start_time": "2023-04-14T20:08:27.991027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "df = bls_api({'WPUFD4': 'PPIFD',\n",
    "              'WPSFD4': 'PPIFDsa',\n",
    "              'WPU00000000': 'PPIACO',\n",
    "              'WPUFD49116': 'PPIFD_Core',\n",
    "              'WPU101707': 'Steel',\n",
    "              'WPU081': 'Lumber'}, (1988, 2023), bls_key)\n",
    "df.to_csv(data_dir / 'ppi_index.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:31.735286Z",
     "start_time": "2023-04-14T20:08:31.716160Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bureau of Labor Statistics \\href{https://www.bls.gov/ppi/}{report} \\textbf{prices producers receive}. The goods-only producer price index (PPI) for all commodities (see {\\color{green!80!blue}\\textbf{---}}) decreased 1.2 percent over the year ending March 2023, far below the 12-month growth rate of 20.9 percent in March 2022. The index for final demand goods, services, and construction increased 2.7 percent over the year ending March 2023 (see {\\color{violet}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'ppi_index.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "ppi = (df[['PPIACO', 'PPIFD']].pct_change(12) * 100)\n",
    "ppi.to_csv(data_dir / 'ppi.csv', index_label='date')\n",
    "\n",
    "adj = node_adj(ppi[['PPIACO', 'PPIFD']])\n",
    "smax = ppi[['PPIACO', 'PPIFD']].iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'PPIACO': 'green!80!blue', \n",
    "          'PPIFD': 'violet'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(ppi[series], color, \n",
    "                            date=date[series], \n",
    "                            percent=True, full_year=True, \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'ppi_nodes.txt', nodes)  \n",
    "\n",
    "ch = value_text(ppi.PPIACO.iloc[-1])\n",
    "fd = value_text(ppi.PPIFD.iloc[-1])\n",
    "prval = ppi.PPIACO.iloc[-13]\n",
    "yr3val = ppi.PPIACO.rolling(36).mean().iloc[-1]\n",
    "compare = compare_text(ppi.PPIACO.iloc[-1], prval, [1.0, 3.0, 5.0])\n",
    "date = dtxt(ppi.index[-1])['mon1']\n",
    "date2 = dtxt(ppi.index[-13])['mon1']\n",
    "\n",
    "text = ('The Bureau of Labor Statistics \\\\href{https://www.bls.gov/ppi/}'+\n",
    "        '{report} \\\\textbf{prices producers receive}. The goods-only producer '+\n",
    "        f'price index (PPI) for all commodities {c_line(colors[\"PPIACO\"])} '+\n",
    "        f'{ch} over the year ending {date}, {compare} the 12-month '+\n",
    "        f'growth rate of {prval:.1f} percent in {date2}. The index for final '+\n",
    "        f'demand goods, services, and construction {fd} over the year ending '+\n",
    "        f'{date} {c_line(colors[\"PPIFD\"])}.')\n",
    "write_txt(text_dir / 'ppi_main.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:33.807841Z",
     "start_time": "2023-04-14T20:08:33.770706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In March 2023, the one-month change in PPI final demand prices was -0.5 percent (see \\cbox{violet}), following -0.0 percent in February 2023. The one-month change in the all commodities index was -0.6 percent (see \\cbox{green!80!blue}) in March 2023 and -0.6 percent in February 2023.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'ppi_index.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "s = df[['PPIFDsa', 'PPIACO']]\n",
    "data = ((np.log(s) - np.log(s.shift(1)))) * 100\n",
    "data['label'] = [dt.strftime('%b\\\\\\`%y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') for dt in data.index]\n",
    "data.iloc[-19:].to_csv(data_dir / 'ppi_monthly.csv', \n",
    "                         index_label='date', float_format='%g')\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "prdate = dtxt(data.index[-2])['mon1']\n",
    "ltval = data.PPIFDsa.iloc[-1]\n",
    "prval = data.PPIFDsa.iloc[-2]\n",
    "ltaval = data.PPIACO.iloc[-1]\n",
    "praval = data.PPIACO.iloc[-2]\n",
    "text = (f'In {ltdate}, the one-month change '+\n",
    "        f'in PPI final demand prices was {ltval:.1f} '+\n",
    "        f'percent {c_box(\"violet\")}, following '+\n",
    "        f'{prval:.1f} percent in {prdate}. The one-month '+\n",
    "        f'change in the all commodities index was {ltaval:.1f} '+\n",
    "        f'percent {c_box(\"green!80!blue\")} in {ltdate} and {praval:.1f} '+\n",
    "        f'percent in {prdate}.')\n",
    "write_txt(text_dir / 'ppi_monthly.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:34.518983Z",
     "start_time": "2023-04-14T20:08:34.489855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the producer price index, cold-rolled steel sheet and strip prices have decreased 31.1 percent over the year ending March 2023, and increased 55.8 percent total since December 2019. Lumber prices decreased 40.8 percent over the year ending March 2023, and increased 25.5 percent total since 2019.\n"
     ]
    }
   ],
   "source": [
    "p = df[['Steel', 'Lumber']]\n",
    "data = (p / p.iloc[0]).loc['1989':]\n",
    "data.to_csv(data_dir / 'ppi_commodities.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "stlt = value_text(data.Steel.pct_change(12).iloc[-1] * 100)\n",
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "st19 = value_text(((data.Steel.iloc[-1] / \n",
    "                    data.loc['2019-12-01', 'Steel']) - 1) * 100)\n",
    "lumlt = value_text(data.Lumber.pct_change(12).iloc[-1] * 100)\n",
    "lum19 = value_text(((data.Lumber.iloc[-1] / \n",
    "                    data.loc['2019-12-01', 'Lumber']) - 1) * 100)\n",
    "text = ('From the producer price index, cold-rolled steel sheet and strip '+\n",
    "        f'prices have {stlt} over the year ending {ltdt}, and {st19} total '+\n",
    "        f'since December 2019. Lumber prices {lumlt} over the year '+\n",
    "        f'ending {ltdt}, and {lum19} total since 2019.')\n",
    "write_txt(text_dir / 'ppi_commodities.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import/Export Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:45.269204Z",
     "start_time": "2023-04-14T20:08:41.518455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'EIUIR': 'Imports', \n",
    "          'EIUIQ': 'Exports',\n",
    "          'EIUIREXFUELS': 'ImpExFuels',\n",
    "          'EIUIR10': 'ImpFuels',\n",
    "          'EIUIQEXAG': 'ExpExAg',\n",
    "          'EIUIQAG': 'ExpAg'}\n",
    "\n",
    "# Start year and end year\n",
    "years = (1988, 2023)\n",
    "df = bls_api(series, years, bls_key)\n",
    "\n",
    "df.to_csv(data_dir / 'mxpi_main.csv', index_label='date')\n",
    "\n",
    "srs = ['Imports', 'Exports']\n",
    "(df[srs].pct_change(12).dropna() * 100).to_csv(data_dir / 'mxpi.csv', \n",
    "                                               index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:45.292635Z",
     "start_time": "2023-04-14T20:08:45.270956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bureau of Labor Statistics \\href{https://www.bls.gov/news.release/ximpim.nr0.htm}{report} changes in the prices of imports and exports. Over the year ending March 2023, \\textbf{US import prices} fell 4.6 percent (see {\\color{cyan!85!yellow}\\textbf{---}}), following a decrease of 1.1 percent in February and an increase of 0.9 percent in January. Excluding fuels, US import prices decreased 1.5 percent in March 2023 and grew 0.2 percent in February. Over the three years ending February 2020, prior to the US COVID-19 pandemic, US import prices increased at an average rate of 1.3 percent. Excluding fuels, import prices increased at an average rate of 0.3 percent during the same three-year pre-COVID period.\n",
      "\n",
      "\\textbf{Prices of US exports} (see {\\color{red!25!orange}\\textbf{---}}) fell 4.8 percent over the year ending March 2023, compared to 0.8 percent in February, an increase of two percent in January, and 1.5 percent on average during the three years ending February 2020. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'mxpi_main.csv', index_col='date')\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "data = (df.pct_change(12).dropna() * 100)\n",
    "\n",
    "adj = node_adj(data[['Imports', 'Exports']])\n",
    "smax = data[['Imports', 'Exports']].iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'Imports': 'cyan!85!yellow', \n",
    "          'Exports': 'red!25!orange'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(data[series], color, \n",
    "                            date=date[series], \n",
    "                            percent=True, full_year=True, \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'mxpi_nodes.txt', nodes)  \n",
    "\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "prdate = dtxt(data.index[-2])['mon1']\n",
    "prdate2 = dtxt(data.index[-3])['mon1']\n",
    "mv1 = data['Imports'].iloc[-1]\n",
    "mv2 = data['Imports'].iloc[-2]\n",
    "mv3 = data['Imports'].iloc[-3]\n",
    "mv4 = data.loc['2017-03-01': '2020-02-01', 'Imports'].mean()\n",
    "m1 = value_text(mv1, casual=True, threshold=0.1, obj='plural')\n",
    "m2 = value_text(mv2, style='increase_of', threshold=0.1, obj='plural')\n",
    "m3 = value_text(mv3, style='increase_of', threshold=0.1, obj='plural')\n",
    "mpc = value_text(mv4, threshold=0.1, obj='plural', adj='average')\n",
    "mfv1 = data['ImpExFuels'].iloc[-1]\n",
    "mfv2 = data['ImpExFuels'].iloc[-2]\n",
    "mfv3 = data.loc['2017-03-01': '2020-02-01', 'ImpExFuels'].mean()\n",
    "mf1 = value_text(mfv1, threshold=0.1, obj='plural')\n",
    "mf2 = value_text(mfv2, casual=True, threshold=0.1, obj='plural')\n",
    "mfpc = value_text(mfv3, threshold=0.1, obj='plural', adj='average')\n",
    "if data.index[-1].year == data.index[-2].year:\n",
    "    prdate = dtxt(data.index[-2])['mon3']\n",
    "if data.index[-2].year == data.index[-3].year:\n",
    "    prdate2 = dtxt(data.index[-3])['mon3']\n",
    "if np.sign(mv2) == np.sign(mv3):\n",
    "    m3 = f'{abs(mv3):.1f} percent'\n",
    "ftxt = f'{m2} in {prdate} and {m3} in {prdate2}'\n",
    "\n",
    "xv1 = data['Exports'].iloc[-1]\n",
    "xv2 = data['Exports'].iloc[-2]\n",
    "xv3 = data['Exports'].iloc[-3]\n",
    "xv4 = data.loc['2017-03-01': '2020-02-01', 'Exports'].mean()\n",
    "x1 = value_text(xv1, casual=True, threshold=0.1, obj='plural')\n",
    "x2 = value_text(xv2, style='increase_of', threshold=0.1, obj='plural')\n",
    "x3 = value_text(xv3, style='increase_of', threshold=0.1, obj='plural')\n",
    "x4 = value_text(xv4, style='increase_of', threshold=0.1, obj='plural')\n",
    "if np.sign(xv1) == np.sign(xv2):\n",
    "        x2 = f'{abs(xv2):.1f} percent'\n",
    "if np.sign(xv2) == np.sign(xv3):\n",
    "        x3 = f'{abs(xv3):.1f} percent'\n",
    "if np.sign(xv3) == np.sign(xv4):\n",
    "        x4 = f'{abs(xv4):.1f} percent'\n",
    "ftxt2 = (f'compared to {x2} in {prdate}, {x3} in {prdate2}, and {x4} '+\n",
    "         'on average during the three years ending February 2020')\n",
    "\n",
    "url = 'https://www.bls.gov/news.release/ximpim.nr0.htm'\n",
    "text = (f'The Bureau of Labor Statistics \\href{{{url}}}{{report}} '+\n",
    "        'changes in the prices of imports and exports. Over the '+\n",
    "        f'year ending {ltdate}, \\\\textbf{{US import prices}} {m1} '+\n",
    "        f'{c_line(colors[\"Imports\"])}, following {ftxt}. Excluding '+\n",
    "        f'fuels, US import prices {mf1} in {ltdate} and {mf2} '+\n",
    "        f'in {prdate}. Over the three years ending February 2020, '+\n",
    "        'prior to the US COVID-19 pandemic, US import prices '+\n",
    "        f'{mpc}. Excluding fuels, import prices {mfpc} '+\n",
    "        'during the same three-year pre-COVID period.\\n\\n'+\n",
    "        f'\\\\textbf{{Prices of US exports}} {c_line(colors[\"Exports\"])} '+\n",
    "        f'{x1} over the year ending {ltdate}, {ftxt2}. ')\n",
    "write_txt(text_dir / 'mxpi.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCE Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-31T15:37:29.627781Z",
     "start_time": "2023-03-31T15:37:29.589117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of February 2023, \\textbf{PCE inflation}, measured as the one-year percent change in the overall index, is 5.0 percent (see {\\color{orange!80!yellow}\\textbf{---}}), compared to 5.3 percent in January 2023, and 6.4 percent in February 2022. Core PCE inflation, which excludes food and energy, was 4.6 percent in February 2023 (see {\\color{blue!60!black}\\textbf{---}}), 4.7 percent in January 2023, and 5.4 percent in February 2022.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'nipa20804.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "df[['DPCERG', 'DPCCRG']].to_csv(data_dir / 'pce_index.csv', \n",
    "                    index_label='date')\n",
    "pce = pd.DataFrame()\n",
    "pce['PCE'] = df['DPCERG'].pct_change(12).dropna() * 100.0\n",
    "node_color = 'orange!80!yellow'\n",
    "node = end_node(pce['PCE'], node_color, date='m', percent=True, \n",
    "                full_year=True, offset=-0.2)\n",
    "write_txt(text_dir / 'pce_pi_node.txt', node)\n",
    "\n",
    "pce['CORE'] = df['DPCCRG'].pct_change(12).dropna() * 100.0\n",
    "pce.to_csv(data_dir / 'pce_pi.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(pce.index[-1])['mon1']\n",
    "prdate = dtxt(pce.index[-2])['mon1']\n",
    "pryrdate = dtxt(pce.index[-13])['mon1']\n",
    "ltval = pce.PCE.iloc[-1]\n",
    "prval = pce.PCE.iloc[-2]\n",
    "pryrval = pce.PCE.iloc[-13]\n",
    "ltcore = pce.CORE.iloc[-1]\n",
    "prcore = pce.CORE.iloc[-2]\n",
    "pryrcore = pce.CORE.iloc[-13]\n",
    "col2 = 'blue!60!black'\n",
    "text = (f'As of {ltdate}, \\\\textbf{{PCE inflation}}, measured as the one-'+\n",
    "        f'year percent change in the overall index, is {ltval:.1f} '+\n",
    "        f'percent {(c_line(node_color))}, compared to '+\n",
    "        f'{prval:.1f} percent in {prdate}, and {pryrval:.1f} '+\n",
    "        f'percent in {pryrdate}. Core PCE inflation, which excludes '+\n",
    "        f'food and energy, was {ltcore:.1f} percent in {ltdate} '+\n",
    "        f'{c_line(col2)}, {prcore:.1f} percent in '+\n",
    "        f'{prdate}, and {pryrcore:.1f} percent in {pryrdate}.')\n",
    "write_txt(text_dir / 'pce_inf_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimmed mean PCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T01:37:30.139086Z",
     "start_time": "2023-04-06T01:37:29.489276Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trimmed-mean PCE from Dallas Fed\n",
    "url = 'https://www.dallasfed.org/research/~/media/documents/research/pce/pcehist.xls'\n",
    "tmpce = (pd.read_excel(url, index_col=0, header=3, parse_dates=True)\n",
    "           .loc['1988':].dropna(axis=1))\n",
    "tmpce.to_csv(data_dir / 'pce_tm.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-06T01:37:30.272168Z",
     "start_time": "2023-04-06T01:37:30.250190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trimmed-mean PCE price index increased 4.6 percent over the year ending February 2023 (see {\\color{violet!60!magenta}\\textbf{---}}). By excluding top and bottom categories, the trimmed-mean rate was 0.4 percentage point below the all-items PCE rate. In January 2023, the \\textbf{trimmed-mean inflation rate} was 4.6 percent, 0.7 percentage point below the all-items rate. From 2017--2019, the average trimmed-mean rate was 1.9 percent, 0.1 percentage point above the all-items rate.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'pce_tm.csv', index_col='date', \n",
    "                 parse_dates=True).loc['1989':, '12-month']\n",
    "pce = pd.read_csv(data_dir / 'pce_pi.csv', index_col='date', \n",
    "                  parse_dates=True).loc['1989':, 'PCE']\n",
    "df.to_csv(data_dir / 'pce_tm12.csv', index_label='date')\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "ltval = df.iloc[-1]\n",
    "prdate = dtxt(df.index[-2])['mon1']\n",
    "prval = df.iloc[-2]\n",
    "ltvaltxt = value_text(ltval, threshold=0.1)\n",
    "diff =  ltval - pce.loc[df.index[-1]]\n",
    "difftxt = value_text(diff, 'above_below', ptype='pp')\n",
    "diff2 =  prval - pce.loc[df.index[-2]]\n",
    "difftxt2  = value_text(diff2, 'above_below', ptype='pp')\n",
    "pcval = df.loc['2017': '2019'].mean()\n",
    "diff3 = pcval - pce.loc['2017': '2019'].mean()\n",
    "difftxt3  = value_text(diff3, 'above_below', ptype='pp')\n",
    "color = 'violet!60!magenta'\n",
    "node = end_node(df, color, date='m', percent=True, \n",
    "                full_year=True, offset=-0.1)\n",
    "write_txt(text_dir / 'pce_tm_node.txt', node)\n",
    "text = (f'The trimmed-mean PCE price index {ltvaltxt} over the year '+\n",
    "        f'ending {ltdate} (see {{\\color{{{color}}}\\\\textbf{{---}}}}). '+\n",
    "        'By excluding top and bottom categories, the trimmed-'+\n",
    "        f'mean rate was {difftxt} the all-items PCE rate. In '+\n",
    "        f'{prdate}, the \\\\textbf{{trimmed-mean inflation rate}} was '+\n",
    "        f'{prval:.1f} percent, {difftxt2} the all-items rate. From '+\n",
    "        f'2017--2019, the average trimmed-mean rate was {pcval:.1f} '+\n",
    "        f'percent, {difftxt3} the all-items rate.')\n",
    "write_txt(text_dir / 'pce_tm_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T20:08:46.716815Z",
     "start_time": "2023-04-14T20:08:46.638688Z"
    }
   },
   "outputs": [],
   "source": [
    "pce = pd.read_csv(data_dir / 'pce_index.csv', \n",
    "                  index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "cpi_rn = {'All items': 'CPI', 'All items less food and energy': 'CPI_CORE'}\n",
    "cpi = (pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                   index_col='date', parse_dates=True)\n",
    "         .rename(cpi_rn, axis=1)).pct_change(12) * 100\n",
    "ppi = pd.read_csv(data_dir / 'ppi_index.csv', \n",
    "                  index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "mxpi = pd.read_csv(data_dir / 'mxpi_main.csv', \n",
    "                   index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "res = pce.join([cpi, ppi, mxpi], how='outer')\n",
    "keep_cols = ['CPI', 'CPI_CORE', 'PPIFD', 'Imports', \n",
    "             'Exports', 'DPCERG', 'DPCCRG']\n",
    "tm = pd.read_csv(data_dir / 'pce_tm.csv', \n",
    "                 index_col='date', parse_dates=True)['12-month']\n",
    "srs = {'CPI': 'CPI, All Items',\n",
    "       'CPI_CORE': 'CPI, ex. Food \\& Energy',\n",
    "       'PPIFD': 'PPI, Final Demand',\n",
    "       'Imports': 'Imports Price Index',\n",
    "       'Exports': 'Exports Price Index',\n",
    "       'DPCERG': 'PCE, All Items',\n",
    "       'DPCCRG': 'PCE, ex. Food \\& Energy',\n",
    "       '12-month': 'PCE, Trimmed Mean'}\n",
    "res12 = (res[keep_cols].join(tm, how='outer').rename(srs, axis=1))\n",
    "tbl = res12.iloc[[-1, -2, -3, -4, -13, -25]].T\n",
    "tbl.columns = [dtxt(c)['mon6'] for c in tbl.columns]\n",
    "tbl['`17--19 Avg.'] = res12.loc['2017': '2019'].mean()\n",
    "tbl['`00-- Avg.'] = res12.loc['2000':].mean()\n",
    "tbl = tbl.applymap('{:.1f}'.format).replace('nan', '--')\n",
    "tbl.to_csv(data_dir / 'prices_12m.tex', sep='&', lineterminator='\\\\\\ ', \n",
    "           quotechar=' ', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
