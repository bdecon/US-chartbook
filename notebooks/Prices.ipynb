{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:18:20.461519Z",
     "start_time": "2022-02-28T03:18:19.833893Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:12:04.798017Z",
     "start_time": "2022-02-28T03:12:04.792427Z"
    }
   },
   "source": [
    "### Consumer Price Index: Collect Information\n",
    "\n",
    "#### Relative importance\n",
    "\n",
    "https://www.bls.gov/cpi/tables/relative-importance/home.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and store latest relative weights\n",
    "# URL should be updated every two years:\n",
    "# https://www.bls.gov/cpi/tables/relative-importance/home.htm\n",
    "wgt_dt = '2021-12-01'\n",
    "url = 'https://www.bls.gov/cpi/tables/relative-importance/2021.htm'\n",
    "t = pd.read_html(url,header=1, index_col=0)\n",
    "t[0].dropna().to_csv(data_dir / 'cpi_rel_wgts_raw.csv', \n",
    "                     index_label=wgt_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series names and display level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve item names and codes\n",
    "url = 'https://download.bls.gov/pub/time.series/cu/cu.item'\n",
    "codes = (pd.read_table(url, index_col=0)\n",
    "           .loc[:, ['item_name', 'display_level']])\n",
    "codes.to_csv(data_dir / 'cpi_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected series to retrieve from API\n",
    "nsa = 'CUUR0000'\n",
    "sa = 'CUSR0000'\n",
    "lt = ['SA0', 'SAF1', 'SAH1', 'SACL1E', 'SASLE', 'SEHA', \n",
    "      'SA0E', 'SA0L1E', 'SETB01', 'SETA01', 'SETA02', 'SAE1',\n",
    "      'SAM']\n",
    "lts = ['SA0', 'SA0L1E']\n",
    "st = ['SAH', 'SEFV', 'SAF11', 'SAR',  'SAT', 'SAA', 'SAE2', \n",
    "      'SAG1', 'SEHC', 'SAH3', 'SEMD', 'SEMC', 'SEME',\n",
    "      'SETB', 'SETG', 'SAH21', 'SEHB', 'SEFV01', 'SEFV02',\n",
    "      'SEEB01', 'SEEB03', 'SEED03', 'SEEE03', ]\n",
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "code_names = codes['item_name'].to_dict().items()\n",
    "\n",
    "# Retrieve recent data from API \n",
    "dst = {nsa + code: name for code, name in code_names \n",
    "       if code in st}\n",
    "years = (2014, 2023)\n",
    "dfs = bls_api(dst, years, bls_key)\n",
    "\n",
    "# Retrieve long-term data from API \n",
    "dlt = {nsa + code: name for code, name in code_names \n",
    "       if code in lt}\n",
    "dlts = {sa + code: name + ' (SA)' for code, name in code_names \n",
    "        if code in lts}\n",
    "years = (1988, 2023)\n",
    "dfl = bls_api({**dlt, **dlts}, years, bls_key)\n",
    "\n",
    "dfl.join(dfs).to_csv(data_dir / 'cpi_raw.csv', \n",
    "                     index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly CPI Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:22:15.559162Z",
     "start_time": "2022-02-28T03:22:15.545730Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In January 2022, the annualized one-month change in the consumer price index was 7.7 percent (see\\cbox{blue}), following 6.9 percent in December 2021. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                parse_dates=True)\n",
    "s = df.rename({'All items (SA)': 'ALL_S'}, axis=1)[['ALL_S']]\n",
    "data = ((np.log(s) - np.log(s.shift(1))) * 12) * 100\n",
    "data['label'] = [dt.strftime('%b\\\\\\`%y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') for dt in data.index]\n",
    "data.iloc[-19:].to_csv(data_dir / 'cpi_monthly.csv', \n",
    "                         index_label='date', float_format='%g')\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "prdate = dtxt(data.index[-2])['mon1']\n",
    "ltval = data.ALL_S.iloc[-1]\n",
    "prval = data.ALL_S.iloc[-2]\n",
    "text = (f'In {ltdate}, the annualized one-month change '+\n",
    "        f'in the consumer price index was {ltval:.1f} '+\n",
    "        f'percent {c_box(\"blue\")}, following '+\n",
    "        f'{prval:.1f} percent in {prdate}. ')\n",
    "write_txt(text_dir / 'cpi_monthly.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Line Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:22:16.856553Z",
     "start_time": "2022-02-28T03:22:16.841049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\href{https://www.bls.gov/cpi/}{Consumer prices} increased 7.5 percent over the year ending January 2022 (see {\\color{blue!60!cyan}\\textbf{---}}), according to the Consumer Price Index for all urban consumers (CPI-U). The core CPI, which does not include the more-volatile food and energy prices, increased six percent over the same one-year period (see {\\color{gray}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                parse_dates=True)\n",
    "rn = {'All items': 'ALL', 'All items less food and energy': 'CORE',\n",
    "      'All items (SA)': 'ALL_S', 'All items less food and energy (SA)': \n",
    "      'CORE_S'}\n",
    "df = df.rename(rn, axis=1)[rn.values()].pct_change(12).dropna() * 100\n",
    "df.to_csv(data_dir / 'cpi.csv', index_label='date', \n",
    "           float_format='%g')\n",
    "\n",
    "node_color = 'blue!60!cyan'\n",
    "node = end_node(df.ALL, node_color, offset=True, percent=True,\n",
    "                date='m', full_year=True)\n",
    "write_txt(text_dir / 'cpi_node.txt', node)\n",
    "\n",
    "date = dtxt(df.index[-1])['mon1']\n",
    "allitems = value_text(df['ALL'].iloc[-1])\n",
    "core = value_text(df['CORE'].iloc[-1])\n",
    "text = ('\\href{https://www.bls.gov/cpi/}{Consumer prices} '+\n",
    "        f'{allitems} over the year ending {date} '+\n",
    "        f'{c_line(node_color)}, according to the Consumer '+\n",
    "        'Price Index for all urban consumers (CPI-U). '+\n",
    "        'The core CPI, which does not include the more-'+\n",
    "        f'volatile food and energy prices, {core} over '+\n",
    "        f'the same one-year period {c_line(\"gray\")}.')\n",
    "write_txt(text_dir / 'cpi_main.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:22:18.880075Z",
     "start_time": "2022-02-28T03:22:18.874893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Line for AHE chart\n",
    "s = pd.read_csv(data_dir / 'cpi.csv', index_col='date', parse_dates=True)\n",
    "cpival = s['ALL_S'].iloc[-1].round(3)\n",
    "cpi_txt = f'{cpival:.1f} percent'\n",
    "text = ('\\\\addplot[dashed, ultra thick, red, sharp plot, update limits=false] '+\n",
    "        f'coordinates {{({cpival},-12.5) ({cpival}, 0.5)}} node[right] at '+\n",
    "        f'(axis cs:{cpival},-12.5) {{\\\\textbf{{CPI}} ({cpi_txt})}};')\n",
    "write_txt(text_dir / 'cpi_lt_line.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI: components contribution to total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:22:20.209543Z",
     "start_time": "2022-02-28T03:22:20.142819Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "# Weights and weight date\n",
    "rw = (pd.read_csv(data_dir / 'cpi_rel_wgts_raw.csv', \n",
    "                  index_col=0))\n",
    "wgt_date = pd.to_datetime(rw.index.name)\n",
    "wgts = rw['CPI-U'].drop_duplicates()\n",
    "\n",
    "# Calculate contribution to annual growth rate\n",
    "uwt = (((df.divide(df.loc[wgt_date])).multiply(wgts))\n",
    "       .divide((df['All items'].divide(df.loc[wgt_date, 'All items'])), \n",
    "               axis=0)).dropna(how='all', axis=1)\n",
    "cols = ['All items', 'Medical care', 'Housing', 'Food', \n",
    "        'Recreation', 'Education', 'Transportation', \n",
    "        'Apparel', 'Energy', 'Communication', 'Personal care']\n",
    "cont = uwt.multiply(df.pct_change(12)).loc['2019':, cols]\n",
    "\n",
    "res = cont.iloc[[-1, -13]].T\n",
    "dates = res.columns\n",
    "res.columns = ['Latest', 'Previous']\n",
    "res = res.sort_values('Latest', ascending=False)\n",
    "res.drop('All items').to_csv(data_dir / 'cpi_comp.csv', \n",
    "                             index_label='name')\n",
    "\n",
    "write_txt(text_dir / 'cpi_mo1.txt', dtxt(dates[0])['mon2'])\n",
    "write_txt(text_dir / 'cpi_mo2.txt', dtxt(dates[1])['mon2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:22:22.238581Z",
     "start_time": "2022-02-28T03:22:22.213060Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In January 2022, transportation prices contributed 3.8 percentage points to the CPI one-year inflation rate of 7.5 percent, far above the category's January 2021 subtraction of 0.2 percentage point. Housing prices added 2.4 percentage points to January 2022 inflation, far above the year-prior contribution of 0.8 percentage point. Energy prices increased the inflation rate by two percentage points in the latest data, compared to a subtraction of 0.2 percentage point in January 2021. The energy category makes up 7.3 percent of the CPI basket, but accounts for 26.7 percent of January 2022 inflation. \n",
      "\n",
      "Food prices increased the inflation rate by 0.9 percentage point in January 2022, substantially above the year-prior contribution of 0.5 percentage point. Medical care prices make up 8.5 percent of the CPI basket and contributed 0.2 percentage point to overall inflation in the latest data, in line with a contribution of 0.2 percentage point one year prior. \n"
     ]
    }
   ],
   "source": [
    "final = res.join(wgts)\n",
    "final['AtWgt'] = ((final['CPI-U'] / 100) * \n",
    "                  final.loc['All items', 'Latest'])\n",
    "final['Share'] = ((final['Latest'] / \n",
    "                   final.loc['All items', 'Latest'])) * 100\n",
    "final = final.drop('All items')\n",
    "final['Ratio'] = abs(final['Latest'] / final['AtWgt'])\n",
    "final['ltabs'] = abs(final['Latest'])\n",
    "final['Points'] = final['CPI-U'] * final['Ratio'] * final['ltabs']\n",
    "\n",
    "# Generate text\n",
    "styles = [('c', 'contribution'), ('to', 'contribution_to'), \n",
    "          ('of', 'contribution_of')]\n",
    "groups = [('lt', 'Latest'), ('pr', 'Previous')]\n",
    "final = final.join(pd.DataFrame({f'{name}_{cname}': final[col].apply(\n",
    "    lambda x: value_text(x, style, 'pp')) for (name, style), (cname, col) \n",
    "                              in itertools.product(styles, groups)}))\n",
    "compare = lambda x: compare_text(x.Latest, x.Previous, \n",
    "                                 cutoffs=[0.05, 0.3, 1])\n",
    "final['Compare'] = final.apply(compare, axis=1)\n",
    "casual = lambda x: value_text(x, 'contribution_to', 'pp', casual=True)\n",
    "final['to_lt_cas'] = final.Latest.apply(casual)\n",
    "increase = lambda x: value_text(x, 'increase_by', 'pp', adj='inflation')\n",
    "final['inc_lt'] = final.Latest.apply(increase)\n",
    "final['same_sign'] = final.apply(lambda x: np.where(\n",
    "    np.sign(x.Latest) == np.sign(x.Previous), \n",
    "    value_text(x.Previous, 'plain', 'pp'), \n",
    "    value_text(x.Previous, 'contribution_of', 'pp')), axis=1)\n",
    "t = final.sort_values('Points', ascending=False)\n",
    "t['of_lt'] = t.of_lt.str.replace(\"a \", \"\")\n",
    "t['of_pr'] = t.of_pr.str.replace(\"a \", \"\")\n",
    "t['overweight'] = ''\n",
    "ltdt = dtxt(dates[0])['mon1']\n",
    "prdt = dtxt(dates[1])['mon1']\n",
    "if t.Ratio.max() > 2:\n",
    "    ocat = t.Ratio.idxmax()\n",
    "    otxt = (f'The {ocat.lower()} category makes up '+\n",
    "            f'{t.loc[ocat, \"CPI-U\"]:.1f} percent of the CPI '+\n",
    "            f'basket, but accounts for {t.loc[ocat, \"Share\"]:.1f} '+\n",
    "            f'percent of {ltdt} inflation. ')\n",
    "    t.at[ocat, 'overweight'] = otxt\n",
    "    \n",
    "cat1 = t.index[0]\n",
    "ltall = res.loc['All items', 'Latest']\n",
    "cat2 = t.index[1]\n",
    "cat3 = t.index[2]\n",
    "cat4 = t.index[3]\n",
    "cat5 = t.drop([cat1, cat2, cat3, cat4]).sort_values('CPI-U').index[-1]\n",
    "text = (f'In {ltdt}, {cat1.lower()} prices {t.loc[cat1, \"to_lt\"]} '+\n",
    "        f'the CPI one-year inflation rate of {ltall:.1f} percent, '+\n",
    "        f\"{t.loc[cat1, 'Compare']} the category's {prdt} \"+\n",
    "        f'{t.loc[cat1, \"of_pr\"]}. {t.loc[cat2, \"overweight\"]}{cat2} '+\n",
    "        f'prices {t.loc[cat2, \"to_lt_cas\"]} {ltdt} inflation, '+\n",
    "        f'{t.loc[cat2, \"Compare\"]} the year-prior {t.loc[cat2, \"of_pr\"]}. '+\n",
    "        f'{t.loc[cat2, \"overweight\"]}{cat3} prices {t.loc[cat3, \"inc_lt\"]} '+\n",
    "        f'in the latest data, compared to {t.loc[cat3, \"same_sign\"]} '+\n",
    "        f'in {prdt}. {t.loc[cat3, \"overweight\"]}\\n\\n{cat4} prices '+\n",
    "        f'{t.loc[cat4, \"inc_lt\"]} in {ltdt}, {t.loc[cat4, \"Compare\"]} '+\n",
    "        f'the year-prior {t.loc[cat4, \"of_pr\"]}. {t.loc[cat4, \"overweight\"]}'+\n",
    "        f'{cat5} prices make up {t.loc[cat5, \"CPI-U\"]:.1f} percent of the '+\n",
    "        f'CPI basket and {t.loc[cat5, \"to_lt\"]} overall inflation in the '+\n",
    "        f'latest data, {t.loc[cat5, \"Compare\"]} a {t.loc[cat5, \"of_pr\"]} '+\n",
    "        f'one year prior. {t.loc[cat5, \"overweight\"]}')\n",
    "write_txt(text_dir / 'cpicomp.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Relative Prices Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:22:26.142266Z",
     "start_time": "2022-02-28T03:22:26.111782Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPI data and calculate percent change\n",
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "dfc = df.pct_change(12) * 100\n",
    "\n",
    "# Create table\n",
    "tbl = dfc.iloc[[-1, -2, -3, -13]]\n",
    "tbl.index = [dtxt(i)['mon6'] for i in tbl.index]\n",
    "t19 = dfc.loc['2019'].mean().rename('2019')\n",
    "tpc = ((df.iloc[-1] / df.loc['2020-02-01']) - 1) * 100\n",
    "tbl = (tbl.append(t19).append(tpc.rename('Since Feb `20'))\n",
    "          .applymap('{:,.1f}'.format))\n",
    "wgt_col = f'Weight, {dtxt(uwt.index[-1])[\"mon6\"]}'\n",
    "tbl = tbl.append(uwt.iloc[-1].apply('{:.3f}'.format).rename(wgt_col))\n",
    "tbl.loc[wgt_col, 'All items'] = '100.0'\n",
    "\n",
    "order = ['All items', 'Housing', \"Owners' equivalent rent of residences\",\n",
    "         'Rent of primary residence', 'Lodging away from home', \n",
    "         'Household furnishings and operations', 'Household energy', \n",
    "         'Transportation', 'New vehicles',\n",
    "         'Used cars and trucks', 'Gasoline (all types)', \n",
    "         'Public transportation', 'Medical care', 'Professional services',\n",
    "         'Hospital and related services', 'Health insurance', 'Food',\n",
    "         'Food at home', 'Food away from home',\n",
    "         'Full service meals and snacks', \n",
    "         'Limited service meals and snacks', 'Recreation',\n",
    "         'Communication', 'Wireless telephone services',\n",
    "         'Internet services and electronic information providers', \n",
    "         'Education', 'College tuition and fees', \n",
    "         'Day care and preschool',\n",
    "         'Apparel', 'Personal care']\n",
    "final = tbl[order].T\n",
    "\n",
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "levels = codes.set_index('item_name')['display_level'].to_dict()\n",
    "final.index = [f'\\hspace{{2mm}} {c}' if levels[c] in [2, 3, 4] else c \n",
    "               for c in final.index]\n",
    "rn = {\"\\hspace{2mm} Owners' equivalent rent of residences\": \n",
    "      \"\\hspace{2mm} Owners' equivalent rent\",\n",
    "      'Household furnishings and operations':\n",
    "      '\\hspace{2mm} Household furnishings \\& ops.',\n",
    "      '\\hspace{2mm} Full service meals and snacks':\n",
    "      '\\hspace{4mm} Full-service',\n",
    "      '\\hspace{2mm} Limited service meals and snacks':\n",
    "      '\\hspace{4mm} Limited-service',\n",
    "      '\\hspace{2mm} Internet services and electronic information providers':\n",
    "      '\\hspace{2mm} Internet services'}\n",
    "final = (final.rename(rn))\n",
    "(final.to_csv(data_dir / 'cpi_comp.tex', sep='&', \n",
    "              line_terminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:47:53.179317Z",
     "start_time": "2022-02-28T03:47:53.167008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing prices increased 5.7 percent over the year ending January 2022, substantially above the pre-COVID rate of 2.9 percent (the average monthly rate during 2019). Medical care prices increased 2.5 percent, these prices grew at an average rate of 2.8 percent during 2019. In contrast, prices of food consumed at home (groceries) increased 7.4 percent in the year ending January 2022 compared to 0.9 percent during 2019.\n",
      "\n",
      "Transportation prices increased 20.8 percent over the year ending January 2022, far above the pre-COVID 0.3 percent decrease. Energy prices increased 27.0 percent in the latest month, compared to an average 2.1 percent decrease in 2019. Energy prices are historically more volatile than other categories. \n"
     ]
    }
   ],
   "source": [
    "ltdt = dfc.index[-1]\n",
    "cdt = '2019'\n",
    "ltdate = dtxt(ltdt)['mon1']\n",
    "dfc = dfc.dropna()\n",
    "res = pd.DataFrame({ltdt: dfc.iloc[-1], \n",
    "                    cdt: dfc.loc[cdt].mean()})\n",
    "\n",
    "hc = res.loc['Housing', ltdt]\n",
    "h1 = value_text(res.loc['Housing', ltdt])\n",
    "hp = res.loc['Housing', cdt]\n",
    "hch = compare_text(hc, hp, [0.3, 1.0, 3.0])\n",
    "m1 = value_text(res.loc['Medical care', ltdt])\n",
    "mpr = value_text(res.loc['Medical care', cdt], casual=True, \n",
    "                 adj='average')\n",
    "fah1 = value_text(res.loc['Food at home', ltdt])\n",
    "fahpr = res.loc['Food at home', cdt]\n",
    "tc = res.loc['Transportation', ltdt]\n",
    "t1 = value_text(tc)\n",
    "tp = res.loc['Transportation', cdt]\n",
    "tpr = (value_text(tp, style='increase_end')\n",
    "       .replace('a ', '').replace('an ', ''))\n",
    "tch = compare_text(tc, tp, [0.3, 1.0, 3.0])\n",
    "e1 = value_text(res.loc['Energy', ltdt])\n",
    "epr = value_text(res.loc['Energy', cdt], style='increase_end', \n",
    "                 adj='average')\n",
    "\n",
    "text = (f'Housing prices {h1} over the year ending {ltdate}, '+\n",
    "        f'{hch} the pre-COVID rate of {hp:.1f} percent (the average '+\n",
    "        f'monthly rate during 2019). Medical care prices {m1}, '+\n",
    "        f'these prices {mpr} during 2019. '+\n",
    "        'In contrast, prices of food consumed at home '+\n",
    "        f'(groceries) {fah1} in the year ending {ltdate} '+\n",
    "        f'compared to {fahpr:.1f} percent during 2019.\\n\\n'+\n",
    "        f'Transportation prices {t1} over the year ending '+\n",
    "        f'{ltdate}, {tch} the pre-COVID {tpr}. Energy prices '+\n",
    "        f'{e1} in the latest month, compared to {epr} in '+\n",
    "        f'2019. Energy prices are historically more '+\n",
    "        'volatile than other categories. ')\n",
    "write_txt(text_dir / 'cpicomp2.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Decomposition (ROUGH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:58:48.019908Z",
     "start_time": "2022-02-28T03:58:48.010758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Relative weights for series of interest, from here: \n",
    "# https://www.bls.gov/cpi/tables/relative-importance/home.htm\n",
    "rel_wgt = {'CUUR0000SAF1': [(('2009-12-01', '2011-12-01'), 13.738),\n",
    "                           (('2011-12-01', '2013-12-01'), 14.308),\n",
    "                           (('2013-12-01', '2015-12-01'), 13.891), \n",
    "                           (('2015-12-01', '2017-12-01'), 14.015), \n",
    "                           (('2017-12-01', '2019-12-01'), 13.384),\n",
    "                           (('2019-12-01', '2021-12-01'), 13.771),\n",
    "                           (('2021-12-01', '2023-12-01'), 13.370)],\n",
    "           'CUUR0000SA0': [(('2009-12-01', '2011-12-01'), 100.0),\n",
    "                           (('2011-12-01', '2013-12-01'), 100.0),\n",
    "                           (('2013-12-01', '2015-12-01'), 100.0), \n",
    "                           (('2015-12-01', '2017-12-01'), 100.0), \n",
    "                           (('2017-12-01', '2019-12-01'), 100.0),\n",
    "                           (('2019-12-01', '2021-12-01'), 100.0),\n",
    "                           (('2021-12-01', '2023-12-01'), 100.0)],\n",
    "           'CUUR0000SA0E': [(('2009-12-01', '2011-12-01'), 8.553),\n",
    "                            (('2011-12-01', '2013-12-01'), 9.679),\n",
    "                            (('2013-12-01', '2015-12-01'), 9.046), \n",
    "                            (('2015-12-01', '2017-12-01'), 6.816), \n",
    "                            (('2017-12-01', '2019-12-01'), 7.513),\n",
    "                            (('2019-12-01', '2021-12-01'), 6.706),\n",
    "                            (('2021-12-01', '2023-12-01'), 7.348)],\n",
    "           'CUUR0000SAH1': [(('2009-12-01', '2011-12-01'), 32.289),\n",
    "                            (('2011-12-01', '2013-12-01'), 31.539),\n",
    "                            (('2013-12-01', '2015-12-01'), 32.029), \n",
    "                            (('2015-12-01', '2017-12-01'), 33.15), \n",
    "                            (('2017-12-01', '2019-12-01'), 32.843),\n",
    "                            (('2019-12-01', '2021-12-01'), 33.158),\n",
    "                            (('2021-12-01', '2023-12-01'), 32.946)],\n",
    "           'CUUR0000SACL1E': [(('2009-12-01', '2011-12-01'), 21.276),\n",
    "                              (('2011-12-01', '2013-12-01'), 19.852),\n",
    "                              (('2013-12-01', '2015-12-01'), 19.71), \n",
    "                              (('2015-12-01', '2017-12-01'), 19.613), \n",
    "                              (('2017-12-01', '2019-12-01'), 19.849),\n",
    "                              (('2019-12-01', '2021-12-01'), 20.137),\n",
    "                              (('2021-12-01', '2023-12-01'), 21.699)],\n",
    "           'CUUR0000SASLE': [(('2009-12-01', '2011-12-01'), 56.432),\n",
    "                             (('2011-12-01', '2013-12-01'), 56.161),\n",
    "                             (('2013-12-01', '2015-12-01'), 57.353), \n",
    "                             (('2015-12-01', '2017-12-01'), 59.556), \n",
    "                             (('2017-12-01', '2019-12-01'), 59.254),\n",
    "                             (('2019-12-01', '2021-12-01'), 59.387),\n",
    "                             (('2021-12-01', '2023-12-01'), 57.583)]}\n",
    "series = {key: key for key, value in rel_wgt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:58:48.994655Z",
     "start_time": "2022-02-28T03:58:48.841284Z"
    }
   },
   "outputs": [],
   "source": [
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "ids = (codes.reset_index().set_index('item_name')\n",
    "       .item_code.apply(lambda x: 'CUUR0000' + x).to_dict())\n",
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                 parse_dates=True).rename(ids, axis=1)\n",
    "\n",
    "# Dictionary combining all the info for each series\n",
    "d = {i: {'name': i,\n",
    "         'values': df[i],\n",
    "         'rel_wgt': rel_wgt[i]} for i in list(rel_wgt.keys())}\n",
    "\n",
    "# Adjust for changes to relative importance\n",
    "df1, df2, df3, df4, df5, df6, df7 = (pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame())\n",
    "for i, v in d.items():\n",
    "    start, end = v['rel_wgt'][0][0][0], v['rel_wgt'][0][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][0][1], v['rel_wgt'][1][1]\n",
    "    df1.at[start: end, i] = (v['values'].loc[start: end])\n",
    "    df1[i] = (df1[i].diff().cumsum() / df1.loc[start, i] + 1)\n",
    "    df1.at[start, i] = 1.0\n",
    "    df1[i] = (df1[i] * rwc)\n",
    "    link = (df1.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][1][0][0], v['rel_wgt'][1][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][1][1], v['rel_wgt'][2][1]\n",
    "    df2[i] = (v['values'].loc[start: end])\n",
    "    df2[i] = df2[i].diff().cumsum() / df2.loc[start, i] + 1\n",
    "    df2.at[start, i] = 1.0\n",
    "    df2[i] = (df2[i] * rwc) * link\n",
    "    link = (df2.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][2][0][0], v['rel_wgt'][2][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][2][1], v['rel_wgt'][3][1]\n",
    "    df3[i] = (v['values'].loc[start: end])\n",
    "    df3[i] = df3[i].diff().cumsum() / df3.loc[start, i] + 1\n",
    "    df3.at[start, i] = 1.0\n",
    "    df3[i] = (df3[i] * rwc) * link\n",
    "    link = (df3.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][3][0][0], v['rel_wgt'][3][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][3][1], v['rel_wgt'][4][1]\n",
    "    df4[i] = (v['values'].loc[start: end])\n",
    "    df4[i] = df4[i].diff().cumsum() / df4.loc[start, i] + 1\n",
    "    df4.at[start, i] = 1.0\n",
    "    df4[i] = (df4[i] * rwc) * link\n",
    "    link = (df4.loc[end, i] / rwn)\n",
    "\n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][4][0][0], v['rel_wgt'][4][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][4][1], v['rel_wgt'][5][1]\n",
    "    df5[i] = (v['values'].loc[start: end])\n",
    "    df5[i] = df5[i].diff().cumsum() / df5.loc[start, i] + 1\n",
    "    df5.at[start, i] = 1.0\n",
    "    df5[i] = (df5[i] * rwc) * link\n",
    "    link = (df5.loc[end, i] / rwn)    \n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][5][0][0], v['rel_wgt'][5][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][5][1], v['rel_wgt'][6][1]\n",
    "    df6[i] = (v['values'].loc[start: end])\n",
    "    df6[i] = df6[i].diff().cumsum() / df6.loc[start, i] + 1\n",
    "    df6.at[start, i] = 1.0\n",
    "    df6[i] = (df6[i] * rwc) * link\n",
    "    link = (df6.loc[end, i] / rwn)   \n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][6][0][0], v['rel_wgt'][6][0][1]\n",
    "    rwc = v['rel_wgt'][6][1]\n",
    "    df7[i] = (v['values'].loc[start: end])\n",
    "    df7[i] = df7[i].diff().cumsum() / df7.loc[start, i] + 1\n",
    "    df7.at[start, i] = 1.0\n",
    "    df7[i] = (df7[i] * rwc) * link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:59:02.311033Z",
     "start_time": "2022-02-28T03:59:02.289446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In January 2022, core goods contributed 2.1 percentage points to the one-year non-seasonally-adjusted CPI inflation rate of 7.5 percent (see\\cbox{blue!85!black}), while core services excluding shelter contributed 0.9 percentage point (see\\cbox{green!60!black}). Shelter added 1.5 percentage points (see\\cbox{cyan!50!white}), and food and energy added 2.9 percentage points (see\\cbox{orange!80!red}). One year prior, in January 2021, the corresponding CPI inflation rate was 1.4 percent; core goods contributed 0.3 percentage point, core services excluding shelter contributed 0.2 percentage point, shelter contributed 0.6 percentage point, and food and energy added 0.2 percentage point.\n"
     ]
    }
   ],
   "source": [
    "res = pd.concat([df1, df2, df3, df4, df5, df6, df7])  \n",
    "# Drop duplicate pivot year data\n",
    "res = res[~res.index.duplicated(keep='first')] \n",
    "final = ((res.diff(12).divide(res['CUUR0000SA0'].diff(12), axis=0))\n",
    "         .multiply(res['CUUR0000SA0'].pct_change(12) * 100, axis=0))\n",
    "# Core services is services less food, energy, and shelter\n",
    "final['core_services'] = final['CUUR0000SASLE'] - final['CUUR0000SAH1']\n",
    "# Combine food and energy\n",
    "final['food_energy'] = final['CUUR0000SAF1'] + final['CUUR0000SA0E']\n",
    "final = final.dropna().round(2)\n",
    "d2 = (final[['CUUR0000SACL1E', 'core_services', 'CUUR0000SAH1', 'food_energy']]\n",
    "      .loc['2011-01-01':])\n",
    "col_names = ['core_goods', 'core_services', 'shelter', 'food_energy']\n",
    "d2.columns = col_names\n",
    "d2['total'] = final['CUUR0000SA0'].loc['2011-01-01':]\n",
    "\n",
    "d2.to_csv(data_dir / 'cpi_decomp.csv', index_label='date', \n",
    "           float_format='%g')\n",
    "\n",
    "ltdate = dtxt(d2.index[-1])['mon1']\n",
    "prdate = dtxt(d2.index[-13])['mon1']\n",
    "cg = value_text(d2.core_goods.iloc[-1], 'contribution_to', 'pp')\n",
    "cs = value_text(d2.core_services.iloc[-1], 'contribution', 'pp')\n",
    "sh = value_text(d2.shelter.iloc[-1], 'contribution', 'pp', \n",
    "                casual=True)\n",
    "fe = value_text(d2.food_energy.iloc[-1], 'contribution', 'pp', \n",
    "                casual=True)\n",
    "tot = d2.total.iloc[-1]\n",
    "cgpr = value_text(d2.core_goods.iloc[-13], 'contribution', 'pp')\n",
    "cspr = value_text(d2.core_services.iloc[-13], 'contribution', 'pp')\n",
    "shpr = value_text(d2.shelter.iloc[-13], 'contribution', 'pp')\n",
    "fepr = value_text(d2.food_energy.iloc[-13], 'contribution', 'pp', \n",
    "                  casual=True)\n",
    "totpr = d2.total.iloc[-13]\n",
    "colors = {'cg': 'blue!85!black', 'cs': 'green!60!black', \n",
    "          'sh': 'cyan!50!white', 'fe': 'orange!80!red'}\n",
    "cbs = {name: c_box(color) for name, color in colors.items()}\n",
    "text = (f'In {ltdate}, core goods {cg} the one-year non-seasonally-'+\n",
    "        f'adjusted CPI inflation rate of {tot:.1f} percent '+\n",
    "        f'{cbs[\"cg\"]}, while core services excluding shelter {cs} '+\n",
    "        f'{fe} {cbs[\"fe\"]}. One year prior, in {prdate}, the '+\n",
    "        f'corresponding CPI inflation rate was {totpr:.1f} percent; '\n",
    "        f'core goods {cgpr}, core services excluding shelter {cspr}, '+\n",
    "        f'shelter {shpr}, and food and energy {fepr}.')\n",
    "write_txt(text_dir / 'cpi_decomp.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-17T00:08:04.432977Z",
     "start_time": "2022-02-17T00:08:04.317232Z"
    }
   },
   "outputs": [],
   "source": [
    "# cols = list(rel_wgt.keys())\n",
    "# d = {c: {} for c in cols}\n",
    "# data = {c: {} for c in cols}\n",
    "# dates = [f'{i}-12-01' for i in range(2009, 2023, 2)]\n",
    "# for s, i in itertools.product(cols, dates):\n",
    "#     start, end, prev = (i, dtxt(pd.to_datetime(i) + \n",
    "#                          pd.DateOffset(years=2))['datetime'],\n",
    "#                         dtxt(pd.to_datetime(i) - \n",
    "#                          pd.DateOffset(years=2))['datetime'])\n",
    "#     ri = [w[1] for w in rel_wgt[s] if w[0][0] == start][0]\n",
    "#     base = df.loc[start, s]\n",
    "#     print(s)\n",
    "#     dt = pd.to_datetime(i)\n",
    "#     d10 = pd.to_datetime('2010-01-01')\n",
    "#     prev_link = d[s][prev] if dt > d10 else df.loc[start, s]\n",
    "#     print(prev_link)\n",
    "#     val = (ri * df.loc[start:end, s]) / prev_link\n",
    "#     d[s][start] = (val[-1] / val[0]) * df.loc[:end, s].iloc[-1]\n",
    "#     data[s].update(val.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T16:00:38.282929Z",
     "start_time": "2022-02-15T16:00:36.306254Z"
    }
   },
   "outputs": [],
   "source": [
    "df = bls_api({'WPU00000000': 'PPIACO'}, (1988, 2022), bls_key)\n",
    "df.to_csv(data_dir / 'ppi_index.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-15T16:00:44.626210Z",
     "start_time": "2022-02-15T16:00:44.598455Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'ppi_index.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "ppi = (df['PPIACO'].pct_change(12) * 100).dropna()\n",
    "ppi.to_csv(data_dir / 'ppi.csv', index_label='date')\n",
    "\n",
    "node_color = 'green!80!blue'\n",
    "node = end_node(ppi, node_color, date='m', percent=True, \n",
    "                full_year=True, offset=-0.1)\n",
    "write_txt(text_dir / 'ppi_node.txt', node)\n",
    "\n",
    "ch = value_text(ppi.iloc[-1])\n",
    "prval = ppi.iloc[-13]\n",
    "yr3val = ppi.rolling(36).mean().iloc[-1]\n",
    "compare = compare_text(ppi.iloc[-1], prval, [1.0, 3.0, 5.0])\n",
    "date = dtxt(ppi.index[-1])['mon1']\n",
    "date2 = dtxt(ppi.index[-13])['mon1']\n",
    "\n",
    "text = ('The Bureau of Labor Statistics \\\\href{https://www.bls.gov/ppi/}'+\n",
    "        '{report} prices producers receive for the various goods '+\n",
    "        'and services they produce. The producer price index for all '+\n",
    "        f'commodities (see {{\\color{{{node_color}}}\\\\textbf{{---}}}}) '+\n",
    "        f'{ch} over the year ending {date}, {compare} the 12-month '+\n",
    "        f'growth rate of {prval:.1f} percent in {date2}. Over the '+\n",
    "        f'past three years, producer prices increased by {yr3val:.1f} '+\n",
    "        'percent per year, on average.')\n",
    "write_txt(text_dir / 'ppi_main.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import/Export Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T14:17:48.493154Z",
     "start_time": "2022-02-16T14:17:44.575272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'EIUIR': 'Imports', \n",
    "          'EIUIQ': 'Exports',\n",
    "          'EIUIREXFUELS': 'ImpExFuels',\n",
    "          'EIUIR10': 'ImpFuels',\n",
    "          'EIUIQEXAG': 'ExpExAg',\n",
    "          'EIUIQAG': 'ExpAg'}\n",
    "\n",
    "# Start year and end year\n",
    "years = (1988, 2022)\n",
    "df = bls_api(series, years, bls_key)\n",
    "\n",
    "df.to_csv(data_dir / 'mxpi_main.csv', index_label='date')\n",
    "\n",
    "srs = ['Imports', 'Exports']\n",
    "(df[srs].pct_change(12).dropna() * 100).to_csv(data_dir / 'mxpi.csv', \n",
    "                                               index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T14:17:50.080004Z",
     "start_time": "2022-02-16T14:17:50.059846Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'mxpi_main.csv', index_col='date')\n",
    "\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "data = (df.pct_change(12).dropna() * 100)\n",
    "\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "prdate = dtxt(data.index[-2])['mon1']\n",
    "prdate2 = dtxt(data.index[-3])['mon1']\n",
    "mv1 = data['Imports'].iloc[-1]\n",
    "mv2 = data['Imports'].iloc[-2]\n",
    "mv3 = data['Imports'].iloc[-3]\n",
    "mv4 = data.loc['2017-03-01': '2020-02-01', 'Imports'].mean()\n",
    "m1 = value_text(mv1, casual=True, threshold=0.1, obj='plural')\n",
    "m2 = value_text(mv2, style='increase_of', threshold=0.1, obj='plural')\n",
    "m3 = value_text(mv3, style='increase_of', threshold=0.1, obj='plural')\n",
    "mpc = value_text(mv4, threshold=0.1, obj='plural', adj='average')\n",
    "mfv1 = data['ImpExFuels'].iloc[-1]\n",
    "mfv2 = data['ImpExFuels'].iloc[-2]\n",
    "mfv3 = data.loc['2017-03-01': '2020-02-01', 'ImpExFuels'].mean()\n",
    "mf1 = value_text(mfv1, threshold=0.1, obj='plural')\n",
    "mf2 = value_text(mfv2, casual=True, threshold=0.1, obj='plural')\n",
    "mfpc = value_text(mfv3, threshold=0.1, obj='plural', adj='average')\n",
    "if data.index[-1].year == data.index[-2].year:\n",
    "    prdate = dtxt(data.index[-2])['mon3']\n",
    "if data.index[-2].year == data.index[-3].year:\n",
    "    prdate2 = dtxt(data.index[-3])['mon3']\n",
    "if np.sign(mv2) == np.sign(mv3):\n",
    "    m3 = f'{abs(mv3):.1f} percent'\n",
    "ftxt = f'{m2} in {prdate} and {m3} in {prdate2}'\n",
    "\n",
    "xv1 = data['Exports'].iloc[-1]\n",
    "xv2 = data['Exports'].iloc[-2]\n",
    "xv3 = data['Exports'].iloc[-3]\n",
    "xv4 = data.loc['2017-03-01': '2020-02-01', 'Exports'].mean()\n",
    "x1 = value_text(xv1, casual=True, threshold=0.1, obj='plural')\n",
    "x2 = value_text(xv2, style='increase_of', threshold=0.1, obj='plural')\n",
    "x3 = value_text(xv3, style='increase_of', threshold=0.1, obj='plural')\n",
    "x4 = value_text(xv4, style='increase_of', threshold=0.1, obj='plural')\n",
    "if np.sign(xv1) == np.sign(xv2):\n",
    "        x2 = f'{abs(xv2):.1f} percent'\n",
    "if np.sign(xv2) == np.sign(xv3):\n",
    "        x3 = f'{abs(xv3):.1f} percent'\n",
    "if np.sign(xv3) == np.sign(xv4):\n",
    "        x4 = f'{abs(xv4):.1f} percent'\n",
    "ftxt2 = (f'compared to {x2} in {prdate}, {x3} in {prdate2}, and {x4} '+\n",
    "         'on average during the three years ending February 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-16T14:17:50.987597Z",
     "start_time": "2022-02-16T14:17:50.984731Z"
    }
   },
   "outputs": [],
   "source": [
    "text = ('The Bureau of Labor Statistics '+\n",
    "        '\\href{https://www.bls.gov/news.release/ximpim.nr0.htm}{report} '\n",
    "        'changes in the prices of imports and exports. Over the year ending '+\n",
    "        f'{ltdate}, US import prices {m1} '+\n",
    "        '(see {\\color{cyan!85!yellow}\\\\textbf{---}}), '+\n",
    "        f'following {ftxt}. Excluding fuels, US import prices '+\n",
    "        f'{mf1} in {ltdate} and {mf2} in {prdate}. Over the three years '+\n",
    "        'ending February 2020, prior to the US COVID-19 pandemic, US import '+\n",
    "        f'prices {mpc}. Excluding fuels, import prices {mfpc} during the '+\n",
    "        'same three-year pre-COVID period.\\n\\n'+\n",
    "        'Prices of US exports (see {\\color{red!25!orange}\\\\textbf{---}}) '+\n",
    "        f'{x1} over the year ending {ltdate}, {ftxt2}. ')\n",
    "write_txt(text_dir / 'mxpi.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCE Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T15:30:17.358189Z",
     "start_time": "2022-02-25T15:30:17.335905Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'nipa20804.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "df[['DPCERG', 'DPCCRG']].to_csv(data_dir / 'pce_index.csv', \n",
    "                    index_label='date')\n",
    "pce = pd.DataFrame()\n",
    "pce['PCE'] = df['DPCERG'].pct_change(12).dropna() * 100.0\n",
    "node_color = 'orange!80!yellow'\n",
    "node = end_node(pce['PCE'], node_color, date='m', percent=True, \n",
    "                full_year=True, offset=-0.2)\n",
    "write_txt(text_dir / 'pce_pi_node.txt', node)\n",
    "\n",
    "pce['CORE'] = df['DPCCRG'].pct_change(12).dropna() * 100.0\n",
    "pce.to_csv(data_dir / 'pce_pi.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(pce.index[-1])['mon1']\n",
    "prdate = dtxt(pce.index[-2])['mon1']\n",
    "pryrdate = dtxt(pce.index[-13])['mon1']\n",
    "ltval = pce.PCE.iloc[-1]\n",
    "prval = pce.PCE.iloc[-2]\n",
    "pryrval = pce.PCE.iloc[-13]\n",
    "ltcore = pce.CORE.iloc[-1]\n",
    "prcore = pce.CORE.iloc[-2]\n",
    "pryrcore = pce.CORE.iloc[-13]\n",
    "\n",
    "text = (f'As of {ltdate}, PCE inflation, measured as the one-year '+\n",
    "        f'percent change in the overall index, is {ltval:.1f} percent '+\n",
    "        f'(see {{\\color{{{node_color}}}\\\\textbf{{---}}}}), '+\n",
    "        f'compared to {prval:.1f} percent in {prdate}, and {pryrval:.1f} '+\n",
    "        f'percent in {pryrdate}. Core PCE inflation, which excludes food '+\n",
    "        f'and energy, was {ltcore:.1f} percent in {ltdate} '+\n",
    "        f'(see {{\\color{{blue!60!black}}\\\\textbf{{---}}}}), {prcore:.1f} '+\n",
    "        f'percent in {prdate}, and {pryrcore:.1f} percent in {pryrdate}.')\n",
    "write_txt(text_dir / 'pce_inf_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimmed mean PCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T18:36:09.610532Z",
     "start_time": "2022-02-25T18:36:07.759427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Trimmed-mean PCE from Dallas Fed\n",
    "url = 'https://www.dallasfed.org/research/~/media/documents/research/pce/pcehist.xls'\n",
    "tmpce = (pd.read_excel(url, index_col=0, header=3, parse_dates=True)\n",
    "           .loc['1988':].dropna(axis=1))\n",
    "tmpce.to_csv(data_dir / 'pce_tm.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-25T18:36:12.124923Z",
     "start_time": "2022-02-25T18:36:12.106403Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'pce_tm.csv', index_col='date', \n",
    "                 parse_dates=True).loc['1989':, '12-month']\n",
    "pce = pd.read_csv(data_dir / 'pce_pi.csv', index_col='date', \n",
    "                  parse_dates=True).loc['1989':, 'PCE']\n",
    "df.to_csv(data_dir / 'pce_tm12.csv', index_label='date')\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "ltval = df.iloc[-1]\n",
    "prdate = dtxt(df.index[-2])['mon1']\n",
    "prval = df.iloc[-2]\n",
    "ltvaltxt = value_text(ltval, threshold=0.1)\n",
    "diff =  ltval - pce.loc[df.index[-1]]\n",
    "difftxt = value_text(diff, 'above_below', ptype='pp')\n",
    "diff2 =  prval - pce.loc[df.index[-2]]\n",
    "difftxt2  = value_text(diff2, 'above_below', ptype='pp')\n",
    "pcval = df.loc['2017': '2019'].mean()\n",
    "diff3 = pcval - pce.loc['2017': '2019'].mean()\n",
    "difftxt3  = value_text(diff3, 'above_below', ptype='pp')\n",
    "color = 'violet!60!magenta'\n",
    "node = end_node(df, color, date='m', percent=True, \n",
    "                full_year=True, offset=-0.1)\n",
    "write_txt(text_dir / 'pce_tm_node.txt', node)\n",
    "text = (f'The trimmed-mean PCE price index {ltvaltxt} over the year '+\n",
    "        f'ending {ltdate} (see {{\\color{{{color}}}\\\\textbf{{---}}}}). '+\n",
    "        'By excluding top and bottom categories, the trimmed-'+\n",
    "        f'mean rate was {difftxt} the all-items PCE rate. In '+\n",
    "        f'{prdate}, the trimmed-mean rate was {prval:.1f} percent, '+\n",
    "        f'{difftxt2} the all-items rate. From 2017--2019, the average '+\n",
    "        f'trimmed-mean rate was {pcval:.1f} percent, {difftxt3} the '+\n",
    "        'all-items rate.')\n",
    "write_txt(text_dir / 'pce_tm_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:16:51.361478Z",
     "start_time": "2022-02-28T03:16:51.332825Z"
    }
   },
   "outputs": [],
   "source": [
    "pce = pd.read_csv(data_dir / 'pce_index.csv', \n",
    "                  index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "cpi_rn = {'All items': 'CPI', 'All items less food and energy': 'CPI_CORE'}\n",
    "cpi = (pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                   index_col='date', parse_dates=True)\n",
    "         .rename(cpi_rn, axis=1)).pct_change(12) * 100\n",
    "ppi = pd.read_csv(data_dir / 'ppi_index.csv', \n",
    "                  index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "mxpi = pd.read_csv(data_dir / 'mxpi_main.csv', \n",
    "                   index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "res = pce.join([cpi, ppi, mxpi], how='outer')\n",
    "keep_cols = ['CPI', 'CPI_CORE', 'PPIACO', 'Imports', \n",
    "             'Exports', 'DPCERG', 'DPCCRG']\n",
    "tm = pd.read_csv(data_dir / 'pce_tm.csv', \n",
    "                 index_col='date', parse_dates=True)['12-month']\n",
    "srs = {'CPI': 'CPI, All Items',\n",
    "       'CPI_CORE': 'CPI, ex. Food \\& Energy',\n",
    "       'PPIACO': 'PPI, All Commodities',\n",
    "       'Imports': 'Imports Price Index',\n",
    "       'Exports': 'Exports Price Index',\n",
    "       'DPCERG': 'PCE, All Items',\n",
    "       'DPCCRG': 'PCE, ex. Food \\& Energy',\n",
    "       '12-month': 'PCE, Trimmed Mean'}\n",
    "res12 = (res[keep_cols].join(tm, how='outer').rename(srs, axis=1))\n",
    "tbl = res12.iloc[[-1, -2, -3, -4, -13, -25]].T\n",
    "tbl.columns = [dtxt(c)['mon6'] for c in tbl.columns]\n",
    "tbl['`17--19 Avg.'] = res12.loc['2017': '2019'].mean()\n",
    "tbl['`00-- Avg.'] = res12.loc['2000':].mean()\n",
    "tbl = tbl.applymap('{:.1f}'.format).replace('nan', '--')\n",
    "tbl.to_csv(data_dir / 'prices_12m.tex', sep='&', line_terminator='\\\\\\ ', \n",
    "           quotechar=' ', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
