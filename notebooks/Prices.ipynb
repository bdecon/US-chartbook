{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:45:44.450970Z",
     "start_time": "2023-10-27T12:45:43.474497Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import uschartbook.config\n",
    "\n",
    "from uschartbook.config import *\n",
    "from uschartbook.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T03:12:04.798017Z",
     "start_time": "2022-02-28T03:12:04.792427Z"
    }
   },
   "source": [
    "### Consumer Price Index: Collect Information\n",
    "\n",
    "#### Relative importance\n",
    "\n",
    "https://www.bls.gov/cpi/tables/relative-importance/home.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:54:14.539858Z",
     "start_time": "2023-10-12T12:54:14.537581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tools to retrieve flat files from BLS\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/110.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:54:17.143190Z",
     "start_time": "2023-10-12T12:54:16.872052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve and store latest relative weights\n",
    "# URL should be updated every two years:\n",
    "# https://www.bls.gov/cpi/tables/relative-importance/home.htm\n",
    "wgt_dt = '2022-12-01'\n",
    "url = 'https://www.bls.gov/cpi/tables/relative-importance/2022.htm'\n",
    "r = requests.get(url, headers=headers)\n",
    "t = pd.read_html(io.StringIO(r.content.decode('utf-8')),header=0, index_col=0)\n",
    "t[0].columns = t[0].columns.str.replace('U.S. City Average, ', '', \n",
    "                                        regex=True)\n",
    "t[0].dropna().to_csv(data_dir / 'cpi_rel_wgts_raw.csv', \n",
    "                     index_label=wgt_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series names and display level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:54:19.313838Z",
     "start_time": "2023-10-12T12:54:18.985872Z"
    }
   },
   "outputs": [],
   "source": [
    "# Retrieve item names and codes\n",
    "url = 'https://download.bls.gov/pub/time.series/cu/cu.item'\n",
    "r = requests.get(url, headers=headers)\n",
    "codes = (pd.read_table(io.StringIO(r.content.decode('utf-8')), index_col=0)\n",
    "           .loc[:, ['item_name', 'display_level']])\n",
    "codes.to_csv(data_dir / 'cpi_codes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:54:36.914658Z",
     "start_time": "2023-10-12T12:54:22.451860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "Post Request Status: REQUEST_SUCCEEDED\n",
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Selected series to retrieve from API\n",
    "nsa = 'CUUR0000'\n",
    "sa = 'CUSR0000'\n",
    "lt = ['SA0', 'SAF1', 'SAH1', 'SACL1E', 'SASLE', 'SEHA', \n",
    "      'SA0E', 'SA0L1E', 'SETB01', 'SETA01', 'SETA02', 'SAE1',\n",
    "      'SAM']\n",
    "lts = ['SA0', 'SA0L1E']\n",
    "st = ['SAH', 'SEFV', 'SAF11', 'SAR',  'SAT', 'SAA', 'SAE2', \n",
    "      'SAG1', 'SEHC', 'SAH3', 'SEMD', 'SEMC', 'SEME',\n",
    "      'SETB', 'SETG', 'SAH21', 'SEHB', 'SEFV01', 'SEFV02',\n",
    "      'SEEB01', 'SEEB03', 'SEED03', 'SEEE03', ]\n",
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "code_names = codes['item_name'].to_dict().items()\n",
    "\n",
    "# Retrieve recent data from API \n",
    "dst = {nsa + code: name for code, name in code_names \n",
    "       if code in st}\n",
    "years = (2014, 2023)\n",
    "dfs = bls_api(dst, years, bls_key)\n",
    "\n",
    "# Retrieve recent data from API (SA)\n",
    "dst2 = {sa + code: name + ' (SA)' for code, name in code_names \n",
    "       if code in st}\n",
    "years = (2014, 2023)\n",
    "dfs2 = bls_api(dst2, years, bls_key)\n",
    "\n",
    "# Retrieve recent data from API (SA)\n",
    "dst3 = {sa + code: name + ' (SA)' for code, name in code_names \n",
    "       if code in lt and code not in lts}\n",
    "years = (2014, 2023)\n",
    "dfs3 = bls_api(dst3, years, bls_key)\n",
    "\n",
    "# Retrieve long-term data from API \n",
    "dlt = {nsa + code: name for code, name in code_names \n",
    "       if code in lt}\n",
    "dlts = {sa + code: name + ' (SA)' for code, name in code_names \n",
    "        if code in lts}\n",
    "years = (1988, 2023)\n",
    "dfl = bls_api({**dlt, **dlts}, years, bls_key)\n",
    "\n",
    "dfl.join(dfs).join(dfs2).join(dfs3).to_csv(data_dir / 'cpi_raw.csv', \n",
    "                     index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly CPI Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:54:43.945816Z",
     "start_time": "2023-10-12T12:54:43.927414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In September 2023, the one-month change in the consumer price index (CPI) was 0.4 percent (see\\cbox{blue!90!black}), following 0.6 percent in August 2023. \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                parse_dates=True)\n",
    "s = df.rename({'All items (SA)': 'ALL_S'}, axis=1)[['ALL_S']]\n",
    "data = s.pct_change() * 100\n",
    "\n",
    "# Last row is empty for nowcast\n",
    "next_mo = data.index[-1] + pd.DateOffset(months=1)\n",
    "data.loc[next_mo, 'ALL_S'] = ''\n",
    "data['label'] = [dt.strftime('%b\\\\\\`%y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') for dt in data.index]\n",
    "data['label2'] = [dt.strftime('%b\\\\\\%Y') if dt.month == 1 \n",
    "                  else dt.strftime('%b') if dt.month in [4, 7, 10]\n",
    "                  else '' for dt in data.index]\n",
    "data['FILL'] = 0\n",
    "data.iloc[-20:].to_csv(data_dir / 'cpi_monthly.csv', \n",
    "                         index_label='date', float_format='%g')\n",
    "ltdate = dtxt(data.index[-2])['mon1']\n",
    "prdate = dtxt(data.index[-3])['mon1']\n",
    "ltval = float(data.ALL_S.iloc[-2])\n",
    "prval = float(data.ALL_S.iloc[-3])\n",
    "text = (f'In {ltdate}, the one-month change '+\n",
    "        f'in the consumer price index (CPI) was {ltval:.1f} '+\n",
    "        f'percent {c_box(\"blue!90!black\")}, following '+\n",
    "        f'{prval:.1f} percent in {prdate}. ')\n",
    "write_txt(text_dir / 'cpi_monthly.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:54:49.612350Z",
     "start_time": "2023-10-12T12:54:49.607388Z"
    }
   },
   "outputs": [],
   "source": [
    "start_date = data.index[-20] - pd.DateOffset(days=21)\n",
    "end_date = data.index[-1] + pd.DateOffset(days=12)\n",
    "val = data['ALL_S'].iloc[:-1].astype('float').mean()\n",
    "color = 'gray!60!white'\n",
    "bar = (f'\\draw [{color}] (axis cs:{{{start_date}}},{val}) -- '+\n",
    "       f'(axis cs:{{{end_date}}},{val});')\n",
    "bardf = pd.Series(index=[start_date, end_date], \n",
    "                data=[val, val], name='Bar')\n",
    "node = end_node(bardf, color, loc='start')\n",
    "write_txt(text_dir / 'cpi_rec_bar_node.txt', bar + '\\n' + node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Line Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:54:54.614028Z",
     "start_time": "2023-10-12T12:54:54.595403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\href{https://www.bls.gov/cpi/}{Consumer prices} increased 3.7 percent over the year ending September 2023 (see {\\color{blue!60!cyan}\\textbf{---}}), according to the Consumer Price Index for all urban consumers (CPI-U). The core CPI, which does not include the more-volatile food and energy prices, increased 4.1 percent over the same one-year period (see {\\color{gray}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                parse_dates=True)\n",
    "rn = {'All items': 'ALL', 'All items less food and energy': 'CORE',\n",
    "      'All items (SA)': 'ALL_S', 'All items less food and energy (SA)': \n",
    "      'CORE_S'}\n",
    "df = df.rename(rn, axis=1)[rn.values()].pct_change(12).dropna() * 100\n",
    "df.to_csv(data_dir / 'cpi.csv', index_label='date', \n",
    "           float_format='%g')\n",
    "\n",
    "node_color = 'blue!60!cyan'\n",
    "node = end_node(df.ALL, node_color, offset=True, percent=True,\n",
    "                date='m', full_year=True)\n",
    "write_txt(text_dir / 'cpi_node.txt', node)\n",
    "\n",
    "date = dtxt(df.index[-1])['mon1']\n",
    "allitems = value_text(df['ALL'].iloc[-1])\n",
    "core = value_text(df['CORE'].iloc[-1])\n",
    "text = ('\\href{https://www.bls.gov/cpi/}{Consumer prices} '+\n",
    "        f'{allitems} over the year ending {date} '+\n",
    "        f'{c_line(node_color)}, according to the Consumer '+\n",
    "        'Price Index for all urban consumers (CPI-U). '+\n",
    "        'The core CPI, which does not include the more-'+\n",
    "        f'volatile food and energy prices, {core} over '+\n",
    "        f'the same one-year period {c_line(\"gray\")}.')\n",
    "write_txt(text_dir / 'cpi_main.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T12:56:50.826757Z",
     "start_time": "2023-10-17T12:56:50.820796Z"
    }
   },
   "outputs": [],
   "source": [
    "# Line for AHE chart\n",
    "s = pd.read_csv(data_dir / 'cpi.csv', index_col='date', parse_dates=True)\n",
    "cpival = s['ALL'].iloc[-1].round(3)\n",
    "cpi_txt = f'{cpival:.1f}\\%'\n",
    "text = ('\\\\addplot[densely dashed, line width=2pt, orange!50!yellow, sharp plot, update limits=false] '+\n",
    "        f'coordinates {{({cpival},-0.7) ({cpival}, 12.5)}} node[right] at '+\n",
    "        f'(axis cs:{cpival},-0.7) {{\\color{{orange!50!yellow}} \\small \\\\textbf{{CPI}}: {cpi_txt}}};')\n",
    "write_txt(text_dir / 'cpi_lt_line.txt', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI: components contribution to total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T00:28:55.596010Z",
     "start_time": "2023-10-16T00:28:55.548317Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "# Weights and weight date\n",
    "rw = (pd.read_csv(data_dir / 'cpi_rel_wgts_raw.csv', \n",
    "                  index_col=0))\n",
    "wgt_date = pd.to_datetime(rw.index.name)\n",
    "wgts = rw['CPI-U'].drop_duplicates()\n",
    "\n",
    "# Calculate contribution to annual growth rate\n",
    "uwt = (((df.divide(df.loc[wgt_date])).multiply(wgts))\n",
    "       .divide((df['All items'].divide(df.loc[wgt_date, 'All items'])), \n",
    "               axis=0)).dropna(how='all', axis=1)\n",
    "cols = ['All items', 'Medical care', 'Housing', 'Food', \n",
    "        'Recreation', 'Education', 'Transportation', \n",
    "        'Apparel', 'Energy', 'Communication', 'Personal care']\n",
    "cont = uwt.multiply(df.pct_change(12)).loc['2019':, cols]\n",
    "\n",
    "res = cont.iloc[[-1, -13]].T\n",
    "dates = res.columns\n",
    "res.columns = ['Latest', 'Previous']\n",
    "res = res.sort_values('Latest', ascending=False)\n",
    "res.drop('All items').to_csv(data_dir / 'cpi_comp.csv', \n",
    "                             index_label='name')\n",
    "\n",
    "write_txt(text_dir / 'cpi_mo1.txt', dtxt(dates[0])['mon2'])\n",
    "write_txt(text_dir / 'cpi_mo2.txt', dtxt(dates[1])['mon2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T00:28:57.636663Z",
     "start_time": "2023-10-16T00:28:57.612150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In September 2023, housing prices contributed 2.5 percentage points to the CPI one-year inflation rate of 3.7 percent, far below the category's September 2022 contribution of 3.5 percentage points. Food prices added 0.5 percentage point to September 2023 inflation, far below the year-prior contribution of 1.5 percentage points. Transportation prices increased the inflation rate by 0.4 percentage point in the latest data, compared to 2.2 percentage points in September 2022.\n",
      "\n",
      "Recreation prices increased the inflation rate by 0.2 percentage point in September 2023, in line with the year-prior contribution of 0.2 percentage point. Medical care prices make up 8.1 percent of the CPI basket and subtracted 0.1 percentage point from overall inflation in the latest data, substantially below a contribution of 0.5 percentage point one year prior. \n"
     ]
    }
   ],
   "source": [
    "final = res.join(wgts)\n",
    "final['AtWgt'] = ((final['CPI-U'] / 100) * \n",
    "                  final.loc['All items', 'Latest'])\n",
    "final['Share'] = ((final['Latest'] / \n",
    "                   final.loc['All items', 'Latest'])) * 100\n",
    "final = final.drop('All items')\n",
    "final['Ratio'] = abs(final['Latest'] / final['AtWgt'])\n",
    "final['ltabs'] = abs(final['Latest'])\n",
    "final['Points'] = final['CPI-U'] * final['Ratio'] * final['ltabs']\n",
    "\n",
    "# Generate text\n",
    "styles = [('c', 'contribution'), ('to', 'contribution_to'), \n",
    "          ('of', 'contribution_of')]\n",
    "groups = [('lt', 'Latest'), ('pr', 'Previous')]\n",
    "final = final.join(pd.DataFrame({f'{name}_{cname}': final[col].apply(\n",
    "    lambda x: value_text(x, style, 'pp', threshold=0.1)) for (name, style), (cname, col) \n",
    "                              in itertools.product(styles, groups)}))\n",
    "compare = lambda x: compare_text(x.Latest, x.Previous, \n",
    "                                 cutoffs=[0.05, 0.3, 1])\n",
    "final['Compare'] = final.apply(compare, axis=1)\n",
    "casual = lambda x: value_text(x, 'contribution_to', 'pp', casual=True)\n",
    "final['to_lt_cas'] = final.Latest.apply(casual)\n",
    "increase = lambda x: value_text(x, 'increase_by', 'pp', adj='inflation')\n",
    "final['inc_lt'] = final.Latest.apply(increase)\n",
    "final['same_sign'] = final.apply(lambda x: np.where(\n",
    "    np.sign(x.Latest) == np.sign(x.Previous), \n",
    "    value_text(x.Previous, 'plain', 'pp'), \n",
    "    value_text(x.Previous, 'contribution_of', 'pp')), axis=1)\n",
    "t = final.sort_values('Points', ascending=False)\n",
    "t['of_lt'] = t.of_lt.str.replace(\"a \", \"\")\n",
    "t['of_pr'] = t.of_pr.str.replace(\"a \", \"\")\n",
    "t['overweight'] = ''\n",
    "ltdt = dtxt(dates[0])['mon1']\n",
    "prdt = dtxt(dates[1])['mon1']\n",
    "if t.Ratio.max() > 2:\n",
    "    ocat = t.Ratio.idxmax()\n",
    "    otxt = (f'The {ocat.lower()} category makes up '+\n",
    "            f'{t.loc[ocat, \"CPI-U\"]:.1f} percent of the CPI '+\n",
    "            f'basket, but accounts for {t.loc[ocat, \"Share\"]:.1f} '+\n",
    "            f'percent of {ltdt} inflation. ')\n",
    "    t.at[ocat, 'overweight'] = otxt\n",
    "    \n",
    "cat1 = t.index[0]\n",
    "ltall = res.loc['All items', 'Latest']\n",
    "cat2 = t.index[1]\n",
    "cat3 = t.index[2]\n",
    "cat4 = t.index[3]\n",
    "cat5 = t.drop([cat1, cat2, cat3, cat4]).sort_values('CPI-U').index[-1]\n",
    "text = (f'In {ltdt}, {cat1.lower()} prices {t.loc[cat1, \"to_lt\"]} '+\n",
    "        f'the CPI one-year inflation rate of {ltall:.1f} percent, '+\n",
    "        f\"{t.loc[cat1, 'Compare']} the category's {prdt} \"+\n",
    "        f'{t.loc[cat1, \"of_pr\"]}. {t.loc[cat2, \"overweight\"]}{cat2} '+\n",
    "        f'prices {t.loc[cat2, \"to_lt_cas\"]} {ltdt} inflation, '+\n",
    "        f'{t.loc[cat2, \"Compare\"]} the year-prior {t.loc[cat2, \"of_pr\"]}. '+\n",
    "        f'{t.loc[cat3, \"overweight\"]}{cat3} prices {t.loc[cat3, \"inc_lt\"]} '+\n",
    "        f'in the latest data, compared to {t.loc[cat3, \"same_sign\"]} '+\n",
    "        f'in {prdt}.\\n\\n{cat4} prices '+\n",
    "        f'{t.loc[cat4, \"inc_lt\"]} in {ltdt}, {t.loc[cat4, \"Compare\"]} '+\n",
    "        f'the year-prior {t.loc[cat4, \"of_pr\"]}. {t.loc[cat4, \"overweight\"]}'+\n",
    "        f'{cat5} prices make up {t.loc[cat5, \"CPI-U\"]:.1f} percent of the '+\n",
    "        f'CPI basket and {t.loc[cat5, \"to_lt\"]} overall inflation in the '+\n",
    "        f'latest data, {t.loc[cat5, \"Compare\"]} a {t.loc[cat5, \"of_pr\"]} '+\n",
    "        f'one year prior. {t.loc[cat5, \"overweight\"]}')\n",
    "write_txt(text_dir / 'cpicomp.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Relative Prices Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T00:29:15.275961Z",
     "start_time": "2023-10-16T00:29:15.248601Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPI data and calculate percent change\n",
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "dfc = df.pct_change(12) * 100\n",
    "\n",
    "# Create table\n",
    "tbl = dfc.iloc[[-1, -2, -3, -13]]\n",
    "tbl.index = [dtxt(i)['mon6'].replace(' ', '\\n\\n') for i in tbl.index]\n",
    "t19 = dfc.loc['2019'].mean().rename('2019')\n",
    "tpc = ((df.iloc[-1] / df.loc['2020-02-01']) - 1) * 100\n",
    "tbl = (pd.concat([tbl, t19.to_frame().T, tpc.rename('Since Feb `20')\n",
    "                  .to_frame().T]).applymap('{:,.1f}'.format))\n",
    "wgt_col = f'Weight, {dtxt(dfc.index[-1])[\"mon6\"]}'\n",
    "tbl = pd.concat([tbl, uwt.iloc[-1].apply('{:.3f}'.format).rename(wgt_col).to_frame().T])\n",
    "tbl.loc[wgt_col, 'All items'] = '100.0'\n",
    "\n",
    "order = ['All items', 'All items less food and energy',\n",
    "         'Housing', \"Owners' equivalent rent of residences\",\n",
    "         'Rent of primary residence', 'Lodging away from home', \n",
    "         'Household furnishings and operations', 'Household energy', \n",
    "         'Transportation', 'New vehicles',\n",
    "         'Used cars and trucks', 'Gasoline (all types)', \n",
    "         'Public transportation', 'Medical care', 'Professional services',\n",
    "         'Hospital and related services', 'Health insurance', 'Food',\n",
    "         'Food at home', 'Food away from home',\n",
    "         'Full service meals and snacks', \n",
    "         'Limited service meals and snacks', 'Recreation',\n",
    "         'Communication', 'Wireless telephone services',\n",
    "         'Internet services and electronic information providers', \n",
    "         'Education', 'College tuition and fees', \n",
    "         'Day care and preschool',\n",
    "         'Apparel', 'Personal care']\n",
    "final = tbl[order].T\n",
    "\n",
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "levels = codes.set_index('item_name')['display_level'].to_dict()\n",
    "final.index = [f'\\hspace{{2mm}} {c}' if levels[c] in [2, 3, 4] else c \n",
    "               for c in final.index]\n",
    "rn = {\"\\hspace{2mm} Owners' equivalent rent of residences\": \n",
    "      \"\\hspace{2mm} Owners' equivalent rent\",\n",
    "      'Household furnishings and operations':\n",
    "      '\\hspace{2mm} Household furnishings \\& ops.',\n",
    "      'Public transportation':\n",
    "      '\\hspace{2mm} Public transportation',\n",
    "      '\\hspace{2mm} Full service meals and snacks':\n",
    "      '\\hspace{4mm} Full-service',\n",
    "      '\\hspace{2mm} Limited service meals and snacks':\n",
    "      '\\hspace{4mm} Limited-service',\n",
    "      '\\hspace{2mm} Internet services and electronic information providers':\n",
    "      '\\hspace{2mm} Internet services'}\n",
    "final = (final.rename(rn))\n",
    "(final.to_csv(data_dir / 'cpi_comp.tex', sep='&', \n",
    "              lineterminator='\\\\\\ ', quotechar=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T00:29:17.995400Z",
     "start_time": "2023-10-16T00:29:17.976463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Housing prices increased 5.6 percent over the year ending September 2023, substantially above the pre-COVID rate of 2.9 percent (the average monthly rate during 2019). Medical care prices decreased 1.4 percent, these prices grew at an average rate of 2.8 percent during 2019. In contrast, prices of food consumed at home (groceries) increased 2.4 percent in the year ending September 2023 compared to 0.9 percent during 2019.\n",
      "\n",
      "Transportation prices increased 2.4 percent over the year ending September 2023, substantially above the pre-COVID 0.3 percent decrease. Energy prices decreased 0.5 percent over the year, compared to an average 2.1 percent decrease on average in 2019. Energy prices are historically more volatile than other categories. \n"
     ]
    }
   ],
   "source": [
    "ltdt = dfc.index[-1]\n",
    "cdt = '2019'\n",
    "ltdate = dtxt(ltdt)['mon1']\n",
    "dfc = dfc.dropna()\n",
    "res = pd.DataFrame({ltdt: dfc.iloc[-1], \n",
    "                    cdt: dfc.loc[cdt].mean()})\n",
    "\n",
    "hc = res.loc['Housing', ltdt]\n",
    "h1 = value_text(res.loc['Housing', ltdt])\n",
    "hp = res.loc['Housing', cdt]\n",
    "hch = compare_text(hc, hp, [0.3, 1.0, 3.0])\n",
    "m1 = value_text(res.loc['Medical care', ltdt])\n",
    "mpr = value_text(res.loc['Medical care', cdt], casual=True, \n",
    "                 adj='average')\n",
    "fah1 = value_text(res.loc['Food at home', ltdt])\n",
    "fahpr = res.loc['Food at home', cdt]\n",
    "tc = res.loc['Transportation', ltdt]\n",
    "t1 = value_text(tc)\n",
    "tp = res.loc['Transportation', cdt]\n",
    "tpr = (value_text(tp, style='increase_end')\n",
    "       .replace('a ', '').replace('an ', ''))\n",
    "tch = compare_text(tc, tp, [0.3, 1.0, 3.0])\n",
    "e1 = value_text(res.loc['Energy', ltdt])\n",
    "epr = value_text(res.loc['Energy', cdt], style='increase_end', \n",
    "                 adj='average')\n",
    "\n",
    "text = (f'Housing prices {h1} over the year ending {ltdate}, '+\n",
    "        f'{hch} the pre-COVID rate of {hp:.1f} percent (the average '+\n",
    "        f'monthly rate during 2019). Medical care prices {m1}, '+\n",
    "        f'these prices {mpr} during 2019. '+\n",
    "        'In contrast, prices of food consumed at home '+\n",
    "        f'(groceries) {fah1} in the year ending {ltdate} '+\n",
    "        f'compared to {fahpr:.1f} percent during 2019.\\n\\n'+\n",
    "        f'Transportation prices {t1} over the year ending '+\n",
    "        f'{ltdate}, {tch} the pre-COVID {tpr}. Energy prices '+\n",
    "        f'{e1} over the year, compared to {epr} on average in '+\n",
    "        f'2019. Energy prices are historically more '+\n",
    "        'volatile than other categories. ')\n",
    "write_txt(text_dir / 'cpicomp2.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:55:15.566452Z",
     "start_time": "2023-10-12T12:55:15.546033Z"
    }
   },
   "outputs": [],
   "source": [
    "# CPI data and calculate percent change\n",
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "dfy = df.pct_change(12) * 100\n",
    "dfc = df.pct_change() * 100\n",
    "dfa = (((dfc / 100) + 1)**(12) - 1) * 100\n",
    "# Create table\n",
    "tbl = dfc.iloc[[-1, -2, -3, -4, -5, -6, -12, -13]]\n",
    "tbl.index = [dtxt(i)['mon6'].replace(' ', '\\n\\n') for i in tbl.index]\n",
    "order = ['All items', 'All items less food and energy',\n",
    "         'Housing', \"Owners' equivalent rent of residences\",\n",
    "         'Rent of primary residence', 'Lodging away from home', \n",
    "         'Household furnishings and operations', 'Household energy', \n",
    "         'Transportation', 'New vehicles',\n",
    "         'Used cars and trucks', 'Gasoline (all types)', \n",
    "         'Public transportation', 'Medical care', 'Professional services',\n",
    "         'Hospital and related services', 'Health insurance', 'Food',\n",
    "         'Food at home', 'Food away from home',\n",
    "         'Full service meals and snacks', \n",
    "         'Limited service meals and snacks', 'Recreation',\n",
    "         'Communication', 'Wireless telephone services',\n",
    "         'Internet services and electronic information providers', \n",
    "         'Education', 'College tuition and fees', \n",
    "         'Day care and preschool',\n",
    "         'Apparel', 'Personal care']\n",
    "\n",
    "nsa = ['Health insurance', 'Limited service meals and snacks', \n",
    "       'Wireless telephone services']\n",
    "\n",
    "order = [i + ' (SA)' if i not in nsa else i for i in order]\n",
    "final = tbl[order].T.applymap('{:,.1f}'.format)\n",
    "final.index = final.index.str.replace(' (SA)', '', regex=False)\n",
    "\n",
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "levels = codes.set_index('item_name')['display_level'].to_dict()\n",
    "final.index = [f'\\hspace{{2mm}} {c}' if levels[c] in [2, 3, 4] else c \n",
    "               for c in final.index]\n",
    "rn = {\"\\hspace{2mm} Owners' equivalent rent of residences\": \n",
    "      \"\\hspace{2mm} Owners' equivalent rent\",\n",
    "      'Household furnishings and operations':\n",
    "      '\\hspace{2mm} Household furnishings \\& ops.',\n",
    "      'Public transportation':\n",
    "      '\\hspace{2mm} Public transportation',\n",
    "      '\\hspace{2mm} Full service meals and snacks':\n",
    "      '\\hspace{4mm} Full-service',\n",
    "      '\\hspace{2mm} Limited service meals and snacks':\n",
    "      '\\hspace{4mm} Limited-service*',\n",
    "      '\\hspace{2mm} Wireless telephone services':\n",
    "      '\\hspace{2mm} Wireless telephone services*',\n",
    "      '\\hspace{2mm} Health insurance':\n",
    "      '\\hspace{2mm} Health insurance*',\n",
    "      '\\hspace{2mm} Internet services and electronic information providers':\n",
    "      '\\hspace{2mm} Internet services'}\n",
    "final = (final.rename(rn))\n",
    "(final.to_csv(data_dir / 'cpi_comp_mo.tex', sep='&', \n",
    "              lineterminator='\\\\\\ ', quotechar=' '))\n",
    "#final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:55:22.360724Z",
     "start_time": "2023-10-12T12:55:22.354609Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Work in progress\n",
    "def month_comp(s):\n",
    "    '''Return text to describe the data from three consecutive months '''\n",
    "    '''from series with length of three and a monthly datetime index.'''\n",
    "    if len(s) != 3:\n",
    "        print('Series must be three consecutive months (length == 3)')\n",
    "        pass\n",
    "    \n",
    "    if isinstance(s, pd.DataFrame):\n",
    "        if len(s.columns == 1):\n",
    "            s = s.squeeze()\n",
    "        else:\n",
    "            print('Input must be series (one column)')\n",
    "            pass\n",
    "    \n",
    "    # Store date, month, and year\n",
    "    dt1 = s.index[-1]\n",
    "    mo1 = dt1.month\n",
    "    yr1 = dt1.year\n",
    "    dt2 = s.index[-2]\n",
    "    mo2 = dt2.month\n",
    "    yr2 = dt2.year\n",
    "    dt3 = s.index[-3]\n",
    "    mo3 = dt3.month\n",
    "    yr3 = dt3.year\n",
    "    \n",
    "    # Create date text for each month\n",
    "    date1 = dtxt(dt1)['mon1']\n",
    "    date2 = dtxt(dt2)['mon1']# if yr1 != yr2 else dtxt(dt2)['mon3']\n",
    "    date3 = dtxt(dt3)['mon1']# if yr1 != yr3 else dtxt(dt3)['mon3']\n",
    "    \n",
    "    # Store the values\n",
    "    val1 = round(s.iloc[-1],1)\n",
    "    vt1 = value_text(val1, threshold=0.1)\n",
    "    val2 = round(s.iloc[-2],1)\n",
    "    vt2 = value_text(val2, threshold=0.1)\n",
    "    val3 = round(s.iloc[-3],1)\n",
    "    vt3 = value_text(val3, threshold=0.1)\n",
    "    \n",
    "    # Check if values are the same\n",
    "    same_all = False\n",
    "    allt = ''\n",
    "    if val1 == val2 == val3:\n",
    "        same_all = True\n",
    "        allt = 'also '\n",
    "        \n",
    "    same1_2 = False\n",
    "    t12 = ''\n",
    "    if val1 == val2:\n",
    "        same1_2 = True\n",
    "        t12 = f'in both {date1} and {date2}'\n",
    "    t23 = ''\n",
    "    same2_3 = False\n",
    "    if val2 == val3:\n",
    "        same2_3 = True\n",
    "        t23 = f'in both {date2} and in {date3}'\n",
    "        \n",
    "    # Value text\n",
    "    txt1 = value_text(val1, 'plain')\n",
    "    txt2 = value_text(val1, 'plain')\n",
    "    txt3 = value_text(val1, 'plain')\n",
    "    \n",
    "    t1 = f'{vt1} in {date1}'\n",
    "    t2 = f'{vt2} in {date2}, and {vt3} in {date3}'\n",
    "    if same2_3 == True:\n",
    "        t2 = f'{vt2} {t23}'\n",
    "        \n",
    "    return([t1, t2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-12T12:55:23.204085Z",
     "start_time": "2023-10-12T12:55:23.191883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning to one-month growth, the core CPI, which excludes food and energy, increased 0.3 percent in September 2023, or 3.9 percent annualized, slightly below the one-year core CPI inflation rate of 4.1 percent. The core CPI increased 0.3 percent in August 2023, and increased 0.2 percent in July 2023.\n",
      "\n",
      "In September, housing prices increased 0.6 percent, (7.3 percent annualized). Over the past three months, housing prices increased at an average annualized rate of 5.1 percent, substantially above the 12-month rate of 4.1 percent. Food prices increased 0.2 percent in September, or 2.8 percent, annualized, compared to a three-month average of 2.9 percent.\n",
      "\n",
      "Transportation prices increased at an annualized rate of 3.9 percent in September, and increased at an average annualized rate of 13.2 percent over the past three months. Energy prices increased at an annualized rate of 19.9 percent in September, and increased at an average annualized rate of 37.7 percent over the past three months.\n"
     ]
    }
   ],
   "source": [
    "# Core CPI\n",
    "s = 'All items less food and energy (SA)'\n",
    "s1 = dfc[s].iloc[-3:]\n",
    "vt = month_comp(s1) # Returns text describing changes\n",
    "\n",
    "# Compare monthly value to one-year (12-month) value\n",
    "chy = dfy[s].iloc[-1]\n",
    "cha = dfa[s].iloc[-1]\n",
    "chat = f'{cha:.1f} percent'\n",
    "ct = compare_text(cha, chy, [0.1, 0.5, 2.0])\n",
    "ctt = f'{ct} the one-year core CPI inflation rate of {chy:.1f} percent'\n",
    "\n",
    "txt1 = ('Turning to one-month growth, the core CPI, which '+\n",
    "        f'excludes food and energy, {vt[0]}, or {chat} annualized, '+\n",
    "        f'{ctt}. The core CPI {vt[1]}.\\n\\n')\n",
    "\n",
    "# Text for different categories\n",
    "ltdt = dtxt(dfc.index[-1])['mon1']\n",
    "ltmo = dtxt(dfc.index[-1])['mon3']\n",
    "\n",
    "cats = ['Housing (SA)', 'Transportation (SA)', 'Food (SA)', 'Energy (SA)']\n",
    "d = {c: {} for c in cats}\n",
    "for c in cats:\n",
    "    t = c[:-4].lower() + 'prices'\n",
    "    s1 = dfc[c].iloc[-3:]\n",
    "    vt = month_comp(s1)\n",
    "    ltv = dfc[c].iloc[-1]\n",
    "    ltvt = value_text(ltv, threshold=0.1)\n",
    "    ltvalmo = f'{ltvt} in {ltmo}'\n",
    "    lta = dfa[c].iloc[-1]\n",
    "    ltat = value_text(lta, 'plain', threshold=0.1)\n",
    "    ltat2 = value_text(lta, threshold=0.1, adj='annualized') + f' in {ltmo}'\n",
    "    lt3m = dfa[c].iloc[-3:].mean()\n",
    "    lt3mt = value_text(lt3m, threshold=0.1, adj='avg_ann')\n",
    "    chy = dfy[s].iloc[-1]\n",
    "    ct = compare_text(lt3m, chy, [0.1, 0.5, 2.0])\n",
    "    ctt = f'{ct} the 12-month rate of {chy:.1f} percent'\n",
    "    eqt = f'equivalent to an annualized rate of {ltat}'\n",
    "    eqt2 = f'an annualized rate of {ltat}'\n",
    "    eqt3 = f'or {ltat}, annualized'\n",
    "    eqt4 = f'({ltat} annualized)'\n",
    "    t3m = f'a three-month average of {lt3m:.1f} percent'\n",
    "    d[c]['t1'] = (f'In {ltmo}, {t} {ltvt}, {eqt4}. '+\n",
    "                  f'Over the past three months, {t} '+\n",
    "                  f'{lt3mt}, {ctt}.')\n",
    "    d[c]['t2'] = vt\n",
    "    d[c]['t3'] = ctt\n",
    "    d[c]['t4'] = eqt2\n",
    "    d[c]['t5'] = t3m\n",
    "    d[c]['t6'] = ltvalmo\n",
    "    d[c]['t7'] = ltat2\n",
    "    d[c]['t8'] = f'{lt3mt} over the past three months'\n",
    "    d[c]['t9'] = eqt3\n",
    "    d[c]['t0'] = eqt4\n",
    "    \n",
    "txt2 = (f'{d[\"Housing (SA)\"][\"t1\"]} Food prices {d[\"Food (SA)\"][\"t6\"]}'+\n",
    "       f', {d[\"Food (SA)\"][\"t9\"]}, compared to '+\n",
    "       f'{d[\"Food (SA)\"][\"t5\"]}.\\n\\nTransportation prices '+\n",
    "       f'{d[\"Transportation (SA)\"][\"t7\"]}, and '+\n",
    "       f'{d[\"Transportation (SA)\"][\"t8\"]}. Energy prices '+\n",
    "       f'{d[\"Energy (SA)\"][\"t7\"]}, and '+\n",
    "       f'{d[\"Energy (SA)\"][\"t8\"]}.')\n",
    "\n",
    "text = txt1 + txt2\n",
    "write_txt(text_dir / 'cpi_monthly_rel.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CPI Decomposition (ROUGH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T00:38:42.166940Z",
     "start_time": "2023-10-13T00:38:42.159713Z"
    }
   },
   "outputs": [],
   "source": [
    "# Relative weights for series of interest, from here: \n",
    "# https://www.bls.gov/cpi/tables/relative-importance/home.htm\n",
    "rel_wgt = {'CUUR0000SAF1': [(('2009-12-01', '2011-12-01'), 13.738),\n",
    "                           (('2011-12-01', '2013-12-01'), 14.308),\n",
    "                           (('2013-12-01', '2015-12-01'), 13.891), \n",
    "                           (('2015-12-01', '2017-12-01'), 14.015), \n",
    "                           (('2017-12-01', '2019-12-01'), 13.384),\n",
    "                           (('2019-12-01', '2021-12-01'), 13.771),\n",
    "                           (('2021-12-01', '2023-12-01'), 13.370)],\n",
    "           'CUUR0000SA0': [(('2009-12-01', '2011-12-01'), 100.0),\n",
    "                           (('2011-12-01', '2013-12-01'), 100.0),\n",
    "                           (('2013-12-01', '2015-12-01'), 100.0), \n",
    "                           (('2015-12-01', '2017-12-01'), 100.0), \n",
    "                           (('2017-12-01', '2019-12-01'), 100.0),\n",
    "                           (('2019-12-01', '2021-12-01'), 100.0),\n",
    "                           (('2021-12-01', '2023-12-01'), 100.0)],\n",
    "           'CUUR0000SA0E': [(('2009-12-01', '2011-12-01'), 8.553),\n",
    "                            (('2011-12-01', '2013-12-01'), 9.679),\n",
    "                            (('2013-12-01', '2015-12-01'), 9.046), \n",
    "                            (('2015-12-01', '2017-12-01'), 6.816), \n",
    "                            (('2017-12-01', '2019-12-01'), 7.513),\n",
    "                            (('2019-12-01', '2021-12-01'), 6.706),\n",
    "                            (('2021-12-01', '2023-12-01'), 7.348)],\n",
    "           'CUUR0000SAH1': [(('2009-12-01', '2011-12-01'), 32.289),\n",
    "                            (('2011-12-01', '2013-12-01'), 31.539),\n",
    "                            (('2013-12-01', '2015-12-01'), 32.029), \n",
    "                            (('2015-12-01', '2017-12-01'), 33.15), \n",
    "                            (('2017-12-01', '2019-12-01'), 32.843),\n",
    "                            (('2019-12-01', '2021-12-01'), 33.158),\n",
    "                            (('2021-12-01', '2023-12-01'), 32.946)],\n",
    "           'CUUR0000SACL1E': [(('2009-12-01', '2011-12-01'), 21.276),\n",
    "                              (('2011-12-01', '2013-12-01'), 19.852),\n",
    "                              (('2013-12-01', '2015-12-01'), 19.71), \n",
    "                              (('2015-12-01', '2017-12-01'), 19.613), \n",
    "                              (('2017-12-01', '2019-12-01'), 19.849),\n",
    "                              (('2019-12-01', '2021-12-01'), 20.137),\n",
    "                              (('2021-12-01', '2023-12-01'), 21.699)],\n",
    "           'CUUR0000SASLE': [(('2009-12-01', '2011-12-01'), 56.432),\n",
    "                             (('2011-12-01', '2013-12-01'), 56.161),\n",
    "                             (('2013-12-01', '2015-12-01'), 57.353), \n",
    "                             (('2015-12-01', '2017-12-01'), 59.556), \n",
    "                             (('2017-12-01', '2019-12-01'), 59.254),\n",
    "                             (('2019-12-01', '2021-12-01'), 59.387),\n",
    "                             (('2021-12-01', '2023-12-01'), 57.583)]}\n",
    "series = {key: key for key, value in rel_wgt.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T00:38:43.873034Z",
     "start_time": "2023-10-13T00:38:43.756561Z"
    }
   },
   "outputs": [],
   "source": [
    "codes = pd.read_csv(data_dir / 'cpi_codes.csv', index_col=0)\n",
    "ids = (codes.reset_index().set_index('item_name')\n",
    "       .item_code.apply(lambda x: 'CUUR0000' + x).to_dict())\n",
    "df = pd.read_csv(data_dir / 'cpi_raw.csv', index_col='date', \n",
    "                 parse_dates=True).rename(ids, axis=1)\n",
    "\n",
    "# Dictionary combining all the info for each series\n",
    "d = {i: {'name': i,\n",
    "         'values': df[i],\n",
    "         'rel_wgt': rel_wgt[i]} for i in list(rel_wgt.keys())}\n",
    "\n",
    "# Adjust for changes to relative importance\n",
    "df1, df2, df3, df4, df5, df6, df7 = (pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame(), pd.DataFrame(), \n",
    "                                     pd.DataFrame())\n",
    "for i, v in d.items():\n",
    "    start, end = v['rel_wgt'][0][0][0], v['rel_wgt'][0][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][0][1], v['rel_wgt'][1][1]\n",
    "    df1.at[start: end, i] = (v['values'].loc[start: end])\n",
    "    df1[i] = (df1[i].diff().cumsum() / df1.loc[start, i] + 1)\n",
    "    df1.at[start, i] = 1.0\n",
    "    df1[i] = (df1[i] * rwc)\n",
    "    link = (df1.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][1][0][0], v['rel_wgt'][1][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][1][1], v['rel_wgt'][2][1]\n",
    "    df2[i] = (v['values'].loc[start: end])\n",
    "    df2[i] = df2[i].diff().cumsum() / df2.loc[start, i] + 1\n",
    "    df2.at[start, i] = 1.0\n",
    "    df2[i] = (df2[i] * rwc) * link\n",
    "    link = (df2.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][2][0][0], v['rel_wgt'][2][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][2][1], v['rel_wgt'][3][1]\n",
    "    df3[i] = (v['values'].loc[start: end])\n",
    "    df3[i] = df3[i].diff().cumsum() / df3.loc[start, i] + 1\n",
    "    df3.at[start, i] = 1.0\n",
    "    df3[i] = (df3[i] * rwc) * link\n",
    "    link = (df3.loc[end, i] / rwn)\n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][3][0][0], v['rel_wgt'][3][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][3][1], v['rel_wgt'][4][1]\n",
    "    df4[i] = (v['values'].loc[start: end])\n",
    "    df4[i] = df4[i].diff().cumsum() / df4.loc[start, i] + 1\n",
    "    df4.at[start, i] = 1.0\n",
    "    df4[i] = (df4[i] * rwc) * link\n",
    "    link = (df4.loc[end, i] / rwn)\n",
    "\n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][4][0][0], v['rel_wgt'][4][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][4][1], v['rel_wgt'][5][1]\n",
    "    df5[i] = (v['values'].loc[start: end])\n",
    "    df5[i] = df5[i].diff().cumsum() / df5.loc[start, i] + 1\n",
    "    df5.at[start, i] = 1.0\n",
    "    df5[i] = (df5[i] * rwc) * link\n",
    "    link = (df5.loc[end, i] / rwn)    \n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][5][0][0], v['rel_wgt'][5][0][1]\n",
    "    rwc, rwn = v['rel_wgt'][5][1], v['rel_wgt'][6][1]\n",
    "    df6[i] = (v['values'].loc[start: end])\n",
    "    df6[i] = df6[i].diff().cumsum() / df6.loc[start, i] + 1\n",
    "    df6.at[start, i] = 1.0\n",
    "    df6[i] = (df6[i] * rwc) * link\n",
    "    link = (df6.loc[end, i] / rwn)   \n",
    "    \n",
    "    # Next set of dates\n",
    "    start, end = v['rel_wgt'][6][0][0], v['rel_wgt'][6][0][1]\n",
    "    rwc = v['rel_wgt'][6][1]\n",
    "    df7[i] = (v['values'].loc[start: end])\n",
    "    df7[i] = df7[i].diff().cumsum() / df7.loc[start, i] + 1\n",
    "    df7.at[start, i] = 1.0\n",
    "    df7[i] = (df7[i] * rwc) * link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T00:38:47.693669Z",
     "start_time": "2023-10-13T00:38:47.675082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In September 2023, core goods did not contribute to the one-year non-seasonally-adjusted CPI inflation rate of 3.7 percent (see\\cbox{blue!85!black}), while core services excluding shelter contributed 0.9 percentage point (see\\cbox{green!60!black}). Shelter added 2.4 percentage points (see\\cbox{cyan!50!white}), and food \\& energy added 0.5 percentage point (see\\cbox{orange!80!red}).\n",
      "\n",
      " One year prior, in September 2022, the corresponding CPI inflation rate was 8.2 percent; core goods contributed 1.2 percentage points, core services excluding shelter contributed 1.7 percentage points, shelter contributed 2.3 percentage points, and food and energy added 3.2 percentage points.\n"
     ]
    }
   ],
   "source": [
    "res = pd.concat([df1, df2, df3, df4, df5, df6, df7])  \n",
    "# Drop duplicate pivot year data\n",
    "res = res[~res.index.duplicated(keep='first')] \n",
    "final = ((res.diff(12).divide(res['CUUR0000SA0'].diff(12), axis=0))\n",
    "         .multiply(res['CUUR0000SA0'].pct_change(12) * 100, axis=0))\n",
    "# Core services is services less food, energy, and shelter\n",
    "final['core_services'] = final['CUUR0000SASLE'] - final['CUUR0000SAH1']\n",
    "# Combine food and energy\n",
    "final['food_energy'] = final['CUUR0000SAF1'] + final['CUUR0000SA0E']\n",
    "final = final.dropna().round(2)\n",
    "d2 = (final[['CUUR0000SACL1E', 'core_services', 'CUUR0000SAH1', 'food_energy']]\n",
    "      .loc['2011-01-01':])\n",
    "col_names = ['core_goods', 'core_services', 'shelter', 'food_energy']\n",
    "d2.columns = col_names\n",
    "d2['total'] = final['CUUR0000SA0'].loc['2011-01-01':]\n",
    "\n",
    "d2.to_csv(data_dir / 'cpi_decomp.csv', index_label='date', \n",
    "           float_format='%g')\n",
    "\n",
    "ltdate = dtxt(d2.index[-1])['mon1']\n",
    "prdate = dtxt(d2.index[-13])['mon1']\n",
    "cg = value_text(d2.core_goods.iloc[-1], 'contribution_to', 'pp', threshold=0.1)\n",
    "cs = value_text(d2.core_services.iloc[-1], 'contribution', 'pp', threshold=0.1)\n",
    "sh = value_text(d2.shelter.iloc[-1], 'contribution', 'pp', \n",
    "                casual=True, threshold=0.1)\n",
    "fe = value_text(d2.food_energy.iloc[-1], 'contribution', 'pp', \n",
    "                casual=True, threshold=0.1)\n",
    "tot = d2.total.iloc[-1]\n",
    "cgpr = value_text(d2.core_goods.iloc[-13], 'contribution', 'pp', threshold=0.1)\n",
    "cspr = value_text(d2.core_services.iloc[-13], 'contribution', 'pp', threshold=0.1)\n",
    "shpr = value_text(d2.shelter.iloc[-13], 'contribution', 'pp', threshold=0.1)\n",
    "fepr = value_text(d2.food_energy.iloc[-13], 'contribution', 'pp', \n",
    "                  casual=True, threshold=0.1)\n",
    "totpr = d2.total.iloc[-13]\n",
    "colors = {'cg': 'blue!85!black', 'cs': 'green!60!black', \n",
    "          'sh': 'cyan!50!white', 'fe': 'orange!80!red'}\n",
    "cbs = {name: c_box(color).replace('see ', 'see') for name, color in colors.items()}\n",
    "text = (f'In {ltdate}, core goods {cg} the one-year non-seasonally-'+\n",
    "        f'adjusted CPI inflation rate of {tot:.1f} percent '+\n",
    "        f'{cbs[\"cg\"]}, while core services excluding shelter {cs} '+\n",
    "        f'{cbs[\"cs\"]}. Shelter {sh} {cbs[\"sh\"]}, and food \\& energy '+\n",
    "        f'{fe} {cbs[\"fe\"]}.\\n\\n One year prior, in {prdate}, the '+\n",
    "        f'corresponding CPI inflation rate was {totpr:.1f} percent; '\n",
    "        f'core goods {cgpr}, core services excluding shelter {cspr}, '+\n",
    "        f'shelter {shpr}, and food and energy {fepr}.')\n",
    "write_txt(text_dir / 'cpi_decomp.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T12:24:31.075479Z",
     "start_time": "2022-05-11T12:24:31.075469Z"
    }
   },
   "outputs": [],
   "source": [
    "# cols = list(rel_wgt.keys())\n",
    "# d = {c: {} for c in cols}\n",
    "# data = {c: {} for c in cols}\n",
    "# dates = [f'{i}-12-01' for i in range(2009, 2023, 2)]\n",
    "# for s, i in itertools.product(cols, dates):\n",
    "#     start, end, prev = (i, dtxt(pd.to_datetime(i) + \n",
    "#                          pd.DateOffset(years=2))['datetime'],\n",
    "#                         dtxt(pd.to_datetime(i) - \n",
    "#                          pd.DateOffset(years=2))['datetime'])\n",
    "#     ri = [w[1] for w in rel_wgt[s] if w[0][0] == start][0]\n",
    "#     base = df.loc[start, s]\n",
    "#     print(s)\n",
    "#     dt = pd.to_datetime(i)\n",
    "#     d10 = pd.to_datetime('2010-01-01')\n",
    "#     prev_link = d[s][prev] if dt > d10 else df.loc[start, s]\n",
    "#     print(prev_link)\n",
    "#     val = (ri * df.loc[start:end, s]) / prev_link\n",
    "#     d[s][start] = (val[-1] / val[0]) * df.loc[:end, s].iloc[-1]\n",
    "#     data[s].update(val.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T12:47:35.012528Z",
     "start_time": "2023-10-11T12:47:31.182219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "df = bls_api({'WPUFD4': 'PPIFD',\n",
    "              'WPSFD4': 'PPIFDsa',\n",
    "              'WPU00000000': 'PPIACO',\n",
    "              'WPUFD49116': 'PPIFD_Core',\n",
    "              'WPU101707': 'Steel',\n",
    "              'WPU081': 'Lumber'}, (1988, 2023), bls_key)\n",
    "df.to_csv(data_dir / 'ppi_index.csv', index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-17T17:56:33.796486Z",
     "start_time": "2023-10-17T17:56:33.767410Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bureau of Labor Statistics \\href{https://www.bls.gov/ppi/}{report} \\textbf{prices producers receive}. The goods-only producer price index (PPI) for all commodities (see {\\color{green!80!blue}\\textbf{---}}) decreased 3.3 percent over the year ending September 2023, far below the 12-month growth rate of 13.7 percent in September 2022. The index for final demand goods, services, and construction increased 2.2 percent over the year ending September 2023 (see {\\color{violet}\\textbf{---}}).\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'ppi_index.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "ppi = (df[['PPIACO', 'PPIFD']].pct_change(12) * 100)\n",
    "ppi.to_csv(data_dir / 'ppi.csv', index_label='date')\n",
    "\n",
    "adj = node_adj(ppi[['PPIACO', 'PPIFD']])\n",
    "smax = ppi[['PPIACO', 'PPIFD']].iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'PPIACO': 'green!80!blue', \n",
    "          'PPIFD': 'violet'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(ppi[series], color, \n",
    "                            date=date[series], \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'ppi_nodes.txt', nodes)  \n",
    "\n",
    "ch = value_text(ppi.PPIACO.iloc[-1])\n",
    "fd = value_text(ppi.PPIFD.iloc[-1])\n",
    "prval = ppi.PPIACO.iloc[-13]\n",
    "yr3val = ppi.PPIACO.rolling(36).mean().iloc[-1]\n",
    "compare = compare_text(ppi.PPIACO.iloc[-1], prval, [1.0, 3.0, 5.0])\n",
    "date = dtxt(ppi.index[-1])['mon1']\n",
    "date2 = dtxt(ppi.index[-13])['mon1']\n",
    "\n",
    "text = ('The Bureau of Labor Statistics \\\\href{https://www.bls.gov/ppi/}'+\n",
    "        '{report} \\\\textbf{prices producers receive}. The goods-only producer '+\n",
    "        f'price index (PPI) for all commodities {c_line(colors[\"PPIACO\"])} '+\n",
    "        f'{ch} over the year ending {date}, {compare} the 12-month '+\n",
    "        f'growth rate of {prval:.1f} percent in {date2}. The index for final '+\n",
    "        f'demand goods, services, and construction {fd} over the year ending '+\n",
    "        f'{date} {c_line(colors[\"PPIFD\"])}.')\n",
    "write_txt(text_dir / 'ppi_main.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T12:47:41.510393Z",
     "start_time": "2023-10-11T12:47:41.485450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In September 2023, the one-month change in PPI final demand prices was 0.5 percent (see\\cbox{violet}), following an increase of 0.7 percent in August 2023. The one-month change in the all commodities index was 0.5 percent (see\\cbox{green!80!blue}) in September 2023 and 1.5 percent in August 2023.\n"
     ]
    }
   ],
   "source": [
    "# One month change\n",
    "df = pd.read_csv(data_dir / 'ppi_index.csv', index_col='date', \n",
    "                 parse_dates=True)\n",
    "s = df[['PPIFDsa', 'PPIACO']]\n",
    "data = ((np.log(s) - np.log(s.shift(1)))) * 100\n",
    "data['label'] = [dt.strftime('%b\\\\\\`%y') if dt.month == 1 \n",
    "                 else dt.strftime('%b') for dt in data.index]\n",
    "data.iloc[-19:].to_csv(data_dir / 'ppi_monthly.csv', \n",
    "                         index_label='date', float_format='%g')\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "prdate = dtxt(data.index[-2])['mon1']\n",
    "ltval = value_text(data.PPIFDsa.iloc[-1], 'plain')\n",
    "prval = value_text(data.PPIFDsa.iloc[-2], 'increase_of', threshold=0.1)\n",
    "ltaval = value_text(data.PPIACO.iloc[-1], 'plain')\n",
    "praval = value_text(data.PPIACO.iloc[-2], 'plain')\n",
    "text = (f'In {ltdate}, the one-month change in PPI final '+\n",
    "        f'demand prices was {ltval} {c_box(\"violet\")}, following '+\n",
    "        f'{prval} in {prdate}. The one-month '+\n",
    "        f'change in the all commodities index was {ltaval} '+\n",
    "        f'{c_box(\"green!80!blue\")} in {ltdate} and {praval} '+\n",
    "        f'in {prdate}.')\n",
    "write_txt(text_dir / 'ppi_monthly.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-11T12:47:43.588305Z",
     "start_time": "2023-10-11T12:47:43.571098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the producer price index, cold-rolled steel sheet and strip prices (see {\\color{blue!50!gray}\\textbf{---}}) have decreased 18.0 percent over the year ending September 2023, and increased 65.8 percent total since December 2019. Lumber prices (see {\\color{green!60!yellow!90!black}\\textbf{---}}) decreased 13.7 percent over the year ending September 2023, and increased 20.0 percent total since 2019.\n"
     ]
    }
   ],
   "source": [
    "p = df[['Steel', 'Lumber']]\n",
    "data = (p / p.iloc[0]).loc['1989':]\n",
    "data.to_csv(data_dir / 'ppi_commodities.csv', index_label='date', \n",
    "            float_format='%g')\n",
    "\n",
    "stlt = value_text(data.Steel.pct_change(12).iloc[-1] * 100)\n",
    "ltdt = dtxt(data.index[-1])['mon1']\n",
    "st19 = value_text(((data.Steel.iloc[-1] / \n",
    "                    data.loc['2019-12-01', 'Steel']) - 1) * 100)\n",
    "lumlt = value_text(data.Lumber.pct_change(12).iloc[-1] * 100)\n",
    "lum19 = value_text(((data.Lumber.iloc[-1] / \n",
    "                    data.loc['2019-12-01', 'Lumber']) - 1) * 100)\n",
    "stcol = c_line('blue!50!gray')\n",
    "lucol = c_line('green!60!yellow!90!black')\n",
    "text = ('From the producer price index, cold-rolled steel sheet and '+\n",
    "        f'strip prices {stcol} have {stlt} over the year ending {ltdt}, '+\n",
    "        f'and {st19} total since December 2019. '+\n",
    "        f'Lumber prices {lucol} {lumlt} over the year ending {ltdt}, '+\n",
    "        f'and {lum19} total since 2019.')\n",
    "write_txt(text_dir / 'ppi_commodities.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import/Export Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T13:45:54.994848Z",
     "start_time": "2023-10-13T13:45:51.270597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post Request Status: REQUEST_SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "# Series stored as a dictionary\n",
    "series = {'EIUIR': 'Imports', \n",
    "          'EIUIQ': 'Exports',\n",
    "          'EIUIREXFUELS': 'ImpExFuels',\n",
    "          'EIUIR10': 'ImpFuels',\n",
    "          'EIUIQEXAG': 'ExpExAg',\n",
    "          'EIUIQAG': 'ExpAg'}\n",
    "\n",
    "# Start year and end year\n",
    "years = (1988, 2023)\n",
    "df = bls_api(series, years, bls_key)\n",
    "\n",
    "df.to_csv(data_dir / 'mxpi_main.csv', index_label='date')\n",
    "\n",
    "srs = ['Imports', 'Exports']\n",
    "(df[srs].pct_change(12).dropna() * 100).to_csv(data_dir / 'mxpi.csv', \n",
    "                                               index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T13:45:56.359574Z",
     "start_time": "2023-10-13T13:45:56.337845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bureau of Labor Statistics \\href{https://www.bls.gov/news.release/ximpim.nr0.htm}{report} changes in the prices of imports and exports. Over the year ending September 2023, \\textbf{US import prices} fell 1.7 percent (see {\\color{cyan!58!white}\\textbf{---}}), following decreases of 2.9 percent in August and 4.7 percent in July. Excluding fuels, US import prices decreased 0.8 percent in September 2023 and fell 0.9 percent in August. In 2019, US import prices decreased at an average rate of 1.3 percent. Excluding fuels, import prices decreased at an average rate of 1.1 percent in 2019.\n",
      "\n",
      "\\textbf{Prices of US exports} fell 4.1 percent over the year ending September 2023 (see {\\color{blue!90!black}\\textbf{---}}), following decreases of 5.7 percent in August, and 8.0 percent in July. In 2019, export prices decreased at an average rate of 0.8 percent.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'mxpi_main.csv', index_col='date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "data = (df.pct_change(12).dropna() * 100)\n",
    "\n",
    "adj = node_adj(data[['Imports', 'Exports']])\n",
    "smax = data[['Imports', 'Exports']].iloc[-1].idxmax()\n",
    "adj[smax] = adj[smax] + 0.35\n",
    "\n",
    "colors = {'Imports': 'cyan!58!white', \n",
    "          'Exports': 'blue!90!black'}\n",
    "date = {series: 'm' if series == smax else None \n",
    "        for series in colors.keys()}\n",
    "nodes  ='\\n'.join([end_node(data[series], color, \n",
    "                            date=date[series], \n",
    "                            size=1.1, offset=adj[series]) \n",
    "                   for series, color in colors.items()])\n",
    "write_txt(text_dir / 'mxpi_nodes.txt', nodes)  \n",
    "\n",
    "ltdate = dtxt(data.index[-1])['mon1']\n",
    "prdate = dtxt(data.index[-2])['mon1']\n",
    "prdate2 = dtxt(data.index[-3])['mon1']\n",
    "mv1 = data['Imports'].iloc[-1]\n",
    "mv2 = data['Imports'].iloc[-2]\n",
    "mv3 = data['Imports'].iloc[-3]\n",
    "mv4 = data.loc['2019', 'Imports'].mean()\n",
    "m1 = value_text(mv1, casual=True, threshold=0.1, obj='plural')\n",
    "m2 = value_text(mv2, style='increase_of', threshold=0.1, obj='plural')\n",
    "m3 = value_text(mv3, style='increase_of', threshold=0.1, obj='plural')\n",
    "mpc = value_text(mv4, threshold=0.1, obj='plural', adj='average')\n",
    "mfv1 = data['ImpExFuels'].iloc[-1]\n",
    "mfv2 = data['ImpExFuels'].iloc[-2]\n",
    "mfv3 = data.loc['2019', 'ImpExFuels'].mean()\n",
    "mf1 = value_text(mfv1, threshold=0.1, obj='plural')\n",
    "mf2 = value_text(mfv2, casual=True, threshold=0.1, obj='plural')\n",
    "mfpc = value_text(mfv3, threshold=0.1, obj='plural', adj='average')\n",
    "if data.index[-1].year == data.index[-2].year:\n",
    "    prdate = dtxt(data.index[-2])['mon3']\n",
    "if data.index[-2].year == data.index[-3].year:\n",
    "    prdate2 = dtxt(data.index[-3])['mon3']\n",
    "if np.sign(mv2) == np.sign(mv3):\n",
    "    m3 = f'{abs(mv3):.1f} percent'\n",
    "ftxt = (f'{m2} in {prdate} and {m3} in {prdate2}'\n",
    "        .replace('a decrease of', 'decreases of')\n",
    "        .replace('an increase of', 'increases of'))\n",
    "\n",
    "xv1 = data['Exports'].iloc[-1]\n",
    "xv2 = data['Exports'].iloc[-2]\n",
    "xv3 = data['Exports'].iloc[-3]\n",
    "xv4 = data.loc['2019', 'Exports'].mean()\n",
    "x1 = value_text(xv1, casual=True, threshold=0.1, obj='plural')\n",
    "x2 = value_text(xv2, style='increase_of', threshold=0.1, obj='plural')\n",
    "x3 = value_text(xv3, style='increase_of', threshold=0.1, obj='plural')\n",
    "x4 = value_text(xv4, adj='average', threshold=0.1, obj='plural')\n",
    "if np.sign(xv2) == np.sign(xv3):\n",
    "        x3 = f'{abs(xv3):.1f} percent'\n",
    "ftxt2 = (f'following {x2} in {prdate}, and {x3} in {prdate2}'\n",
    "         .replace('a decrease of', 'decreases of')\n",
    "         .replace('an increase of', 'increases of'))\n",
    "\n",
    "url = 'https://www.bls.gov/news.release/ximpim.nr0.htm'\n",
    "text = (f'The Bureau of Labor Statistics \\href{{{url}}}{{report}} '+\n",
    "        'changes in the prices of imports and exports. Over the '+\n",
    "        f'year ending {ltdate}, \\\\textbf{{US import prices}} {m1} '+\n",
    "        f'{c_line(colors[\"Imports\"])}, following {ftxt}. Excluding '+\n",
    "        f'fuels, US import prices {mf1} in {ltdate} and {mf2} '+\n",
    "        f'in {prdate}. In 2019, US import prices {mpc}. Excluding '+\n",
    "        f'fuels, import prices {mfpc} in 2019.\\n\\n'+\n",
    "        f'\\\\textbf{{Prices of US exports}} {x1} over the year '+\n",
    "        f'ending {ltdate} {c_line(colors[\"Exports\"])}, {ftxt2}. '+\n",
    "        f'In 2019, export prices {x4}.')\n",
    "write_txt(text_dir / 'mxpi.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCE Price Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T12:45:50.234331Z",
     "start_time": "2023-10-27T12:45:50.213171Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of September 2023, \\textbf{PCE inflation}, measured as the one-year percent change in the overall index, is 3.4 percent (see {\\color{orange!80!yellow}\\textbf{---}}), compared to 3.4 percent in August 2023, and 6.6 percent in September 2022. Core PCE inflation, which excludes food and energy, was 3.7 percent in September 2023 (see {\\color{blue!60!black}\\textbf{---}}), 3.8 percent in August 2023, and 5.5 percent in September 2022.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'nipa20804.csv', \n",
    "                 index_col='date', parse_dates=True)\n",
    "df[['DPCERG', 'DPCCRG']].to_csv(data_dir / 'pce_index.csv', \n",
    "                    index_label='date')\n",
    "pce = pd.DataFrame()\n",
    "pce['PCE'] = df['DPCERG'].pct_change(12).dropna() * 100.0\n",
    "node_color = 'orange!80!yellow'\n",
    "node = end_node(pce['PCE'], node_color, date='m', offset=0.3)\n",
    "write_txt(text_dir / 'pce_pi_node.txt', node)\n",
    "\n",
    "pce['CORE'] = df['DPCCRG'].pct_change(12).dropna() * 100.0\n",
    "pce.to_csv(data_dir / 'pce_pi.csv', index_label='date')\n",
    "\n",
    "ltdate = dtxt(pce.index[-1])['mon1']\n",
    "prdate = dtxt(pce.index[-2])['mon1']\n",
    "pryrdate = dtxt(pce.index[-13])['mon1']\n",
    "ltval = pce.PCE.iloc[-1]\n",
    "prval = pce.PCE.iloc[-2]\n",
    "pryrval = pce.PCE.iloc[-13]\n",
    "ltcore = pce.CORE.iloc[-1]\n",
    "prcore = pce.CORE.iloc[-2]\n",
    "pryrcore = pce.CORE.iloc[-13]\n",
    "col2 = 'blue!60!black'\n",
    "text = (f'As of {ltdate}, \\\\textbf{{PCE inflation}}, measured as the one-'+\n",
    "        f'year percent change in the overall index, is {ltval:.1f} '+\n",
    "        f'percent {(c_line(node_color))}, compared to '+\n",
    "        f'{prval:.1f} percent in {prdate}, and {pryrval:.1f} '+\n",
    "        f'percent in {pryrdate}. Core PCE inflation, which excludes '+\n",
    "        f'food and energy, was {ltcore:.1f} percent in {ltdate} '+\n",
    "        f'{c_line(col2)}, {prcore:.1f} percent in '+\n",
    "        f'{prdate}, and {pryrcore:.1f} percent in {pryrdate}.')\n",
    "write_txt(text_dir / 'pce_inf_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trimmed mean PCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:01:34.978654Z",
     "start_time": "2023-10-27T14:01:34.150075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "September 2023\n"
     ]
    }
   ],
   "source": [
    "# Trimmed-mean PCE from Dallas Fed\n",
    "url = 'https://www.dallasfed.org/research/~/media/documents/research/pce/pcehist.xls'\n",
    "tmpce = (pd.read_excel(url, index_col=0, header=3, parse_dates=True)\n",
    "           .loc['1988':].dropna(axis=1))\n",
    "tmpce.to_csv(data_dir / 'pce_tm.csv', index_label='date')\n",
    "print(dtxt(tmpce.index[-1])['mon1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:01:39.519055Z",
     "start_time": "2023-10-27T14:01:39.495142Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trimmed-mean PCE price index increased 3.9 percent over the year ending September 2023 (see {\\color{violet!60!magenta}\\textbf{---}}). By excluding top and bottom categories, the trimmed-mean rate was 0.4 percentage point above the all-items PCE rate. In August 2023, the \\textbf{trimmed-mean inflation rate} was 3.9 percent, 0.5 percentage point above the all-items rate. From 2017--2019, the average trimmed-mean rate was 1.9 percent, 0.1 percentage point above the all-items rate.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir / 'pce_tm.csv', index_col='date', \n",
    "                 parse_dates=True).loc['1989':, '12-month']\n",
    "pce = pd.read_csv(data_dir / 'pce_pi.csv', index_col='date', \n",
    "                  parse_dates=True).loc['1989':, 'PCE']\n",
    "df.to_csv(data_dir / 'pce_tm12.csv', index_label='date')\n",
    "ltdate = dtxt(df.index[-1])['mon1']\n",
    "ltval = df.iloc[-1]\n",
    "prdate = dtxt(df.index[-2])['mon1']\n",
    "prval = df.iloc[-2]\n",
    "ltvaltxt = value_text(ltval, threshold=0.1)\n",
    "diff =  ltval - pce.loc[df.index[-1]]\n",
    "difftxt = value_text(diff, 'above_below', ptype='pp')\n",
    "diff2 =  prval - pce.loc[df.index[-2]]\n",
    "difftxt2  = value_text(diff2, 'above_below', ptype='pp')\n",
    "pcval = df.loc['2017': '2019'].mean()\n",
    "diff3 = pcval - pce.loc['2017': '2019'].mean()\n",
    "difftxt3  = value_text(diff3, 'above_below', ptype='pp')\n",
    "color = 'violet!60!magenta'\n",
    "node = end_node(df, color, date='m', offset=0.35, size=1.4)\n",
    "write_txt(text_dir / 'pce_tm_node.txt', node)\n",
    "text = (f'The trimmed-mean PCE price index {ltvaltxt} over the year '+\n",
    "        f'ending {ltdate} (see {{\\color{{{color}}}\\\\textbf{{---}}}}). '+\n",
    "        'By excluding top and bottom categories, the trimmed-'+\n",
    "        f'mean rate was {difftxt} the all-items PCE rate. In '+\n",
    "        f'{prdate}, the \\\\textbf{{trimmed-mean inflation rate}} was '+\n",
    "        f'{prval:.1f} percent, {difftxt2} the all-items rate. From '+\n",
    "        f'2017--2019, the average trimmed-mean rate was {pcval:.1f} '+\n",
    "        f'percent, {difftxt3} the all-items rate.')\n",
    "write_txt(text_dir / 'pce_tm_basic.txt', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prices Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-27T14:01:42.655141Z",
     "start_time": "2023-10-27T14:01:42.624527Z"
    }
   },
   "outputs": [],
   "source": [
    "pce = pd.read_csv(data_dir / 'pce_index.csv', \n",
    "                  index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "cpi_rn = {'All items': 'CPI', 'All items less food and energy': 'CPI_CORE'}\n",
    "cpi = (pd.read_csv(data_dir / 'cpi_raw.csv', \n",
    "                   index_col='date', parse_dates=True)\n",
    "         .rename(cpi_rn, axis=1)).pct_change(12) * 100\n",
    "ppi = pd.read_csv(data_dir / 'ppi_index.csv', \n",
    "                  index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "mxpi = pd.read_csv(data_dir / 'mxpi_main.csv', \n",
    "                   index_col='date', parse_dates=True).pct_change(12) * 100\n",
    "res = pce.join([cpi, ppi, mxpi], how='outer')\n",
    "keep_cols = ['CPI', 'CPI_CORE', 'PPIFD', 'Imports', \n",
    "             'Exports', 'DPCERG', 'DPCCRG']\n",
    "tm = pd.read_csv(data_dir / 'pce_tm.csv', \n",
    "                 index_col='date', parse_dates=True)['12-month']\n",
    "srs = {'CPI': 'CPI, All Items',\n",
    "       'CPI_CORE': 'CPI, ex. Food \\& Energy',\n",
    "       'PPIFD': 'PPI, Final Demand',\n",
    "       'Imports': 'Imports Price Index',\n",
    "       'Exports': 'Exports Price Index',\n",
    "       'DPCERG': 'PCE, All Items',\n",
    "       'DPCCRG': 'PCE, ex. Food \\& Energy',\n",
    "       '12-month': 'PCE, Trimmed Mean'}\n",
    "res12 = (res[keep_cols].join(tm, how='outer').rename(srs, axis=1))\n",
    "tbl = res12.iloc[[-1, -2, -3, -4, -13, -25]].T\n",
    "tbl.columns = [dtxt(c)['mon6'] for c in tbl.columns]\n",
    "tbl['`17--19 Avg.'] = res12.loc['2017': '2019'].mean()\n",
    "tbl['`00-- Avg.'] = res12.loc['2000':].mean()\n",
    "tbl = tbl.applymap('{:.1f}'.format).replace('nan', '--')\n",
    "tbl.to_csv(data_dir / 'prices_12m.tex', sep='&', lineterminator='\\\\\\ ', \n",
    "           quotechar=' ', float_format='%g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
